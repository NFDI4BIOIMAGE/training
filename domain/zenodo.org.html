
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Zenodo.org (155) &#8212; NFDI4BioImage Training Materials</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'domain/zenodo.org';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Statistics" href="../statistics/readme.html" />
    <link rel="prev" title="Www.youtube.com (20)" href="www.youtube.com.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
    <meta name="docbuild:last-update" content="2024-12-10"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../readme.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="NFDI4BioImage Training Materials - Home"/>
    <img src="../_static/logo.png" class="logo__image only-dark pst-js-only" alt="NFDI4BioImage Training Materials - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../readme.html">
                    NFDI4BioImage Training Materials
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">What's new</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../whats_new.html">Recently added (10)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Contributing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../contributing/index.html">How to contribute</a></li>

<li class="toctree-l1"><a class="reference internal" href="../contributing/submit_app.html">Using the Training Materials Submission App</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing/format.html">YML format</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">By tag</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tags/artificial_intelligence.html">Artificial intelligence (29)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/bioimage_analysis.html">Bioimage analysis (165)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/bioimage_data.html">Bioimage data (20)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/bioinformatics.html">Bioinformatics (8)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/data_stewardship.html">Data stewardship (6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/deep_learning.html">Deep learning (11)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/fair-principles.html">Fair-principles (27)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/image_data_management.html">Image data management (14)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/imagej.html">Imagej (19)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/large_language_models.html">Large language models (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/licensing.html">Licensing (6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/metadata.html">Metadata (14)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/microscopy_image_analysis.html">Microscopy image analysis (14)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/napari.html">Napari (13)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/neubias.html">Neubias (26)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/nfdi4bioimage.html">Nfdi4bioimage (23)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/omero.html">Omero (30)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/open_science.html">Open science (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/open_source_software.html">Open source software (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/python.html">Python (70)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/research_data_management.html">Research data management (109)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/segmentation.html">Segmentation (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/sharing.html">Sharing (11)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/training.html">Training (12)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/workflow.html">Workflow (10)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/workflow_engine.html">Workflow engine (13)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">By content type</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../content_types/blog.html">Blog (19)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/book.html">Book (18)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/code.html">Code (10)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/collection.html">Collection (79)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/data.html">Data (8)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/document.html">Document (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/documentation.html">Documentation (19)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/event.html">Event (8)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/github%20repository.html">Github repository (37)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/notebook.html">Notebook (54)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/online%20tutorial.html">Online tutorial (10)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/poster.html">Poster (10)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/preprint.html">Preprint (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/publication.html">Publication (60)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/slide.html">Slide (41)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/slides.html">Slides (40)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/tutorial.html">Tutorial (40)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/video.html">Video (24)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/website.html">Website (9)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/workshop.html">Workshop (12)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">By license</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../licenses/all_rights_reserved.html">All rights reserved (13)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../licenses/bsd-2-clause.html">Bsd-2-clause (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../licenses/bsd-3-clause.html">Bsd-3-clause (22)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../licenses/cc-by-4.0.html">Cc-by-4.0 (231)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../licenses/cc0-1.0.html">Cc0-1.0 (10)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../licenses/gpl-2.0.html">Gpl-2.0 (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../licenses/mit.html">Mit (24)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../licenses/unknown.html">Unknown (82)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">By domain</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="biapol.github.io.html">Biapol.github.io (6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="docs.google.com.html">Docs.google.com (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="doi.org.html">Doi.org (168)</a></li>
<li class="toctree-l1"><a class="reference internal" href="f1000research.com.html">F1000research.com (11)</a></li>
<li class="toctree-l1"><a class="reference internal" href="focalplane.biologists.com.html">Focalplane.biologists.com (13)</a></li>
<li class="toctree-l1"><a class="reference internal" href="git.mpi-cbg.de.html">Git.mpi-cbg.de (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="github.com.html">Github.com (115)</a></li>
<li class="toctree-l1"><a class="reference internal" href="www.biorxiv.org.html">Www.biorxiv.org (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="www.ebi.ac.uk.html">Www.ebi.ac.uk (10)</a></li>
<li class="toctree-l1"><a class="reference internal" href="www.nature.com.html">Www.nature.com (16)</a></li>
<li class="toctree-l1"><a class="reference internal" href="www.youtube.com.html">Www.youtube.com (20)</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Zenodo.org (155)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../statistics/readme.html">Statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../export/readme.html">Open data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../imprint.html">Imprint</a></li>

</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/NFDI4BIOIMAGE/training" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/NFDI4BIOIMAGE/training/issues/new?title=Issue%20on%20page%20%2Fdomain/zenodo.org.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/domain/zenodo.org.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Zenodo.org (155)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zenodo-und-co-was-bringt-und-wer-braucht-ein-repositorium">“ZENODO und Co.” Was bringt und wer braucht ein Repositorium?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#d-nuclei-annotations-and-stardist-3d-model-s-rat-brain">3D Nuclei annotations and StarDist 3D model(s) (rat brain)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#steps-towards-reproducible-research">6 Steps Towards Reproducible Research</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-glimpse-of-the-open-source-flim-analysis-software-tools-flimfit-flute-and-napari-flim-phasor-plotter">A Glimpse of the Open-Source FLIM Analysis Software Tools FLIMfit, FLUTE and napari-flim-phasor-plotter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-journey-to-fair-microscopy-data">A journey to FAIR microscopy data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abdominal-imaging-window-aiw-for-intravital-imaging">Abdominal Imaging Window (AIW) for Intravital Imaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#alles-meins-oder-urheberrechte-klaren-fur-forschungsdaten">Alles meins – oder!? Urheberrechte klären für Forschungsdaten</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#artificial-blobs-and-labels-image">Artificial Blobs and Labels image</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#axioscan-7-fluorescent-channels-not-displaying-in-qupath">Axioscan 7 fluorescent channels not displaying in QuPath</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-data-strudel-for-workshop-on-research-data-management-in-tu-dresden-core-facilities">Bio-Image Data Strudel for Workshop on Research Data Management in TU Dresden Core Facilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis-code-generation">Bio-image Analysis Code Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis-code-generation-using-bia-bob">Bio-image Analysis Code Generation using bia-bob</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis-with-the-help-of-large-language-models">Bio-image Analysis with the Help of Large Language Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-data-science-lectures-uni-leipzig-scads-ai">Bio-image Data Science Lectures @ Uni Leipzig / ScaDS.AI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-fair-image-analysis-pipelines-for-high-content-screening-hcs-data-using-galaxy">Building FAIR image analysis pipelines for high-content-screening (HCS) data using Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-a-fair-image-data-ecosystem-for-microscopy-communities">Building a FAIR image data ecosystem for microscopy communities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#czi-carl-zeiss-image-dataset-with-artificial-test-camera-images-with-various-dimension-for-testing-libraries-reading">CZI (Carl Zeiss Image) dataset with artificial test camera images with various dimension for testing libraries reading</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#czi-file-examples">CZI file examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#czi-open-science-program-collection">CZI: Open Science Program Collection</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellpose-model-for-digital-phase-contrast-images">Cellpose model for Digital Phase Contrast images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellpose-models-for-label-prediction-from-brightfield-and-digital-phase-contrast-images">Cellpose models for Label Prediction from Brightfield and Digital Phase Contrast images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chatgpt-for-image-analysis">ChatGPT for Image Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#combining-the-bids-and-arc-directory-structures-for-multimodal-research-data-organization">Combining the BIDS and ARC Directory Structures for Multimodal Research Data Organization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conference-slides-4th-day-of-intravital-microscopy">Conference Slides - 4th Day of Intravital Microscopy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#crashkurs-forschungsdatenmanagement">Crashkurs Forschungsdatenmanagement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-open-computational-curricula">Creating open computational curricula</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cultivating-open-training">Cultivating Open Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cultivating-open-training-to-advance-bio-image-analysis">Cultivating Open Training to advance Bio-image Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dalia-interchange-format">DALIA Interchange Format</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-stewardship-and-research-data-management-tools-for-multimodal-linking-of-imaging-data-in-plasma-medicine">Data stewardship and research data management tools for multimodal linking of imaging data in plasma medicine</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datenmanagement">Datenmanagement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datenmanagement-im-fokus-organisation-speicherstrategien-und-datenschutz">Datenmanagement im Fokus: Organisation, Speicherstrategien und Datenschutz</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datenmanagementplane-erstellen-teil-1">Datenmanagementpläne erstellen - Teil 1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datenmanagementplane-erstellen-teil-2">Datenmanagementpläne erstellen - Teil 2</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deconvolution-test-dataset">Deconvolution Test Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#development-of-a-platform-for-advanced-optics-education-training-and-prototyping">Development of a platform for advanced optics education, training and prototyping</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#digital-phase-contrast-on-primary-dermal-human-fibroblasts-cells">Digital Phase Contrast on Primary Dermal Human Fibroblasts cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#efficiently-starting-institutional-research-data-management">Efficiently starting institutional research data management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#einblicke-ins-forschungsdatenmanagement-darf-ich-das-veroffentlichen-rechtsfragen-im-umgang-mit-forschungsdaten">Einblicke ins Forschungsdatenmanagement - Darf ich das veröffentlichen? Rechtsfragen im Umgang mit Forschungsdaten</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#engineering-a-software-environment-for-research-data-management-of-microscopy-image-data-in-a-core-facility">Engineering a Software Environment for Research Data Management of Microscopy Image Data in a Core Facility</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-scientific-ambassadors-program">Euro-BioImaging  Scientific Ambassadors Program</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-eric-annual-report-2022">Euro-BioImaging ERIC Annual Report 2022</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-s-guide-to-fair-bioimage-data-practical-tasks">Euro-BioImaging’s Guide to FAIR BioImage Data - Practical Tasks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-s-template-for-research-data-management-plans">Euro-BioImaging’s Template for Research Data Management Plans</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-batchconvert-v0-0-4">Euro-BioImaging/BatchConvert: v0.0.4</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evident-oir-sample-files-tiles-stitched-image-fv-4000">Evident OIR sample files tiles + stitched image - FV 4000</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evident-oir-sample-files-with-lambda-scan-fv-4000">Evident OIR sample files with lambda scan - FV 4000</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-imaris-ims-datasets">Example Imaris ims datasets.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-microscopy-metadata-json-files-produced-using-micro-meta-app-to-document-example-microscopy-experiments-performed-at-individual-core-facilities">Example Microscopy Metadata JSON files produced using Micro-Meta App to document example microscopy experiments performed at individual core facilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-operetta-dataset">Example Operetta Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#excel-template-for-adding-key-value-pairs-to-images">Excel template for adding Key-Value Pairs to images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forschungsdatenmanagement-zukunftsfest-gestalten-impulse-fur-die-strukturevaluation-der-nationalen-forschungsdateninfrastruktur-nfdi">Forschungsdatenmanagement zukunftsfest gestalten – Impulse für die   Strukturevaluation der Nationalen Forschungsdateninfrastruktur (NFDI)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-cells-to-pixels-bridging-biologists-and-image-analysts-through-a-common-language">From Cells to Pixels: Bridging Biologists and  Image Analysts Through a Common Language</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-paper-to-pixels-navigation-through-your-research-data-presentations-of-speakers">From Paper to Pixels: Navigation through your Research Data - presentations of speakers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gerbi-chat-teil-1-vom-bedarf-bis-zum-groszgerateantrag-schreiben">GerBI-Chat: Teil 1 - Vom Bedarf bis zum Großgeräteantrag-Schreiben</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gerbi-chat-teil-2-wie-schreibe-ich-am-besten-einen-groszegrateantrag">GerBI-Chat: Teil 2 - Wie schreibe ich am besten einen Großegräteantrag</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-started-with-python-intro-and-set-up-a-conda-environment">Getting started with Python: intro and set-up a conda environment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gut-analysis-toolbox">Gut Analysis Toolbox</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gut-analysis-toolbox-training-data-and-2d-models-for-segmenting-enteric-neurons-neuronal-subtypes-and-ganglia">Gut Analysis Toolbox: Training data and 2D models for segmenting enteric neurons, neuronal subtypes and ganglia</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hackaton-results-conversion-of-knime-image-analysis-workflows-to-galaxy">Hackaton Results - Conversion of KNIME image analysis workflows to Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hela-kyoto-cells-under-the-scope">HeLa “Kyoto” cells under the scope</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#high-throughput-automated-data-analysis-and-data-management-workflow-with-cellprofiler-and-omero">High throughput &amp; automated data analysis and data management workflow with Cellprofiler and OMERO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#human-dab-staining-axioscan-bf-20x">Human DAB staining Axioscan BF 20x</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#i3d-bio-s-omero-training-material-re-usable-adjustable-multi-purpose-slides-for-local-user-training">I3D:bio’s OMERO training material: Re-usable, adjustable, multi-purpose slides for local user training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ics-ids-stitched-file">ICS/IDS stitched file</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-repository-decision-tree-where-do-i-deposit-my-imaging-data">Image Repository Decision Tree - Where do I deposit my imaging data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imagej-tool-for-percentage-estimation-of-pneumonia-in-lungs">ImageJ tool for percentage estimation of pneumonia in lungs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-kidney">Implantation of abdominal imaging windows on the mouse kidney</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-kidney-short-version">Implantation of abdominal imaging windows on the mouse kidney - short version</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-liver">Implantation of abdominal imaging windows on the mouse liver</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-liver-short-version">Implantation of abdominal imaging windows on the mouse liver - short version</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ink-in-a-dish">Ink in a dish</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#insights-and-impact-from-five-cycles-of-essential-open-source-software-for-science">Insights and Impact From Five Cycles of Essential Open Source Software for Science</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#insights-from-acquiring-open-medical-imaging-datasets-for-foundation-model-development">Insights from Acquiring Open Medical Imaging  Datasets for Foundation Model Development</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Insights from Acquiring Open Medical Imaging Datasets for Foundation Model Development</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#institutionalization-and-collaboration-as-a-way-of-addressing-the-challenges-open-science-presents-to-libraries-the-university-of-konstanz-as-a-national-pioneer">Institutionalization and Collaboration as a Way of Addressing the Challenges Open Science Presents to Libraries: The University of Konstanz as a National Pioneer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interactive-image-data-flow-graphs">Interactive Image Data Flow Graphs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#intravital-microscopy-contrasting-agents-for-application-database">Intravital microscopy contrasting agents for application - Database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-light-microscopy-widefield-microscopy">Introduction to light-microscopy / Widefield microscopy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pair-template-for-annotation-in-omero-for-light-microscopy-data-acquired-with-axioscan7-core-facility-cellular-imaging-cfci">Key-Value pair template for annotation in OMERO for light microscopy data acquired with AxioScan7 - Core Facility Cellular Imaging (CFCI)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pair-template-for-annotation-of-datasets-in-omero-perikles-study">Key-Value pair template for annotation of datasets in OMERO (PERIKLES study)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pair-template-for-annotation-of-datasets-in-omero-for-light-and-electron-microscopy-data-within-the-research-group-of-prof-muller-reichert">Key-Value pair template for annotation of datasets in OMERO for light- and electron microscopy data within the research group of Prof. Müller-Reichert</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kollaboratives-arbeiten-und-versionskontrolle-mit-git">Kollaboratives Arbeiten und Versionskontrolle mit Git</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#leo-linking-eln-with-omero">LEO: Linking ELN with OMERO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lz4-compressed-imaris-ims-example-datasets">LZ4-compressed Imaris ims example datasets.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#large-language-models-an-introduction-for-life-scientists">Large Language Models: An Introduction for Life Scientists</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#large-tiling-confocal-acquisition-rat-brain">Large tiling confocal acquisition (rat brain)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laulauthom-maskfromrois-fiji-masks-from-rois-plugins-for-fiji-initial-release">LauLauThom/MaskFromRois-Fiji: Masks from ROIs plugins for Fiji - initial release</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#leitfaden-zur-digitalen-datensparsamkeit-mit-praxisbeispielen">Leitfaden zur digitalen Datensparsamkeit (mit Praxisbeispielen)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limeseg-test-datasets">LimeSeg Test Datasets</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linked-open-data-for-microbial-population-biology">Linked (Open) Data for Microbial Population Biology</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#liver-micrometastases-area-quantification-using-qupath-and-pixel-classifier">Liver Micrometastases area quantification using QuPath and pixel classifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#measuring-reporter-activity-domain-in-epi-aggregates-and-gastruloids-ijm">Measuring reporter activity domain in EPI aggregates and Gastruloids.ijm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metadata-annotation-workflow-for-omero-with-tabbles">Metadata Annotation Workflow for OMERO with Tabbles</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microsam-talks">MicroSam-Talks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#morphological-analysis-of-neural-cells-with-weka-and-snt-fiji-plugins">Morphological analysis of neural cells with WEKA and SNT Fiji plugins</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-template-matching-for-object-detection-slides">Multi-Template-Matching for object-detection (slides)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiplexed-histology-of-covid-19-post-mortem-lung-samples-control-case-1-fov1">Multiplexed histology of COVID-19 post-mortem lung samples - CONTROL CASE 1 FOV1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#my-journey-through-bioimage-analysis-teaching-methods-from-classroom-to-cloud">My Journey Through Bioimage Analysis Teaching Methods From Classroom to Cloud</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage">NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis-conference-talk-the-pelagic-imaging-consortium-meets-helmholtz-imaging-5-10-2023-hamburg">NFDI4BIOIMAGE - National Research Data Infrastructure for Microscopy and BioImage Analysis [conference talk: The Pelagic Imaging Consortium meets Helmholtz Imaging, 5.10.2023, Hamburg]</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis">NFDI4BIOIMAGE - National Research Data Infrastructure for Microscopy and Bioimage Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon-2023-github-repository">NFDI4Bioimage - TA3-Hackathon - UoC-2023 (Cologne-Hackathon-2023, GitHub repository)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-2024-october-original-image">NFDI4Bioimage Calendar 2024 October; original image</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#new-kid-on-the-nfdi-block-nfdi4bioimage-a-national-initiative-for-fair-data-management-in-bioimaging-and-bioimage-analysis">New Kid on the (NFDI) Block: NFDI4BIOIMAGE  - A National Initiative for FAIR Data Management in Bioimaging and Bioimage Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nextflow-scalable-and-reproducible-scientific-workflows">Nextflow: Scalable and reproducible scientific workflows</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome2024-ngff-challenge-results">OME2024 NGFF Challenge Results</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-science-sharing-licensing">Open Science, Sharing &amp; Licensing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimisation-and-validation-of-a-swarm-intelligence-based-segmentation-algorithm-for-low-contrast-positron-emission-tomography">Optimisation and Validation of a Swarm Intelligence based Segmentation Algorithm for low Contrast Positron Emission Tomography</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprint-be-sustainable-recommendations-for-fair-resources-in-life-sciences-research-eosc-life-s-lessons">Preprint: “Be Sustainable”, Recommendations for FAIR Resources in Life Sciences research: EOSC-Life’s Lessons</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qupath-open-source-software-for-analysing-awkward-images">QuPath: Open source software for analysing (awkward) images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdf-as-a-bridge-to-domain-platforms-like-omero-or-there-and-back-again">RDF as a bridge to domain-platforms like OMERO, or There and back again.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-management-on-campus-and-in-nfdi4bioimage">RESEARCH DATA MANAGEMENT on Campus and in NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#report-on-a-pilot-study-implementation-of-omero-for-microscopy-data-management">Report on a pilot study:  Implementation of OMERO for  microscopy data management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-management-seminar-slides">Research Data Management Seminar - Slides</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-managemet-and-how-not-to-get-overwhelmed-with-data">Research Data Managemet and how not to get overwhelmed with data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#round-table-workshop-1-sample-stabilization-in-intravital-imaging">Round Table Workshop 1 - Sample Stabilization in intravital Imaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#round-table-workshop-2-correction-of-drift-and-movement">Round Table Workshop 2 - Correction of Drift and Movement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sciaugment">SciAugment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#slides-about-flute-a-python-gui-for-interactive-phasor-analysis-of-flim-data">Slides about FLUTE: a Python GUI for interactive phasor analysis of FLIM data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#so-geschlossen-wie-notig-so-offen-wie-moglich-datenschutz-beim-umgang-mit-forschungsdaten">So geschlossen wie nötig, so offen wie möglich - Datenschutz beim Umgang mit Forschungsdaten</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stackview-sliceplot-example-data">Stackview sliceplot example data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#structuring-of-data-and-metadata-in-bioimaging-concepts-and-technical-solutions-in-the-context-of-linked-data">Structuring of Data and Metadata in Bioimaging: Concepts and technical Solutions in the Context of Linked Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sustainable-data-stewardship">Sustainable Data Stewardship</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-dataset-for-whole-slide-image-registration">Test Dataset for Whole Slide Image Registration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-information-infrastructure-for-bioimage-data-i3d-bio-project-to-advance-fair-microscopy-data-management-for-the-community">The Information Infrastructure for BioImage Data (I3D:bio) project to advance FAIR microscopy data management for the community</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-role-of-helmholtz-centers-in-nfdi4bioimage-a-national-consortium-enhancing-fair-data-management-for-microscopy-and-bioimage-analysis">The role of Helmholtz Centers in NFDI4BIOIMAGE - A national consortium enhancing FAIR data management for microscopy and bioimage analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#thinking-data-management-on-different-scales">Thinking data management on different scales</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#towards-preservation-of-life-science-data-with-nfdi4bioimage">Towards Preservation of Life Science Data with NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#towards-transparency-and-knowledge-exchange-in-ai-assisted-data-analysis-code-generation">Towards Transparency and Knowledge Exchange in AI-assisted Data Analysis Code Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-the-trainer-concept-on-research-data-management">Train-the-Trainer Concept on Research Data Management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#welcome-to-bioimage-town">Welcome to BioImage Town</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#who-you-gonna-call-data-stewards-to-the-rescue">Who you gonna call? - Data Stewards to the rescue</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter">Zeiss AxioZoom Stage Adapter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter-12-6well-plate">Zeiss AxioZoom Stage Adapter - 12/6Well Plate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter-em-block-holder">Zeiss AxioZoom Stage Adapter - EM block holder</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter-microscope-slides">Zeiss AxioZoom Stage Adapter - Microscope slides</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bina-cc-scalable-strategies-for-a-next-generation-of-fair-bioimaging">[BINA CC] Scalable strategies for a next-generation of FAIR bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cordi-2023-zarr-a-cloud-optimized-storage-for-interactive-access-of-large-arrays">[CORDI 2023] Zarr: A Cloud-Optimized Storage for Interactive Access of Large Arrays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#community-meeting-2024-overview-team-image-data-analysis-and-management">[Community Meeting 2024] Overview Team Image Data Analysis and Management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#community-meeting-2024-supporting-and-financing-rdm-projects-within-gerbi">[Community Meeting 2024] Supporting and financing RDM projects within GerBI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#elmi-2024-ai-s-dirty-little-secret-without">[ELMI 2024]  AI’s Dirty Little Secret: Without</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#elmi-2024-ai-s-dirty-little-secret-without-fair-data-it-s-just-fancy-math">[ELMI 2024] AI’s Dirty Little Secret: Without FAIR Data, It’s Just Fancy Math</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gbi-eoe-vii-five-or-ten-must-have-items-for-making-it-infrastructure-for-managing-bioimage-data">[GBI EOE VII] Five (or ten) must-have items for making IT infrastructure for managing bioimage data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gbi-eoe-ix-nfdi4bioimage">[GBI EoE IX] NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#i2k-scalable-strategies-for-a-next-generation-of-fair-bioimaging">[I2K] Scalable strategies for a next-generation of FAIR bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#n4bi-ahm-welcome-to-bioimage-town">[N4BI AHM] Welcome to BioImage Town</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#swat4hcls-2023-nfdi4bioimage-perspective-for-a-national-bioimage-standard">[SWAT4HCLS 2023] NFDI4BIOIMAGE: Perspective for a national bioimage standard</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#short-talk-nfdi4bioimage-a-consortium-in-the-national-research-data-infrastructure">[Short Talk] NFDI4BIOIMAGE - A consortium in the National Research Data Infrastructure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workshop-material-fit-for-omero-how-imaging-facilities-and-it-departments-work-together-to-enable-rdm-for-bioimaging-october-16-17-2024-heidelberg">[Workshop Material] Fit for OMERO - How imaging facilities and IT departments work together to enable RDM for bioimaging, October 16-17, 2024, Heidelberg</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workshop-bioimage-data-management-and-analysis-with-omero">[Workshop] Bioimage data management and analysis with OMERO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workshop-fair-data-handling-for-microscopy-structured-metadata-annotation-in-omero">[Workshop] FAIR data handling for microscopy: Structured metadata annotation in OMERO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ilastik-interactive-machine-learning-for-bio-image-analysis">ilastik: interactive machine learning for (bio)image analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#martinschatz-cz-scicount-v1-0-0-with-reusable-example-notebooks">martinschatz-cz/SciCount: v1.0.0 with reusable example notebooks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quantixed-thedigitalcell-first-complete-code-set">quantixed/TheDigitalCell: First complete code set</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="zenodo-org-155">
<h1><a class="reference external" href="http://Zenodo.org">Zenodo.org</a> (155)<a class="headerlink" href="#zenodo-org-155" title="Link to this heading">#</a></h1>
<section id="zenodo-und-co-was-bringt-und-wer-braucht-ein-repositorium">
<h2>“ZENODO und Co.” Was bringt und wer braucht ein Repositorium?<a class="headerlink" href="#zenodo-und-co-was-bringt-und-wer-braucht-ein-repositorium" title="Link to this heading">#</a></h2>
<p>Elfi Hesse, Jan-Christoph Deinert, Christian Löschen</p>
<p>Published 2021-01-25</p>
<p>Licensed CC-BY-4.0</p>
<p>Die Online-Veranstaltung fand am 21.01.2021 im Rahmen der SaxFDM-Veranstaltungsreihe “Digital Kitchen - Küchengespräche mit SaxFDM” statt. SaxFDM-Sprecherin Elfi Hesse (HTW Dresden) erläuterte zunächst Grundsätzliches zum Thema Repositorien. Anschließend teilten Nutzer (Jan Deinert – HZDR) und Anbieter (Christian Löschen – TU Dresden/ZIH) lokaler Repositorien ihre Erfahrungen mit uns.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/4461261">https://zenodo.org/records/4461261</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4461261">https://doi.org/10.5281/zenodo.4461261</a></p>
</section>
<hr class="docutils" />
<section id="d-nuclei-annotations-and-stardist-3d-model-s-rat-brain">
<h2>3D Nuclei annotations and StarDist 3D model(s) (rat brain)<a class="headerlink" href="#d-nuclei-annotations-and-stardist-3d-model-s-rat-brain" title="Link to this heading">#</a></h2>
<p>Romain Guiet</p>
<p>Published 2022-06-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: 3D Nuclei annotations and StarDist3D model(s) (rat brain)</p>
<p>Images:  From a large tiling acquisition ( <a class="reference external" href="https://doi.org/10.5281/zenodo.6646128">https://doi.org/10.5281/zenodo.6646128</a> ) individual Tile (xyz : 1024x1024x62) were downsampled and cropped (128x128x62). Four crops, from different tiles (./annotations_BIOP/images/) were manually annotated with ITK-SNAP (./annotations_BIOP/masks/)</p>
<p>These four images, and their corresponding masks, were cropped into four quadrants (./crops_BIOP_v1/) in order to get 16 different images (64x64x62).</p>
<p>Conda environment: A conda environment was created using the yml file  stardist0.8_TF1.15.yml</p>
<p>Training : Training was performed using the jupyter notebook 1-Training_notebook.ipynb.
Three different trainings (with the same random seed, same anisotropy, patch size and grid) were performed and produced three different models (./models/)</p>
<p>Validation images (from the random seed used) were exported to ease the visual inspection of the results(./val_rdm42/).</p>
<p>Validation:  To save metrics in a csv file and compare predictions to the annotations the jupyter notebook 2-QC_notebook.ipynb can be used on the validation folder.</p>
<p>Large images: To test the model on larger images one can use Whole_ds441.tif (or Crop_ds441.tif )
These images were obtained using the plugin BigSticher on the raw data ( <a class="reference external" href="https://doi.org/10.5281/zenodo.6646128">https://doi.org/10.5281/zenodo.6646128</a> ), resaved as h5 and exported the downsample by 4 version.</p>
<p> </p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/6645978">https://zenodo.org/records/6645978</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6645978">https://doi.org/10.5281/zenodo.6645978</a></p>
</section>
<hr class="docutils" />
<section id="steps-towards-reproducible-research">
<h2>6 Steps Towards Reproducible Research<a class="headerlink" href="#steps-towards-reproducible-research" title="Link to this heading">#</a></h2>
<p>Heidi Seibold</p>
<p>Licensed CC-BY-4.0</p>
<p>A short book with 6 steps that get you closer to making your work reproducible.</p>
<p>Tags: Reproducibility, Research Data Management</p>
<p>Content type: Book</p>
<p><a class="reference external" href="https://zenodo.org/records/12744715">https://zenodo.org/records/12744715</a></p>
</section>
<hr class="docutils" />
<section id="a-glimpse-of-the-open-source-flim-analysis-software-tools-flimfit-flute-and-napari-flim-phasor-plotter">
<h2>A Glimpse of the Open-Source FLIM Analysis Software Tools FLIMfit, FLUTE and napari-flim-phasor-plotter<a class="headerlink" href="#a-glimpse-of-the-open-source-flim-analysis-software-tools-flimfit-flute-and-napari-flim-phasor-plotter" title="Link to this heading">#</a></h2>
<p>Anca Margineanu, Chiara Stringari, Marcelo Zoccoler, Cornelia Wetzker</p>
<p>Published 2024-03-27</p>
<p>Licensed CC-BY-4.0</p>
<p>The presentations introduce open-source software to read in, visualize and analyse fluorescence lifetime imaging microscopy (FLIM) raw data developed for life scientists. The slides were presented at German Bioimaging (GerBI) FLIM Workshop held February 26 to 29 2024 at the Biomedical Center of LMU München by Anca Margineanu, Chiara Stringari and Conni Wetzker. </p>
<p><a class="reference external" href="https://zenodo.org/records/10886750">https://zenodo.org/records/10886750</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10886750">https://doi.org/10.5281/zenodo.10886750</a></p>
</section>
<hr class="docutils" />
<section id="a-journey-to-fair-microscopy-data">
<h2>A journey to FAIR microscopy data<a class="headerlink" href="#a-journey-to-fair-microscopy-data" title="Link to this heading">#</a></h2>
<p>Stefanie Weidtkamp-Peters, Janina Hanne, Christian Schmidt</p>
<p>Published 2023-05-03</p>
<p>Licensed CC-BY-4.0</p>
<p>Oral presentation, 32nd MoMAN “From Molecules to Man” Seminar, Ulm, online. Monday February 6th, 2023</p>
<p>Abstract:</p>
<p>Research data management is essential in nowadays research, and one of the big opportunities to accelerate collaborative and innovative scientific projects. To achieve this goal, all our data needs to be FAIR (findable, accessible, interoperable, reproducible). For data acquired on microscopes, however, a common ground for FAIR data sharing is still to be established. Plenty of work on file formats, data bases, and training needs to be performed to highlight the value of data sharing and exploit its potential for bioimaging data.</p>
<p>In this presentation, Stefanie Weidtkamp-Peters will introduce the challenges for bioimaging data management, and the necessary steps to achieve data FAIRification. German BioImaging - GMB e.V., together with other institutions, contributes to this endeavor. Janina Hanne will present how the network of imaging core facilities, research groups and industry partners is key to the German bioimaging community’s aligned collaboration toward FAIR bioimaging data. These activities have paved the way for two data management initiatives in Germany: I3D:bio (Information Infrastructure for BioImage Data) and NFDI4BIOIMAGE, a consortium of the National Research Data Infrastructure. Christian Schmidt will introduce the goals and measures of these initiatives to the benefit of imaging scientist’s work and everyday practice.  </p>
<p><a class="reference external" href="https://zenodo.org/records/7890311">https://zenodo.org/records/7890311</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7890311">https://doi.org/10.5281/zenodo.7890311</a></p>
</section>
<hr class="docutils" />
<section id="abdominal-imaging-window-aiw-for-intravital-imaging">
<h2>Abdominal Imaging Window (AIW) for Intravital Imaging<a class="headerlink" href="#abdominal-imaging-window-aiw-for-intravital-imaging" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-11-15</p>
<p>Licensed CC-BY-4.0</p>
<p>This upload features a simple model for the creation (Manufacturing/Prototyping) of an abdominal imaging window (AIW) for use in mice intravital microscopy.
Manufacture in titanium for chronic implantation. Measures in mm.</p>
<p><a class="reference external" href="https://zenodo.org/records/14168603">https://zenodo.org/records/14168603</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14168603">https://doi.org/10.5281/zenodo.14168603</a></p>
</section>
<hr class="docutils" />
<section id="alles-meins-oder-urheberrechte-klaren-fur-forschungsdaten">
<h2>Alles meins – oder!? Urheberrechte klären für Forschungsdaten<a class="headerlink" href="#alles-meins-oder-urheberrechte-klaren-fur-forschungsdaten" title="Link to this heading">#</a></h2>
<p>Stephan Wünsche</p>
<p>Published 2024-06-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Wem gehören Forschungsdaten? Diese Frage stellt sich bei Daten, an deren Entstehung mehrere Personen beteiligt waren, und besonders bei Textdaten, Bildern und Videos. Hier lernen Sie, für Ihr eigenes Forschungsvorhaben zu erkennen, wessen Urheber- und Leistungsschutzrechte zu berücksichtigen sind. Sie erfahren, wie Sie mit Hilfe von Vereinbarungen frühzeitig Rechtssicherheit herstellen, etwa um Daten weitergeben oder publizieren zu können.
 
 </p>
<p>Tags: Research Data Management, Licensing</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/11472148">https://zenodo.org/records/11472148</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11472148">https://doi.org/10.5281/zenodo.11472148</a></p>
</section>
<hr class="docutils" />
<section id="artificial-blobs-and-labels-image">
<h2>Artificial Blobs and Labels image<a class="headerlink" href="#artificial-blobs-and-labels-image" title="Link to this heading">#</a></h2>
<p>Romain</p>
<p>Published 2023-05-10</p>
<p>Licensed CC-BY-4.0</p>
<p>A groovy script to use in Fiji to generate artificial images and labels, with example images.</p>
<p><a class="reference external" href="https://zenodo.org/records/7919117">https://zenodo.org/records/7919117</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7919117">https://doi.org/10.5281/zenodo.7919117</a></p>
</section>
<hr class="docutils" />
<section id="axioscan-7-fluorescent-channels-not-displaying-in-qupath">
<h2>Axioscan 7 fluorescent channels not displaying in QuPath<a class="headerlink" href="#axioscan-7-fluorescent-channels-not-displaying-in-qupath" title="Link to this heading">#</a></h2>
<p>j</p>
<p>Published 2024-06-25</p>
<p>Hi &#64;ome team,Please find the .czi file attached. When loaded into QuPath using BioFormats, the fluorescence channels populate the brightness/contrast panel but do not show up in the viewer. Re-exporting as OME.Tiff from Zen and loading into QuPath does not help either - the channels do not populate the brightness/contrast panel in this case, and it shows as a RGB image.Please let me know if any further info is needed from me to troubleshoot!
Best,J</p>
<p><a class="reference external" href="https://zenodo.org/records/12533989">https://zenodo.org/records/12533989</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12533989">https://doi.org/10.5281/zenodo.12533989</a></p>
</section>
<hr class="docutils" />
<section id="bio-image-data-strudel-for-workshop-on-research-data-management-in-tu-dresden-core-facilities">
<h2>Bio-Image Data Strudel for Workshop on Research Data Management in TU Dresden Core Facilities<a class="headerlink" href="#bio-image-data-strudel-for-workshop-on-research-data-management-in-tu-dresden-core-facilities" title="Link to this heading">#</a></h2>
<p>Cornelia Wetzker</p>
<p>Published 2023-11-08</p>
<p>Licensed CC-BY-4.0</p>
<p>This presentation gives a short outline of the complexity of data and metadata in the bioimaging universe. It introduces NFDI4BIOIMAGE as a newly formed consortium as part of the German ‘Nationale Forschungsdateninfrastruktur’ (NFDI) and its goals and tools for data management including its current members on TU Dresden campus.  </p>
<p>Tags: Research Data Management, Tu Dresden, Bioimage Data, Nfdi4Bioimage</p>
<p>Content type: Slide</p>
<p><a class="reference external" href="https://zenodo.org/records/10083555">https://zenodo.org/records/10083555</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10083555">https://doi.org/10.5281/zenodo.10083555</a></p>
</section>
<hr class="docutils" />
<section id="bio-image-analysis-code-generation">
<h2>Bio-image Analysis Code Generation<a class="headerlink" href="#bio-image-analysis-code-generation" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-10-28</p>
<p>Licensed CC-BY-4.0</p>
<p>Large Language Models are changing the way we interact with computers, especially how we write code. In this tutorial, we will generate bio-image analysis code using two LLM-based code generators, bia-bob and git-bob.
<a class="github reference external" href="https://github.com/haesleinhuepf/bia-bob">haesleinhuepf/bia-bob</a>
<a class="github reference external" href="https://github.com/haesleinhuepf/git-bob">haesleinhuepf/git-bob</a>
 </p>
<p><a class="reference external" href="https://zenodo.org/records/14001044">https://zenodo.org/records/14001044</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14001044">https://doi.org/10.5281/zenodo.14001044</a></p>
</section>
<hr class="docutils" />
<section id="bio-image-analysis-code-generation-using-bia-bob">
<h2>Bio-image Analysis Code Generation using bia-bob<a class="headerlink" href="#bio-image-analysis-code-generation-using-bia-bob" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-10-09</p>
<p>Licensed CC-BY-4.0</p>
<p>In this presentation I introduce bia-bob, an AI-based code generator that integrates into Jupyter Lab and allows for easy generation of Bio-Image Analysis Python code. It highlights how to get started with using large language models and prompt engineering to get high-quality bio-image analysis code.</p>
<p><a class="reference external" href="https://zenodo.org/records/13908108">https://zenodo.org/records/13908108</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13908108">https://doi.org/10.5281/zenodo.13908108</a></p>
</section>
<hr class="docutils" />
<section id="bio-image-analysis-with-the-help-of-large-language-models">
<h2>Bio-image Analysis with the Help of Large Language Models<a class="headerlink" href="#bio-image-analysis-with-the-help-of-large-language-models" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-03-13</p>
<p>Licensed CC-BY-4.0</p>
<p>Large Language Models (LLMs) change the way how we use computers. This also has impact on the bio-image analysis community. We can generate code that analyzes biomedical image data if we ask the right prompts. This talk outlines introduces basic principles, explains prompt engineering and how to apply it to bio-image analysis. We also compare how different LLM vendors perform on code generation tasks and which challenges are ahead for the bio-image analysis community.</p>
<p>Tags: Large Language Models, Python</p>
<p>Content type: Slide</p>
<p><a class="reference external" href="https://zenodo.org/records/10815329">https://zenodo.org/records/10815329</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10815329">https://doi.org/10.5281/zenodo.10815329</a></p>
</section>
<hr class="docutils" />
<section id="bio-image-data-science-lectures-uni-leipzig-scads-ai">
<h2>Bio-image Data Science Lectures &#64; Uni Leipzig / <a class="reference external" href="http://ScaDS.AI">ScaDS.AI</a><a class="headerlink" href="#bio-image-data-science-lectures-uni-leipzig-scads-ai" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Licensed CC-BY-4.0</p>
<p>These are the PPTx training resources for Students at Uni Leipzig who want to dive into bio-image data science with Python. The material developed here between April and July 2024.</p>
<p>Tags: Bioimage Analysis, Deep Learning, Microscopy Image Analysis, Python</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/12623730">https://zenodo.org/records/12623730</a></p>
</section>
<hr class="docutils" />
<section id="building-fair-image-analysis-pipelines-for-high-content-screening-hcs-data-using-galaxy">
<h2>Building FAIR image analysis pipelines for high-content-screening (HCS) data using Galaxy<a class="headerlink" href="#building-fair-image-analysis-pipelines-for-high-content-screening-hcs-data-using-galaxy" title="Link to this heading">#</a></h2>
<p>Riccardo Massei, Matthias Berndt, Beatriz Serrano-Solano, Wibke Busch, Stefan Scholz, Hannes Bohring, Jo Nyffeler, Luise Reger, Jan Bumberger, Lucille Lopez-Delisle</p>
<p>Published 2024-11-06</p>
<p>Licensed CC-BY-4.0</p>
<p>Imaging is crucial across various scientific disciplines, particularly in life sciences, where it plays a key role in studies ranging from single molecules to whole organisms. However, the complexity and sheer volume of image data, especially from high-content screening (HCS) experiments involving cell lines or other organisms, present significant challenges. Managing and analysing this data efficiently requires well-defined image processing tools and analysis pipelines that align with the FAIR principles—ensuring they are findable, accessible, interoperable, and reusable across different domains.
In the frame of NFDI4BioImaging (the National Research Data Infrastructure focusing on bioimaging in Germany), we want to find viable solutions for storing, processing, analysing, and sharing HCS data. In particular, we want to develop solutions to make findable and machine-readable metadata using (semi)automatic analysis pipelines. In scientific research, such pipelines are crucial for maintaining data integrity, supporting reproducibility, and enabling interdisciplinary collaboration. These tools can be used by different users to retrieve images based on specific attributes as well as support quality control by identifying appropriate metadata.
Galaxy, an open-source, web-based platform for data-intensive research, offers a solution by enabling the construction of reproducible pipelines for image analysis. By integrating popular analysis software like CellProfiler and connecting with cloud services such as OMERO and IDR, Galaxy facilitates the seamless access and management of image data. This capability is particularly valuable in bioimaging, where automated pipelines can streamline the handling of complex metadata, ensuring data integrity and fostering interdisciplinary collaboration. This approach not only increases the efficiency of HCS bioimaging but also contributes to the broader scientific community’s efforts to embrace FAIR principles, ultimately advancing scientific discovery and innovation.
In the present study, we proposed an automated analysis pipeline for storing, processing, analysing, and sharing HCS bioimaging data. The (semi)automatic workflow was developed by taking as a case study a dataset of zebrafish larvae and cell lines images previously obtained from an automated imaging system generating data in an HCS fashion. In our workflows, images are automatically enriched with metadata (i.e. key-value pairs, tags, raw data, regions of interest) and uploaded to the UFZ-OME Remote Objects (OMERO) server using a novel OMERO tool suite developed with GALAXY. Workflows give the possibility to the user to intuitively fetch images from the local server and perform image analysis (i.e. annotation) or even more complex toxicological analyses (dose response modelling). Furthermore, we want to improve the FAIRness of the protocol by adding a direct upload link to the Image Data Resource (IDR) repository to automatically prepare the data for publication and sharing.</p>
<p><a class="reference external" href="https://zenodo.org/records/14044640">https://zenodo.org/records/14044640</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14044640">https://doi.org/10.5281/zenodo.14044640</a></p>
<p><a class="reference external" href="https://galaxyproject.org/news/2024-11-08-galaxy-imaging-fair-pipelines/">https://galaxyproject.org/news/2024-11-08-galaxy-imaging-fair-pipelines/</a></p>
</section>
<hr class="docutils" />
<section id="building-a-fair-image-data-ecosystem-for-microscopy-communities">
<h2>Building a FAIR image data ecosystem for microscopy communities<a class="headerlink" href="#building-a-fair-image-data-ecosystem-for-microscopy-communities" title="Link to this heading">#</a></h2>
<p>Isabel Kemmer, Antje Keppler, Beatriz Serrano-Solano, Arina Rybina, Bugra Özdemir, Johanna Bischof, El Ghadraoui, Ayoub, Eriksson, John E., Aastha Mathur</p>
<p>Published 2023-03-31</p>
<p>Licensed CC-BY-4.0</p>
<p>Bioimaging has now entered the era of big data with faster than ever development of complex microscopy technologies leading to increasingly complex datasets. This enormous increase in data size and informational complexity within those datasets has brought with it several difficulties in terms of common and harmonized data handling, analysis and management practices, which are currently hampering the full potential of image data being realized. Here we outline a wide range of efforts and solutions currently being developed by the microscopy community to address these challenges on the path towards FAIR bioimage data. We also highlight how different actors in the microscopy ecosystem are working together, creating synergies that develop new approaches, and how research infrastructures, such as Euro-BioImaging, are fostering these interactions to shape the field. </p>
<p><a class="reference external" href="https://zenodo.org/records/7788899">https://zenodo.org/records/7788899</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7788899">https://doi.org/10.5281/zenodo.7788899</a></p>
</section>
<hr class="docutils" />
<section id="czi-carl-zeiss-image-dataset-with-artificial-test-camera-images-with-various-dimension-for-testing-libraries-reading">
<h2>CZI (Carl Zeiss Image) dataset with artificial test camera images with various dimension for testing libraries reading<a class="headerlink" href="#czi-carl-zeiss-image-dataset-with-artificial-test-camera-images-with-various-dimension-for-testing-libraries-reading" title="Link to this heading">#</a></h2>
<p>Sebastian Rhode</p>
<p>Published 2022-08-22</p>
<p>Licensed CC-BY-4.0</p>
<p>Set of CZI test images created by using a simulated microscope with a test grayscale camera (no LSM or AiryScan or RGB). The filename indicates the used dimension(s) for the acquisition experiment. The files can be used to test the basic functionality of libraries reading CZI files.</p>
<p>Examples:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>S=2_T=3_CH=1.czi = 2 Scenes, 3 TimePoints and 1 Channel

	Z-Stack was not activated inside acquisition experiment


S=2_T=3_Z=5_CH=2.czi = 2 Scenes, 3 TimePoints, 5-Z-Planes and 1 Channels

	Z-Stack was activated inside acquisition experiment
</pre></div>
</div>
<p>The test files (so far) contain not any data with more “advanced” dimensions like AiryScan rawdata, illumination angles etc. Also no CZI files with pixel type RGB are included yet.</p>
<p> </p>
<p> </p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/7015307">https://zenodo.org/records/7015307</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7015307">https://doi.org/10.5281/zenodo.7015307</a></p>
</section>
<hr class="docutils" />
<section id="czi-file-examples">
<h2>CZI file examples<a class="headerlink" href="#czi-file-examples" title="Link to this heading">#</a></h2>
<p>Nicolas Chiaruttini</p>
<p>Published 2023-08-18</p>
<p>Licensed CC-BY-4.0</p>
<p>A set of public CZI files. These can be used for testing CZI readers.</p>
<ul class="simple">
<li><p>Demo LISH 4x8 15pct 647.czi: A cleared mouse brain acquired with a Zeiss LightSheet Z1 with 32 tiles. Courtesy of the Carl Petersen lab LSENS (<a class="reference external" href="https://www.epfl.ch/labs/lsens">https://www.epfl.ch/labs/lsens</a>). Sampled prepared by Yanqi Liu an imaged by Olivier Burri.</p></li>
<li><p>test_gray.czi: a synthetically generated CZI file without metadata, made by Sebastian Rhode</p></li>
<li><p>Image_1_2023_08_18__14_32_31_964.czi: an example multi-part CZI file, containing only camera noise</p></li>
<li><p>a xt scan, xz scan, xzt scan</p></li>
<li><p>a set of multi angle, multi illumination, mutli tile acquisition, taken on the LightSheet Z1 microscope of the PTBIOP by Lorenzo Talà</p></li>
</ul>
<p><a class="reference external" href="https://zenodo.org/records/8305531">https://zenodo.org/records/8305531</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8305531">https://doi.org/10.5281/zenodo.8305531</a></p>
</section>
<hr class="docutils" />
<section id="czi-open-science-program-collection">
<h2>CZI: Open Science Program Collection<a class="headerlink" href="#czi-open-science-program-collection" title="Link to this heading">#</a></h2>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://zenodo.org/communities/eoss">https://zenodo.org/communities/eoss</a></p>
</section>
<hr class="docutils" />
<section id="cellpose-model-for-digital-phase-contrast-images">
<h2>Cellpose model for Digital Phase Contrast images<a class="headerlink" href="#cellpose-model-for-digital-phase-contrast-images" title="Link to this heading">#</a></h2>
<p>Laura Capolupo, Olivier Burri, Romain Guiet</p>
<p>Published 2022-02-09</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: Cellpose model for Digital Phase Contrast images</p>
<p>Data type: Cellpose model, trained via transfer learning from ‘cyto’ model.</p>
<p>Training Dataset: Light microscopy (Digital Phase Contrast) and Manual annotations (10.5281/zenodo.5996883)</p>
<p>Training Procedure: Model was trained using a Cellpose version 0.6.5 with GPU support (NVIDIA GeForce RTX 2080) using default settings as per the Cellpose documentation </p>
<p>python -m cellpose –train –dir TRAINING/DATASET/PATH/train –test_dir TRAINING/DATASET/PATH/test –pretrained_model cyto –chan 0 –chan2 0</p>
<p>The model file (MODEL NAME) in this repository is the result of this training.</p>
<p>Prediction Procedure: Using this model, a label image can be obtained from new unseen images in a given folder with</p>
<p>python -m cellpose –dir NEW/DATASET/PATH –pretrained_model FULL_MODEL_PATH –chan 0 –chan2 0 –save_tif –no_npy</p>
<p><a class="reference external" href="https://zenodo.org/records/6023317">https://zenodo.org/records/6023317</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6023317">https://doi.org/10.5281/zenodo.6023317</a></p>
</section>
<hr class="docutils" />
<section id="cellpose-models-for-label-prediction-from-brightfield-and-digital-phase-contrast-images">
<h2>Cellpose models for Label Prediction from Brightfield and Digital Phase Contrast images<a class="headerlink" href="#cellpose-models-for-label-prediction-from-brightfield-and-digital-phase-contrast-images" title="Link to this heading">#</a></h2>
<p>Romain Guiet, Olivier Burri</p>
<p>Published 2022-02-25</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: Cellpose models for Brightfield and Digital Phase Contrast images</p>
<p>Data type: Cellpose models trained via transfer learning from the ‘nuclei’ and ‘cyto2’ pretrained model with additional Training Dataset . Includes corresponding csv files with ‘Quality Control’ metrics(§) (model.zip).</p>
<p>Training Dataset: Light microscopy (Digital Phase Contrast or Brightfield) and automatic annotations (nuclei or cyto) (<a class="reference external" href="https://doi.org/10.5281/zenodo.6140064">https://doi.org/10.5281/zenodo.6140064</a>)</p>
<p>Training Procedure: The cellpose models were trained using cellpose version 1.0.0 with GPU support (NVIDIA GeForce K40) using default settings as per the Cellpose documentation . Training was done using a Renku environment (renku template).</p>
<p> </p>
<p>Command Line Execution for the different trained models</p>
<p>nuclei_from_bf:</p>
<p>cellpose –train –dir ‘data/train/’ –test_dir ‘data/test/’ –pretrained_model nuclei  –img_filter _bf –mask_filter _nuclei –chan 0 –chan2 0 –use_gpu –verbose</p>
<p>cyto_from_bf:</p>
<p>cellpose –train –dir ‘data/train/’ –test_dir ‘data/test/’ –pretrained_model cyto2 –img_filter _bf –mask_filter _cyto –chan 0 –chan2 0 –use_gpu –verbose</p>
<p> </p>
<p>nuclei_from_dpc:</p>
<p>cellpose –train –dir ‘data/train/’ –test_dir ‘data/test/’ –pretrained_model nuclei  –img_filter _dpc –mask_filter _nuclei –chan 0 –chan2 0 –use_gpu –verbose</p>
<p>cyto_from_dpc:</p>
<p>cellpose –train –dir ‘data/train/’ –test_dir ‘data/test/’ –pretrained_model cyto2 –img_filter _dpc –mask_filter _cyto –chan 0 –chan2 0 –use_gpu –verbose</p>
<p> </p>
<p>nuclei_from_sqrdpc:</p>
<p>cellpose –train –dir ‘data/train/’ –test_dir ‘data/test/’ –pretrained_model nuclei –img_filter _sqrdpc –mask_filter _nuclei –chan 0 –chan2 0 –use_gpu –verbose</p>
<p>cyto_from_sqrdpc:</p>
<p>cellpose –train –dir ‘data/train/’ –test_dir ‘data/test/’ –pretrained_model cyto2 –img_filter _sqrdpc –mask_filter _cyto –chan 0 –chan2 0 –use_gpu –verbose</p>
<p> </p>
<p>NOTE (§): We provide a notebook for Quality Control, which is an adaptation of the “Cellpose (2D and 3D)” notebook from ZeroCostDL4Mic .</p>
<p>NOTE: This dataset used a training dataset from the Zenodo entry(<a class="reference external" href="https://doi.org/10.5281/zenodo.6140064">https://doi.org/10.5281/zenodo.6140064</a>) generated from the “HeLa “Kyoto” cells under the scope”  dataset Zenodo entry(<a class="reference external" href="https://doi.org/10.5281/zenodo.6139958">https://doi.org/10.5281/zenodo.6139958</a>) in order to automatically generate the label images.</p>
<p>NOTE: Make sure that you delete the “_flow” images that are auto-computed when running the training. If you do not, then the flows from previous runs will be used for the new training, which might yield confusing results.</p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/6140111">https://zenodo.org/records/6140111</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6140111">https://doi.org/10.5281/zenodo.6140111</a></p>
</section>
<hr class="docutils" />
<section id="chatgpt-for-image-analysis">
<h2>ChatGPT for Image Analysis<a class="headerlink" href="#chatgpt-for-image-analysis" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-08-25</p>
<p>Licensed CC-BY-4.0</p>
<p>Large Language Models (LLMs) such as ChatGPT are changing the way we interact with computers, including how we analye microscopy imaging data. In this talk I introduce basic concepts of asking LLMs to write code and how to modify the questions to get the best out of it. For trying out these prompt engineering basics there are additional online resources available: <a class="reference external" href="https://scads.github.io/prompt-engineering-basics-2024/intro.html">https://scads.github.io/prompt-engineering-basics-2024/intro.html</a></p>
<p><a class="reference external" href="https://zenodo.org/records/13371196">https://zenodo.org/records/13371196</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13371196">https://doi.org/10.5281/zenodo.13371196</a></p>
</section>
<hr class="docutils" />
<section id="combining-the-bids-and-arc-directory-structures-for-multimodal-research-data-organization">
<h2>Combining the BIDS and ARC Directory Structures for Multimodal Research Data Organization<a class="headerlink" href="#combining-the-bids-and-arc-directory-structures-for-multimodal-research-data-organization" title="Link to this heading">#</a></h2>
<p>Torsten Stöter, Tobias Gottschall, Andrea Schrader, Peter Zentis, Monica Valencia-Schneider, Niraj Kandpal, Werner Zuschratter, Astrid Schauss, Timo Dickscheid, Timo Mühlhaus, Dirk von Suchodoletz</p>
<p>Licensed CC-BY-4.0</p>
<p>Interdisciplinary collaboration and integrating large, diverse datasets are crucial for answering complex research questions, requiring multimodal data analysis and adherence to FAIR principles. To address challenges in capturing the full research cycle and contextualizing data, DataPLANT developed the Annotated Research Context (ARC), while the neuroimaging community extended the Brain Imaging Data Structure (BIDS) for microscopic image data, both providing standardized, file system-based storage structures for organizing and sharing data with metadata.</p>
<p>Tags: Research Data Management, FAIR-Principles</p>
<p>Content type: Poster</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.8349562">https://zenodo.org/doi/10.5281/zenodo.8349562</a></p>
</section>
<hr class="docutils" />
<section id="conference-slides-4th-day-of-intravital-microscopy">
<h2>Conference Slides - 4th Day of Intravital Microscopy<a class="headerlink" href="#conference-slides-4th-day-of-intravital-microscopy" title="Link to this heading">#</a></h2>
<p>Ishikawa-Ankerhold, Dr. Hellen</p>
<p>Published 2024-11-13</p>
<p>Licensed CC-BY-4.0</p>
<p>Conference Slides for the presentation of GerBI e.V. at the 4th Day of Intravital Microscopy in Leuven, Belgium.
Features Structure, activities and Links to join GerBI e.V.</p>
<p><a class="reference external" href="https://zenodo.org/records/14113714">https://zenodo.org/records/14113714</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14113714">https://doi.org/10.5281/zenodo.14113714</a></p>
</section>
<hr class="docutils" />
<section id="crashkurs-forschungsdatenmanagement">
<h2>Crashkurs Forschungsdatenmanagement<a class="headerlink" href="#crashkurs-forschungsdatenmanagement" title="Link to this heading">#</a></h2>
<p>Barbara Weiner, Stephan Wünsche, Stefan Kühne, Pia Voigt, Sebastian Frericks, Clemens Hoffmann, Romy Elze, Ronny Gey</p>
<p>Published 2020-04-30</p>
<p>Licensed CC-BY-4.0</p>
<p>Diese Präsentation bietet einen Einstieg in alle relevanten Bereiche des Forschungsdatenmanagements an der Universität Leipzig. Behandelt werden Grundlagen des Forschungsdatenmanagements, technische, ethische und rechtliche Aspekte sowie die Archivierung und Publikation von Forschungsdaten. Die Präsentation enthält zahlreiche weiterführende Links (rot) und Literaturhinweise.</p>
<p>Ergänzend hierzu wird eine Präsentation mit Übungsaufgaben angeboten, die helfen soll, das Gelernte zu festigen und in der eigenen Forschungspraxis umzusetzen. Den Aufgaben folgen jeweils eine Antwortfolie sowie deren Auflösung.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/3778431">https://zenodo.org/records/3778431</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.3778431">https://doi.org/10.5281/zenodo.3778431</a></p>
</section>
<hr class="docutils" />
<section id="creating-open-computational-curricula">
<h2>Creating open computational curricula<a class="headerlink" href="#creating-open-computational-curricula" title="Link to this heading">#</a></h2>
<p>Kari Jordan, Zhian Kamvar, Toby Hodges</p>
<p>Published 2020-12-11</p>
<p>Licensed CC-BY-4.0</p>
<p>In this interactive session, Carpentries team members will guide attendees through three stages of the backward design process to create a lesson development plan for the open source tool of their choosing. Attendees will leave having identified what practical skills they aim to teach (learning objectives), an approach for designing challenge questions (formative assessment), and mechanisms to give and receive feedback.</p>
<p>Content type: Slide</p>
<p><a class="reference external" href="https://zenodo.org/records/4317149">https://zenodo.org/records/4317149</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4317149">https://doi.org/10.5281/zenodo.4317149</a></p>
</section>
<hr class="docutils" />
<section id="cultivating-open-training">
<h2>Cultivating Open Training<a class="headerlink" href="#cultivating-open-training" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-03-14</p>
<p>Licensed CC-BY-4.0</p>
<p>In this SaxFDM Digital Kitchen, I introduced current challenges and potential solutions for openly sharing training materials, softly focusing on bio-image analysis. In this field a lot of training materials circulate in private channels, but openly shared, reusable materials, according to the FAIR-principles, are still rare. Using the CC-BY license and uploading materials to publicly acessible repositories are proposed to fill this gap.</p>
<p>Tags: Open Science, Research Data Management, FAIR-Principles, Bioimage Analysis, Licensing</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/10816895">https://zenodo.org/records/10816895</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10816895">https://doi.org/10.5281/zenodo.10816895</a></p>
</section>
<hr class="docutils" />
<section id="cultivating-open-training-to-advance-bio-image-analysis">
<h2>Cultivating Open Training to advance Bio-image Analysis<a class="headerlink" href="#cultivating-open-training-to-advance-bio-image-analysis" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-04-25</p>
<p>Licensed CC-BY-4.0</p>
<p>These slides introduce current challenges and potential solutions for openly sharing training materials, focusing on bio-image analysis. In this field a lot of training materials circulate in private channels, but openly shared, reusable materials, according to the FAIR-principles, are still rare. Using the CC-BY license and publicly acessible repositories are proposed to fill this gap.</p>
<p>Tags: Research Data Management, Licensing, FAIR-Principles</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/11066250">https://zenodo.org/records/11066250</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11066250">https://doi.org/10.5281/zenodo.11066250</a></p>
</section>
<hr class="docutils" />
<section id="dalia-interchange-format">
<h2>DALIA Interchange Format<a class="headerlink" href="#dalia-interchange-format" title="Link to this heading">#</a></h2>
<p>Jonathan Geiger, Petra Steiner, Abdelmoneim Amer Desouki, Frank Lange</p>
<p>Published 2024-06-07</p>
<p>Licensed CC-BY-SA-4.0</p>
<p>The DALIA (Data Literacy Alliance) project aims to develop a knowledge graph for FAIR teaching and learning materials on data literacy, data competencies and research data management (RDM) skills within the National Research Data Infrastructure (NFDI) and the RDM landscape. Such a platform thrives on the participation of users who want to search, create, manage or use teaching and learning materials.
A schematization of the metadata is necessary for the interoperability of teaching and learning materials. This is done by the DALIA Interchange Format (DIF), which provides a framework for making the metadata of teaching and learning materials transparent, comparable and smooth to integrate into the DALIA platform. It includes the description and explanation of the data fields for the online publication of educational resources.
The DIF was developed in close consultation with the scientific community. This development process included several feedback rounds in which valuable feedback was provided and subsequently incorporated into the DIF. This not only contributed to the clear, transparent and user-oriented definitions of the data fields, and to a clear structure, but also to the integration of many existing data standards and to the (special) requirements of the scientific community. The selection of elements is based on the Dublin Core Application Profile.
The DIF is provided as a PDF document and in table form (ODS) to convey the attributes of the teaching and learning materials and their definitions in an easily understandable form and to facilitate communication. It also includes a legend and an example in tabular form. In addition, a template (CSV) with the attributes as column headers is provided, which can be used for recording the metadata of the teaching and learning materials. The tables can also be transferred to technical application profiles.
We would like to thank all the commentators of the previous versions, especially Susanne Arndt, Sophie Boße, Sonja Felder, Marc Fuhrmans, Jan-Michael Haugwitz, Marina Lemaire, Karoline Lemke, Birte Lindstädt, Juliane Röder, and Jakob Voß. Without their feedback and advice, the DIF would be less transparent.</p>
<p><a class="reference external" href="https://zenodo.org/records/11521029">https://zenodo.org/records/11521029</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11521029">https://doi.org/10.5281/zenodo.11521029</a></p>
</section>
<hr class="docutils" />
<section id="data-stewardship-and-research-data-management-tools-for-multimodal-linking-of-imaging-data-in-plasma-medicine">
<h2>Data stewardship and research data management tools for multimodal linking of imaging data in plasma medicine<a class="headerlink" href="#data-stewardship-and-research-data-management-tools-for-multimodal-linking-of-imaging-data-in-plasma-medicine" title="Link to this heading">#</a></h2>
<p>Ahmadi, Mohsen, Wagner, Robert, Mattern, Philipp, Plathe, Nick, Bekeschus, Sander, Becker, Markus M., Stöter, Torsten, Weidtkamp-Peters, Stefanie</p>
<p>Published 2023-11-03</p>
<p>Licensed CC-BY-4.0</p>
<p>A more detailed understanding of the effect of plasmas on biological systems can be fostered by combining data from different imaging modalities, such as optical imaging, fluorescence imaging, and mass spectrometry imaging. This, however, requires the implementation and use of sophisticated research data management (RDM) solutions to incorporate the influence of plasma parameters and treatment procedures as well as the effects of plasma on the treated targets. In order to address this, RDM activities on different levels and from different perspectives are started and brought together within the framework of the NFDI consortium NFDI4BIOIMAGE.</p>
<p><a class="reference external" href="https://zenodo.org/records/10069368">https://zenodo.org/records/10069368</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10069368">https://doi.org/10.5281/zenodo.10069368</a></p>
</section>
<hr class="docutils" />
<section id="datenmanagement">
<h2>Datenmanagement<a class="headerlink" href="#datenmanagement" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-04-14</p>
<p>Licensed CC-BY-4.0</p>
<p>In dieser Data Management Session wird der Lebenszyklus von Daten näher beleuchtet. Wie entstehen Daten, was passiert mit ihnen, wenn sie verarbeitet werden? Wem gehören die Daten und wer ist dafür verantwortlich, sie zu veröffentlichen, zu archivieren und gegebenenfalls wiederzuverwenden? Wir werden einen Datenmanagementplan in Gruppenarbeit entwerfen, ggf. mit Hilfe von ChatGPT.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/10970869">https://zenodo.org/records/10970869</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10970869">https://doi.org/10.5281/zenodo.10970869</a></p>
</section>
<hr class="docutils" />
<section id="datenmanagement-im-fokus-organisation-speicherstrategien-und-datenschutz">
<h2>Datenmanagement im Fokus: Organisation, Speicherstrategien und Datenschutz<a class="headerlink" href="#datenmanagement-im-fokus-organisation-speicherstrategien-und-datenschutz" title="Link to this heading">#</a></h2>
<p>Pia Voigt, Carolin Hundt</p>
<p>Published 2024-04-19</p>
<p>Licensed CC-BY-4.0</p>
<p>Workshop zum Thema „Datenmanagement im Fokus: Organisation, Speicherstrategien und Datenschutz“ auf der Data Week Leipzig
Der Umgang mit Daten ist im Alltag nicht immer leicht: Wie und wo speichert man Daten idealerweise? Welche Strategien helfen, den Überblick zu behalten und wie geht man mit personenbezogenen Daten um? Diese Fragen möchten wir gemeinsam mit Ihnen anhand individueller Datenprobleme besprechen und Ihnen Lösungen aufzeigen, wie Sie ihr Datenmanagement effizient gestalten können.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/11107798">https://zenodo.org/records/11107798</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11107798">https://doi.org/10.5281/zenodo.11107798</a></p>
</section>
<hr class="docutils" />
<section id="datenmanagementplane-erstellen-teil-1">
<h2>Datenmanagementpläne erstellen - Teil 1<a class="headerlink" href="#datenmanagementplane-erstellen-teil-1" title="Link to this heading">#</a></h2>
<p>Pia Voigt, Barbara Weiner</p>
<p>Published 2021-03-23</p>
<p>Licensed CC-BY-4.0</p>
<p>Was ist ein Datenmanagementplan? Welche Vorgaben sollte ich beachten? Wie erstelle ich einen solchen für mein Forschungsprojekt und welche nützlichen Tools kann ich hierfür verwenden?</p>
<p>Die Anforderungen der Forschungsförderer zum Datenmanagement steigen stetig. Damit verbunden ist häufig auch das Erstellen eines Datenmanagementplans. Dabei erwarten DFG, BMBF oder die EU jeweils unterschiedliche Angaben zur Erhebung, Speicherung und Veröffentlichung von projektbezogenen Forschungsdaten. Zudem bietet das Erstellen eines Datenmanagementplans viele Vorteile und hilft Ihnen nicht zuletzt, die Anforderungen der guten wissenschaftlichen Praxis strukturiert umzusetzen.</p>
<p>Was im ersten Moment unübersichtlich und überfordernd wirkt, soll in diesem Kurs anhand einer grundlegenden theoretischen Einführung im ersten und praxisorientierter Beispiele im zweiten Teil der Veranstaltung handhabbar gemacht werden. Sie lernen, was hinter den Anforderungen der Forschungsförderer steckt, welche Elemente ein Datenmanagementplan enthalten sollte und wie sie einen solchen mithilfe interaktiver Tools selbst erstellen können.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/4630788">https://zenodo.org/records/4630788</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4630788">https://doi.org/10.5281/zenodo.4630788</a></p>
</section>
<hr class="docutils" />
<section id="datenmanagementplane-erstellen-teil-2">
<h2>Datenmanagementpläne erstellen - Teil 2<a class="headerlink" href="#datenmanagementplane-erstellen-teil-2" title="Link to this heading">#</a></h2>
<p>Pia Voigt, Barbara Weiner</p>
<p>Published 2021-03-30</p>
<p>Licensed CC-BY-4.0</p>
<p>Was ist ein Datenmanagementplan? Welche Vorgaben sollte ich beachten? Wie erstelle ich einen solchen für mein Forschungsprojekt und welche nützlichen Tools kann ich hierfür verwenden?</p>
<p>Die Anforderungen der Forschungsförderer zum Datenmanagement steigen stetig. Damit verbunden ist häufig auch das Erstellen eines Datenmanagementplans. Dabei erwarten DFG, BMBF oder die EU jeweils unterschiedliche Angaben zur Erhebung, Speicherung und Veröffentlichung von projektbezogenen Forschungsdaten. Zudem bietet das Erstellen eines Datenmanagementplans viele Vorteile und hilft Ihnen nicht zuletzt, die Anforderungen der guten wissenschaftlichen Praxis strukturiert umzusetzen.</p>
<p>Was im ersten Moment unübersichtlich und überfordernd wirkt, soll in diesem Kurs anhand einer grundlegenden theoretischen Einführung im ersten und praxisorientierter Beispiele im zweiten Teil der Veranstaltung handhabbar gemacht werden. Sie lernen, was hinter den Anforderungen der Forschungsförderer steckt, welche Elemente ein Datenmanagementplan enthalten sollte und wie sie einen solchen mithilfe interaktiver Tools selbst erstellen können.</p>
<p>Version 2 enthält aktuelle Links und weiterführende Hinweise zu einzelnen Aspekten eines Datenmanagementplans.</p>
<p>Version 3 ist die überarbeitete und aktualisierte Version der ersten beiden und enthält u.a. Hinweise zur Lizenzierung und zu Nutzungsrechten an Forschungsdaten.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/4748534">https://zenodo.org/records/4748534</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4748534">https://doi.org/10.5281/zenodo.4748534</a></p>
</section>
<hr class="docutils" />
<section id="deconvolution-test-dataset">
<h2>Deconvolution Test Dataset<a class="headerlink" href="#deconvolution-test-dataset" title="Link to this heading">#</a></h2>
<p>Romain Guiet</p>
<p>Published 2021-07-14</p>
<p>Licensed CC-BY-4.0</p>
<p>This a test dataset, HeLa cells stained for action using Phalloidin-488 acquired on confocal Zeiss LSM710, which contains</p>
<ul class="simple">
<li><p>Ph488.czi (contains all raw metadata)</p></li>
<li><p>Raw_large.tif ( is the tif version of Ph488.czi, provided for conveninence as tif doesn’t need Bio-Formats to be open in Fiji )</p></li>
<li><p>Raw.tif , is a crop of the large image</p></li>
</ul>
<p>- PSFHuygens_confocal_Theopsf.tif , is a theoretical PSF generated with HuygensPro</p>
<p>- PSFgen_WF_WBpsf.tif  , is a theoretical PSF generated with PSF generator</p>
<ul class="simple">
<li><p>PSFgen_WFsquare_WBpsf.tif, is the result of the square operation on PSFgen_WF_WBpsf.tif , to approximate a confocal PSF</p></li>
</ul>
<p><a class="reference external" href="https://zenodo.org/records/5101351">https://zenodo.org/records/5101351</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5101351">https://doi.org/10.5281/zenodo.5101351</a></p>
</section>
<hr class="docutils" />
<section id="development-of-a-platform-for-advanced-optics-education-training-and-prototyping">
<h2>Development of a platform for advanced optics education, training and prototyping<a class="headerlink" href="#development-of-a-platform-for-advanced-optics-education-training-and-prototyping" title="Link to this heading">#</a></h2>
<p>Nadine Utz, Sabine Reither, Ruth Hans, Christian Feldhaus</p>
<p>Published 2023-10-05</p>
<p>Licensed CC-BY-4.0</p>
<p>In bio-medical research we often need to combine a broad range of expertise to run complex experiments and analyse and interpret their results. Also, it is desirable that all stakeholders of a project understand all parts of the experiment and analysis to draw and support the right conclusions. For imaging experiments this usually requires a basic understanding of the underlying physics. This has not necessarily been part of the professional training of all stakeholders, e.g. biologists or data scientists. Therefore an affordable platform for easily demonstrating and explaining imaging principles would be desirable.
Building up on a commercially available STEM Optics kit we developed extensions with widely available and affordable components to demonstrate advanced imaging techniques like e.g. confocal, lightsheet, OPT, spectral imaging. All models are quick and easy to build, yet demonstrate the important physical principles each imaging technique is based on.
Further use cases for this kit are training courses, demonstrations for imaging newbies when designing an experiment and outreach activities but also basic level prototyping.</p>
<p><a class="reference external" href="https://zenodo.org/records/10925217">https://zenodo.org/records/10925217</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10925217">https://doi.org/10.5281/zenodo.10925217</a></p>
</section>
<hr class="docutils" />
<section id="digital-phase-contrast-on-primary-dermal-human-fibroblasts-cells">
<h2>Digital Phase Contrast on Primary Dermal Human Fibroblasts cells<a class="headerlink" href="#digital-phase-contrast-on-primary-dermal-human-fibroblasts-cells" title="Link to this heading">#</a></h2>
<p>Laura Capolupo</p>
<p>Published 2022-02-09</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: Digital Phase Contrast on Primary Dermal Human Fibroblasts cells </p>
<p>Data type: Paired microscopy images (Digital Phase Contrast, square rooted) and corresponding labels/masks used for cellpose training (the corresponding Brightfield images are also present), organized as recommended by cellpose documentation.</p>
<p>Microscopy data type: Light microscopy (Digital Phase Contrast and Brighfield )</p>
<p>Manual annotations: Labels/masks obtained via manual segmentation. For each region, all cells were annotated manually. Uncertain objects (Dust, fused cells) were left unannotated, so that the cellpose model (10.5281/zenodo.6023317) may mimic the same user bias during prediction. This was particularly necessary due to the accumulation of floating debris in the center of the well.</p>
<p>Microscope: Perkin Elmer Operetta microscope with a 10x 0.35 NA objective</p>
<p>Cell type: Primary Dermal Human Fibroblasts cells</p>
<p>File format: .tif (16-bit for DPC and 16-bit for the masks)</p>
<p>Image size: 1024x1024 (Pixel size: 634 nm)</p>
<p>NOTE : This dataset was used to train cellpose model ( 10.5281/zenodo.6023317 )</p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/5996883">https://zenodo.org/records/5996883</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5996883">https://doi.org/10.5281/zenodo.5996883</a></p>
</section>
<hr class="docutils" />
<section id="efficiently-starting-institutional-research-data-management">
<h2>Efficiently starting institutional research data management<a class="headerlink" href="#efficiently-starting-institutional-research-data-management" title="Link to this heading">#</a></h2>
<p>Katarzyna Biernacka, Katrin Cortez, Kerstin Helbig</p>
<p>Published 2019-10-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Researchers are increasingly often confronted with research data management (RDM) topics during their work. Higher education institutions therefore begin to offer services for RDM at some point to give support and advice. However, many groundbreaking decisions have to be made at the very beginning of RDM services. Priorities must be set and policies formulated. Likewise, the staff must first be qualified in order to provide advice and adequately deal with the manifold problems awaiting.
The FDMentor project has therefore bundled the expertise of five German universities with different experiences and levels of RDM knowledge to jointly develop strategies, roadmaps, guidelines, and open access training material. Humboldt-Universität zu Berlin, Freie Universität Berlin, Technische Universität Berlin, University of Potsdam, and European University Viadrina Frankfurt (Oder) have worked together on common solutions that are easy to adapt. With funding of the German Federal Ministry of Education and Research, the collaborative project addressed four problem areas: strategy development, legal issues, policy development, and competence enhancement. The aim of the project outcomes is to provide other higher education institutions with the best possible support for the efficient introduction of research data management. Therefore, all project results are freely accessible under the CC-BY 4.0 international license. The early involvement of the community in the form of workshops and the collection of feedback has proven its worth: the FDMentor strategies, roadmaps, guidelines, and training materials are applied and adapted beyond the partner universities.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Document</p>
<p><a class="reference external" href="https://zenodo.org/record/3490058">https://zenodo.org/record/3490058</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.3490058">https://doi.org/10.5281/zenodo.3490058</a></p>
</section>
<hr class="docutils" />
<section id="einblicke-ins-forschungsdatenmanagement-darf-ich-das-veroffentlichen-rechtsfragen-im-umgang-mit-forschungsdaten">
<h2>Einblicke ins Forschungsdatenmanagement - Darf ich das veröffentlichen? Rechtsfragen im Umgang mit Forschungsdaten<a class="headerlink" href="#einblicke-ins-forschungsdatenmanagement-darf-ich-das-veroffentlichen-rechtsfragen-im-umgang-mit-forschungsdaten" title="Link to this heading">#</a></h2>
<p>Stephan Wünsche, Pia Voigt</p>
<p>Published 2021-05-11</p>
<p>Licensed CC-BY-4.0</p>
<p>Diese Präsentation wurde im Zuge der digitalen Veranstaltungsreihe “Einblicke ins Forschungsdatenmanagement” erstellt. Diese findet seit dem SS 2020 an der Universität Leipzig für alle Interessierten zu verschiedenen Themen des Forschungsdatenmanagements statt.</p>
<p>Dieser Teil der Reihe dreht sich um Rechtsfragen im Umgang mit Forschungsdaten und deren Bedeutung für die wissenschaftliche Praxis. Sie finden in der vorliegenden Präsentation einen Überblick über relevante Rechtsbereiche sowie Erläuterungen zum Datenschutz, Urheberrecht und den Grundsätzen der guten wissenschaftlichen Praxis mit Fokus auf deren Bedeutung im Forschungsdatenmanagement.</p>
<p>Tags: Research Data Management, Data Protection</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/4748510">https://zenodo.org/records/4748510</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4748510">https://doi.org/10.5281/zenodo.4748510</a></p>
</section>
<hr class="docutils" />
<section id="engineering-a-software-environment-for-research-data-management-of-microscopy-image-data-in-a-core-facility">
<h2>Engineering a Software Environment for Research Data Management of Microscopy Image Data in a Core Facility<a class="headerlink" href="#engineering-a-software-environment-for-research-data-management-of-microscopy-image-data-in-a-core-facility" title="Link to this heading">#</a></h2>
<p>Kunis</p>
<p>Published 2022-05-30</p>
<p>This thesis deals with concepts and solutions in the field of data management in everyday scientific life for image data from microscopy. The focus of the formulated requirements has so far been on published data, which represent only a small subset of the data generated in the scientific process. More and more, everyday research data are moving into the focus of the principles for the management of research data that were formulated early on (FAIR-principles). The adequate management of this mostly multimodal data is a real challenge in terms of its heterogeneity and scope. There is a lack of standardised and established workflows and also the software solutions available so far do not adequately reflect the special requirements of this area. However, the success of any data management process depends heavily on the degree of integration into the daily work routine. Data management must, as far as possible, fit seamlessly into this process. Microscopy data in the scientific process is embedded in pre-processing, which consists of preparatory laboratory work and the analytical evaluation of the microscopy data. In terms of volume, the image data often form the largest part of data generated within this entire research process. In this paper, we focus on concepts and techniques related to the handling and description of this image data and address the necessary basics. The aim is to improve the embedding of the existing data management solution for image data (OMERO) into the everyday scientific work. For this purpose, two independent software extensions for OMERO were implemented within the framework of this thesis: OpenLink and MDEmic. OpenLink simplifies the access to the data stored in the integrated repository in order to feed them into established workflows for further evaluations and enables not only the internal but also the external exchange of data without weakening the advantages of the data repository. The focus of the second implemented software solution, MDEmic, is on the capturing of relevant metadata for microscopy. Through the extended metadata collection, a corresponding linking of the multimodal data by means of a unique description and the corresponding semantic background is aimed at. The configurability of MDEmic is designed to address the currently very dynamic development of underlying concepts and formats. The main goal of MDEmic is to minimise the workload and to automate processes. This provides the scientist with a tool to handle this complex and extensive task of metadata acquisition for microscopic data in a simple way. With the help of the software, semantic and syntactic standardisation can take place without the scientist having to deal with the technical concepts. The generated metadata descriptions are automatically integrated into the image repository and, at the same time, can be transferred by the scientists into formats that are needed when publishing the data.</p>
<p><a class="reference external" href="https://zenodo.org/records/6905931">https://zenodo.org/records/6905931</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6905931">https://doi.org/10.5281/zenodo.6905931</a></p>
</section>
<hr class="docutils" />
<section id="euro-bioimaging-scientific-ambassadors-program">
<h2>Euro-BioImaging  Scientific Ambassadors Program<a class="headerlink" href="#euro-bioimaging-scientific-ambassadors-program" title="Link to this heading">#</a></h2>
<p>Beatriz Serrano-Solano</p>
<p>Published 2023-07-25</p>
<p>Licensed CC-BY-4.0</p>
<p>Graduation presentation for the 7th cohort of the Open Seeds mentoring &amp; training program for Open Science ambassadors. The project presented is called “Euro-BioImaging  Scientific Ambassadors Program”.</p>
<p><a class="reference external" href="https://zenodo.org/records/8182154">https://zenodo.org/records/8182154</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8182154">https://doi.org/10.5281/zenodo.8182154</a></p>
</section>
<hr class="docutils" />
<section id="euro-bioimaging-eric-annual-report-2022">
<h2>Euro-BioImaging ERIC Annual Report 2022<a class="headerlink" href="#euro-bioimaging-eric-annual-report-2022" title="Link to this heading">#</a></h2>
<p>Euro-BioImaging ERIC</p>
<p>Published 2023-07-14</p>
<p>Licensed CC-BY-4.0</p>
<p>Euro-BioImaging ERIC is the European landmark research infrastructure for biological and biomedical imaging as recognized by the European Strategy Forum on Research Infrastructures (ESFRI). Euro-BioImaging is the gateway to world-class imaging facilities across Europe. This document is the Euro-BioImaging Annual Report for the year 2022.</p>
<p><a class="reference external" href="https://zenodo.org/records/8146412">https://zenodo.org/records/8146412</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8146412">https://doi.org/10.5281/zenodo.8146412</a></p>
</section>
<hr class="docutils" />
<section id="euro-bioimaging-s-guide-to-fair-bioimage-data-practical-tasks">
<h2>Euro-BioImaging’s Guide to FAIR BioImage Data - Practical Tasks<a class="headerlink" href="#euro-bioimaging-s-guide-to-fair-bioimage-data-practical-tasks" title="Link to this heading">#</a></h2>
<p>Isabel Kemmer, Euro-BioImaging ERIC</p>
<p>Published 2024-06-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Hands-on exercises on FAIR Bioimage Data from the interactive online workshop “Euro-BioImaging’s Guide to FAIR BioImage Data 2024” (<a class="reference external" href="https://www.eurobioimaging.eu/news/a-guide-to-fair-bioimage-data-2024/">https://www.eurobioimaging.eu/news/a-guide-to-fair-bioimage-data-2024/</a>).  Types of tasks included: FAIR characteristics of a real world dataset Data Management Plan (DMP) Journal Policies on FAIR data sharing Ontology search Metadata according to REMBI scheme (Image from: Sarkans, U., Chiu, W., Collinson, L. et al. REMBI: Recommended Metadata for Biological Images—enabling reuse of microscopy data in biology. Nat Methods 18, 1418–1422 (2021). <a class="reference external" href="https://doi.org/10.1038/s41592-021-01166-8">https://doi.org/10.1038/s41592-021-01166-8</a>) Matching datasets to bioimage repositories Browsing bioimage repositories</p>
<p>Tags: Bioimage Analysis, FAIR-Principles, Research Data Management</p>
<p>Content type: Slides, Tutorial</p>
<p><a class="reference external" href="https://zenodo.org/records/11474407">https://zenodo.org/records/11474407</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11474407">https://doi.org/10.5281/zenodo.11474407</a></p>
</section>
<hr class="docutils" />
<section id="euro-bioimaging-s-template-for-research-data-management-plans">
<h2>Euro-BioImaging’s Template for Research Data Management Plans<a class="headerlink" href="#euro-bioimaging-s-template-for-research-data-management-plans" title="Link to this heading">#</a></h2>
<p>Isabel Kemmer, Euro-BioImaging ERIC</p>
<p>Published 2024-06-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Euro-BioImaging has developed a Data Management Plan (DMP) template with questions tailored to bioimaging research projects. Outlining data management practices in this way ensures traceability of project data, allowing for a continuous and unambiguous flow of information throughout the research project. This template can be used to satisfy the requirement to submit a DMP to certain funders. Regardless of the funder, Euro-BioImaging users are encouraged to provide a DMP and can use this template accordingly. 
This DMP template is available as a fillable PDF with further instructions and sample responses available by hovering over the fillable fields. </p>
<p>Tags: Bioimage Analysis, FAIR-Principles, Research Data Management</p>
<p>Content type: Collection, Tutorial</p>
<p><a class="reference external" href="https://zenodo.org/records/11473803">https://zenodo.org/records/11473803</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11473803">https://doi.org/10.5281/zenodo.11473803</a></p>
</section>
<hr class="docutils" />
<section id="euro-bioimaging-batchconvert-v0-0-4">
<h2>Euro-BioImaging/BatchConvert: v0.0.4<a class="headerlink" href="#euro-bioimaging-batchconvert-v0-0-4" title="Link to this heading">#</a></h2>
<p>bugraoezdemir</p>
<p>Published 2024-02-19</p>
<p>Licensed CC-BY-4.0</p>
<p>Changes implemented since v0.0.3</p>
<p>Support provided for file paths with spaces.
Support provided for globbing filenames from s3 for one-to-one conversion (parse_s3_filenames.py modified).
Support provided for single file import from s3 (parse_s3_filenames.py modified).
run_conversion.py replaces batchconvert_cli.sh and construct_cli.py, uniting them.
Error handling updated for each process</p>
<p><a class="reference external" href="https://zenodo.org/records/10679318">https://zenodo.org/records/10679318</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10679318">https://doi.org/10.5281/zenodo.10679318</a></p>
</section>
<hr class="docutils" />
<section id="evident-oir-sample-files-tiles-stitched-image-fv-4000">
<h2>Evident OIR sample files tiles + stitched image - FV 4000<a class="headerlink" href="#evident-oir-sample-files-tiles-stitched-image-fv-4000" title="Link to this heading">#</a></h2>
<p>Nicolas Chiaruttini</p>
<p>Published 2024-09-04</p>
<p>Licensed CC-BY-4.0</p>
<p>The files contained in this repository are confocal images taken with the Evident FV 4000 of a sample containing DAPI and mCherry stains, excited with a 405 nm laser and a 561 nm laser</p>
<p>individual tiles are named <code class="docutils literal notranslate"><span class="pre">tiling-sample-brain-section_A01_G001_{i}.oir</span></code>
The stiched image is named <code class="docutils literal notranslate"><span class="pre">Stitch_A01_G001</span></code> and contains an extra file <code class="docutils literal notranslate"><span class="pre">Stitch_A01_G001_00001</span></code>
Some metadata like the tiles positions are stored in the extra files (omp2info)</p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/13680725">https://zenodo.org/records/13680725</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13680725">https://doi.org/10.5281/zenodo.13680725</a></p>
</section>
<hr class="docutils" />
<section id="evident-oir-sample-files-with-lambda-scan-fv-4000">
<h2>Evident OIR sample files with lambda scan - FV 4000<a class="headerlink" href="#evident-oir-sample-files-with-lambda-scan-fv-4000" title="Link to this heading">#</a></h2>
<p>Nicolas Chiaruttini</p>
<p>Published 2024-07-18</p>
<p>Licensed CC-BY-4.0</p>
<p>The files contained in this repository are confocal images taken with the Evident FV 4000 of a sample containing DAPI and mCherry stains, excited with the 405 nm laser and images for different emission windows (lambda scan).
They are public sample files which goal is to help test edge cases of the bio-formats library (<a class="reference external" href="https://www.openmicroscopy.org/bio-formats/">https://www.openmicroscopy.org/bio-formats/</a>), in particular for the proper handling of lambda scans.</p>
<p>DAPI_mCherry_22Lambda-420-630-w10nm-s10nm.oir : 22 planes, each plane is an emission window, starting from 420 nm up to 630 nm by steps of 10 nm
DAPI_mCherry_4T_5Lambda-420-630-w10nm-s50nm.oir : 20 planes, 5 lambdas from 420 to 630 nm by steps of 50 nm, 4 timepoints
DAPI_mCherry_4Z_5Lambda-420-630-w10nm-s50nm.oir : 20 planes, 5 lambdas from 420 to 630 nm by steps of 50 nm, 4 slices
DAPI-mCherry_3T_4Z_5Lambda-420-630-w10nm-s50nm.oir : 60 planes, 5 lambdas from 420 to 630 nm by steps of 50 nm, 4 slices, 3 timepoints</p>
<p><a class="reference external" href="https://zenodo.org/records/12773657">https://zenodo.org/records/12773657</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12773657">https://doi.org/10.5281/zenodo.12773657</a></p>
</section>
<hr class="docutils" />
<section id="example-imaris-ims-datasets">
<h2>Example Imaris ims datasets.<a class="headerlink" href="#example-imaris-ims-datasets" title="Link to this heading">#</a></h2>
<p>Marco Stucchi</p>
<p>Published 2024-11-28</p>
<p>Licensed CC-BY-4.0</p>
<p>The files contained in this repository are example Imaris ims images.
 
Initially related to <a class="github reference external" href="https://github.com/ome/bioformats/pull/4249">ome/bioformats#4249</a></p>
<p><a class="reference external" href="https://zenodo.org/records/14235726">https://zenodo.org/records/14235726</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14235726">https://doi.org/10.5281/zenodo.14235726</a></p>
</section>
<hr class="docutils" />
<section id="example-microscopy-metadata-json-files-produced-using-micro-meta-app-to-document-example-microscopy-experiments-performed-at-individual-core-facilities">
<h2>Example Microscopy Metadata JSON files produced using Micro-Meta App to document example microscopy experiments performed at individual core facilities<a class="headerlink" href="#example-microscopy-metadata-json-files-produced-using-micro-meta-app-to-document-example-microscopy-experiments-performed-at-individual-core-facilities" title="Link to this heading">#</a></h2>
<p>Alessandro Rigano, Ulrike Boehm, Claire M. Brown, Joel Ryan, James J. Chambers, Robert A. Coleman, Orestis Faklaris, Thomas Guilbert, Michelle S. Itano, Judith Lacoste, Alex Laude, Marco Marcello, Paula Montero-Llopis, Glyn Nelson, Roland Nitschke, Jaime A. Pimentel, Stefanie Weidtkamp-Peters, Caterina Strambio-De-Castillia</p>
<p>Published 2022-01-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Example Microscopy Metadata (Microscope.JSON and Settings.JSON) files produced using Micro-Meta App to document the Hardware Specifications of example Microscopes and the Image Acquisition Settings utilized to acquire example images as listed in the table below.</p>
<p>For each facility, the dataset contains two JSON files:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Microscope.JSON file (e.g., 01_marcello_uliverpool_cci_zeiss_axioobserz1_lsm710.json)
Settings.JSON file (indicated with the name of the image and with the _AS suffix)
</pre></div>
</div>
<p>Micro-Meta App was developed as part of a global community initiative including the 4D Nucleome (4DN) Imaging Working Group, BioImaging North America (BINA) Quality Control and Data Management Working Group, and QUAlity and REProducibility for Instrument and Images in Light Microscopy (QUAREP-LiMi), to extend the Open Microscopy Environment (OME) data model.</p>
<p>The works of this global community effort resulted in multiple publications featured on a recent Nature Methods FOCUS ISSUE dedicated to Reporting and reproducibility in microscopy.</p>
<p>Learn More! For a thorough description of Micro-Meta App consult our recent Nature Methods and <a class="reference external" href="http://BioRxiv.org">BioRxiv.org</a> publications!</p>
<p> </p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>		Nr.
		Manufacturer
		Model
		Tier
		&amp;Epsilon;xperiment Type
		Facility Name
		Department and Institution
		URL
		References
	
	
		1
		Carl Zeiss Microscopy
		Axio Observer Z1 (with LSM 710 scan head)
		1
		3D visualization of superhydrophobic polymer-nanoparticles
		Centre for Cell Imaging (CCI)
		University of Liverpool
		https://cci.liv.ac.uk/equipment_710.html
		Upton et al., 2020
	
	
		2
		Carl Zeiss Microscopy
		Axio Observer (Axiovert 200M)
		2
		&amp;Mu;easurement of illumination stability on Chinese Hamster Ovary cells expressing Paxillin-EGFP
		Advanced BioImaging Facility (ABIF).
		McGill University
		https://www.mcgill.ca/abif/equipment/axiovert-1
		Kiepas et al., 2020
	
	
		3
		Carl Zeiss Microscopy
		Axio Observer Z1 (with Spinning Disk)
		2
		Immunofluorescence imaging of cryosection of Mouse kidney
		Imagerie Cellulaire; Quality Control managed by Miacellavie (https://miacellavie.com/)
		Centre de recherche du Centre Hospitalier Universit&amp;eacute; de Montr&amp;eacute;al (CR CHUM), University of Montreal
		https://www.chumontreal.qc.ca/crchum/plateformes-et-services&amp;nbsp; (the web site is for all core facilities, not specifically for the core facility hosting this microscope)
		Pilliod et al., 2020
	
	
		4
		Carl Zeiss Microscopy
		Axio Imager Z2 (with Apotome)
		2
		Immunofluorescence imaging of mitotic division in Hela cells using&amp;nbsp;&amp;nbsp;
		Bioimaging Unit
		Newcastle University
		https://www.ncl.ac.uk/bioimaging/
		Watson et al., 2020
	
	
		5
		Carl Zeiss Microscopy
		Axio Observer Z1
		2
		Fluorescence microscopy of human skin fibroblasts from Glycogen Storage Disease patients.
		Life Imaging Center (LIC)
		Centre for Integrative Signalling Analysis (CISA), University of Freiburg
		https://miap.eu/equipments/sd-i-abl/
		Hannibal et al., 2020
	
	
		6
		Leica Microsystems
		DMI6000B
		2
		3D immunofluorescence imaging&amp;nbsp; rhinovirus infected macrophages&amp;nbsp;
		IMAG&amp;#39;IC Confocal Microscopy Facility
		Institut Cochin, CNRS, INSERM, Universit&amp;eacute; de Paris
		https://www.institutcochin.fr/core_facilities/confocal-microscopy/cochin-imaging-photonic-microscopy/organigram_team/10054/view
		Jubrail et al., 2020
	
	
		7
		Leica Microsystems
		DM5500B
		2
		Immunofluorescence analysis of the colocalization of PML bodies with DNA double-strand breaks
		Bioimaging Unit
		Edwardson Building on the Campus for Ageing and Vitality, Newcastle University
		https://www.ncl.ac.uk/bioimaging/equipment/leica-dm5500/#overview
		da Silva et al., 2019; Nelson et al., 2012
		&amp;nbsp;&amp;nbsp;
	
	
		8
		Leica Microsystems
		DMI8-CS (with TCS SP8 STED 3X)
		2
		Live-cell imaging of N. benthamiana leaves cells-derived protoplasts
		Center for Advanced Imaging (CAi)
		School of Mathematics/Natural Sciences, Heinrich-Heine-Universit&amp;auml;t D&amp;uuml;sseldorf
		https://www.cai.hhu.de/en/equipment/super-resolution-microscopy/leica-tcs-sp8-sted-3x
		Singer et al., 2017; H&amp;auml;nsch et al., 2020
	
	
		9
		Nikon Instruments
		Eclipse Ti
		2
		Immunofluorescence analysis of the cytoskeleton structure in COS cells
		Advanced Imaging Center (AIC)
		Janelia Research Campus, Howard Hughes Medical Institute
		https://www.janelia.org/support-team/light-microscopy/equipment
		Abdelfattah et al., 2019; Qian et al., 2019; Grimm et al., 2020
	
	
		10
		Nikon Instruments
		Eclipse Ti-E (HCA)
		2
		&amp;Tau;ime-lapse analysis of the bursting behavior of amine-functionalized vesicular assemblies
		Light Microscopy Facility (IALS-LIF)
		Institute for Applied Life Sciences, University of Massachusetts at Amherst
		https://www.umass.edu/ials/light-microscopy
		Fernandez et al., 2020
	
	
		11
		Nikon Instruments/Coleman laboratory (customized)
		TIRF HILO Epifluorescence light Microscope (THEM)/ Eclipse Ti
		2
		Single-particle tracking of Halo-tagged PCNA in Lox cells
		Coleman laboratory
		Anatomy and Structural Biology Department, The Albert Einstein College of Medicine
		https://einsteinmed.org/faculty/12252/robert-coleman/
		Drosopoulos et al., 2020
	
	
		12
		Nikon Instruments
		Eclipse Ti (with Andor Dragon Fly Spinning Disk)
		2
		Investigation of the 3D structure of cerebral organoids
		Montpellier Resources Imagerie
		Centre de Recherche de Biologie cellulaire de Montpellier (MRI-CRBM), CNRS, Univerity of Montpellier
		https://www.mri.cnrs.fr/en/optical-imaging/our-facilities/mri-crbm.html
		Ayala-Nunez et al., 2019
	
	
		13
		Nikon Instruments
		Eclipse Ti2
		2
		&amp;Iota;mmunofluorescence imaging of cryosections of mouse hearth myocardium&amp;nbsp;
		Neuroscience Center Microscopy Core
		Neuroscience Center, University of North Carolina
		https://www.med.unc.edu/neuroscience/core-facilities/neuro-microscopy/
		Aghajanian et al., 2021
	
	
		14
		Nikon Instruments
		Eclipse Ti2
		2
		Live-cell imaging of bacterial cells expressing GFP-PopZ
		Microscopy Resources on the North Quad (MicRoN)
		Harvard Medical School&amp;nbsp;
		https://micron.hms.harvard.edu/
		Lim and Bernhardt 2019; Lim et al., 2019
	
	
		15
		Olympus/Biomedical Imaging Group (customized)
		TIRF Epifluorescence Structured light Microscope (TESM)/IX71
		3
		3D distribution of HIV-1 in the nucleus of human cells
		Biomedical Imaging Group
		Program in Molecular Medicine, University of Massachusetts Medical School
		https://trello.com/b/BQ8zCcQC/tirf-epi-fluorescence-structured-light-microscope
		Navaroli et al., 2012
	
	
		16
		Olympus/Computer Vision Laboratory (customized)
		3D BrightField Scanner/IX71
		3
		Transmitted light brightfield visualization of swimming spermatocytes
		Laboratorio Nacional de Microscopia Avanzada (LNMA) and Computer Vision Laboratory of the Institute of Biotechnology
		Universidad Nacional Autonoma de Mexico (UNAM)
		https://lnma.unam.mx/wp/
		Pimentel et al., 2012; Silva-Villalobos et al., 2014
</pre></div>
</div>
<p>Getting started</p>
<p>Use these videos to get started with using Micro-Meta App after installation into OMERO and downloading the example data files:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Video 1
Video 2
</pre></div>
</div>
<p>More information</p>
<p>For full information on how to use Micro-Meta App please utilize the following resources:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Micro-Meta App website
Full documentation
Installation instructions
Step-by-Step Instructions
Tutorial Videos
</pre></div>
</div>
<p>Background</p>
<p>If you want to learn more about the importance of metadata and quality control to ensure full reproducibility, quality and scientific value in light microscopy, please take a look at our recent publications describing the development of community-driven light 4DN-BINA-OME Microscopy Metadata specifications Nature Methods and <a class="reference external" href="http://BioRxiv.org">BioRxiv.org</a> and our overview manuscript entitled A perspective on Microscopy Metadata: data provenance and quality control.</p>
<p> </p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/5847477">https://zenodo.org/records/5847477</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5847477">https://doi.org/10.5281/zenodo.5847477</a></p>
</section>
<hr class="docutils" />
<section id="example-operetta-dataset">
<h2>Example Operetta Dataset<a class="headerlink" href="#example-operetta-dataset" title="Link to this heading">#</a></h2>
<p>Nicolas Chiaruttini</p>
<p>Published 2023-07-17</p>
<p>Licensed CC-BY-4.0</p>
<p>This is a microscopy image dataset generated by the Perkin Elmer Operetta HCS microscope by of the user of the PTBIOP EPFL facility.</p>
<p>As of the 17th of July 2023, opening this file in ImageJ/Fiji using the BioFormats 6.14 library, this dataset generates a Null Pointer Exception.</p>
<p>A post on <a class="reference external" href="http://forum.image.sc">forum.image.sc</a> is linked to this issue:</p>
<p><a class="reference external" href="https://forum.image.sc/t/null-pointer-exception-in-perkin-elmer-operetta-dataset-with-bio-formats-6-14/83784">https://forum.image.sc/t/null-pointer-exception-in-perkin-elmer-operetta-dataset-with-bio-formats-6-14/83784</a></p>
<p> </p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/8153907">https://zenodo.org/records/8153907</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8153907">https://doi.org/10.5281/zenodo.8153907</a></p>
</section>
<hr class="docutils" />
<section id="excel-template-for-adding-key-value-pairs-to-images">
<h2>Excel template for adding Key-Value Pairs to images<a class="headerlink" href="#excel-template-for-adding-key-value-pairs-to-images" title="Link to this heading">#</a></h2>
<p>Thomas Zobel, Jens Wendt</p>
<p>Published 2024-10-30</p>
<p>Licensed CC-BY-4.0</p>
<p>This Excel Workbook contains some simple Macros to help with the generation of a .csv in the necessary format for Key-Value pair annotations of images in OMERO.
The format is tailored for the <a class="reference external" href="http://OMERO.web">OMERO.web</a> script “KeyVal_from_csv.py”  (from the version &lt;=5.8.3 of the core omero-scripts).
Attached is also a video of Thomas Zobel, the head of the imaging core facility Uni Münster, showcasing the use of the Excel workbook.The video uses a slightly older version of the workbook and OMERO, but the core functionality remains unchanged.
Please keep in mind, that the <a class="reference external" href="http://OMERO.web">OMERO.web</a> script(s) to handle Key-Value Pairs from/to .csv files will undergo a major change very soon.This might break the compatibility with the format used now for the generated .csv from the workbook.</p>
<p><a class="reference external" href="https://zenodo.org/records/14014252">https://zenodo.org/records/14014252</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14014252">https://doi.org/10.5281/zenodo.14014252</a></p>
</section>
<hr class="docutils" />
<section id="forschungsdatenmanagement-zukunftsfest-gestalten-impulse-fur-die-strukturevaluation-der-nationalen-forschungsdateninfrastruktur-nfdi">
<h2>Forschungsdatenmanagement zukunftsfest gestalten – Impulse für die   Strukturevaluation der Nationalen Forschungsdateninfrastruktur (NFDI)<a class="headerlink" href="#forschungsdatenmanagement-zukunftsfest-gestalten-impulse-fur-die-strukturevaluation-der-nationalen-forschungsdateninfrastruktur-nfdi" title="Link to this heading">#</a></h2>
<p>Steuerungsgremium Allianz-Schwerpunkt, Alexander von Humboldt Foundation, Deutsche Forschungsgemeinschaft, Fraunhofer Society, German Rectors’ Conference, Leibniz Association, German National Academy of Sciences Leopoldina, German Academic Exchange Service, Helmholtz Association of German Research Centres, Max Planck Society</p>
<p>Published 2024-11-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Arbeitspapier des Steuerungsgremiums des Allianz-Schwerpunkts “Digitalität in der Wissenschaft”</p>
<p><a class="reference external" href="https://zenodo.org/records/14032908">https://zenodo.org/records/14032908</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14032908">https://doi.org/10.5281/zenodo.14032908</a></p>
</section>
<hr class="docutils" />
<section id="from-cells-to-pixels-bridging-biologists-and-image-analysts-through-a-common-language">
<h2>From Cells to Pixels: Bridging Biologists and  Image Analysts Through a Common Language<a class="headerlink" href="#from-cells-to-pixels-bridging-biologists-and-image-analysts-through-a-common-language" title="Link to this heading">#</a></h2>
<p>Elnaz Fazeli, Haase Robert, Doube Michael, Miura Kota, Legland David</p>
<p>Published 2024-08-16</p>
<p>Licensed CC-BY-4.0</p>
<p>Bioimaging has transformed our understanding of biological processes, yet extracting meaningful information from complex datasets remains a challenge, particularly for early career scientists. This paper proposes a simplified, systematic approach to bioimage analysis, focusing on categorizing commonly observed structures and shapes, and providing relevant analysis methods. Our approach includes illustrative examples and a visual flowchart, enabling researchers to define analysis objectives clearly. By understanding the diversity of bioimage structures and aligning them with appropriate analysis approaches, the framework empowers researchers to navigate bioimage datasets more efficiently. It also aims to foster a common language between researchers and analysts, thereby enhancing mutual understanding and facilitating effective communication.</p>
<p><a class="reference external" href="https://zenodo.org/records/13331351">https://zenodo.org/records/13331351</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13331351">https://doi.org/10.5281/zenodo.13331351</a></p>
</section>
<hr class="docutils" />
<section id="from-paper-to-pixels-navigation-through-your-research-data-presentations-of-speakers">
<h2>From Paper to Pixels: Navigation through your Research Data - presentations of speakers<a class="headerlink" href="#from-paper-to-pixels-navigation-through-your-research-data-presentations-of-speakers" title="Link to this heading">#</a></h2>
<p>Marcelo Zoccoler, Simon Bekemeier, Tom Boissonnet, Simon Parker, Luca Bertinetti, Marc Gentzel, Riccardo Massei, Cornelia Wetzker</p>
<p>Published 2024-06-10</p>
<p>Licensed CC-BY-4.0</p>
<p>The workshop introduced key topics of research data management (RDM) and the implementation thereof on a life science campus. Internal and external experts of RDM including scientists that apply chosen software tools presented the basic concepts and their implementation to a broad audience. 
Talks covered general aspects of data handling and sorting, naming conventions, data storage repositories and archives, licensing of material, data and code management using git, data protection particularly regarding patient data and in genome sequencing and more. Two data management concepts and exemplary tools were highlighted in particular, being electronic lab notebooks with eLabFTW and the bio-image management software OMERO. Those were chosen because of three aspects: the large benefit of these management tools for a life science campus, their free availability as open source tools with the option of contribution of required functionalities and first existing use cases on campus already supported by CMCB/PoL IT.
Two talks by Robert Haase (<a class="reference external" href="http://ScaDS.AI/">ScaDS.AI/</a> Uni Leipzig) and Robert Müller (Kontaktstelle Forschungsdaten, TU Dresden with contributions from Denise Dörfel) that opened the symposium were shared independently:
<a class="reference external" href="https://zenodo.org/records/11382341">https://zenodo.org/records/11382341</a>
<a class="reference external" href="https://zenodo.org/records/11261115">https://zenodo.org/records/11261115</a>
The workshop organization was funded by the CMCB/PoL Networking Grant and supported by the consortium NFDI4BIOIMAGE (funded by DFG grant number NFDI 46/1, project number 501864659).</p>
<p>Tags: Research Data Management</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/11548617">https://zenodo.org/records/11548617</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11548617">https://doi.org/10.5281/zenodo.11548617</a></p>
</section>
<hr class="docutils" />
<section id="gerbi-chat-teil-1-vom-bedarf-bis-zum-groszgerateantrag-schreiben">
<h2>GerBI-Chat: Teil 1 - Vom Bedarf bis zum Großgeräteantrag-Schreiben<a class="headerlink" href="#gerbi-chat-teil-1-vom-bedarf-bis-zum-groszgerateantrag-schreiben" title="Link to this heading">#</a></h2>
<p>Financial &amp; Legal Framework of Core Facilities, Elmar Endl, Jana Hedrich, Juliane Hoth, Julia Nagy, Astrid Schauss, Nina Schulze, Silke Tulok</p>
<p>Published 2024-09-11</p>
<p>Licensed CC-BY-4.0</p>
<p>Die GermanBioImaging (GerBI-GMB) - Deutsche Gesellschaft für Mikroskopie und Bildanalyse e.V. bietet über regelmäßig stattfindende Treffen (GerBI-Chats) die Möglichkeit zum aktiven Austausch der Mitglieder untereinander. Das GerBI-GMB Team “Legal und Finacial Framwork”, welches sich mit administrativen Aufgaben rund um das Core Facility Management beschäftigt, nutzt diese Möglichkeit zum aktiven Austausch innerhalb des Netzwerkes und darüber hinaus. 
Der Beschaffungsprozess von Forschungsgroßgeräten ist komplex und je nach Institution unterschiedlich geregelt. Aus unserer Sicht lässt sich dieser Prozess grob in drei Stufen aufteilen:</p>
<p>Bedarfsanmeldung
Antragsvorbereitung und -fertigstellung
Antragsbewilligung und Nutzung </p>
<p>Dieser hier enthaltene Beitrag ist der Initialvortrag des GerBi-Chats zum Teil 1 - Von der Bedarfsanmeldung bis zum Beginn der Antragststellung. Die weiteren Stufen der Großgerätebeschaffung werden in nachfolgenden Beiträgen behandelt.</p>
<p><a class="reference external" href="https://zenodo.org/records/13810879">https://zenodo.org/records/13810879</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13810879">https://doi.org/10.5281/zenodo.13810879</a></p>
</section>
<hr class="docutils" />
<section id="gerbi-chat-teil-2-wie-schreibe-ich-am-besten-einen-groszegrateantrag">
<h2>GerBI-Chat: Teil 2 - Wie schreibe ich am besten einen Großegräteantrag<a class="headerlink" href="#gerbi-chat-teil-2-wie-schreibe-ich-am-besten-einen-groszegrateantrag" title="Link to this heading">#</a></h2>
<p>Financial &amp; Legal Framework of Core Facilities, Elmar Endl, Jana Hedrich, Juliane Hoth, Julia Nagy, Astrid Schauss, Nina Schulze, Silke Tulok</p>
<p>Published 2024-10-02</p>
<p>Licensed CC-BY-4.0</p>
<p>Die GermanBioImaging (GerBI-GMB) - Deutsche Gesellschaft für Mikroskopie und Bildanalyse e.V. bietet über regelmäßig stattfindende Treffen (GerBI-Chats) die Möglichkeit zum aktiven Austausch der Mitglieder untereinander. Das GerBI-GMB Team “Legal und Finacial Framwork”, welches sich mit administrativen Aufgaben rund um das Core Facility Management beschäftigt, nutzt diese Möglichkeit zum aktiven Austausch innerhalb des Netzwerkes und darüber hinaus. 
Der Beschaffungsprozess von Forschungsgroßgeräten ist komplex und je nach Institution unterschiedlich geregelt. Aus unserer Sicht lässt sich dieser Prozess grob in drei Stufen aufteilen:</p>
<p>Bedarfsanmeldung
Antragsvorbereitung und -fertigstellung
Antragsbewilligung und Nutzung </p>
<p>Nach dem Initialvortrag der GerBI-Chat Reihe, in dem das Thema Bedarfsanmeldung im Fokus stand, geht es im hier enthaltenen zweiten Teil „Antragsvorbereitung und -fertigstellung: Wie schreibe ich am besten einen Großgeräteantrag?“ um die Beantragung von Forschungsgroßgeräten nach Art. 91b GG.</p>
<p><a class="reference external" href="https://zenodo.org/records/13807114">https://zenodo.org/records/13807114</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13807114">https://doi.org/10.5281/zenodo.13807114</a></p>
</section>
<hr class="docutils" />
<section id="getting-started-with-python-intro-and-set-up-a-conda-environment">
<h2>Getting started with Python: intro and set-up a conda environment<a class="headerlink" href="#getting-started-with-python-intro-and-set-up-a-conda-environment" title="Link to this heading">#</a></h2>
<p>Riccardo Massei</p>
<p>Published 2024-10-09</p>
<p>Licensed CC-BY-4.0</p>
<p>YMIA python event 2024
Presentation :  “Getting started with Python: intro and set-up a conda environment with Dr. Riccardo Massei”</p>
<p><a class="reference external" href="https://zenodo.org/records/13908480">https://zenodo.org/records/13908480</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13908480">https://doi.org/10.5281/zenodo.13908480</a></p>
</section>
<hr class="docutils" />
<section id="gut-analysis-toolbox">
<h2>Gut Analysis Toolbox<a class="headerlink" href="#gut-analysis-toolbox" title="Link to this heading">#</a></h2>
<p>Luke Sorensen, Ayame Saito, Sabrina Poon, Noe Han, Myat, Ryan Hamnett, Peter Neckel, Adam Humenick, Keith Mutunduwe, Christie Glennan, Narges Mahdavian, JH Brookes, Simon, M McQuade, Rachel, PP Foong, Jaime, Estibaliz Gómez-de-Mariscal, Muñoz Barrutia, Arrate, Kaltschmidt, Julia A., King, Sebastian K., Robert Haase, Simona Carbone, A. Veldhuis, Nicholas, P. Poole, Daniel, Pradeep Rajasekhar</p>
<p>Published 2024-09-10</p>
<p>Licensed CC-BY-4.0</p>
<p>What’s Changed</p>
<p>Updating User Dialogs by &#64;mattyrowey in <a class="github reference external" href="https://github.com/pr4deepr/GutAnalysisToolbox/pull/18">pr4deepr/GutAnalysisToolbox#18</a>
Added Dialog Boxes and Grammar Corrections by &#64;mattyrowey in <a class="github reference external" href="https://github.com/pr4deepr/GutAnalysisToolbox/pull/19">pr4deepr/GutAnalysisToolbox#19</a>
Updated Dialog Prompts for Clarity by &#64;mattyrowey in <a class="github reference external" href="https://github.com/pr4deepr/GutAnalysisToolbox/pull/20">pr4deepr/GutAnalysisToolbox#20</a>
Batch analysis option added.
fixed a bunch of bugs related to ganglia segmentation and user workflow</p>
<p>New Contributors</p>
<p>&#64;mattyrowey made their first contribution in <a class="github reference external" href="https://github.com/pr4deepr/GutAnalysisToolbox/pull/18">pr4deepr/GutAnalysisToolbox#18</a></p>
<p>Full Changelog: <a class="reference external" href="https://github.com/pr4deepr/GutAnalysisToolbox/compare/v0.6...v0.7">https://github.com/pr4deepr/GutAnalysisToolbox/compare/v0.6…v0.7</a></p>
<p><a class="reference external" href="https://zenodo.org/records/13739137">https://zenodo.org/records/13739137</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13739137">https://doi.org/10.5281/zenodo.13739137</a></p>
</section>
<hr class="docutils" />
<section id="gut-analysis-toolbox-training-data-and-2d-models-for-segmenting-enteric-neurons-neuronal-subtypes-and-ganglia">
<h2>Gut Analysis Toolbox: Training data and 2D models for segmenting enteric neurons, neuronal subtypes and ganglia<a class="headerlink" href="#gut-analysis-toolbox-training-data-and-2d-models-for-segmenting-enteric-neurons-neuronal-subtypes-and-ganglia" title="Link to this heading">#</a></h2>
<p>Luke Sorensen, Ayame Saito, Sabrina Poon, Myat Noe Han, Adam Humenick, Peter Neckel, Keith Mutunduwe, Christie Glennan, Narges Mahdavian, Simon JH Brookes, Rachel M McQuade, Jaime PP Foong, Sebastian K. King, Estibaliz  Gómez-de-Mariscal, Arrate Muñoz-Barrutia, Robert Haase, Simona Carbone, Nicholas A. Veldhuis, Daniel P. Poole, Pradeep Rajasekhar</p>
<p>Published 2022-02-15</p>
<p>Licensed CC-BY-4.0</p>
<p>This upload is associated with the software, Gut Analysis Toolbox (GAT).
If you use it please cite:
Sorensen et al. Gut Analysis Toolbox: Automating quantitative analysis of enteric neurons. J Cell Sci 2024; jcs.261950. doi: <a class="reference external" href="https://doi.org/10.1242/jcs.261950">https://doi.org/10.1242/jcs.261950</a>
The upload contains StarDist models for segmenting enteric neurons in 2D, enteric neuronal subtypes in 2D and UNet model for enteric ganglia in 2D in gut wholemount tissue. GAT is implemented in Fiji, but the models can be used in any software that supports StarDist and the use of 2D UNet models. The files here also consist of Python notebooks (Google Colab), training and test data as well as reports on model performance.
The model files are located in the respective folders as zip files. The folders have also been zipped:</p>
<p>Neuron (Hu; StarDist model):</p>
<p>Main folder: 2D_enteric_neuron_model_QA.zip
Model File:2D_enteric_neuron_v4_1.zip </p>
<p>Neuronal subtype (StarDist model): </p>
<p>Main folder: 2D_enteric_neuron_subtype_model_QA.zip
Model File: 2D_enteric_neuron_subtype_v4.zip</p>
<p>Enteric ganglia (2D UNet model; Use in FIJI with deepImageJ)</p>
<p>Main folder: 2D_enteric_ganglia_model_QA.zip
Model File: 2D_Ganglia_RGB_v2.bioimage.io.model.zip (Compatible with deepimageJ v3)</p>
<p>For the all models, files included are:</p>
<p>Model for segmenting cells or ganglia in 2D FIJI. StarDist or 2D UNet.
Training and Test datasets used for training.
Google Colab notebooks used for training and quality assurance (ZeroCost DL4Mic notebooks).
Quality assurance reports generated from above notebooks.
StarDist model exported for use in QuPath.</p>
<p>The model files can be used within can be used within the software, StarDist. They are intended to be used within FIJI or QuPath, but can be used in any software that supports the implementation of StarDist in 2D.
Data:
All the images were collected from 4 different research labs and a public database (SPARC database) to account for variations in image acquisition, sample preparation and immunolabelling.
For enteric neurons the pan-neuronal marker, Hu has been used and the  2D wholemounts images from mouse, rat and human tissue.
For enteric neuronal subtypes, 2D images for nNOS, MOR, DOR, ChAT, Calretinin, Calbindin, Neurofilament, CGRP and SST from mouse tissue have been used..
25 images were used from the following entries in the SPARC database:</p>
<p>Howard, M. (2021). 3D imaging of enteric neurons in mouse (Version 1) [Data set]. SPARC Consortium.
Graham, K. D., Huerta-Lopez, S., Sengupta, R., Shenoy, A., Schneider, S., Wright, C. M., Feldman, M., Furth, E., Lemke, A., Wilkins, B. J., Naji, A., Doolin, E., Howard, M., &amp; Heuckeroth, R. (2020). Robust 3-Dimensional visualization of human colon enteric nervous system without tissue sectioning (Version 1) [Data set]. SPARC Consortium.
Wang, L., Yuan, P.-Q., Gould, T. and Tache, Y. (2021). Antibodies Tested in theColon – Mouse (Version 1) [Data set]. SPARC Consortium. doi:10.26275/i7dl-58h</p>
<p>The images have been acquired using a combination different microscopes. The images for the mouse tissue were acquired using: </p>
<p>Leica TCS-SP8 confocal system (20x HC PL APO NA 1.33, 40 x HC PL APO NA 1.3) </p>
<p>Leica TCS-SP8 lightning confocal system (20x HC PL APO NA 0.88) </p>
<p>Zeiss Axio Imager M2 (20X HC PL APO NA 0.3) </p>
<p>Zeiss Axio Imager Z1 (10X HC PL APO NA 0.45) </p>
<p>Human tissue images were acquired using: </p>
<p>IX71 Olympus microscope (10X HC PL APO NA 0.3) </p>
<p>For more information, visit the Documentation website.
NOTE: The images for enteric neurons and neuronal subtypes have been rescaled to 0.568 µm/pixel for mouse and rat. For human neurons, it has been rescaled to 0.9 µm/pixel . This is to ensure the neuronal cell bodies have similar pixel area across images. The area of cells in pixels can vary based on resolution of image, magnification of objective used, animal species (larger animals -&gt; larger neurons) and potentially how the tissue is stretched during wholemount preparation 
Average neuron area for neuronal model: 701.2 ± 195.9 pixel2 (Mean ± SD, 6267 cells)
Average neuron area for neuronal subtype model: 880.9 ± 316 pixel2 (Mean ± SD, 924 cells)
Software References:
Stardist
Schmidt, U., Weigert, M., Broaddus, C., &amp; Myers, G. (2018, September). Cell detection with star-convex polygons. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 265-273). Springer, Cham.
deepImageJ
Gómez-de-Mariscal, E., García-López-de-Haro, C., Ouyang, W., Donati, L., Lundberg, E., Unser, M., Muñoz-Barrutia, A. and Sage, D., 2021. DeepImageJ: A user-friendly environment to run deep learning models in ImageJ. Nature Methods, 18(10), pp.1192-1195.
ZeroCost DL4Mic
von Chamier, L., Laine, R.F., Jukkala, J., Spahn, C., Krentzel, D., Nehme, E., Lerche, M., Hernández-Pérez, S., Mattila, P.K., Karinou, E. and Holden, S., 2021. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nature communications, 12(1), pp.1-18.</p>
<p><a class="reference external" href="https://zenodo.org/records/10460434">https://zenodo.org/records/10460434</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10460434">https://doi.org/10.5281/zenodo.10460434</a></p>
</section>
<hr class="docutils" />
<section id="hackaton-results-conversion-of-knime-image-analysis-workflows-to-galaxy">
<h2>Hackaton Results - Conversion of KNIME image analysis workflows to Galaxy<a class="headerlink" href="#hackaton-results-conversion-of-knime-image-analysis-workflows-to-galaxy" title="Link to this heading">#</a></h2>
<p>Riccardo Massei</p>
<p>Published 2024-03-07</p>
<p>Licensed CC-BY-4.0</p>
<p>Results of the project “Conversion of KNIME image analysis workflows to Galaxy” during the Hackathon “Image Analysis in Galaxy” (Freiburg 26 Feb - 01 Mar 2024)
 </p>
<p><a class="reference external" href="https://zenodo.org/records/10793700">https://zenodo.org/records/10793700</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10793700">https://doi.org/10.5281/zenodo.10793700</a></p>
</section>
<hr class="docutils" />
<section id="hela-kyoto-cells-under-the-scope">
<h2>HeLa “Kyoto” cells under the scope<a class="headerlink" href="#hela-kyoto-cells-under-the-scope" title="Link to this heading">#</a></h2>
<p>Romain Guiet</p>
<p>Published 2022-02-25</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: HeLa “Kyoto” cells under the scope</p>
<p>Microscope: Perkin Elmer Operetta microscope with a 20x N.A. 0.8 objective and an Andor Zyla 5.5 camera.</p>
<p>Microscopy data type: The time-lapse datasets were acquired every 15 minutes, for 60 hours. From the individual plan images (channels, time-points, field of view exported by the PerkinElmer software Harmony) multi-dimension images were generated using the Operetta_Importer-0.1.21  with a downscaling of 4. </p>
<p>Channel 1 : Low Contrast DPC (Digital Phase Contrast)</p>
<p>Channel 2 : High Contrast DPC</p>
<p>Channel 3 : Brightfield</p>
<p>Channel 4 : EGFP-α-tubulin</p>
<p>Channel 5 : mCherry-H2B</p>
<p>File format: .tif (16-bit)</p>
<p>Image size: 540x540 (Pixel size: 0.299 nm), 5c, 1z , 240t</p>
<p> </p>
<p>Cell type: HeLa “Kyoto” cells, expressing EGFP-α-tubulin and mCherry-H2B ( Schmitz et al, 2010 )</p>
<p>Protocol: Cells were resuspended in Imaging media and were seeded in a microscopy grade 96 wells plate ( CellCarrier Ultra 96, Perkin Elmer). The day after seeding, and for 60 hours, images were acquired in 3 wells, in 25 different fields of view, every 15 minutes.</p>
<p>Imaging media: DMEM red-phenol-free media (FluoroBrite™ DMEM, Gibco) complemented with Fetal Calf Serum and Glutamax.</p>
<p> </p>
<p>NOTE: This dataset was used to automatically generate label images in the following Zenodo entry:  <a class="reference external" href="https://doi.org/10.5281/zenodo.6140064">https://doi.org/10.5281/zenodo.6140064</a></p>
<p>NOTE: This dataset was used to train the cellpose models in the following Zenodo entry: <a class="reference external" href="https://doi.org/10.5281/zenodo.6140111">https://doi.org/10.5281/zenodo.6140111</a></p>
<p><a class="reference external" href="https://zenodo.org/records/6139958">https://zenodo.org/records/6139958</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6139958">https://doi.org/10.5281/zenodo.6139958</a></p>
</section>
<hr class="docutils" />
<section id="high-throughput-automated-data-analysis-and-data-management-workflow-with-cellprofiler-and-omero">
<h2>High throughput &amp; automated data analysis and data management workflow with Cellprofiler and OMERO<a class="headerlink" href="#high-throughput-automated-data-analysis-and-data-management-workflow-with-cellprofiler-and-omero" title="Link to this heading">#</a></h2>
<p>Sarah Weischer, Jens Wendt, Thomas Zobel</p>
<p>Licensed CC-BY-4.0</p>
<p>In this workshop a fully integrated data analysis solutions employing OMERO and commonly applied image analysis tools (e.g., CellProfiler, Fiji) using existing python interfaces (OMERO Python language bindings, ezOmero, Cellprofiler Python API) is presented.</p>
<p>Tags: OMERO, Data Analysis, Bioimage Analysis</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.8139353">https://zenodo.org/doi/10.5281/zenodo.8139353</a></p>
</section>
<hr class="docutils" />
<section id="human-dab-staining-axioscan-bf-20x">
<h2>Human DAB staining Axioscan BF 20x<a class="headerlink" href="#human-dab-staining-axioscan-bf-20x" title="Link to this heading">#</a></h2>
<p>Mario Garcia</p>
<p>Published 2024-05-21</p>
<p>Licensed CC-BY-4.0</p>
<p>Human brain tissue with DAB immunostaining. Image acquired by BF microscopy in  Zeiss Axioscan at 20x. </p>
<p><a class="reference external" href="https://zenodo.org/records/11234863">https://zenodo.org/records/11234863</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11234863">https://doi.org/10.5281/zenodo.11234863</a></p>
</section>
<hr class="docutils" />
<section id="i3d-bio-s-omero-training-material-re-usable-adjustable-multi-purpose-slides-for-local-user-training">
<h2>I3D:bio’s OMERO training material: Re-usable, adjustable, multi-purpose slides for local user training<a class="headerlink" href="#i3d-bio-s-omero-training-material-re-usable-adjustable-multi-purpose-slides-for-local-user-training" title="Link to this heading">#</a></h2>
<p>Christian Schmidt, Michele Bortolomeazzi, Tom Boissonnet, Carsten Fortmann-Grote, Julia Dohle, Peter Zentis, Niraj Kandpal, Susanne Kunis, Thomas Zobel, Stefanie Weidtkamp-Peters, Elisa Ferrando-May</p>
<p>Published 2023-11-13</p>
<p>Licensed CC-BY-4.0</p>
<p>The open-source software OME Remote Objects (OMERO) is a data management software that allows storing, organizing, and annotating bioimaging/microscopy data. OMERO has become one of the best-known systems for bioimage data management in the bioimaging community. The Information Infrastructure for BioImage Data (I3D:bio) project facilitates the uptake of OMERO into research data management (RDM) practices at universities and research institutions in Germany. Since the adoption of OMERO into researchers’ daily routines requires intensive training, a broad portfolio of training resources for OMERO is an asset. On top of using the OMERO guides curated by the Open Microscopy Environment Consortium (OME) team, imaging core facility staff at institutions where OMERO is used often prepare additional material tailored to be applicable for their own OMERO instances. Based on experience gathered in the Research Data Management for Microscopy group (RDM4mic) in Germany, and in the use cases in the I3D:bio project, we created a set of reusable, adjustable, openly available slide decks to serve as the basis for tailored training lectures, video tutorials, and self-guided instruction manuals directed at beginners in using OMERO. The material is published as an open educational resource complementing the existing resources for OMERO contributed by the community.</p>
<p>Tags: OMERO, Research Data Management, Nfdi4Bioimage, I3Dbio</p>
<p>Content type: Slide, Video</p>
<p><a class="reference external" href="https://zenodo.org/records/8323588">https://zenodo.org/records/8323588</a></p>
<p><a class="reference external" href="https://www.youtube.com/playlist?list=PL2k-L-zWPoR7SHjG1HhDIwLZj0MB_stlU">https://www.youtube.com/playlist?list=PL2k-L-zWPoR7SHjG1HhDIwLZj0MB_stlU</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8323588">https://doi.org/10.5281/zenodo.8323588</a></p>
</section>
<hr class="docutils" />
<section id="ics-ids-stitched-file">
<h2>ICS/IDS stitched file<a class="headerlink" href="#ics-ids-stitched-file" title="Link to this heading">#</a></h2>
<p>IMCF</p>
<p>Published 2024-06-13</p>
<p>Licensed CC-BY-4.0</p>
<p>Hi &#64;ome team !
We usually use ICS/IDS file formats as an output to our stitching pipeline as the reading and writing is pretty fast. However, it seems that since Bio-Formats 7.x opening the files is not working anymore.
I tried with a Fiji with Bio-Formats 6.10.1 and the files open, but more recent versions give an issue.
 
java.lang.NullPointerException
at loci.formats.in.ICSReader.initFile(ICSReader.java:1481)
at loci.formats.FormatReader.setId(FormatReader.java:1480)
at loci.plugins.in.ImportProcess.initializeFile(ImportProcess.java:498)
at loci.plugins.in.ImportProcess.execute(ImportProcess.java:141)
at loci.plugins.in.Importer.showDialogs(Importer.java:156)
at loci.plugins.in.Importer.run(Importer.java:77)
at loci.plugins.LociImporter.run(LociImporter.java:78)
at ij.IJ.runUserPlugIn(IJ.java:244)
at ij.IJ.runPlugIn(IJ.java:210)
at ij.Executer.runCommand(Executer.java:152)
at ij.Executer.run(Executer.java:70)
at ij.IJ.run(IJ.java:326)
at ij.IJ.run(IJ.java:337)
at ij.macro.Functions.doRun(Functions.java:703)
at ij.macro.Functions.doFunction(Functions.java:99)
at ij.macro.Interpreter.doStatement(Interpreter.java:281)
at ij.macro.Interpreter.doStatements(Interpreter.java:267)
at ij.macro.Interpreter.run(Interpreter.java:163)
at ij.macro.Interpreter.run(Interpreter.java:93)
at ij.macro.MacroRunner.run(MacroRunner.java:146)
at java.lang.Thread.run(Thread.java:750)</p>
<p>You can find one example file at this link 1.
Thanks for your help !Best,Laurent</p>
<p><a class="reference external" href="https://zenodo.org/records/11637422">https://zenodo.org/records/11637422</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11637422">https://doi.org/10.5281/zenodo.11637422</a></p>
</section>
<hr class="docutils" />
<section id="image-repository-decision-tree-where-do-i-deposit-my-imaging-data">
<h2>Image Repository Decision Tree - Where do I deposit my imaging data<a class="headerlink" href="#image-repository-decision-tree-where-do-i-deposit-my-imaging-data" title="Link to this heading">#</a></h2>
<p>Kemmer, Isabel, Romdhane, Feriel, Euro-BioImaging ERIC</p>
<p>Published 2024-10-22</p>
<p>Licensed CC-BY-4.0</p>
<p>Depositing data in quality data repositories is one crucial step towards FAIR (Findable, Accessible, Interoperable, and Reusable) data. Accordingly, Euro-BioImaging strongly encourages sharing scientific imaging data in established, thematic repositories. 
To guide you in the selection of appropriate repositories, we have created an overview of available repositories for different types of image data, including their scope and requirements. This decision tree guides you through questions about your data and directs you to the correct repository, and/or provides instructions for further processing to meet the critera of the repositories. 
Three seperate trees are provided for different classes of imaging data: open bioimage data, preclinical data, and human imaging data. </p>
<p><a class="reference external" href="https://zenodo.org/records/13945179">https://zenodo.org/records/13945179</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13945179">https://doi.org/10.5281/zenodo.13945179</a></p>
</section>
<hr class="docutils" />
<section id="imagej-tool-for-percentage-estimation-of-pneumonia-in-lungs">
<h2>ImageJ tool for percentage estimation of pneumonia in lungs<a class="headerlink" href="#imagej-tool-for-percentage-estimation-of-pneumonia-in-lungs" title="Link to this heading">#</a></h2>
<p>Martin Schätz, Olga Rubešová, Jan Mareš, Alan Spark</p>
<p>Published 2023-05-02</p>
<p>Licensed CC-BY-4.0</p>
<p>The software tool is developed on demand of Radiological Department of Faculty Hospital of Královské Vinohrady, with the aim to provide a tool to estimate the percentage of pneumonia (or COVID-19 presence) in lungs. Paper Estimation of Covid-19 lungs damage based on computer tomography images analysis presenting the tool is available on F1000reserach DOI: 10.12688/f1000research.109020.1. The underlying dataset is published in Zenodo (DOI:10.5281/zenodo.5805939). One of the challenges was to design a tool that would be available without complicated install procedures and would process data in a reasonable time even on office computers. For this reason, 8-bit and 16-bit version of the tool exists. The FIJI software (or ImageJ with Bio-Formats plugin installed) was selected as the best candidate. Examples of use and tutorials are available at GitHub. </p>
<p>Underlying data:
DOI:10.5281/zenodo.5805939
The first five datasets are analyzed using this tool, with results and parameters to repeat the analysis in results_csv.csv or results.xlsx.</p>
<p>Contributions:
Martin SCHÄTZ:       Coding, tool testing, data curation, data set analysis
Olga RUBEŠOVÁ:    Code review, tutorial preparation, tool testing, data set analysis
Jan MAREŠ:             Tool testing, data set analysis
Alan SPARK:             Tool testing</p>
<p>The work was funded by the Ministry of Education, Youth and Sports by grant ‘Development of Advanced Computational Algorithms for evaluating post-surgery rehabilitation’ number LTAIN19007. The work was also supported from the grant of Specific university research – grant No FCHI 2022-001.</p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/7885379">https://zenodo.org/records/7885379</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7885379">https://doi.org/10.5281/zenodo.7885379</a></p>
</section>
<hr class="docutils" />
<section id="implantation-of-abdominal-imaging-windows-on-the-mouse-kidney">
<h2>Implantation of abdominal imaging windows on the mouse kidney<a class="headerlink" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-kidney" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-09-04</p>
<p>Licensed CC-BY-ND-4.0</p>
<p>This video describes the surgical process of implanting an abdominal imaging window (AIW) on the kidney of mice. This window can be used for acute or longitudinal imaging. All experiments have been reviewed and approved by the local authorities (Landesdirektion Sachsen).
Implantation of chronic abdominal windows allows for microscopical investigation of highly dynamic processes in physiological and pathological circumstances and is generally tolerated well by experimental animals. It enables insights which otherwise could only be obtained using high numbers of experimental animals. The method can be regarded as reduction approach in terms of 3R implementation.
This upload contains the full version and is distributed under CC BY-ND 4.0 license to inhibit decontextualized misuse. Please check license terms for usage, especially for remixing/transforming! If you want to remix the material, get in contact with the author.</p>
<p><a class="reference external" href="https://zenodo.org/records/13682928">https://zenodo.org/records/13682928</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13682928">https://doi.org/10.5281/zenodo.13682928</a></p>
</section>
<hr class="docutils" />
<section id="implantation-of-abdominal-imaging-windows-on-the-mouse-kidney-short-version">
<h2>Implantation of abdominal imaging windows on the mouse kidney - short version<a class="headerlink" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-kidney-short-version" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-09-09</p>
<p>Licensed CC-BY-ND-4.0</p>
<p>This video describes the surgical process of implanting an abdominal imaging window (AIW) on the kidney of mice. This window can be used for acute or longitudinal imaging. All experiments have been reviewed and approved by the local authorities (Landesdirektion Sachsen).
Implantation of chronic abdominal windows allows for microscopical investigation of highly dynamic processes in physiological and pathological circumstances and is generally tolerated well by experimental animals. It enables insights which otherwise could only be obtained using high numbers of experimental animals. The method can be regarded as reduction approach in terms of 3R implementation.
This upload contains the shortened version and is distributed under CC BY-ND 4.0 license to inhibit decontextualized misuse. Please check license terms for usage, especially for remixing/transforming! If you want to remix the material, get in contact with the author.</p>
<p><a class="reference external" href="https://zenodo.org/records/13736240">https://zenodo.org/records/13736240</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13736240">https://doi.org/10.5281/zenodo.13736240</a></p>
</section>
<hr class="docutils" />
<section id="implantation-of-abdominal-imaging-windows-on-the-mouse-liver">
<h2>Implantation of abdominal imaging windows on the mouse liver<a class="headerlink" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-liver" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-09-04</p>
<p>Licensed CC-BY-ND-4.0</p>
<p>This video describes the surgical process of implanting an abdominal imaging window (AIW) on the liver of mice. This window can be used for acute or longitudinal imaging. All experiments have been reviewed and approved by the local authorities (Landesdirektion Sachsen).
Implantation of chronic abdominal windows allows for microscopical investigation of highly dynamic processes in physiological and pathological circumstances and is generally tolerated well by experimental animals. It enables insights which otherwise could only be obtained using high numbers of experimental animals. The method can be regarded as reduction approach in terms of 3R implementation.
This upload contains the full version and is distributed under CC BY-ND 4.0 license to inhibit decontextualized misuse. Please check license terms for usage, especially for remixing/transforming! If you want to remix the material, get in contact with the author.</p>
<p><a class="reference external" href="https://zenodo.org/records/13683167">https://zenodo.org/records/13683167</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13683167">https://doi.org/10.5281/zenodo.13683167</a></p>
</section>
<hr class="docutils" />
<section id="implantation-of-abdominal-imaging-windows-on-the-mouse-liver-short-version">
<h2>Implantation of abdominal imaging windows on the mouse liver - short version<a class="headerlink" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-liver-short-version" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-09-09</p>
<p>Licensed CC-BY-ND-4.0</p>
<p>This video describes the surgical process of implanting an abdominal imaging window (AIW) on the liver of mice. This window can be used for acute or longitudinal imaging. All experiments have been reviewed and approved by the local authorities (Landesdirektion Sachsen).
Implantation of chronic abdominal windows allows for microscopical investigation of highly dynamic processes in physiological and pathological circumstances and is generally tolerated well by experimental animals. It enables insights which otherwise could only be obtained using high numbers of experimental animals. The method can be regarded as reduction approach in terms of 3R implementation.
This upload contains the short version and is distributed under CC BY-ND 4.0 license to inhibit decontextualized misuse. Please check license terms for usage, especially for remixing/transforming! If you want to remix the material, get in contact with the author.</p>
<p><a class="reference external" href="https://zenodo.org/records/13736218">https://zenodo.org/records/13736218</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13736218">https://doi.org/10.5281/zenodo.13736218</a></p>
</section>
<hr class="docutils" />
<section id="ink-in-a-dish">
<h2>Ink in a dish<a class="headerlink" href="#ink-in-a-dish" title="Link to this heading">#</a></h2>
<p>Cavanagh</p>
<p>Published 2024-09-03</p>
<p>Licensed CC-ZERO</p>
<p>A test data set for troublshooting. no scientific meaning.</p>
<p><a class="reference external" href="https://zenodo.org/records/13642395">https://zenodo.org/records/13642395</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13642395">https://doi.org/10.5281/zenodo.13642395</a></p>
</section>
<hr class="docutils" />
<section id="insights-and-impact-from-five-cycles-of-essential-open-source-software-for-science">
<h2>Insights and Impact From Five Cycles of Essential Open Source Software for Science<a class="headerlink" href="#insights-and-impact-from-five-cycles-of-essential-open-source-software-for-science" title="Link to this heading">#</a></h2>
<p>Kate Hertweck, Carly Strasser, Dario Taraborelli</p>
<p>Licensed CC-BY-4.0</p>
<p>Open source software (OSS) is essential for advancing scientific discovery, particularly in biomedical research, yet funding to support these vital tools has been limited. The Chan Zuckerberg Initiative’s Essential Open Source Software for Science (EOSS) program has significantly contributed to this field by providing $51.8 million in funding over five years to support the maintenance, growth, and community engagement of critical OSS tools. The program has impacted scientific OSS projects by improving their technical outputs, community building, and sustainability practices, and fostering collaborations within the OSS community. Additionally, EOSS funding has enhanced diversity, equity, and inclusion within the OSS community, although changes in principal investigator demographics were not observed. The funded projects have had a substantial impact on biomedical research by improving the usability and accessibility of scientific software, which has led to increased adoption and advancements in various biomedical fields.</p>
<p>Tags: Open Source Software, Funding, Sustainability</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://zenodo.org/records/11201216">https://zenodo.org/records/11201216</a></p>
</section>
<hr class="docutils" />
<section id="insights-from-acquiring-open-medical-imaging-datasets-for-foundation-model-development">
<h2>Insights from Acquiring Open Medical Imaging  Datasets for Foundation Model Development<a class="headerlink" href="#insights-from-acquiring-open-medical-imaging-datasets-for-foundation-model-development" title="Link to this heading">#</a></h2>
<p>Stefan Dvoretskii</p>
<p>Published 2024-04-10</p>
<p>Licensed CC-BY-4.0</p>
<p><a class="reference external" href="https://zenodo.org/records/11503289">https://zenodo.org/records/11503289</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11503289">https://doi.org/10.5281/zenodo.11503289</a></p>
</section>
<hr class="docutils" />
<section id="id1">
<h2>Insights from Acquiring Open Medical Imaging Datasets for Foundation Model Development<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>Stefan Dvoretskii</p>
<p>Published 2024-04-10</p>
<p>Licensed CC-BY-4.0</p>
<p><a class="reference external" href="https://zenodo.org/records/13380289">https://zenodo.org/records/13380289</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13380289">https://doi.org/10.5281/zenodo.13380289</a></p>
</section>
<hr class="docutils" />
<section id="institutionalization-and-collaboration-as-a-way-of-addressing-the-challenges-open-science-presents-to-libraries-the-university-of-konstanz-as-a-national-pioneer">
<h2>Institutionalization and Collaboration as a Way of Addressing the Challenges Open Science Presents to Libraries: The University of Konstanz as a National Pioneer<a class="headerlink" href="#institutionalization-and-collaboration-as-a-way-of-addressing-the-challenges-open-science-presents-to-libraries-the-university-of-konstanz-as-a-national-pioneer" title="Link to this heading">#</a></h2>
<p>Sophie Habinger, Maximilian Heber, Sonja Kralj, Emilia Mikautsch</p>
<p>Published 2024-07-09</p>
<p>Licensed CC-BY-4.0</p>
<p>The rise of Open Science (OS) and the academic community’s needs that come with it bring about a range of challenges for academic libraries. To face these challenges, the University of Konstanz has created a competence unit called Team Open Science in the Communication, Information, Media Center (KIM) - a joint unit of library and IT infrastructure. The Team creates synergies within itself and across the library. In December 2023, it involved 12 staff members specialising in open access (OA), research data management (RDM), open educational resources (OER) and virtual research environments (VRE). It collaborates closely with other KIM departments. This submission shall serve as a best practice example for the impact of OS on research libraries and, beyond that, the impact of research libraries on universities.
To enhance and foster OS, the Team provides individual consultations, services and office hours for researchers. Here, it collaborates closely with other librarians like subject specialists and the Team University Publications. Along similar lines, the KIM offers institutional repositories for publications (KOPS) and research data (KonDATA). Beyond that, the Team provides solutions to host OA journals and analyses researchers’ VRE needs to decide on implementation options. In sum, the Team is the central OS contact point for the entire university, underlining the major role the library holds in making institutional impact.
Furthermore, the Team had the leading role in creating the University of Konstanz’ OS Policy, one of the first ones passed by a German university. This policy stands out because it encompasses various OS domains. It demands, among other things, that text publications be made OA and that research data be managed according to relevant subject-specific standards. If permissible and reasonable, it demands that research data should be made publicly available at the earliest possible time. Along these lines, the policy has a large impact on how the library handles closed access books and subscription-based journals. As a consequence, OA is pursued wherever possible, leading to the highest OA quota of all German universities. In that sense, the Team is a crucial driving force of OS in the University of Konstanz, which ties in with the library’s major role of open research transformation.
Beyond the University of Konstanz, the Team is involved in a range of national and international projects collaborating with other libraries. On a national level, they lead the project open.access-network which provides an information platform for researchers and librarians and connects the German-speaking OA community through events like bar camps. The project KOALA-AV supports libraries in establishing consortial solutions for financing Diamond OA publications. Moreover, the Team is involved in the federal state initiative for RDM in Baden-Württemberg (bwFDM). Here, the Team is in charge of <a class="reference external" href="http://forschungsdaten.info">forschungsdaten.info</a>, the German-speaking countries’ leading RDM information platform, which will be offered in English within the next years. Internationally, the Team cooperates with librarians and other OS professionals from the European Reform University Alliance (ERUA) and the European University for Well-Being (EUniWell), establishing formats for best practice exchange, such as monthly OS Meet-Ups.</p>
<p><a class="reference external" href="https://zenodo.org/records/12699637">https://zenodo.org/records/12699637</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12699637">https://doi.org/10.5281/zenodo.12699637</a></p>
</section>
<hr class="docutils" />
<section id="interactive-image-data-flow-graphs">
<h2>Interactive Image Data Flow Graphs<a class="headerlink" href="#interactive-image-data-flow-graphs" title="Link to this heading">#</a></h2>
<p>Martin Schätz, Martin Schätz</p>
<p>Published 2022-10-17</p>
<p>Licensed CC-BY-4.0</p>
<p>The slides were presented during the Macro programming with ImageJ workshop (<a class="reference external" href="https://www.16mcm.cz/programme/#workshops">https://www.16mcm.cz/programme/#workshops</a>) which was part of the 16th Multinational Congress on Microscopy. It is a collection and “reshuffle” of slides originally made by Robert Haase on topics from Image Analysis in general up to User-friendly GPU-accelerated bio-image analysis and CLIJ2.</p>
<p><a class="reference external" href="https://zenodo.org/records/7215114">https://zenodo.org/records/7215114</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7215114">https://doi.org/10.5281/zenodo.7215114</a></p>
</section>
<hr class="docutils" />
<section id="intravital-microscopy-contrasting-agents-for-application-database">
<h2>Intravital microscopy contrasting agents for application - Database<a class="headerlink" href="#intravital-microscopy-contrasting-agents-for-application-database" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-06-19</p>
<p>Licensed CC-BY-4.0</p>
<p>This is a set of databases containing published use of substances which can be applied to rodents in order to contrast specific structures for optical intravital microscopy.
The first dataset contains applied final dosages, calculated for 25g-mice, as well as the orignally published amounts, concentrations and application routes of agents directly applied into the target organism.
The second dataset contains dosages and cell numbers for the external contrastation and subsequent application of cells into the target organism.
Filtering possible for organ system and contrasted structure/cell type in both datasets, substance class and fluorescent detection windows can be filtered in the dataset for direct agent application.
Source publications are listed by DOI.
 </p>
<p><a class="reference external" href="https://zenodo.org/records/12166710">https://zenodo.org/records/12166710</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12166710">https://doi.org/10.5281/zenodo.12166710</a></p>
</section>
<hr class="docutils" />
<section id="introduction-to-light-microscopy-widefield-microscopy">
<h2>Introduction to light-microscopy / Widefield microscopy<a class="headerlink" href="#introduction-to-light-microscopy-widefield-microscopy" title="Link to this heading">#</a></h2>
<p>Thomas Laurent</p>
<p>Published 2022-05-10</p>
<p>Licensed OTHER-AT</p>
<p>This is a short introduction to light-microscopy, illustrated with widefield microscopy.</p>
<p>It introduces :</p>
<ul class="simple">
<li><p>upright and inverted widefield microscopes</p></li>
<li><p>the transmitted and fluorescent light-path</p></li>
</ul>
<p>- contrasting methods (optical and at the sample level)</p>
<ul class="simple">
<li><p>the molecular principle of fluorescence (Perrin-Jablonski)</p></li>
<li><p>objective, resolution and limitations of the method (diffraction, diffusion/scattering)</p></li>
</ul>
<p>In addition to the PPT (with few animations), a lighter PDF version is provided for preview in Zenodo.</p>
<p> </p>
<p>Illustrations are mostly extracted from the ThermoFisher Molecular Probes School of Fluorescence educator packet and from the course material from Micron Facility in Oxford.</p>
<p>As stated in the presentation, illustrations are copyrighted but can be reproduced provided the original attribution is conserved.</p>
<p><a class="reference external" href="https://zenodo.org/records/6535296">https://zenodo.org/records/6535296</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6535296">https://doi.org/10.5281/zenodo.6535296</a></p>
</section>
<hr class="docutils" />
<section id="key-value-pair-template-for-annotation-in-omero-for-light-microscopy-data-acquired-with-axioscan7-core-facility-cellular-imaging-cfci">
<h2>Key-Value pair template for annotation in OMERO for light microscopy data acquired with AxioScan7 - Core Facility Cellular Imaging (CFCI)<a class="headerlink" href="#key-value-pair-template-for-annotation-in-omero-for-light-microscopy-data-acquired-with-axioscan7-core-facility-cellular-imaging-cfci" title="Link to this heading">#</a></h2>
<p>Silke Tulok, Anja Nobst, Anett Jannasch, Tom Boissonnet, Gunar Fabig</p>
<p>Published 2024-06-28</p>
<p>Licensed CC-BY-4.0</p>
<p>This Key-Value pair template is used for the data documentation during imaging experiments and the later data annotation in OMERO. It is tailored for the usage and image acquisition at the slide scanning system Zeiss AxioScan 7 in the Core Facility Cellular Imaging (CFCI). It contains important metadata of the imaging experiment, which are not saved in the corresponding imaging files. All users of the Core Facility Cellular Imaging are trained to use that file to document their imaging parameters directly during the data acquisition with the possibility for a later upload to OMERO. Furthermore, there is a corresponding public example image used in the publication “Setting up an institutional OMERO environment for bioimage data: perspectives from both facility staff and users” and is available here:
<a class="reference external" href="https://omero.med.tu-dresden.de/webclient/?show=image-33248">https://omero.med.tu-dresden.de/webclient/?show=image-33248</a>
This template was developed by the CFCI staff during the setup and usage of the AxioScan 7 and is based on the REMBI recommendations (<a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015</a>).
With this template it is possible to create a csv-file, that can be used to annotate an image or dataset in OMERO using the annotation script (<a class="github reference external" href="https://github.com/ome/omero-scripts/blob/develop/omero/annotation_scripts/">ome/omero-scripts</a>).
How to use:</p>
<p>fill the template sheet  with your metadata
select and copy the data range containing the Keys and Values
open a new excel sheet and paste transpose in cell A1 
Important: cell A1 contains always the name ‘dataset’ and cell A2 contains the exact name of the image/dataset, which should be annotated in OMERO
save the new excel sheet in csv-file (comma separated values) format</p>
<p>An example can be seen in sheet 3 ‘csv_AxioScan’.
Important note: The code has to be 8-Bit UCS transformation format (UTF-8) otherwise several characters (for example µ, %,°) might be not able to decode by the annotation script. We encountered this issue with old Microsoft-Office versions (MS Office 2016). 
Note: By filling the values in the excel sheet, avoid the usage of comma as decimal delimiter.
See cross reference:
10.5281/zenodo.12547566 Key-Value pair template for annotation of datasets in OMERO for light- and electron microscopy data within the research group of Prof. Mueller-Reichert
10.5281/zenodo.12546808 Key-Value pair template for annotation of datasets in OMERO (PERIKLES study)</p>
<p><a class="reference external" href="https://zenodo.org/records/12578084">https://zenodo.org/records/12578084</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12578084">https://doi.org/10.5281/zenodo.12578084</a></p>
</section>
<hr class="docutils" />
<section id="key-value-pair-template-for-annotation-of-datasets-in-omero-perikles-study">
<h2>Key-Value pair template for annotation of datasets in OMERO (PERIKLES study)<a class="headerlink" href="#key-value-pair-template-for-annotation-of-datasets-in-omero-perikles-study" title="Link to this heading">#</a></h2>
<p>Anett Jannasch, Silke Tulok, Fuchs, Vanessa Aphaia Fiona, Tom Boissonnet, Christian Schmidt, Michele Bortolomeazzi, Gunar Fabig, Chukwuebuka Okafornta</p>
<p>Published 2024-06-26</p>
<p>Licensed CC-BY-4.0</p>
<p>This is a Key-Value pair template used for the annotation of datasets in OMERO. It is tailored for a research study (PERIKLES project) on the biocompatibility of newly designed biomaterials out of pericardial tissue for cardiovascular substitutes (<a class="reference external" href="https://doi.org/10.1063/5.0182672">https://doi.org/10.1063/5.0182672</a>) conducted in the research department of Cardiac Surgery at the Faculty of Medicine Carl Gustav Carus at the Technische Universität Dresden . A corresponding public example dataset is used in the publication “Setting up an institutional OMERO environment for bioimage data: perspectives from both facility staff and users” and is available here
(<a class="reference external" href="https://omero.med.tu-dresden.de/webclient/?show=dataset-1557">https://omero.med.tu-dresden.de/webclient/?show=dataset-1557</a>).
The template is based on the REMBI recommendations (<a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015</a>) and it was developed during the PoL-Bio-Image Analysis Symposium in Dresden Aug 28th- Sept 1th 2023. 
With this template it is possible to create a csv-file, that can be used to annotate a dataset in OMERO using the annotation script (<a class="github reference external" href="https://github.com/ome/omero-scripts/blob/develop/omero/annotation_scripts/">ome/omero-scripts</a>).
How to use:
select and copy the data range containing Keys and Values
open a new excel sheet and paste transpose in column B1
type in A1 ‘dataset’
insert in A2 the exact name of the dataset, which should be annotated in OMERO
save the new excel sheet in csv- (comma seperated values) file format</p>
<p>Example can be seen in sheet 1 ‘csv import’. Important note; the code has to be 8-Bit UCS transformation format (UTF-8) otherwise several characters (for example µ, %,°) might not be able to decode by the annotation script. We encountered this issue with old Microsoft Office versions (e.g. MS Office 2016). 
Note: By filling the values in the excel sheet, avoid the usage of decimal delimiter.
 
See cross reference:
10.5281/zenodo.12547566 Key-Value pair template for annotation of datasets in OMERO (light- and electron microscopy data within the research group of Prof. Mueller-Reichert)
10.5281/zenodo.12578084 Key-Value pair template for annotation in OMERO for light microscopy data acquired with AxioScan7 - Core Facility Cellular Imaging (CFCI)</p>
<p><a class="reference external" href="https://zenodo.org/records/12546808">https://zenodo.org/records/12546808</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12546808">https://doi.org/10.5281/zenodo.12546808</a></p>
</section>
<hr class="docutils" />
<section id="key-value-pair-template-for-annotation-of-datasets-in-omero-for-light-and-electron-microscopy-data-within-the-research-group-of-prof-muller-reichert">
<h2>Key-Value pair template for annotation of datasets in OMERO for light- and electron microscopy data within the research group of Prof. Müller-Reichert<a class="headerlink" href="#key-value-pair-template-for-annotation-of-datasets-in-omero-for-light-and-electron-microscopy-data-within-the-research-group-of-prof-muller-reichert" title="Link to this heading">#</a></h2>
<p>Fabig, Gunar, Jannasch, Anett, Okafornta, Chukwuebuka, Boissonnet, Tom, Schmidt, Christian, Bortolomeazzi, Michele, Fuchs, Vanessa Aphaia Fiona, Koeckert, Maria, Poddar, Aayush, Vogel, Martin, Schwarzbach, Hanna-Margareta, Vogelsang, Andy, Gerlach, Michael, Nobst, Anja, Müller-Reichert, Thomas, Tulok, Silke</p>
<p>Published 2024-06-26</p>
<p>Licensed CC-BY-4.0</p>
<p>This are a two Key-Value pair templates used for the annotation of datasets in OMERO. They are tailored for light- and electron microcopy data for all research projects of the research group of Prof. T. Mueller-Reichert.  All members of the Core Facility Cellular Imaging agreed for using these templates to annotate data in OMERO. Furthermore, there are a corresponding public example datasets used in the publication “Setting up an institutional OMERO environment for bioimage data: perspectives from both facility staff and users” and are available here:
<a class="reference external" href="https://omero.med.tu-dresden.de/webclient/?show=dataset-1552">https://omero.med.tu-dresden.de/webclient/?show=dataset-1552</a> –&gt; for lattice-light sheet microscopy
<a class="reference external" href="https://omero.med.tu-dresden.de/webclient/?show=dataset-1555--&amp;amp;gt">https://omero.med.tu-dresden.de/webclient/?show=dataset-1555–&amp;gt</a>; for electron microscopy data
That templates are based on the REMBI recommendations (<a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015</a>) and were developed during the PoL-Bio-Image Analysis Symposium in Dresden Aug 28th- Sept 1st in 2023 and further adapeted during the usage of OMERO. 
With every template it is possible to create a csv-file, that can be used to annotate a dataset in OMERO using the annotation script (<a class="github reference external" href="https://github.com/ome/omero-scripts/blob/develop/omero/annotation_scripts/">ome/omero-scripts</a>).
How to use:</p>
<p>fill the template with metadata
select and copy the data range containing the Keys and Values
open a new excel sheet and paste transpose in cell A1
Important: cell A1 contains always the name ‘dataset’ and cell A2 contains the exact name of the dataset, which should be annotated in OMERO
save the new excel sheet in csv-file (comma separated values) format</p>
<p>Examples can be seen in sheet 3 ‘csv_TOMO’ and sheet 5 csv_TEM’.
Important note: The code has to be 8-Bit UCS transformation format (UTF-8) otherwise several characters (for example µ, %,°) might be not able to decode by the annotation script. We encountered this issue with old Microsoft-Office versions (MS Office 2016). 
Note: By filling the values in the excel sheet, avoid the usage of comma as decimal delimiter.
See cross reference:
10.5281/zenodo.12546808 Key-Value pair template for annotation of datasets in OMERO (PERIKLES study)
10.5281/zenodo.12578084 Key-Value pair template for annotation in OMERO for light microscopy data acquired with AxioScan7 - Core Facility Cellular Imaging (CFCI)
 </p>
<p><a class="reference external" href="https://zenodo.org/records/12547566">https://zenodo.org/records/12547566</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12547566">https://doi.org/10.5281/zenodo.12547566</a></p>
</section>
<hr class="docutils" />
<section id="kollaboratives-arbeiten-und-versionskontrolle-mit-git">
<h2>Kollaboratives Arbeiten und Versionskontrolle mit Git<a class="headerlink" href="#kollaboratives-arbeiten-und-versionskontrolle-mit-git" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-04-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Gemeinsames Arbeiten im Internet stellt uns vor neue Herausforderungen: Wer hat eine Datei wann hochgeladen? Wer hat zum Inhalt beigetragen? Wie kann man Inhalte zusammenfuehren, wenn mehrere Mitarbeiter gleichzeitig Aenderungen gemacht haben? Das Versionskontrollwerkzeug git stellt eine umfassende Loesung fuer solche Fragen bereit. Die Onlineplatform <a class="reference external" href="http://github.com">github.com</a> stellt nicht nur Softwareentwicklern weltweit eine git-getriebene Platform zur Verfuegung und erlaubt ihnen effektiv zusammen zu arbeiten. In diesem Workshop lernen wir:</p>
<p>Infuerung in FAIR-Prinzipien im Softwarecontext
Arbeiten mit git: Pull-requests
Aufloesen von Merge-Konflikten
Automatisiertes Archivieren von Inhalten nach <a class="reference external" href="http://Zenodo.org">Zenodo.org</a>
Eigene Webseiten auf <a class="reference external" href="http://github.io">github.io</a> publizieren</p>
<p>Tags: Research Data Management, FAIR-Principles, Git, Zenodo</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/10972692">https://zenodo.org/records/10972692</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10972692">https://doi.org/10.5281/zenodo.10972692</a></p>
</section>
<hr class="docutils" />
<section id="leo-linking-eln-with-omero">
<h2>LEO: Linking ELN with OMERO<a class="headerlink" href="#leo-linking-eln-with-omero" title="Link to this heading">#</a></h2>
<p>Escobar Diaz Guerrero, Rodrigo</p>
<p>Published 2024-05-08</p>
<p>Licensed CC-BY-4.0</p>
<p>First updates of LEO (Linking ELN with OMERO)</p>
<p><a class="reference external" href="https://zenodo.org/records/11146807">https://zenodo.org/records/11146807</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11146807">https://doi.org/10.5281/zenodo.11146807</a></p>
</section>
<hr class="docutils" />
<section id="lz4-compressed-imaris-ims-example-datasets">
<h2>LZ4-compressed Imaris ims example datasets.<a class="headerlink" href="#lz4-compressed-imaris-ims-example-datasets" title="Link to this heading">#</a></h2>
<p>Marco Stucchi</p>
<p>Published 2024-11-21</p>
<p>Licensed CC-BY-4.0</p>
<p>The files contained in this repository are cropped versions of Imaris demo images compressed with LZ4.</p>
<p><a class="reference external" href="https://zenodo.org/records/14197622">https://zenodo.org/records/14197622</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14197622">https://doi.org/10.5281/zenodo.14197622</a></p>
</section>
<hr class="docutils" />
<section id="large-language-models-an-introduction-for-life-scientists">
<h2>Large Language Models: An Introduction for Life Scientists<a class="headerlink" href="#large-language-models-an-introduction-for-life-scientists" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-08-27</p>
<p>Licensed CC-BY-4.0</p>
<p>Large Language Models (LLMs) are changing the way how humans interact with computers. This has impact on all scientific fields by enabling new ways to achieve for example data analysis goals. In this talk we will go through an introduction to LLMs with respect to applications in the life sciences, focusing on bio-image analysis. We will see how to generate text and images using LLMs and how LLMs can extract information from reproducibly images through code-generation. We will go through selected prompt engineering techniques enabling scientists to tune the output of LLMs towards their scientific goal and how to do quality assurance in this context.</p>
<p><a class="reference external" href="https://zenodo.org/records/13379394">https://zenodo.org/records/13379394</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13379394">https://doi.org/10.5281/zenodo.13379394</a></p>
</section>
<hr class="docutils" />
<section id="large-tiling-confocal-acquisition-rat-brain">
<h2>Large tiling confocal acquisition (rat brain)<a class="headerlink" href="#large-tiling-confocal-acquisition-rat-brain" title="Link to this heading">#</a></h2>
<p>Julie Meystre</p>
<p>Published 2022-06-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: Large tiling confocal acquisition (rat brain)</p>
<p>Microscope: Zeiss LSM700</p>
<p>Microscopy data type: 108 tiles, each with 62 z-slices and 2 channels :
Channel 1: DAPI
Channel 2: cck staining</p>
<p>File format: .lsm (16-bit)</p>
<p>Image size: 1024x1024x62 (Pixel size: 0.152 x 0.152 x 1 micron), 2 channels.</p>
<p> </p>
<p>NOTE : Some tiles were annotated and used to train a StarDist3D model (<a class="reference external" href="https://doi.org/10.5281/zenodo.6645978">https://doi.org/10.5281/zenodo.6645978</a>   )</p>
<p><a class="reference external" href="https://zenodo.org/records/6646128">https://zenodo.org/records/6646128</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6646128">https://doi.org/10.5281/zenodo.6646128</a></p>
</section>
<hr class="docutils" />
<section id="laulauthom-maskfromrois-fiji-masks-from-rois-plugins-for-fiji-initial-release">
<h2>LauLauThom/MaskFromRois-Fiji: Masks from ROIs plugins for Fiji - initial release<a class="headerlink" href="#laulauthom-maskfromrois-fiji-masks-from-rois-plugins-for-fiji-initial-release" title="Link to this heading">#</a></h2>
<p>Laurent Thomas, Pierre Trehin</p>
<p>Published 2021-07-22</p>
<p>Licensed MIT</p>
<p>Fiji plugins for the creation of binary and semantic masks from ROIs in the RoiManager. Works with stacks too.</p>
<p>Installation in Fiji: activate the Rois from masks update site in Fiji.</p>
<p>See GitHub readme for the documentation.</p>
<p>Latest tested with Fiji 2.1.0/ImageJ 1.53j</p>
<p><a class="reference external" href="https://zenodo.org/records/5121890">https://zenodo.org/records/5121890</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5121890">https://doi.org/10.5281/zenodo.5121890</a></p>
</section>
<hr class="docutils" />
<section id="leitfaden-zur-digitalen-datensparsamkeit-mit-praxisbeispielen">
<h2>Leitfaden zur digitalen Datensparsamkeit (mit Praxisbeispielen)<a class="headerlink" href="#leitfaden-zur-digitalen-datensparsamkeit-mit-praxisbeispielen" title="Link to this heading">#</a></h2>
<p>Heber, Maximilian, Jakob, Moritz, Landwehr, Matthias, Leendertse, Jan, Müller, Maximilian, Schneider, Gabriel, von Suchodoletz, Dirk, Ulrich, Robert</p>
<p>Published 2024-06-03</p>
<p>Licensed CC-BY-4.0</p>
<p>Im Zuge der stetig wachsenden Brisanz des Forschungsdatenmanagements fallen immer größere Mengen an Forschungsdaten an. Diese an sich begrüßenswerte Entwicklung führt zu technischen und organisatorischen Herausforderungen nicht nur im Bereich der Speicherung von Forschungsdaten, sondern in allen Phasen des Forschungsdatenlebenszyklus. Der vorliegende Beitrag erläutert vor diesem Hintergrund mögliche Motivationen hinter digitaler Datensparsamkeit mit Blick auf organisatorische, technische und ethische Kriterien, Datenschutz und Nachhaltigkeit. Anschließend werden vor dem Hintergrund zentraler Herausforderungen Umsetzungsvorschläge für das Vorfeld sowie den Verlauf eines Forschungsvorhabens gemacht. Zudem werden grundlegende Empfehlungen zur digitalen Datensparsamkeit ausgesprochen.
Eine kürzere Ausgabe des Leitfadens ist im Mai 2024 in der Zeitschrift o | bib erschienen: <a class="reference external" href="https://doi.org/10.5282/o-bib/6036">https://doi.org/10.5282/o-bib/6036</a>
Diese Ausgabe enthält ein zusätzliches Kapitel (4.2) mit konkreten Praxisbeispielen.
Dieser Artikel wurde ins Englische übersetzt:
Heber, M., Jakob, M., Landwehr, M., Leendertse, J., Müller, M., Schneider, G., von Suchodoletz, D., &amp; Ulrich, R. (2024). A Users’ Guide to Economical Digital Data Usage. Zenodo. <a class="reference external" href="https://doi.org/10.5281/zenodo.13752220">https://doi.org/10.5281/zenodo.13752220</a></p>
<p><a class="reference external" href="https://zenodo.org/records/11445843">https://zenodo.org/records/11445843</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11445843">https://doi.org/10.5281/zenodo.11445843</a></p>
</section>
<hr class="docutils" />
<section id="limeseg-test-datasets">
<h2>LimeSeg Test Datasets<a class="headerlink" href="#limeseg-test-datasets" title="Link to this heading">#</a></h2>
<p>Sarah Machado, Vincent Mercier, Nicolas Chiaruttini</p>
<p>Published 2018-10-27</p>
<p>Licensed CC-BY-4.0</p>
<p>Image datasets from the publication : LimeSeg: A coarse-grained lipid membrane simulation for 3D image segmentation</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Vesicles.tif: spinning-disc confocal images of giant unilamellar vesicles
HelaCell-FIBSEM.tif:&amp;nbsp;a 3D Electron&amp;nbsp;Microscopy (EM)&amp;nbsp;dataset of nearly isotropic sections of a Hela cell, acquired with a focused ion beam scanning electron microscope (FIB-SEM). Sections are aligned with TrackEm2 (doi: ), without additional preprocessing.
DrosophilaEggChamber.tif: point scanning confocal images of a Drosophila egg chamber. Channel&amp;nbsp;1: cell nuclei &amp;nbsp;stained with DAPI. Channel 2:&amp;nbsp;cell membranes visualized with fused membrane proteins Nrg::GFP and Bsg::GFP.&amp;nbsp;
</pre></div>
</div>
<p>Image metadata contains extra information including voxel sizes.</p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/1472859">https://zenodo.org/records/1472859</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.1472859">https://doi.org/10.5281/zenodo.1472859</a></p>
</section>
<hr class="docutils" />
<section id="linked-open-data-for-microbial-population-biology">
<h2>Linked (Open) Data for Microbial Population Biology<a class="headerlink" href="#linked-open-data-for-microbial-population-biology" title="Link to this heading">#</a></h2>
<p>Carsten Fortmann-Grote</p>
<p>Published 2024-03-12</p>
<p>Licensed CC-BY-4.0</p>
<p><a class="reference external" href="https://zenodo.org/records/10808486">https://zenodo.org/records/10808486</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10808486">https://doi.org/10.5281/zenodo.10808486</a></p>
</section>
<hr class="docutils" />
<section id="liver-micrometastases-area-quantification-using-qupath-and-pixel-classifier">
<h2>Liver Micrometastases area quantification using QuPath and pixel classifier<a class="headerlink" href="#liver-micrometastases-area-quantification-using-qupath-and-pixel-classifier" title="Link to this heading">#</a></h2>
<p>Laia Simó-Riudalbas, Romain Guiet, Olivier Burri, Julien Duc, Didier Trono</p>
<p>Published 2022-05-06</p>
<p>Licensed CC-BY-4.0</p>
<p>Sample: Mouse (NSG) liver slices with human colorectal cancer cells metastases, stained with Hematoxylin &amp; Eosin. </p>
<p>Image Acquisition: Images were acquired on an Olympus VS120 Whole Slide Scanner, using a 20x objective (UPLSAPO, N.A. 0.75) and a color camera (Pike F505 Color) with an image pixel size of 0.345 microns.</p>
<p>Image Processing and Analysis: Obtained images were analyzed using the software QuPath [1] (version 0.3.2) using groovy scripts, making use of a pixel classifier to segment and measure cancer cell clusters.</p>
<p>Files :</p>
<p>Detailed_worflow.pdf : contains a detailed description of how pixel classifier was created</p>
<p>images_for_classifier_training.zip : contains all the vsi file obtained from the microscope and used for the training</p>
<p>project_for_classifier_training.zip : contains the QuPath project, with Training Image, annotations, classifiers and scripts for analysis</p>
<p>PythonCode.txt : code ran to transform output results from QuPath to final results</p>
<p> </p>
<p>[1] Bankhead, P. et al. QuPath: Open source software for digital pathology image analysis. Scientific Reports (2017). <a class="reference external" href="https://doi.org/10.1038/s41598-017-17204-5">https://doi.org/10.1038/s41598-017-17204-5</a></p>
<p><a class="reference external" href="https://zenodo.org/records/6523649">https://zenodo.org/records/6523649</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6523649">https://doi.org/10.5281/zenodo.6523649</a></p>
</section>
<hr class="docutils" />
<section id="measuring-reporter-activity-domain-in-epi-aggregates-and-gastruloids-ijm">
<h2>Measuring reporter activity domain in EPI aggregates and Gastruloids.ijm<a class="headerlink" href="#measuring-reporter-activity-domain-in-epi-aggregates-and-gastruloids-ijm" title="Link to this heading">#</a></h2>
<p>Romain Guiet, Olivier Burri, Mehmet Girgin, Matthias Lutolf</p>
<p>Published 2022-12-07</p>
<p>Licensed CC-BY-4.0</p>
<p>This imagej macro analyses the reporter intensity activity and expression domain in EPI aggregates and Gastruloids.</p>
<p><a class="reference external" href="https://zenodo.org/records/7409423">https://zenodo.org/records/7409423</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7409423">https://doi.org/10.5281/zenodo.7409423</a></p>
</section>
<hr class="docutils" />
<section id="metadata-annotation-workflow-for-omero-with-tabbles">
<h2>Metadata Annotation Workflow for OMERO with Tabbles<a class="headerlink" href="#metadata-annotation-workflow-for-omero-with-tabbles" title="Link to this heading">#</a></h2>
<p>Wendt Jens</p>
<p>Published 2023-09-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Short presentation given at at PoL BioImage Analysis Symposium Dresden 2023</p>
<p><a class="reference external" href="https://zenodo.org/records/8314968">https://zenodo.org/records/8314968</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8314968">https://doi.org/10.5281/zenodo.8314968</a></p>
</section>
<hr class="docutils" />
<section id="microsam-talks">
<h2>MicroSam-Talks<a class="headerlink" href="#microsam-talks" title="Link to this heading">#</a></h2>
<p>Constantin Pape</p>
<p>Published 2024-05-23</p>
<p>Licensed CC-BY-4.0</p>
<p>Talks about Segment Anything for Microscopy: <a class="github reference external" href="https://github.com/computational-cell-analytics/micro-sam">computational-cell-analytics/micro-sam</a>.
Currently contains slides for two talks:</p>
<p>Overview of Segment Anythign for Microscopy given at the SWISSBIAS online meeting in April 2024
Talk about vision foundation models and Segment Anything for Microscopy given at Human Technopole as part of the EMBO Deep Learning Course in May 2024</p>
<p>Tags: Image Segmentation, Bioimage Analysis, Deep Learning</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/11265038">https://zenodo.org/records/11265038</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11265038">https://doi.org/10.5281/zenodo.11265038</a></p>
</section>
<hr class="docutils" />
<section id="morphological-analysis-of-neural-cells-with-weka-and-snt-fiji-plugins">
<h2>Morphological analysis of neural cells with WEKA and SNT Fiji plugins<a class="headerlink" href="#morphological-analysis-of-neural-cells-with-weka-and-snt-fiji-plugins" title="Link to this heading">#</a></h2>
<p>Daniel Waiger</p>
<p>Published 2022-07-14</p>
<p>Licensed CC-BY-4.0</p>
<p>A simple workflow to detect Soma and neurite paths, from light microscopy datasets.</p>
<p>Using open-source tools for beginners.</p>
<p><a class="reference external" href="https://zenodo.org/records/6834214">https://zenodo.org/records/6834214</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6834214">https://doi.org/10.5281/zenodo.6834214</a></p>
</section>
<hr class="docutils" />
<section id="multi-template-matching-for-object-detection-slides">
<h2>Multi-Template-Matching for object-detection (slides)<a class="headerlink" href="#multi-template-matching-for-object-detection-slides" title="Link to this heading">#</a></h2>
<p>Laurent Thomas</p>
<p>Published 2022-05-16</p>
<p>Licensed CC-BY-4.0</p>
<p>This presentations describes Multi-Template-Matching, a novel method extending on template-matching for object-detection in images.</p>
<p>The project was part of the PhD project of Laurent Thomas between 2017 and 2020, under supervision of Jochen Gehrig. The project was hosted at ACQUIFER Imaging with collaboration of the medical university of Heidelberg, and part of the ImageInLife Horizon2020 ITN (PhD program). </p>
<p><a class="reference external" href="https://zenodo.org/records/6554166">https://zenodo.org/records/6554166</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6554166">https://doi.org/10.5281/zenodo.6554166</a></p>
</section>
<hr class="docutils" />
<section id="multiplexed-histology-of-covid-19-post-mortem-lung-samples-control-case-1-fov1">
<h2>Multiplexed histology of COVID-19 post-mortem lung samples - CONTROL CASE 1 FOV1<a class="headerlink" href="#multiplexed-histology-of-covid-19-post-mortem-lung-samples-control-case-1-fov1" title="Link to this heading">#</a></h2>
<p>Anna Pascual Reguant, Ronja Mothes, Helena Radbruch, Anja E. Hauser</p>
<p>Published 2022-12-16</p>
<p>Licensed CC-BY-4.0</p>
<p>Image-based data set of a post-mortem lung sample from a non-COVID-related pneumonia donor (CONTROL CASE 1, FOV1)</p>
<p>Each image shows the same field of view (FOV), sequentially stained with the depicted fluorescence-labelled antibodies, including surface proteins, intracellular proteins and transcription factors. Images contain 2024 x 2024 pixels and are generated using an inverted wide-field fluorescence microscope with a 20x objective, a lateral resolution of 325 nm and an axial resolution above 5 µm. Images have been normalized and intensities adjusted.</p>
<p><a class="reference external" href="https://zenodo.org/records/7447491">https://zenodo.org/records/7447491</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7447491">https://doi.org/10.5281/zenodo.7447491</a></p>
</section>
<hr class="docutils" />
<section id="my-journey-through-bioimage-analysis-teaching-methods-from-classroom-to-cloud">
<h2>My Journey Through Bioimage Analysis Teaching Methods From Classroom to Cloud<a class="headerlink" href="#my-journey-through-bioimage-analysis-teaching-methods-from-classroom-to-cloud" title="Link to this heading">#</a></h2>
<p>Elnaz Fazeli</p>
<p>Published 2024-02-19</p>
<p>Licensed CC-BY-4.0</p>
<p>In these slides I introducemy journey through teaching bioimage analysis courses in different formats, from in person courses to online material. I have an overview of different training formats and comparing these for different audiences. </p>
<p>Tags: Teaching</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/10679054">https://zenodo.org/records/10679054</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10679054">https://doi.org/10.5281/zenodo.10679054</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage">
<h2>NFDI4BIOIMAGE<a class="headerlink" href="#nfdi4bioimage" title="Link to this heading">#</a></h2>
<p>Carsten Fortmann-Grote</p>
<p>Published 2024-04-22</p>
<p>Licensed CC-BY-4.0</p>
<p>This presentation was given at the 2nd MPG-NFDI Workshop on April 18th.</p>
<p><a class="reference external" href="https://zenodo.org/records/11031747">https://zenodo.org/records/11031747</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11031747">https://doi.org/10.5281/zenodo.11031747</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis-conference-talk-the-pelagic-imaging-consortium-meets-helmholtz-imaging-5-10-2023-hamburg">
<h2>NFDI4BIOIMAGE - National Research Data Infrastructure for Microscopy and BioImage Analysis [conference talk: The Pelagic Imaging Consortium meets Helmholtz Imaging, 5.10.2023, Hamburg]<a class="headerlink" href="#nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis-conference-talk-the-pelagic-imaging-consortium-meets-helmholtz-imaging-5-10-2023-hamburg" title="Link to this heading">#</a></h2>
<p>Riccardo Massei</p>
<p>Licensed CC-BY-4.0</p>
<p>NFDI4BIOIMAGE is a consortium within the framework of the National Research Data Infrastructure (NFDI) in Germany. In this talk, the consortium and the contribution to the work programme by the Helmholtz Centre for Environmental Research (UFZ) in Leipzig are outlined.</p>
<p>Tags: Research Data Management, Bioimage Analysis, Nfdi4Bioimage</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.8414318">https://zenodo.org/doi/10.5281/zenodo.8414318</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis">
<h2>NFDI4BIOIMAGE - National Research Data Infrastructure for Microscopy and Bioimage Analysis<a class="headerlink" href="#nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis" title="Link to this heading">#</a></h2>
<p>Marcelo Zoccoler</p>
<p>Published 2024-08-07</p>
<p>Licensed CC-BY-4.0</p>
<p>Bioimaging refers to a collection of methods to visualize the internal structures and mechanisms of living organisms. The fundamental tool, the microscope, has enabled seminal discoveries like that of the cell as the smallest unit of life, and continues to expand our understanding of biological processes. Today, we can follow the interaction of single molecules within nanoseconds in a living cell, and the development of complete small organisms like fish and flies over several days starting from the fertilized egg. Each image pixel encodes multiple spatiotemporal and spectral dimensions, compounding the massive volume and complexity of bioimage data. Proper handling of this data is indispensable for analysis and its lack has become a growing hindrance for the many disciplines of the life and biomedical sciences relying on bioimaging. No single domain has the expertise to tackle this bottleneck alone.
As a method-specific consortium, NFDI4BIOMAGE seeks to address these issues, enabling bioimaging data to be shared and re-used like they are acquired, i.e., independently of disciplinary boundaries. We will provide solutions for exploiting the full information content of bioimage data and enable new discoveries through sharing and re-analysis. Our RDM strategy is based on a robust needs analysis that derives not only from a community survey but also from over a decade of experience in German BioImaging, the German Society for Microscopy and Image Analysis. It considers the entire lifecycle of bioimaging data, from acquisition to archiving, including analysis and enabling re-use. A foundational element of this strategy is the definition of a common, cloud-compatible, and interoperable digital object that bundles binary images with their descriptive and provenance metadata. With members from plant biology to neuroscience, NFDI4BIOIMAGE will champion the standardization of bioimage data to create a framework that answers discipline-specific needs while ensuring communication and interoperability with data types and RDM systems across domains. Integration of bioimage data with, e.g., omics data as the basis for spatial omics, holds great promise for fields such as cancer medicine. Unlocking the full potential of bioimage data will rely on the development and broad availability of exceptional analysis tools and training sets. NFDI4BIOIMAGE will make these accessible and usable including cutting-edge AI-based methods in scalable cloud environments. NFDI4BIOIMAGE intersects with multiple NFDI consortia, most prominently with GHGA for linking image and genomics data and with DataPLANT on the definition of FAIR data objects. Last but not least, NFDI4BIOIMAGE is internationally well connected and represents the opportunity for German scientists to keep path with and have a voice in several international initiatives focusing on the FAIRification of bioimage data as one of the main challenges for the advancement of knowledge in the life and biomedical sciences.</p>
<p><a class="reference external" href="https://zenodo.org/records/13168693">https://zenodo.org/records/13168693</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13168693">https://doi.org/10.5281/zenodo.13168693</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon-2023-github-repository">
<h2>NFDI4Bioimage - TA3-Hackathon - UoC-2023 (Cologne-Hackathon-2023, GitHub repository)<a class="headerlink" href="#nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon-2023-github-repository" title="Link to this heading">#</a></h2>
<p>Mohamed Abdrabbou, Mehrnaz Babaki, Tom Boissonnet, Michele Bortolomeazzi, Eik Dahms, Vanessa Fuchs, A. F. Moritz Hoevels, Niraj Kandpal, Christoph Möhl, Joshua A. Moore, Astrid Schauss, Andrea Schrader, Torsten Stöter, Julia Thönnißen, Monica Valencia-S., H. Lukas Weil, Jens Wendt, Peter Zentis</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository documents the first NFDI4Bioimage - TA3-Hackathon - UoC-2023 (Cologne Hackathon), where topics like ‘Interoperability’, ‘REMBI / Mapping’, and ‘Neuroglancer (OMERO / zarr)’ were explored through collaborative discussions and workflow sessions, culminating in reports that bridge NFDI4Bioimage to DataPLANT. Funded by various DFG initiatives, this event emphasized documentation and use cases, contributing preparatory work for future interoperability projects at the 2nd de.NBI BioHackathon in Bielefeld.</p>
<p>Tags: Research Data Management, FAIR-Principles, Bioimage Analysis, Nfdi4Bioimage</p>
<p>Content type: Github Repository</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.10609770">https://zenodo.org/doi/10.5281/zenodo.10609770</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-calendar-2024-october-original-image">
<h2>NFDI4Bioimage Calendar 2024 October; original image<a class="headerlink" href="#nfdi4bioimage-calendar-2024-october-original-image" title="Link to this heading">#</a></h2>
<p>Christian Jüngst, Peter Zentis</p>
<p>Published 2024-09-25</p>
<p>Licensed CC-BY-4.0</p>
<p>Raw microscopy image from the NFDI4Bioimage calendar October 2024</p>
<p><a class="reference external" href="https://zenodo.org/records/13837146">https://zenodo.org/records/13837146</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13837146">https://doi.org/10.5281/zenodo.13837146</a></p>
</section>
<hr class="docutils" />
<section id="new-kid-on-the-nfdi-block-nfdi4bioimage-a-national-initiative-for-fair-data-management-in-bioimaging-and-bioimage-analysis">
<h2>New Kid on the (NFDI) Block: NFDI4BIOIMAGE  - A National Initiative for FAIR Data Management in Bioimaging and Bioimage Analysis<a class="headerlink" href="#new-kid-on-the-nfdi-block-nfdi4bioimage-a-national-initiative-for-fair-data-management-in-bioimaging-and-bioimage-analysis" title="Link to this heading">#</a></h2>
<p>Cornelia Wetzker</p>
<p>Published 2024-10-29</p>
<p>Licensed CC-BY-4.0</p>
<p>The poster introduces the consortium NFDI4BIOIMAGE with its central objectives, provides an overview of challenges in bioimage data handling, sharing and analysis and lists support options by the consortium through its data stewardship team.
It is part of the work of the German consortium NFDI4BIOIMAGE funded by the Deutsche Forschungsgemeinschaft (DFG grant number NFDI 46/1, project number 501864659) and has been presented at the conference FDM&#64;Campus held in Göttingen September 23-25, 2024.</p>
<p><a class="reference external" href="https://zenodo.org/records/14006558">https://zenodo.org/records/14006558</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14006558">https://doi.org/10.5281/zenodo.14006558</a></p>
</section>
<hr class="docutils" />
<section id="nextflow-scalable-and-reproducible-scientific-workflows">
<h2>Nextflow: Scalable and reproducible scientific workflows<a class="headerlink" href="#nextflow-scalable-and-reproducible-scientific-workflows" title="Link to this heading">#</a></h2>
<p>Floden Evan, Di Tommaso Paolo</p>
<p>Published 2020-12-17</p>
<p>Licensed CC-BY-4.0</p>
<p>Nextflow is an open-source workflow management system that prioritizes portability and reproducibility. It enables users to develop and seamlessly scale genomics workflows locally, on HPC clusters, or in major cloud providers’ infrastructures. Developed since 2014 and backed by a fast-growing community, the Nextflow ecosystem is made up of users and developers across academia, government and industry. It counts over 1M downloads and over 10K users worldwide.</p>
<p>Tags: Workflow Engine</p>
<p>Content type: Slide</p>
<p><a class="reference external" href="https://zenodo.org/records/4334697">https://zenodo.org/records/4334697</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4334697">https://doi.org/10.5281/zenodo.4334697</a></p>
</section>
<hr class="docutils" />
<section id="ome2024-ngff-challenge-results">
<h2>OME2024 NGFF Challenge Results<a class="headerlink" href="#ome2024-ngff-challenge-results" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Published 2024-11-01</p>
<p>Licensed CC-BY-4.0</p>
<p>Presented at the 2024 FoundingGIDE event in Okazaki, Japan: <a class="reference external" href="https://founding-gide.eurobioimaging.eu/event/foundinggide-community-event-2024/">https://founding-gide.eurobioimaging.eu/event/foundinggide-community-event-2024/</a>
Note: much of the presentation was a demonstration of the OME2024-NGFF-Challenge – <a class="reference external" href="https://ome.github.io/ome2024-ngff-challenge/">https://ome.github.io/ome2024-ngff-challenge/</a> especially of querying an extraction of the metadata (<a class="github reference external" href="https://github.com/ome/ome2024-ngff-challenge-metadata">ome/ome2024-ngff-challenge-metadata</a>)
 </p>
<p><a class="reference external" href="https://zenodo.org/records/14234608">https://zenodo.org/records/14234608</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14234608">https://doi.org/10.5281/zenodo.14234608</a></p>
</section>
<hr class="docutils" />
<section id="open-science-sharing-licensing">
<h2>Open Science, Sharing &amp; Licensing<a class="headerlink" href="#open-science-sharing-licensing" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-04-18</p>
<p>Licensed CC-BY-4.0</p>
<p>Wir tauchen ein in die Welt der Open Science und definieren Begriffe wie Open Source, Open Access und die FAIR-Prinzipien (Findable, Accessible, Interoperable and Reuasable). Wir diskutieren, wie diese Methoden der [wissenschaftlichen] Kommunikation und des Datenmanagements die Welt verändern und wie wir sie praktisch in unsere Arbeit integrieren können. Dabei spielen Aspekte wie Copyright und Lizenzierung eine wichtige Rolle.</p>
<p>Tags: Research Data Management, Open Access, FAIR-Principles, Licensing</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/10990107">https://zenodo.org/records/10990107</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10990107">https://doi.org/10.5281/zenodo.10990107</a></p>
</section>
<hr class="docutils" />
<section id="optimisation-and-validation-of-a-swarm-intelligence-based-segmentation-algorithm-for-low-contrast-positron-emission-tomography">
<h2>Optimisation and Validation of a Swarm Intelligence based Segmentation Algorithm for low Contrast Positron Emission Tomography<a class="headerlink" href="#optimisation-and-validation-of-a-swarm-intelligence-based-segmentation-algorithm-for-low-contrast-positron-emission-tomography" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2014-04-01</p>
<p>Licensed CC-BY-4.0</p>
<p>In the field of radiooncological research, individualised therapy is one of the hot topics at the moment. As a key aspect biologically-adapted therapy is discussed. Therapy adaption based on biological parameters may include tomographic imaging to determine biological properties of the tumour. One often invoked imaging modality is positron emission tomography (PET) using the tracer [18F]-fluoromisonidazole (FMISO) for hypoxia imaging. Hypoxia imaging is of interest, because hypoxic tumours are known to be radiorestistant. Even further, patients with hypoxic tumours have worse prognosis compared to patients with normoxic tumours. Thus, hypoxia imaging appears promising for radiotherapy treatment adaption. For example, volumetric analysis of FMISO PET could deliver additional hypoxia target volumes, which may be irradiated with higher radiation doses to improve the therapeutic effect. However, limited contrast between target volume and background in FMISO PET images interferes image analysis.Established methods for target volume delineation in PET do not allow determination of reliable contours in FMISO PET. To tackle this aspect, this thesis focusses on an earlier developed swarm intelligence based segmentation algorithm for FMISO PET and rather, its optimisation and validation in a clinically relevant setting. In this setting, clinical FMISO PET images were used which were acquired as part of a clinical trial performed at the Clinic and Policlinic for Radiation Therapy and Radiooncology of the University Hospital Carl Gustav Carus Dresden. The segmentation algorithm was applied to these imaging data sets and optimised using a cross-validation approach incorporating reference contours from experienced observers who outlined FMISO PET positive volumes manually. Afterwards, the performance of the algorithm and the properties of the resulting contours were studied in more detail. The algorithm was shown to deliver contours which were similar to manually-created contours to a degree like manually-created contours were similar to each other. Thus, the application of the algorithm in clinical research is recommended to eliminate inter-observer-variabilities. Finally, it was shown that repeated FMISO PET imaging before and shortly after the beginning of combined radiochemotherapy lead to manually-created contours with significantly higher variations than the variations of automatically-created contours using the proposed algorithm. Increased contour similarity in subsequently acquired imaging data highlights the observer-independence of the algorithm. While several observers outline different volumes, in identical data sets as well as in subsequent imaging data sets, the algorithm outlines more stable volumes in both cases. Thus, increased contour reproducibility is reached by automation of the delineation process by the proposed algorithm. </p>
<p><a class="reference external" href="https://zenodo.org/records/7209862">https://zenodo.org/records/7209862</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7209862">https://doi.org/10.5281/zenodo.7209862</a></p>
</section>
<hr class="docutils" />
<section id="preprint-be-sustainable-recommendations-for-fair-resources-in-life-sciences-research-eosc-life-s-lessons">
<h2>Preprint: “Be Sustainable”, Recommendations for FAIR Resources in Life Sciences research: EOSC-Life’s Lessons<a class="headerlink" href="#preprint-be-sustainable-recommendations-for-fair-resources-in-life-sciences-research-eosc-life-s-lessons" title="Link to this heading">#</a></h2>
<p>Romain David, Arina Rybina, Jean-Marie Burel, Jean-Karim Heriche, Pauline Audergon, Jan-Willem Boiten, Frederik Coppens, Sara Crockett, Exter Katrina, Sven Fahrener, Maddalena Fratelli, Carole Goble, Philipp Gormanns, Tobias Grantner, Bjorn Gruning, Gurwitz, Kim Tamara, John Hancock, Henriette Harmse, Petr Holub, Nick Juty, Geoffrey Karnbach, Emma Karoune, Antje Keppler, Jessica Klemeier, Carla Lancelotti, Jean-Luc Legras, Lister, L. Allyson, Livio Longo, Dario, Rebecca Ludwig, Benedicte Madon, Marzia Massimi, Vera Matser, Rafaele Matteoni, Mayrhofer, Michaela Th., Christian Ohmann, Maria Panagiotopoulou, Helen Parkinson, Isabelle Perseil, Claudia Pfander, Roland Pieruschka, Michael Raess, Andreas Rauber, Richard, Audrey S., Paolo Romano, Antonio Rosato, Alex Sanchez-Pla, Susanna-Assunta Sansone, Ugis Sarkans, Beatriz Serrano-Solano, Jing Tang, Ziaurrehman Tanoli, Jonathan Tedds, Harald Wagener, Martin Weise, Westerhoff, Hans V., Rudolf Wittner, Jonathan Ewbank, Niklas Blomberg, Philip Gribbon</p>
<p>Published 2023-09-12</p>
<p>Licensed CC-BY-4.0</p>
<p>“Be SURE - Be SUstainable REcommendations”The main goals and challenges for the Life Science (LS) communities in the Open Science framework are to increase reuse and sustainability of data resources, software tools, and workflows, especially in large-scale data-driven research and computational analyses. Here, we present key findings, procedures, effective measures and recommendations for generating and establishing sustainable LS resources based on the collaborative, cross-disciplinary work done within the EOSC-Life (European Open Science Cloud for Life Sciences) consortium. Bringing together 13 European LS Research Infrastructures (RIs), it has laid the foundation for an open, digital space to support biological and medical research. Using lessons learned from 27 selected projects, we describe the organisational, technical, financial and legal/ethical challenges that represent the main barriers to sustainability in the life sciences. We show how EOSC-Life provides a model for sustainable FAIR data management, including solutions for sensitive- and industry-related resources, by means of cross-disciplinary training and best practices sharing. Finally, we illustrate how data harmonisation and collaborative work facilitate interoperability of tools, data, solutions and lead to a better understanding of concepts, semantics and functionalities in the life <a class="reference external" href="http://sciences.IN">sciences.IN</a> PRESS EMBO Journal: <a class="reference external" href="https://www.embopress.org/journal/14602075&amp;amp;nbsp;AVAILABLE">https://www.embopress.org/journal/14602075&amp;nbsp;AVAILABLE</a> SOON at : <a class="reference external" href="https://doi.org/10.15252/embj.2023115008">https://doi.org/10.15252/embj.2023115008</a> </p>
<p><a class="reference external" href="https://zenodo.org/records/8338931">https://zenodo.org/records/8338931</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8338931">https://doi.org/10.5281/zenodo.8338931</a></p>
</section>
<hr class="docutils" />
<section id="qupath-open-source-software-for-analysing-awkward-images">
<h2>QuPath: Open source software for analysing (awkward) images<a class="headerlink" href="#qupath-open-source-software-for-analysing-awkward-images" title="Link to this heading">#</a></h2>
<p>Peter Bankhead</p>
<p>Published 2020-12-16</p>
<p>Licensed CC-BY-4.0</p>
<p>Slides from the CZI/EOSS online meeting in December 2020.</p>
<p>Tags: Bioimage Analysis</p>
<p>Content type: Slide</p>
<p><a class="reference external" href="https://zenodo.org/records/4328911">https://zenodo.org/records/4328911</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4328911">https://doi.org/10.5281/zenodo.4328911</a></p>
</section>
<hr class="docutils" />
<section id="rdf-as-a-bridge-to-domain-platforms-like-omero-or-there-and-back-again">
<h2>RDF as a bridge to domain-platforms like OMERO, or There and back again.<a class="headerlink" href="#rdf-as-a-bridge-to-domain-platforms-like-omero-or-there-and-back-again" title="Link to this heading">#</a></h2>
<p>Josh Moore, Andra Waagmeester, Kristina Hettne, Katherine Wolstencroft, Susanne Kunis</p>
<p>Licensed CC-BY-4.0</p>
<p>In 2005, the first version of OMERO stored RDF natively. However, just a year after the 1.0 release of RDF, performance considerations led to the development of a more traditional SQL approach for OMERO. A binary protocol makes it possible to query and retrieve metadata but the resulting information cannot immediately be combined with other sources. This is the adventure of rediscovering the benefit of RDF triples as a – if not the – common exchange mechanism.</p>
<p>Tags: Research Data Management, FAIR-Principles, Bioimage Analysis</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.10687658">https://zenodo.org/doi/10.5281/zenodo.10687658</a></p>
</section>
<hr class="docutils" />
<section id="research-data-management-on-campus-and-in-nfdi4bioimage">
<h2>RESEARCH DATA MANAGEMENT on Campus and in NFDI4BIOIMAGE<a class="headerlink" href="#research-data-management-on-campus-and-in-nfdi4bioimage" title="Link to this heading">#</a></h2>
<p>Cornelia Wetzker, Michael Schlierf</p>
<p>Published 2024-08-29</p>
<p>Licensed CC-BY-4.0</p>
<p>The poster is part of the work of the German consortium NFDI4BIOIMAGE funded by the Deutsche Forschungsgemeinschaft (DFG grant number NFDI 46/1, project number 501864659).</p>
<p><a class="reference external" href="https://zenodo.org/records/13684187">https://zenodo.org/records/13684187</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13684187">https://doi.org/10.5281/zenodo.13684187</a></p>
</section>
<hr class="docutils" />
<section id="report-on-a-pilot-study-implementation-of-omero-for-microscopy-data-management">
<h2>Report on a pilot study:  Implementation of OMERO for  microscopy data management<a class="headerlink" href="#report-on-a-pilot-study-implementation-of-omero-for-microscopy-data-management" title="Link to this heading">#</a></h2>
<p>Silke Tulok, Gunar Fabig, Andy Vogelsang, Thomas Kugel, Thomas Müller-Reichert</p>
<p>Published 2023-11-10</p>
<p>Licensed CC-BY-4.0</p>
<p>The Core Facility Cellular Imaging (CFCI) at the Faculty of Medicine Carl Gustav Carus (TU Dresden) is currently running a pilot project for testing the use and handling of the OMERO software. This is done together with interested users of the imaging facility and a research group. Currently, we are pushing forward this pilot study on a small scale without any data steward. Our experiences argue so far for giving data management issues into the hands of dedicated personnel not fully involved in research projects. As funding agencies will ask for higher and higher standards for implementing FAIRdata principles in the future, this will be a releva</p>
<p><a class="reference external" href="https://zenodo.org/records/10103316">https://zenodo.org/records/10103316</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10103316">https://doi.org/10.5281/zenodo.10103316</a></p>
</section>
<hr class="docutils" />
<section id="research-data-management-seminar-slides">
<h2>Research Data Management Seminar - Slides<a class="headerlink" href="#research-data-management-seminar-slides" title="Link to this heading">#</a></h2>
<p>Della Chiesa, Stefano</p>
<p>Published 2022-05-18</p>
<p>Licensed CC-BY-4.0</p>
<p>This Research Data Management (RDM) Slides introduce to the multidisciplinary knowledge and competencies required to address policy compliance and research data management best practices throughout a project lifecycle, and beyond it.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Module 1 - Introduces the RDM giving its context in the Research Data Governance
Module 2 - Illustrates the most important RDM policies and principles
Module 3 - Provides the most relevant RDM knowledge bricks
Module 4 - Discuss the Data Management Plans (DMPs), examples, templates and guidance
</pre></div>
</div>
<p> </p>
<p>Tags: Research Data Management</p>
<p>Content type: Slide</p>
<p><a class="reference external" href="https://zenodo.org/record/6602101">https://zenodo.org/record/6602101</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6602101">https://doi.org/10.5281/zenodo.6602101</a></p>
</section>
<hr class="docutils" />
<section id="research-data-managemet-and-how-not-to-get-overwhelmed-with-data">
<h2>Research Data Managemet and how not to get overwhelmed with data<a class="headerlink" href="#research-data-managemet-and-how-not-to-get-overwhelmed-with-data" title="Link to this heading">#</a></h2>
<p>Martin Schätz</p>
<p>Published 2023-09-23</p>
<p>Licensed CC-BY-4.0</p>
<p>Research data management and how not to get overwhelmed with data presentation is an overview of bioimage analysis with a focus on the basics for data management planning, FAIR principles, and how to practically organize folders and prepares naming convention. The presentation includes an overview of metadata, Creative Common licenses, and a sum up of electronic laboratory notebooks. The last two slides go through how all of that works in practice in open access core microscopy facility.</p>
<p><a class="reference external" href="https://zenodo.org/records/8372703">https://zenodo.org/records/8372703</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8372703">https://doi.org/10.5281/zenodo.8372703</a></p>
</section>
<hr class="docutils" />
<section id="round-table-workshop-1-sample-stabilization-in-intravital-imaging">
<h2>Round Table Workshop 1 - Sample Stabilization in intravital Imaging<a class="headerlink" href="#round-table-workshop-1-sample-stabilization-in-intravital-imaging" title="Link to this heading">#</a></h2>
<p>Michael Gerlach, Hans-Ulrich Fried, Christiane Peuckert</p>
<p>Published 2024-11-14</p>
<p>Licensed CC-BY-4.0</p>
<p>Notes from a round table workshop on the 4th Day of Intravital Microscopy in Leuven, Belgium.
Contains hands-on tips, tricks and schemes to improve sample stability during various models of Intravital Miroscopy.</p>
<p><a class="reference external" href="https://zenodo.org/records/14161289">https://zenodo.org/records/14161289</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14161289">https://doi.org/10.5281/zenodo.14161289</a></p>
</section>
<hr class="docutils" />
<section id="round-table-workshop-2-correction-of-drift-and-movement">
<h2>Round Table Workshop 2 - Correction of Drift and Movement<a class="headerlink" href="#round-table-workshop-2-correction-of-drift-and-movement" title="Link to this heading">#</a></h2>
<p>Ishikawa-Ankerhold, Dr. Hellen, Max Nobis</p>
<p>Published 2024-11-14</p>
<p>Licensed CC-BY-4.0</p>
<p>Session 2 of a round table workshop. Features description of image processing methods useful in intravital imaging to compensate for the motion of living tissue.</p>
<p><a class="reference external" href="https://zenodo.org/records/14161633">https://zenodo.org/records/14161633</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14161633">https://doi.org/10.5281/zenodo.14161633</a></p>
</section>
<hr class="docutils" />
<section id="sciaugment">
<h2>SciAugment<a class="headerlink" href="#sciaugment" title="Link to this heading">#</a></h2>
<p>Martin Schätz</p>
<p>Published 2022-07-29</p>
<p>Licensed OTHER-OPEN</p>
<p>SciAugment v0.2.0 has pip installable version, channel-wise augmentation was added, and an option for all augmentations or no augmentation. Examples of how to use the tool are in README and in Google Colab notebooks. Practical examples of how to use results with YOLOv5 on scientific data can be found in the SciCount project.</p>
<p>SciAugment aims to provide an option to create an augmented image set with similar changes in data as the imaging sensor and technique would do.</p>
<p><a class="reference external" href="https://zenodo.org/records/6991106">https://zenodo.org/records/6991106</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6991106">https://doi.org/10.5281/zenodo.6991106</a></p>
</section>
<hr class="docutils" />
<section id="slides-about-flute-a-python-gui-for-interactive-phasor-analysis-of-flim-data">
<h2>Slides about FLUTE: a Python GUI for interactive phasor analysis of FLIM data<a class="headerlink" href="#slides-about-flute-a-python-gui-for-interactive-phasor-analysis-of-flim-data" title="Link to this heading">#</a></h2>
<p>Chiara Stringari</p>
<p>Published 2024-03-19</p>
<p>Licensed CC-BY-4.0</p>
<p>This presentation introduces the open source software to analyze FLIM data:
FLUTE – (F)luorescence (L)ifetime (U)ltima(T)e (E)xplorer:
a Python GUI for interactive phasor analysis of FLIM data
 
The software is available on GitHub: <a class="github reference external" href="https://github.com/LaboratoryOpticsBiosciences/FLUTE">LaboratoryOpticsBiosciences/FLUTE</a>
and it is published on Biological imaging Journal: Gottlieb, D., Asadipour, B., Kostina, P., Ung, T., &amp; Stringari, C. (2023). FLUTE: A Python GUI for interactive phasor analysis of FLIM data. Biological Imaging, 1-22. doi:10.1017/S2633903X23000211
The lecture was part of the short talks on community developed FLIM-software at the German BioImaging workshop on FLIM in Munich.</p>
<p><a class="reference external" href="https://zenodo.org/records/10839310">https://zenodo.org/records/10839310</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10839310">https://doi.org/10.5281/zenodo.10839310</a></p>
</section>
<hr class="docutils" />
<section id="so-geschlossen-wie-notig-so-offen-wie-moglich-datenschutz-beim-umgang-mit-forschungsdaten">
<h2>So geschlossen wie nötig, so offen wie möglich - Datenschutz beim Umgang mit Forschungsdaten<a class="headerlink" href="#so-geschlossen-wie-notig-so-offen-wie-moglich-datenschutz-beim-umgang-mit-forschungsdaten" title="Link to this heading">#</a></h2>
<p>Pia Voigt</p>
<p>Published 2024-05-30</p>
<p>Licensed CC-BY-4.0</p>
<p>Der Umgang mit personenbezogenen Daten stellt Forschende oft vor rechtliche Herausforderungen: Unter welchen Bedingungen dürfen personenbezogene Daten verarbeitet werden? Welche Voraussetzungen müssen erfüllt sein und welche Strategien können angewendet werden, um Daten sicher speichern, verarbeiten, teilen und aufbewahren zu können? Mit Hilfe dieses Foliensatzes erhalten Sie Einblicke in datenschutzrechtliche Aspekte beim Umgang mit Ihren Forschungsdaten. </p>
<p>Tags: Research Data Management, Data Protection, FAIR-Principles</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/11396199">https://zenodo.org/records/11396199</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11396199">https://doi.org/10.5281/zenodo.11396199</a></p>
</section>
<hr class="docutils" />
<section id="stackview-sliceplot-example-data">
<h2>Stackview sliceplot example data<a class="headerlink" href="#stackview-sliceplot-example-data" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-11-03</p>
<p>Licensed CC-BY-4.0</p>
<p>This is a dataset of PNG images of <a class="reference external" href="https://zenodo.org/records/12623730">Bio-Image Data Science teaching slides</a>. The png_umap.yml file contains a list of all images and a dimensionality reduced embedding (Uniform Manifold Approximation Projection, UMAP) made using OpenAI’s text-embedding-ada-002 model.
A notebook for visualizing this data is published here: <a class="github reference external" href="https://github.com/haesleinhuepf/stackview/blob/main/docs/sliceplot.ipynb">haesleinhuepf/stackview</a></p>
<p><a class="reference external" href="https://zenodo.org/records/14030307">https://zenodo.org/records/14030307</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14030307">https://doi.org/10.5281/zenodo.14030307</a></p>
</section>
<hr class="docutils" />
<section id="structuring-of-data-and-metadata-in-bioimaging-concepts-and-technical-solutions-in-the-context-of-linked-data">
<h2>Structuring of Data and Metadata in Bioimaging: Concepts and technical Solutions in the Context of Linked Data<a class="headerlink" href="#structuring-of-data-and-metadata-in-bioimaging-concepts-and-technical-solutions-in-the-context-of-linked-data" title="Link to this heading">#</a></h2>
<p>Sarah Weischer, Jens Wendt, Thomas Zobel</p>
<p>Published 2022-07-12</p>
<p>Licensed CC-BY-4.0</p>
<p>Provides an overview of contexts, frameworks, and models from the world of bioimage data as well as metadata. Visualizes the techniques for structuring this data as Linked Data. (Walkthrough Video: <a class="reference external" href="https://doi.org/10.5281/zenodo.7018928">https://doi.org/10.5281/zenodo.7018928</a> )</p>
<p>Content:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Types of metadata
Data formats
Data Models Microscopy Data
Tools to edit/gather metadata
ISA Framework
FDO Framework
Ontology
RDF
JSON-LD
SPARQL
Knowledge Graph
Linked Data
Smart Data
...
</pre></div>
</div>
<p><a class="reference external" href="https://zenodo.org/records/7018750">https://zenodo.org/records/7018750</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7018750">https://doi.org/10.5281/zenodo.7018750</a></p>
</section>
<hr class="docutils" />
<section id="sustainable-data-stewardship">
<h2>Sustainable Data Stewardship<a class="headerlink" href="#sustainable-data-stewardship" title="Link to this heading">#</a></h2>
<p>Stefano Della Chiesa</p>
<p>Published 2024-03-25</p>
<p>Licensed CC-BY-4.0</p>
<p>These slides were presented at the 2. SaxFDM-Beratungsstammtisch and delve into the strategic integration of Research Data Management (RDM) within research organizations. The Leibniz IOER presented an insightful overview of RDM activities and approaches, emphasizing the criticality of embedding RDM strategically within research institutions. The presentation showcases some best practices in RDM implementation through practical examples, offering valuable insights for optimizing data stewardship processes.</p>
<p>Tags: Research Data Management, Data Stewardship</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/10942559">https://zenodo.org/records/10942559</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10942559">https://doi.org/10.5281/zenodo.10942559</a></p>
</section>
<hr class="docutils" />
<section id="test-dataset-for-whole-slide-image-registration">
<h2>Test Dataset for Whole Slide Image Registration<a class="headerlink" href="#test-dataset-for-whole-slide-image-registration" title="Link to this heading">#</a></h2>
<p>Romain Guiet, Nicolas Chiaruttini</p>
<p>Published 2021-04-12</p>
<p>Licensed CC-BY-4.0</p>
<p>Mouse duodenum fixed in 4% PFA overnight at 4°C, processed for paraffin infiltration using a standard histology procedure and cut at 4 microns were dewaxed, rehydrated, permeabilized with 0.5% Triton X-100 in PBS 1x and stained with Azide - Alexa Fluor 555 (Thermo Fisher) to detect EdU and DAPI for nuclei. The images were taken using a Leica DM5500 microscope with a 40X N.A.1 objective (black&amp;white camera: DFC350FXR2, pixel dimension: 0.161 microns). Next, the slide was unmounted and stained using the fully automated Ventana Discovery xT autostainer (Roche Diagnostics, Rotkreuz, Switzerland). All steps were performed on automate with Ventana solutions. Sections were pretreated with heat using the CC1 solution under mild conditions. The primary rat anti BrDU (clone: BU1/75 (ICR1), Serotec, diluted 1:300) was incubated 1 hour at 37°C. After incubation with a donkey anti rat biotin diluted 1:200 (Jackson ImmunoResearch Laboratories), chromogenic revelation was performed with DabMap kit. The section was counterstained with Harris hematoxylin (J.T. Baker) before a second round of imaging on DM5500 PL Fluotar 40X N.A.1.0 oil (color camera: DFC 320 R2, pixel dimension: 0.1725 microns). Before acquisition, a white-balance as well as a shading correction is performed according to Leica LAS software wizard. The fluorescence and DAB images were converted in ome.tiff multiresolution file with the kheops Fiji Plugin.</p>
<p>Sampled prepared in the EPFL histology core facility by Nathalie Müller and Gian-Filippo Mancini.</p>
<p>Associated documents:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>https://c4science.ch/w/bioimaging_and_optics_platform_biop/teaching/dab-intensity/
https://imagej.net/plugins/bdv/warpy/warpy
</pre></div>
</div>
<p>This document contains a full QuPath project with an example of registered image.</p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/5675686">https://zenodo.org/records/5675686</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5675686">https://doi.org/10.5281/zenodo.5675686</a></p>
</section>
<hr class="docutils" />
<section id="the-information-infrastructure-for-bioimage-data-i3d-bio-project-to-advance-fair-microscopy-data-management-for-the-community">
<h2>The Information Infrastructure for BioImage Data (I3D:bio) project to advance FAIR microscopy data management for the community<a class="headerlink" href="#the-information-infrastructure-for-bioimage-data-i3d-bio-project-to-advance-fair-microscopy-data-management-for-the-community" title="Link to this heading">#</a></h2>
<p>Christian Schmidt, Michele Bortolomeazzi, Tom Boissonnet, Julia Dohle, Tobias Wernet, Janina Hanne, Roland Nitschke, Susanne Kunis, Karen Bernhardt, Stefanie Weidtkamp-Peters, Elisa Ferrando-May</p>
<p>Published 2024-03-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Research data management (RDM) in microscopy and image analysis is a challenging task. Large files in proprietary formats, complex N-dimensional array structures, and various metadata models and formats can make image data handling inconvenient and difficult. For data organization, annotation, and sharing, researchers need solutions that fit everyday practice and comply with the FAIR (Findable, Accessible, Interoperable, Reusable) principles. International community-based efforts have begun creating open data models (OME), an open file format and translation library (OME-TIFF, Bio-Formats), data management software platforms, and microscopy metadata recommendations and annotation tools. Bringing these developments into practice requires support and training. Iterative feedback and tool improvement is needed to foster practical adoption by the scientific community. The Information Infrastructure for BioImage Data (I3D:bio) project works on guidelines, training resources, and practical assistance for FAIR microscopy RDM adoption with a focus on the management platform OMERO and metadata annotations.</p>
<p><a class="reference external" href="https://zenodo.org/records/10805204">https://zenodo.org/records/10805204</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10805204">https://doi.org/10.5281/zenodo.10805204</a></p>
</section>
<hr class="docutils" />
<section id="the-role-of-helmholtz-centers-in-nfdi4bioimage-a-national-consortium-enhancing-fair-data-management-for-microscopy-and-bioimage-analysis">
<h2>The role of Helmholtz Centers in NFDI4BIOIMAGE - A national consortium enhancing FAIR data management for microscopy and bioimage analysis<a class="headerlink" href="#the-role-of-helmholtz-centers-in-nfdi4bioimage-a-national-consortium-enhancing-fair-data-management-for-microscopy-and-bioimage-analysis" title="Link to this heading">#</a></h2>
<p>Riccardo Massei, Christian Schmidt, Michele Bortolomeazzi, Julia Thoennissen, Jan Bumberger, Timo Dickscheid, Jan-Philipp Mallm, Elisa Ferrando-May</p>
<p>Published 2024-06-06</p>
<p>Licensed CC-BY-4.0</p>
<p>Germany’s National Research Data Infrastructure (NFDI) aims to establish a sustained, cross-disciplinary research data management (RDM) infrastructure that enables researchers to handle FAIR (findable, accessible, interoperable, reusable) data. While FAIR principles have been adopted by funders, policymakers, and publishers, their practical implementation remains an ongoing effort. In the field of bio-imaging, harmonization of data formats, metadata ontologies, and open data repositories is necessary to achieve FAIR data. The NFDI4BIOIMAGE was established to address these issues and develop tools and best practices to facilitate FAIR microscopy and image analysis data in alignment with international community activities. The consortium operates through its Data Stewards team to provide expertise and direct support to help overcome RDM challenges. The three Helmholtz Centers in NFDI4BIOIMAGE aim to collaborate closely with other centers and initiatives, such as HMC, Helmholtz AI, and HIP. Here we present NFDI4BIOIMAGE’s work and its significance for research in Helmholtz and beyond</p>
<p><a class="reference external" href="https://zenodo.org/records/11501662">https://zenodo.org/records/11501662</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11501662">https://doi.org/10.5281/zenodo.11501662</a></p>
</section>
<hr class="docutils" />
<section id="thinking-data-management-on-different-scales">
<h2>Thinking data management on different scales<a class="headerlink" href="#thinking-data-management-on-different-scales" title="Link to this heading">#</a></h2>
<p>Susanne Kunis</p>
<p>Licensed CC-BY-4.0</p>
<p>Presentation given at PoL BioImage Analysis Symposium Dresden 2023</p>
<p>Tags: Research Data Management, Nfdi4Bioimage</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.8329305">https://zenodo.org/doi/10.5281/zenodo.8329305</a></p>
</section>
<hr class="docutils" />
<section id="towards-preservation-of-life-science-data-with-nfdi4bioimage">
<h2>Towards Preservation of Life Science Data with NFDI4BIOIMAGE<a class="headerlink" href="#towards-preservation-of-life-science-data-with-nfdi4bioimage" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-09-03</p>
<p>Licensed CC-BY-4.0</p>
<p>This talk will present the initiatives of the NFDI4BioImage consortium aimed at the long-term preservation of life science data. We will discuss our efforts to establish metadata standards, which are crucial for ensuring data reusability and integrity. The development of sustainable infrastructure is another key focus, enabling seamless data integration and analysis in the cloud. We will take a look at how we manage training materials and communicate with our community. Through these actions, NFDI4BioImage seeks to enable FAIR bioimage data management for German researchers, across disciplines and embedded in the international framework.</p>
<p><a class="reference external" href="https://zenodo.org/records/13640979">https://zenodo.org/records/13640979</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13640979">https://doi.org/10.5281/zenodo.13640979</a></p>
</section>
<hr class="docutils" />
<section id="towards-transparency-and-knowledge-exchange-in-ai-assisted-data-analysis-code-generation">
<h2>Towards Transparency and Knowledge Exchange in AI-assisted Data Analysis Code Generation<a class="headerlink" href="#towards-transparency-and-knowledge-exchange-in-ai-assisted-data-analysis-code-generation" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-10-14</p>
<p>Licensed CC-BY-4.0</p>
<p>The integration of Large Language Models (LLMs) in scientific research presents both opportunities and challenges for life scientists. Key challenges include ensuring transparency in AI-generated content and facilitating efficient knowledge exchange among researchers. These issues arise from the in-transparent nature of AI-driven code generation and the informal sharing of AI insights, which may hinder reproducibility and collaboration. This paper introduces git-bob, an innovative AI-assistant designed to address these challenges by fostering an interactive and transparent collaboration platform within GitHub. By enabling seamless dialogue between humans and AI, git-bob ensures that AI contributions are transparent and reproducible. Moreover, it supports collaborative knowledge exchange, enhancing the interdisciplinary dialogue necessary for cutting-edge life sciences research. The open-source nature of git-bob further promotes accessibility and customization, positioning it as a vital tool in employing LLMs responsibly and effectively within scientific communities.</p>
<p><a class="reference external" href="https://zenodo.org/records/13928832">https://zenodo.org/records/13928832</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13928832">https://doi.org/10.5281/zenodo.13928832</a></p>
</section>
<hr class="docutils" />
<section id="train-the-trainer-concept-on-research-data-management">
<h2>Train-the-Trainer Concept on Research Data Management<a class="headerlink" href="#train-the-trainer-concept-on-research-data-management" title="Link to this heading">#</a></h2>
<p>Katarzyna Biernacka, Maik Bierwirth, Petra Buchholz, Dominika Dolzycka, Kerstin Helbig, Janna Neumann, Carolin Odebrecht, Cord Wiljes, Ulrike Wuttke</p>
<p>Published 2020-11-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Within the project FDMentor, a German Train-the-Trainer Programme on Research Data Management (RDM) was developed and piloted in a series of workshops. The topics cover many aspects of research data management, such as data management plans and the publication of research data, as well as didactic units on learning concepts, workshop design and a range of didactic methods.</p>
<p>After the end of the project, the concept was supplemented and updated by members of the Sub-Working Group Training/Further Education (UAG Schulungen/Fortbildungen) of the DINI/nestor Working Group Research Data (DINI/nestor-AG Forschungsdaten). The newly published English version of the Train-the-Trainer Concept contains the translated concept, the materials and all methods of the Train-the-Trainer Programme. Furthermore, additional English references and materials complement this version.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Book</p>
<p><a class="reference external" href="https://zenodo.org/record/4071471">https://zenodo.org/record/4071471</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4071471">https://doi.org/10.5281/zenodo.4071471</a></p>
</section>
<hr class="docutils" />
<section id="welcome-to-bioimage-town">
<h2>Welcome to BioImage Town<a class="headerlink" href="#welcome-to-bioimage-town" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Licensed CC-BY-4.0</p>
<p>Welcome at NFDI4BIOIMAGE All-Hands Meeting in Düsseldorf, Germany, October 16, 2023</p>
<p>Tags: OMERO, Bioimage Analysis, Nfdi4Bioimage</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.10008464">https://zenodo.org/doi/10.5281/zenodo.10008464</a></p>
</section>
<hr class="docutils" />
<section id="who-you-gonna-call-data-stewards-to-the-rescue">
<h2>Who you gonna call? - Data Stewards to the rescue<a class="headerlink" href="#who-you-gonna-call-data-stewards-to-the-rescue" title="Link to this heading">#</a></h2>
<p>Fuchs, Vanessa Aphaia Fiona, Jens Wendt, Maximilian Müller, Mohsen Ahmadi, Riccardo Massei, Cornelia Wetzker</p>
<p>Published 2024-03-01</p>
<p>Licensed CC-BY-4.0</p>
<p>The Data Steward Team of the NFDI4BIOIMAGE consortium presents themselves and the services (including the Helpdesk) that we offer.</p>
<p><a class="reference external" href="https://zenodo.org/records/10730424">https://zenodo.org/records/10730424</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10730424">https://doi.org/10.5281/zenodo.10730424</a></p>
</section>
<hr class="docutils" />
<section id="zeiss-axiozoom-stage-adapter">
<h2>Zeiss AxioZoom Stage Adapter<a class="headerlink" href="#zeiss-axiozoom-stage-adapter" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-06-20</p>
<p>Licensed CC-BY-4.0</p>
<p>A 3D- printable microscope stage adapter for the reproducible accomodation of samples at a Zeiss AxioZoom stereomicroscope.
4 cylindrical anchors are fixed to the glass plate of the stage. The stage adapter is reversibly placed on these anchors.
 </p>
<p><a class="reference external" href="https://zenodo.org/records/7963020">https://zenodo.org/records/7963020</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7963020">https://doi.org/10.5281/zenodo.7963020</a></p>
</section>
<hr class="docutils" />
<section id="zeiss-axiozoom-stage-adapter-12-6well-plate">
<h2>Zeiss AxioZoom Stage Adapter - 12/6Well Plate<a class="headerlink" href="#zeiss-axiozoom-stage-adapter-12-6well-plate" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-06-20</p>
<p>Licensed CC-BY-4.0</p>
<p>A 3D- printable microscope stage adapter for the reproducible accomodation of 6 or 12-well plates at a Zeiss AxioZoom microscope.
4 cylindrical anchors are fixed to the glass plate of the stage. The stage adapter is reversibly placed on these anchors and acommodates a standard Greiner 6- or 12-well plate.</p>
<p><a class="reference external" href="https://zenodo.org/records/7944877">https://zenodo.org/records/7944877</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7944877">https://doi.org/10.5281/zenodo.7944877</a></p>
</section>
<hr class="docutils" />
<section id="zeiss-axiozoom-stage-adapter-em-block-holder">
<h2>Zeiss AxioZoom Stage Adapter - EM block holder<a class="headerlink" href="#zeiss-axiozoom-stage-adapter-em-block-holder" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-06-20</p>
<p>Licensed CC-BY-4.0</p>
<p>A 3D- printable microscope stage adapter for the reproducible accomodation of EM Blocks at a Zeiss AxioZoom microscope.</p>
<p>4 cylindrical anchors are fixed to the glass plate of the stage. The stage adapter is reversibly placed on these anchors and acommodates 70 standard resin EM blocks.</p>
<p><a class="reference external" href="https://zenodo.org/records/7963006">https://zenodo.org/records/7963006</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7963006">https://doi.org/10.5281/zenodo.7963006</a></p>
</section>
<hr class="docutils" />
<section id="zeiss-axiozoom-stage-adapter-microscope-slides">
<h2>Zeiss AxioZoom Stage Adapter - Microscope slides<a class="headerlink" href="#zeiss-axiozoom-stage-adapter-microscope-slides" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-06-21</p>
<p>Licensed CC-BY-4.0</p>
<p>A 3D- printable microscope stage adapter for the reproducible accomodation of microscopic slides at a Zeiss AxioZoom microscope.
4 cylindrical anchors are fixed to the glass plate of the stage. The stage adapter is reversibly placed on these anchors and acommodates 4 standard glass slides.</p>
<p><a class="reference external" href="https://zenodo.org/records/7945018">https://zenodo.org/records/7945018</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7945018">https://doi.org/10.5281/zenodo.7945018</a></p>
</section>
<hr class="docutils" />
<section id="bina-cc-scalable-strategies-for-a-next-generation-of-fair-bioimaging">
<h2>[BINA CC] Scalable strategies for a next-generation of FAIR bioimaging<a class="headerlink" href="#bina-cc-scalable-strategies-for-a-next-generation-of-fair-bioimaging" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Published 2024-09-24</p>
<p>Licensed CC-BY-4.0</p>
<p>Presented at <a class="reference external" href="https://www.bioimagingnorthamerica.org/events/bina-2024-community-congress/">https://www.bioimagingnorthamerica.org/events/bina-2024-community-congress/</a></p>
<p><a class="reference external" href="https://zenodo.org/records/13831274">https://zenodo.org/records/13831274</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13831274">https://doi.org/10.5281/zenodo.13831274</a></p>
</section>
<hr class="docutils" />
<section id="cordi-2023-zarr-a-cloud-optimized-storage-for-interactive-access-of-large-arrays">
<h2>[CORDI 2023] Zarr: A Cloud-Optimized Storage for Interactive Access of Large Arrays<a class="headerlink" href="#cordi-2023-zarr-a-cloud-optimized-storage-for-interactive-access-of-large-arrays" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Licensed CC-BY-4.0</p>
<p>For decades, the sharing of large N-dimensional datasets has posed issues across multiple domains. Interactively accessing terabyte-scale data has previously required significant server resources to properly prepare cropped or down-sampled representations on the fly. Now, a cloud-native chunked format easing this burden has been adopted in the bioimaging domain for standardization. The format — Zarr — is potentially of interest for other consortia and sections of NFDI.</p>
<p>Tags: Research Data Management, Bioimage Analysis, Data Science</p>
<p>Content type: Poster</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.8340247">https://zenodo.org/doi/10.5281/zenodo.8340247</a></p>
</section>
<hr class="docutils" />
<section id="community-meeting-2024-overview-team-image-data-analysis-and-management">
<h2>[Community Meeting 2024] Overview Team Image Data Analysis and Management<a class="headerlink" href="#community-meeting-2024-overview-team-image-data-analysis-and-management" title="Link to this heading">#</a></h2>
<p>Susanne Kunis, Thomas Zobel</p>
<p>Published 2024-03-08</p>
<p>Licensed CC-BY-4.0</p>
<p>Overview of Activities of the Team Image Data Analysis and Management of German BioImaging e.V.
 </p>
<p><a class="reference external" href="https://zenodo.org/records/10796364">https://zenodo.org/records/10796364</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10796364">https://doi.org/10.5281/zenodo.10796364</a></p>
</section>
<hr class="docutils" />
<section id="community-meeting-2024-supporting-and-financing-rdm-projects-within-gerbi">
<h2>[Community Meeting 2024] Supporting and financing RDM projects within GerBI<a class="headerlink" href="#community-meeting-2024-supporting-and-financing-rdm-projects-within-gerbi" title="Link to this heading">#</a></h2>
<p>Stefanie Weidtkamp-Peters, Josh Moore, Christian Schmidt, Roland Nitschke, Susanne Kunis, Thomas Zobel</p>
<p>Published 2024-03-28</p>
<p>Licensed CC-BY-4.0</p>
<p>Overview of GerBI RDM projects: why and how?</p>
<p><a class="reference external" href="https://zenodo.org/records/10889694">https://zenodo.org/records/10889694</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10889694">https://doi.org/10.5281/zenodo.10889694</a></p>
</section>
<hr class="docutils" />
<section id="elmi-2024-ai-s-dirty-little-secret-without">
<h2>[ELMI 2024]  AI’s Dirty Little Secret: Without<a class="headerlink" href="#elmi-2024-ai-s-dirty-little-secret-without" title="Link to this heading">#</a></h2>
<p>FAIR Data, It’s Just Fancy Math</p>
<p>Josh Moore, Susanne Kunis</p>
<p>Published 2024-05-21</p>
<p>Licensed CC-BY-4.0</p>
<p>Poster presented at the European Light Microscopy Initiative meeting in Liverpool (<a class="reference external" href="https://www.elmi2024.org/">https://www.elmi2024.org/</a>)</p>
<p><a class="reference external" href="https://zenodo.org/records/11235513">https://zenodo.org/records/11235513</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11235513">https://doi.org/10.5281/zenodo.11235513</a></p>
</section>
<hr class="docutils" />
<section id="elmi-2024-ai-s-dirty-little-secret-without-fair-data-it-s-just-fancy-math">
<h2>[ELMI 2024] AI’s Dirty Little Secret: Without FAIR Data, It’s Just Fancy Math<a class="headerlink" href="#elmi-2024-ai-s-dirty-little-secret-without-fair-data-it-s-just-fancy-math" title="Link to this heading">#</a></h2>
<p>Josh Moore, Susanne Kunis</p>
<p>Licensed CC-BY-4.0</p>
<p>Poster presented at the European Light Microscopy Initiative meeting in Liverpool (<a class="reference external" href="https://www.elmi2024.org/">https://www.elmi2024.org/</a>)</p>
<p>Tags: Research Data Management, FAIR-Principles, Bioimage Analysis, Nfdi4Bioimage</p>
<p>Content type: Poster</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.11235512">https://zenodo.org/doi/10.5281/zenodo.11235512</a></p>
</section>
<hr class="docutils" />
<section id="gbi-eoe-vii-five-or-ten-must-have-items-for-making-it-infrastructure-for-managing-bioimage-data">
<h2>[GBI EOE VII] Five (or ten) must-have items for making IT infrastructure for managing bioimage data<a class="headerlink" href="#gbi-eoe-vii-five-or-ten-must-have-items-for-making-it-infrastructure-for-managing-bioimage-data" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Published 2024-05-26</p>
<p>Licensed CC-BY-4.0</p>
<p>Presentation made to the GBI Image Data Management Working Group during the 7th Exchange of Experience in Uruguay.</p>
<p><a class="reference external" href="https://zenodo.org/records/11318151">https://zenodo.org/records/11318151</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11318151">https://doi.org/10.5281/zenodo.11318151</a></p>
</section>
<hr class="docutils" />
<section id="gbi-eoe-ix-nfdi4bioimage">
<h2>[GBI EoE IX] NFDI4BIOIMAGE<a class="headerlink" href="#gbi-eoe-ix-nfdi4bioimage" title="Link to this heading">#</a></h2>
<p>National Research Data Infrastructure
for Microscopy and BioImage Analysis</p>
<p>Josh Moore</p>
<p>Published 2024-10-29</p>
<p>Licensed CC-BY-4.0</p>
<p>Presented at <a class="reference external" href="https://globalbioimaging.org/exchange-of-experience/exchange-of-experience-ix">https://globalbioimaging.org/exchange-of-experience/exchange-of-experience-ix</a> in Okazaki, Japan.</p>
<p><a class="reference external" href="https://zenodo.org/records/14001388">https://zenodo.org/records/14001388</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14001388">https://doi.org/10.5281/zenodo.14001388</a></p>
</section>
<hr class="docutils" />
<section id="i2k-scalable-strategies-for-a-next-generation-of-fair-bioimaging">
<h2>[I2K] Scalable strategies for a next-generation of FAIR bioimaging<a class="headerlink" href="#i2k-scalable-strategies-for-a-next-generation-of-fair-bioimaging" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Published 2024-10-25</p>
<p>Licensed CC-BY-4.0</p>
<p>or, “OME-Zarr: ‘even a talk on formats [can be] interesting’”
Presented at <a class="reference external" href="https://events.humantechnopole.it/event/1/">https://events.humantechnopole.it/event/1/</a></p>
<p><a class="reference external" href="https://zenodo.org/records/13991322">https://zenodo.org/records/13991322</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13991322">https://doi.org/10.5281/zenodo.13991322</a></p>
</section>
<hr class="docutils" />
<section id="n4bi-ahm-welcome-to-bioimage-town">
<h2>[N4BI AHM] Welcome to BioImage Town<a class="headerlink" href="#n4bi-ahm-welcome-to-bioimage-town" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Published 2023-10-16</p>
<p>Licensed CC-BY-4.0</p>
<p>Keynote at the NFDI4BIOIMAGE All-Hands Meeting in Düsseldorf, Germany, October 16, 2023.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/10008465">https://zenodo.org/records/10008465</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10008465">https://doi.org/10.5281/zenodo.10008465</a></p>
</section>
<hr class="docutils" />
<section id="swat4hcls-2023-nfdi4bioimage-perspective-for-a-national-bioimage-standard">
<h2>[SWAT4HCLS 2023] NFDI4BIOIMAGE: Perspective for a national bioimage standard<a class="headerlink" href="#swat4hcls-2023-nfdi4bioimage-perspective-for-a-national-bioimage-standard" title="Link to this heading">#</a></h2>
<p>Josh Moore, Susanne Kunis</p>
<p>Licensed CC-BY-4.0</p>
<p>Poster presented at Semantic Web Applications and Tools for Health Care and Life Sciences (SWAT4HCLS 2023), Feb 13–16, 2023, Basel, Switzerland. NFDI4BIOIMAGE is a newly established German consortium dedicated to the FAIR representation of biological imaging data. A key deliverable is the definition of a semantically-compatible FAIR image object integrating RDF metadata with web-compatible storage of large n-dimensional binary data in OME-Zarr. We invite feedback from and collaboration with other endeavors during the soon-to-begin 5 year funding period.</p>
<p>Tags: Research Data Management, FAIR-Principles, Nfdi4Bioimage</p>
<p>Content type: Poster</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.7928332">https://zenodo.org/doi/10.5281/zenodo.7928332</a></p>
</section>
<hr class="docutils" />
<section id="short-talk-nfdi4bioimage-a-consortium-in-the-national-research-data-infrastructure">
<h2>[Short Talk] NFDI4BIOIMAGE - A consortium in the National Research Data Infrastructure<a class="headerlink" href="#short-talk-nfdi4bioimage-a-consortium-in-the-national-research-data-infrastructure" title="Link to this heading">#</a></h2>
<p>Christian Schmidt</p>
<p>Published 2024-04-10</p>
<p>Licensed CC-BY-4.0</p>
<p>Short Talk about the NFDI4BIOIMAGE consortium presented at the RDM in (Bio-)Medicine Information Event on April 10th, 2024, organized C³RDM &amp; ZB MED.</p>
<p><a class="reference external" href="https://zenodo.org/records/10939520">https://zenodo.org/records/10939520</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10939520">https://doi.org/10.5281/zenodo.10939520</a></p>
</section>
<hr class="docutils" />
<section id="workshop-material-fit-for-omero-how-imaging-facilities-and-it-departments-work-together-to-enable-rdm-for-bioimaging-october-16-17-2024-heidelberg">
<h2>[Workshop Material] Fit for OMERO - How imaging facilities and IT departments work together to enable RDM for bioimaging, October 16-17, 2024, Heidelberg<a class="headerlink" href="#workshop-material-fit-for-omero-how-imaging-facilities-and-it-departments-work-together-to-enable-rdm-for-bioimaging-october-16-17-2024-heidelberg" title="Link to this heading">#</a></h2>
<p>Tom Boissonnet, Bettina Hagen, Susanne Kunis, Christian Schmidt, Stefanie Weidtkamp-Peters</p>
<p>Published 2024-11-18</p>
<p>Licensed CC-BY-4.0</p>
<p>Fit for OMERO: How imaging facilities and IT departments work together to enable RDM for bioimaging
Description:
Research data management (RDM) in bioimaging is challenging because of large file sizes, heterogeneous file formats and the variability of imaging methods. The image data management system OMERO (OME Remote Objects) allows for centralized and secure storage, organization, annotation, and interrogation of microscopy data by researchers. It is an internationally well-supported open-source software tool that has become one of the best-known image data management tools among bioimaging scientists. Nevertheless, the de novo setup of OMERO at an institute is a multi-stakeholder process that demands time, funds, organization and iterative implementation. In this workshop, participants learn how to begin setting up OMERO-based image data management at their institution. The topics include:</p>
<p>Stakeholder identification at the university / research institute
Process management, time line expectations, and resources planning
Learning about each other‘s perspectives on chances and challenges for RDM
Funding opportunities and strategies for IT and imaging core facilities
Hands-on: Setting up an OMERO server in a virtual machine environment</p>
<p>Target audience:
This workshop was directed at universities and research institutions who consider or plan to implement OMERO, or are in an early phase of implementation. This workshop was intended for teams from IT departments and imaging facilities to participate together with one person from the IT department, and one person from the imaging core facility at the same institution.
The trainers:</p>
<p>Prof. Dr. Stefanie Weidtkamp-Peters (Imaging Core Facility Head, Center for Advanced Imaging, Heinrich Heine University of Düsseldorf)
Dr. Susanne Kunis (Software architect, OMERO administrator, metadata specialist, University of Osnabrück)
Dr. Tom Boissonnet (OMERO admin and image metadata specialist, Center for Advanced Imaging, Heinrich Heine University of Düsseldorf)
Dr. Bettina Hagen (IT Administration and service specialist, Max Planck Institute for the Biology of Ageing, Cologne) 
Dr. Christian Schmidt (Science Manager for Research Data Management in Bioimaging, German Cancer Research Center (DKFZ), Heidelberg)</p>
<p>Time and place
The format was a two-day, in-person workshop (October 16-17, 2024). Location: Heidelberg, Germany
Workshop learning goals</p>
<p>Learn the steps to establish a local RDM environment fit for bioimaging data
Create a network of IT experts and bioimaging specialists for bioimage RDM across institutions
Establish a stakeholder process management for installing OMERO-based RDM
Learn from each other, leverage different expertise
Learn how to train users, establish sustainability strategies, and foster FAIR RDM for bioimaging at your institution</p>
<p><a class="reference external" href="https://zenodo.org/records/14178789">https://zenodo.org/records/14178789</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14178789">https://doi.org/10.5281/zenodo.14178789</a></p>
</section>
<hr class="docutils" />
<section id="workshop-bioimage-data-management-and-analysis-with-omero">
<h2>[Workshop] Bioimage data management and analysis with OMERO<a class="headerlink" href="#workshop-bioimage-data-management-and-analysis-with-omero" title="Link to this heading">#</a></h2>
<p>Riccardo Massei, Michele Bortolomeazzi, Christian Schmidt</p>
<p>Published 2024-05-13</p>
<p>Licensed CC-BY-4.0</p>
<p>Here we share the material used in a workshop held on May 13th, 2024, at the German Cancer Research Center in Heidelberg (on-premise)
Description:Microscopy experiments generate information-rich, multi-dimensional data, allowing us to investigate biological processes at high spatial and temporal resolution. Image processing and analysis is a standard procedure to retrieve quantitative information from biological imaging. Due to the complex nature of bioimaging files that often come in proprietary formats, it can be challenging to organize, structure, and annotate bioimaging data throughout a project. Data often needs to be moved between collaboration partners, transformed into open formats, processed with a variety of software tools, and exported to smaller-sized images for presentation. The path from image acquisition to final publication figures with quantitative results must be documented and reproducible.
In this workshop, participants learn how to use OMERO to organize their data and enrich the bioimage data with structured metadata annotations.We also focus on image analysis workflows in combination with OMERO based on the Fiji/ImageJ software and using Jupyter Notebooks. In the last part, we explore how OMERO can be used to create publication figures and prepare bioimage data for publication in a suitable repository such as the Bioimage Archive.
Module 1 (9 am - 10.15 am): Basics of OMERO, data structuring and annotation
Module 2 (10.45 am - 12.45 pm): OMERO and Fiji
Module 3 (1.45 pm - 3.45 pm): OMERO and Jupyter Notebooks
Module 4 (4.15 pm - 6. pm): Publication-ready figures and data with OMERO
The target group for this workshopThis workshop is directed at researchers at all career levels who plan to or have started to use OMERO for their microscopy research data management. We encourage the workshop participants to bring example data from their research to discuss suitable metadata annotation for their everyday practice.
Prerequisites:Users should bring their laptops and have access to the internet through one of the following options:- eduroam- institutional WiFi- VPN connection to their institutional networks to access OMERO
Who are the trainers?
Dr. Riccardo Massei (Helmholtz-Center for Environmental Research, UFZ, Leipzig) - Data Steward for Bioimaging Data in NFDI4BIOIMAGE
Dr. Michele Bortolomeazzi (DKFZ, Single cell Open Lab, bioimage data specialist, bioinformatician, staff scientist in the NFDI4BIOIMAGE project)
Dr. Christian Schmidt (Science Manager for Research Data Management in Bioimaging, German Cancer Research Center, Heidelberg, Project Coordinator of the NFDI4BIOIMAGE project)</p>
<p><a class="reference external" href="https://zenodo.org/records/11350689">https://zenodo.org/records/11350689</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11350689">https://doi.org/10.5281/zenodo.11350689</a></p>
</section>
<hr class="docutils" />
<section id="workshop-fair-data-handling-for-microscopy-structured-metadata-annotation-in-omero">
<h2>[Workshop] FAIR data handling for microscopy: Structured metadata annotation in OMERO<a class="headerlink" href="#workshop-fair-data-handling-for-microscopy-structured-metadata-annotation-in-omero" title="Link to this heading">#</a></h2>
<p>Vanessa Fuchs, Fiona Aphaia, Christian Schmidt, Tom Boissonnet</p>
<p>Published 2024-05-06</p>
<p>Licensed CC-BY-4.0</p>
<p>Description
Microscopy experiments generate information-rich, multi-dimensional data, allowing us to investigate biological processes at high spatial and temporal resolution. Image processing and analysis is a standard procedure to retrieve quantitative information from biological imaging. Due to the complex nature of bioimaging files that often come in proprietary formats, it can be challenging to organize, structure, and annotate bioimaging data throughout a project. Data often needs to be moved between collaboration partners, transformed into open formats, processed with a variety of software tools, and exported to smaller-sized images for presentation. The path from image acquisition to final publication figures with quantitative results must be documented and reproducible.
In this workshop, participants learn how to use structured metadata annotations in the image data management platform OMERO (OME Remote Objects) to optimize their data handling. This strategy helps both with organizing data for easier processing and analysis and for the preparation of data publication in journal manuscripts and in public repositories such as the BioImage Archive. Participants learn the principles of leveraging object-oriented data organization in OMERO to enhance findability and usability of their data, also in collaborative settings. The integration of OMERO with image analysis tools, in particular ImageJ/Fiji, will be trained. Moreover, users learn about community-accepted metadata checklists (REMBI) to enrich the value of their data toward reproducibility and reusability. In this workshop, we will provide hands-on training and recommendations on:</p>
<p>Structured metadata annotation features in OMERO and how to use them
Types of metadata in bioimaging: Technical metadata, sample metadata, analysis metadata
The use of ontologies and terminologies for metadata annotation
REMBI, the recommended metadata for biological images
Metadata-assisted image analysis streamlining
Tools for metadata annotation in OMERO</p>
<p>The target group for this workshop
This workshop is directed at researchers at all career levels who have started using OMERO for their microscopy research data management. We encourage the workshop participants to bring example data from their research to discuss suitable metadata annotation for their everyday practice.
Who are the trainers (see trainer description below for more details)</p>
<p>Dr. Vanessa Fuchs (NFDI4BIOIMAGE Data Steward, Center for Advanced Imaging, Heinrich-Heine University of Düsseldorf)
Dr. Tom Boissonnet (OMERO admin and image metadata specialist, Center for Advanced Imaging, Heinrich-Heine University of Düsseldorf)
Dr. Christian Schmidt (Science Manager for Research Data Management in Bioimaging, German Cancer Research Center, Heidelberg)</p>
<p>Material Description
Published here are the presentation slides that were used for input from the trainers during the different sessions of the programme. Additionally, a Fiji Macro is published that depends on the OMERO Extensions Plugin by Pouchin et al, 2022, F100Research, <a class="reference external" href="https://doi.org/10.12688/f1000research.110385.2">https://doi.org/10.12688/f1000research.110385.2</a> 
Programme Overview
Day 1 - April 29th, 2024 09.00 a.m. to 10.00 a.m.: Session 1 - Welcome and Introduction
10.00 a.m. to 10.30 a.m.:  Session 2 - Introduction to the FAIR principles &amp; data annotation
10:30 a.m. to 10:45 a.m.: Coffee break
10.45 a.m. to 12.00 a.m.: Session 3 - Data structure (datasets in OMERO) and organization with Tags 
12.00 a.m. to 1.00 p.m.:  Lunch Break
1.00 p.m. to 2.00 p.m.:  Session 4 - REMBI, Key-Value pair annotations in bioimaging
2:00 p.m. to 2.30 p.m.:  Session 5 - Ontologies for Key-Value Pairs in OMERO
2:30 p.m. to 2:45 p.m. Coffee break
2.45 p.m. to 3.45 p.m.:  Wrap-up, discussion, outlook on day 2
Day 2 - April 30th, 2024
09.00 a.m. to 09.30 a.m.:  Arrival and Start into day 2
09.30 a.m. to 11.30 a.m.:  Session 6 - Hands-on : REMBI-based Key-Value Pair annotation in OMERO
11.30 a.m. to 12.30 a.m.:  Lunch Break
12.30 a.m. to 1.15 p.m.: Session 7 - OMERO and OMERO.plugins
1.15 p.m. to 2.00 p.m.: Session 8 - Loading OMERO-hosted data into Fiji
2.00 p.m. to 2.15 p.m.: Coffee break 
2.15 p.m. to 3.00 p.m.: Discussion, Outlook</p>
<p><a class="reference external" href="https://zenodo.org/records/11109616">https://zenodo.org/records/11109616</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11109616">https://doi.org/10.5281/zenodo.11109616</a></p>
</section>
<hr class="docutils" />
<section id="ilastik-interactive-machine-learning-for-bio-image-analysis">
<h2>ilastik: interactive machine learning for (bio)image analysis<a class="headerlink" href="#ilastik-interactive-machine-learning-for-bio-image-analysis" title="Link to this heading">#</a></h2>
<p>Anna Kreshuk, Dominik Kutra</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Artificial Intelligence, Bioimage Analysis</p>
<p>Content type: Slide</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.4330625">https://zenodo.org/doi/10.5281/zenodo.4330625</a></p>
</section>
<hr class="docutils" />
<section id="martinschatz-cz-scicount-v1-0-0-with-reusable-example-notebooks">
<h2>martinschatz-cz/SciCount: v1.0.0 with reusable example notebooks<a class="headerlink" href="#martinschatz-cz-scicount-v1-0-0-with-reusable-example-notebooks" title="Link to this heading">#</a></h2>
<p>Martin Schätz, Lukáš Mrazík, Karolina Máhlerova</p>
<p>Published 2022-08-02</p>
<p>Licensed OTHER-OPEN</p>
<p>The first version contains an example of augmentation of scientific data and object detection with YOLO_v5 on colony counting (2 classes), object counting in blood smears (can be used as semisupervised learning for faster annotation), and wildlife detection from night records with a camera trap.</p>
<p>The project is available on GitHub.</p>
<p><a class="reference external" href="https://zenodo.org/records/6953610">https://zenodo.org/records/6953610</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6953610">https://doi.org/10.5281/zenodo.6953610</a></p>
</section>
<hr class="docutils" />
<section id="quantixed-thedigitalcell-first-complete-code-set">
<h2>quantixed/TheDigitalCell: First complete code set<a class="headerlink" href="#quantixed-thedigitalcell-first-complete-code-set" title="Link to this heading">#</a></h2>
<p>Stephen Royle</p>
<p>Published 2019-04-17</p>
<p>Licensed GPL-3.0</p>
<p>First complete code set for The Digital Cell book.</p>
<p>Tags: Bioimage Analysis</p>
<p>Content type: Code</p>
<p><a class="github reference external" href="https://github.com/quantixed/TheDigitalCell">quantixed/TheDigitalCell</a></p>
<p><a class="reference external" href="https://zenodo.org/records/2643411">https://zenodo.org/records/2643411</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.2643411">https://doi.org/10.5281/zenodo.2643411</a></p>
<hr class="docutils" />
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./domain"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="www.youtube.com.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Www.youtube.com (20)</p>
      </div>
    </a>
    <a class="right-next"
       href="../statistics/readme.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Statistics</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zenodo-und-co-was-bringt-und-wer-braucht-ein-repositorium">“ZENODO und Co.” Was bringt und wer braucht ein Repositorium?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#d-nuclei-annotations-and-stardist-3d-model-s-rat-brain">3D Nuclei annotations and StarDist 3D model(s) (rat brain)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#steps-towards-reproducible-research">6 Steps Towards Reproducible Research</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-glimpse-of-the-open-source-flim-analysis-software-tools-flimfit-flute-and-napari-flim-phasor-plotter">A Glimpse of the Open-Source FLIM Analysis Software Tools FLIMfit, FLUTE and napari-flim-phasor-plotter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-journey-to-fair-microscopy-data">A journey to FAIR microscopy data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abdominal-imaging-window-aiw-for-intravital-imaging">Abdominal Imaging Window (AIW) for Intravital Imaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#alles-meins-oder-urheberrechte-klaren-fur-forschungsdaten">Alles meins – oder!? Urheberrechte klären für Forschungsdaten</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#artificial-blobs-and-labels-image">Artificial Blobs and Labels image</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#axioscan-7-fluorescent-channels-not-displaying-in-qupath">Axioscan 7 fluorescent channels not displaying in QuPath</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-data-strudel-for-workshop-on-research-data-management-in-tu-dresden-core-facilities">Bio-Image Data Strudel for Workshop on Research Data Management in TU Dresden Core Facilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis-code-generation">Bio-image Analysis Code Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis-code-generation-using-bia-bob">Bio-image Analysis Code Generation using bia-bob</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis-with-the-help-of-large-language-models">Bio-image Analysis with the Help of Large Language Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-data-science-lectures-uni-leipzig-scads-ai">Bio-image Data Science Lectures @ Uni Leipzig / ScaDS.AI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-fair-image-analysis-pipelines-for-high-content-screening-hcs-data-using-galaxy">Building FAIR image analysis pipelines for high-content-screening (HCS) data using Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-a-fair-image-data-ecosystem-for-microscopy-communities">Building a FAIR image data ecosystem for microscopy communities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#czi-carl-zeiss-image-dataset-with-artificial-test-camera-images-with-various-dimension-for-testing-libraries-reading">CZI (Carl Zeiss Image) dataset with artificial test camera images with various dimension for testing libraries reading</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#czi-file-examples">CZI file examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#czi-open-science-program-collection">CZI: Open Science Program Collection</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellpose-model-for-digital-phase-contrast-images">Cellpose model for Digital Phase Contrast images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellpose-models-for-label-prediction-from-brightfield-and-digital-phase-contrast-images">Cellpose models for Label Prediction from Brightfield and Digital Phase Contrast images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chatgpt-for-image-analysis">ChatGPT for Image Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#combining-the-bids-and-arc-directory-structures-for-multimodal-research-data-organization">Combining the BIDS and ARC Directory Structures for Multimodal Research Data Organization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conference-slides-4th-day-of-intravital-microscopy">Conference Slides - 4th Day of Intravital Microscopy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#crashkurs-forschungsdatenmanagement">Crashkurs Forschungsdatenmanagement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-open-computational-curricula">Creating open computational curricula</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cultivating-open-training">Cultivating Open Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cultivating-open-training-to-advance-bio-image-analysis">Cultivating Open Training to advance Bio-image Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dalia-interchange-format">DALIA Interchange Format</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-stewardship-and-research-data-management-tools-for-multimodal-linking-of-imaging-data-in-plasma-medicine">Data stewardship and research data management tools for multimodal linking of imaging data in plasma medicine</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datenmanagement">Datenmanagement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datenmanagement-im-fokus-organisation-speicherstrategien-und-datenschutz">Datenmanagement im Fokus: Organisation, Speicherstrategien und Datenschutz</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datenmanagementplane-erstellen-teil-1">Datenmanagementpläne erstellen - Teil 1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datenmanagementplane-erstellen-teil-2">Datenmanagementpläne erstellen - Teil 2</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deconvolution-test-dataset">Deconvolution Test Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#development-of-a-platform-for-advanced-optics-education-training-and-prototyping">Development of a platform for advanced optics education, training and prototyping</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#digital-phase-contrast-on-primary-dermal-human-fibroblasts-cells">Digital Phase Contrast on Primary Dermal Human Fibroblasts cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#efficiently-starting-institutional-research-data-management">Efficiently starting institutional research data management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#einblicke-ins-forschungsdatenmanagement-darf-ich-das-veroffentlichen-rechtsfragen-im-umgang-mit-forschungsdaten">Einblicke ins Forschungsdatenmanagement - Darf ich das veröffentlichen? Rechtsfragen im Umgang mit Forschungsdaten</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#engineering-a-software-environment-for-research-data-management-of-microscopy-image-data-in-a-core-facility">Engineering a Software Environment for Research Data Management of Microscopy Image Data in a Core Facility</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-scientific-ambassadors-program">Euro-BioImaging  Scientific Ambassadors Program</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-eric-annual-report-2022">Euro-BioImaging ERIC Annual Report 2022</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-s-guide-to-fair-bioimage-data-practical-tasks">Euro-BioImaging’s Guide to FAIR BioImage Data - Practical Tasks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-s-template-for-research-data-management-plans">Euro-BioImaging’s Template for Research Data Management Plans</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-batchconvert-v0-0-4">Euro-BioImaging/BatchConvert: v0.0.4</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evident-oir-sample-files-tiles-stitched-image-fv-4000">Evident OIR sample files tiles + stitched image - FV 4000</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evident-oir-sample-files-with-lambda-scan-fv-4000">Evident OIR sample files with lambda scan - FV 4000</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-imaris-ims-datasets">Example Imaris ims datasets.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-microscopy-metadata-json-files-produced-using-micro-meta-app-to-document-example-microscopy-experiments-performed-at-individual-core-facilities">Example Microscopy Metadata JSON files produced using Micro-Meta App to document example microscopy experiments performed at individual core facilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-operetta-dataset">Example Operetta Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#excel-template-for-adding-key-value-pairs-to-images">Excel template for adding Key-Value Pairs to images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forschungsdatenmanagement-zukunftsfest-gestalten-impulse-fur-die-strukturevaluation-der-nationalen-forschungsdateninfrastruktur-nfdi">Forschungsdatenmanagement zukunftsfest gestalten – Impulse für die   Strukturevaluation der Nationalen Forschungsdateninfrastruktur (NFDI)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-cells-to-pixels-bridging-biologists-and-image-analysts-through-a-common-language">From Cells to Pixels: Bridging Biologists and  Image Analysts Through a Common Language</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-paper-to-pixels-navigation-through-your-research-data-presentations-of-speakers">From Paper to Pixels: Navigation through your Research Data - presentations of speakers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gerbi-chat-teil-1-vom-bedarf-bis-zum-groszgerateantrag-schreiben">GerBI-Chat: Teil 1 - Vom Bedarf bis zum Großgeräteantrag-Schreiben</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gerbi-chat-teil-2-wie-schreibe-ich-am-besten-einen-groszegrateantrag">GerBI-Chat: Teil 2 - Wie schreibe ich am besten einen Großegräteantrag</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-started-with-python-intro-and-set-up-a-conda-environment">Getting started with Python: intro and set-up a conda environment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gut-analysis-toolbox">Gut Analysis Toolbox</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gut-analysis-toolbox-training-data-and-2d-models-for-segmenting-enteric-neurons-neuronal-subtypes-and-ganglia">Gut Analysis Toolbox: Training data and 2D models for segmenting enteric neurons, neuronal subtypes and ganglia</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hackaton-results-conversion-of-knime-image-analysis-workflows-to-galaxy">Hackaton Results - Conversion of KNIME image analysis workflows to Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hela-kyoto-cells-under-the-scope">HeLa “Kyoto” cells under the scope</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#high-throughput-automated-data-analysis-and-data-management-workflow-with-cellprofiler-and-omero">High throughput &amp; automated data analysis and data management workflow with Cellprofiler and OMERO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#human-dab-staining-axioscan-bf-20x">Human DAB staining Axioscan BF 20x</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#i3d-bio-s-omero-training-material-re-usable-adjustable-multi-purpose-slides-for-local-user-training">I3D:bio’s OMERO training material: Re-usable, adjustable, multi-purpose slides for local user training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ics-ids-stitched-file">ICS/IDS stitched file</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-repository-decision-tree-where-do-i-deposit-my-imaging-data">Image Repository Decision Tree - Where do I deposit my imaging data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imagej-tool-for-percentage-estimation-of-pneumonia-in-lungs">ImageJ tool for percentage estimation of pneumonia in lungs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-kidney">Implantation of abdominal imaging windows on the mouse kidney</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-kidney-short-version">Implantation of abdominal imaging windows on the mouse kidney - short version</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-liver">Implantation of abdominal imaging windows on the mouse liver</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-liver-short-version">Implantation of abdominal imaging windows on the mouse liver - short version</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ink-in-a-dish">Ink in a dish</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#insights-and-impact-from-five-cycles-of-essential-open-source-software-for-science">Insights and Impact From Five Cycles of Essential Open Source Software for Science</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#insights-from-acquiring-open-medical-imaging-datasets-for-foundation-model-development">Insights from Acquiring Open Medical Imaging  Datasets for Foundation Model Development</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Insights from Acquiring Open Medical Imaging Datasets for Foundation Model Development</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#institutionalization-and-collaboration-as-a-way-of-addressing-the-challenges-open-science-presents-to-libraries-the-university-of-konstanz-as-a-national-pioneer">Institutionalization and Collaboration as a Way of Addressing the Challenges Open Science Presents to Libraries: The University of Konstanz as a National Pioneer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interactive-image-data-flow-graphs">Interactive Image Data Flow Graphs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#intravital-microscopy-contrasting-agents-for-application-database">Intravital microscopy contrasting agents for application - Database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-light-microscopy-widefield-microscopy">Introduction to light-microscopy / Widefield microscopy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pair-template-for-annotation-in-omero-for-light-microscopy-data-acquired-with-axioscan7-core-facility-cellular-imaging-cfci">Key-Value pair template for annotation in OMERO for light microscopy data acquired with AxioScan7 - Core Facility Cellular Imaging (CFCI)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pair-template-for-annotation-of-datasets-in-omero-perikles-study">Key-Value pair template for annotation of datasets in OMERO (PERIKLES study)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pair-template-for-annotation-of-datasets-in-omero-for-light-and-electron-microscopy-data-within-the-research-group-of-prof-muller-reichert">Key-Value pair template for annotation of datasets in OMERO for light- and electron microscopy data within the research group of Prof. Müller-Reichert</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kollaboratives-arbeiten-und-versionskontrolle-mit-git">Kollaboratives Arbeiten und Versionskontrolle mit Git</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#leo-linking-eln-with-omero">LEO: Linking ELN with OMERO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lz4-compressed-imaris-ims-example-datasets">LZ4-compressed Imaris ims example datasets.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#large-language-models-an-introduction-for-life-scientists">Large Language Models: An Introduction for Life Scientists</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#large-tiling-confocal-acquisition-rat-brain">Large tiling confocal acquisition (rat brain)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laulauthom-maskfromrois-fiji-masks-from-rois-plugins-for-fiji-initial-release">LauLauThom/MaskFromRois-Fiji: Masks from ROIs plugins for Fiji - initial release</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#leitfaden-zur-digitalen-datensparsamkeit-mit-praxisbeispielen">Leitfaden zur digitalen Datensparsamkeit (mit Praxisbeispielen)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limeseg-test-datasets">LimeSeg Test Datasets</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linked-open-data-for-microbial-population-biology">Linked (Open) Data for Microbial Population Biology</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#liver-micrometastases-area-quantification-using-qupath-and-pixel-classifier">Liver Micrometastases area quantification using QuPath and pixel classifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#measuring-reporter-activity-domain-in-epi-aggregates-and-gastruloids-ijm">Measuring reporter activity domain in EPI aggregates and Gastruloids.ijm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metadata-annotation-workflow-for-omero-with-tabbles">Metadata Annotation Workflow for OMERO with Tabbles</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microsam-talks">MicroSam-Talks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#morphological-analysis-of-neural-cells-with-weka-and-snt-fiji-plugins">Morphological analysis of neural cells with WEKA and SNT Fiji plugins</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-template-matching-for-object-detection-slides">Multi-Template-Matching for object-detection (slides)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiplexed-histology-of-covid-19-post-mortem-lung-samples-control-case-1-fov1">Multiplexed histology of COVID-19 post-mortem lung samples - CONTROL CASE 1 FOV1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#my-journey-through-bioimage-analysis-teaching-methods-from-classroom-to-cloud">My Journey Through Bioimage Analysis Teaching Methods From Classroom to Cloud</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage">NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis-conference-talk-the-pelagic-imaging-consortium-meets-helmholtz-imaging-5-10-2023-hamburg">NFDI4BIOIMAGE - National Research Data Infrastructure for Microscopy and BioImage Analysis [conference talk: The Pelagic Imaging Consortium meets Helmholtz Imaging, 5.10.2023, Hamburg]</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis">NFDI4BIOIMAGE - National Research Data Infrastructure for Microscopy and Bioimage Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon-2023-github-repository">NFDI4Bioimage - TA3-Hackathon - UoC-2023 (Cologne-Hackathon-2023, GitHub repository)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-2024-october-original-image">NFDI4Bioimage Calendar 2024 October; original image</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#new-kid-on-the-nfdi-block-nfdi4bioimage-a-national-initiative-for-fair-data-management-in-bioimaging-and-bioimage-analysis">New Kid on the (NFDI) Block: NFDI4BIOIMAGE  - A National Initiative for FAIR Data Management in Bioimaging and Bioimage Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nextflow-scalable-and-reproducible-scientific-workflows">Nextflow: Scalable and reproducible scientific workflows</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome2024-ngff-challenge-results">OME2024 NGFF Challenge Results</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-science-sharing-licensing">Open Science, Sharing &amp; Licensing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimisation-and-validation-of-a-swarm-intelligence-based-segmentation-algorithm-for-low-contrast-positron-emission-tomography">Optimisation and Validation of a Swarm Intelligence based Segmentation Algorithm for low Contrast Positron Emission Tomography</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprint-be-sustainable-recommendations-for-fair-resources-in-life-sciences-research-eosc-life-s-lessons">Preprint: “Be Sustainable”, Recommendations for FAIR Resources in Life Sciences research: EOSC-Life’s Lessons</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qupath-open-source-software-for-analysing-awkward-images">QuPath: Open source software for analysing (awkward) images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdf-as-a-bridge-to-domain-platforms-like-omero-or-there-and-back-again">RDF as a bridge to domain-platforms like OMERO, or There and back again.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-management-on-campus-and-in-nfdi4bioimage">RESEARCH DATA MANAGEMENT on Campus and in NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#report-on-a-pilot-study-implementation-of-omero-for-microscopy-data-management">Report on a pilot study:  Implementation of OMERO for  microscopy data management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-management-seminar-slides">Research Data Management Seminar - Slides</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-managemet-and-how-not-to-get-overwhelmed-with-data">Research Data Managemet and how not to get overwhelmed with data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#round-table-workshop-1-sample-stabilization-in-intravital-imaging">Round Table Workshop 1 - Sample Stabilization in intravital Imaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#round-table-workshop-2-correction-of-drift-and-movement">Round Table Workshop 2 - Correction of Drift and Movement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sciaugment">SciAugment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#slides-about-flute-a-python-gui-for-interactive-phasor-analysis-of-flim-data">Slides about FLUTE: a Python GUI for interactive phasor analysis of FLIM data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#so-geschlossen-wie-notig-so-offen-wie-moglich-datenschutz-beim-umgang-mit-forschungsdaten">So geschlossen wie nötig, so offen wie möglich - Datenschutz beim Umgang mit Forschungsdaten</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stackview-sliceplot-example-data">Stackview sliceplot example data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#structuring-of-data-and-metadata-in-bioimaging-concepts-and-technical-solutions-in-the-context-of-linked-data">Structuring of Data and Metadata in Bioimaging: Concepts and technical Solutions in the Context of Linked Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sustainable-data-stewardship">Sustainable Data Stewardship</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-dataset-for-whole-slide-image-registration">Test Dataset for Whole Slide Image Registration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-information-infrastructure-for-bioimage-data-i3d-bio-project-to-advance-fair-microscopy-data-management-for-the-community">The Information Infrastructure for BioImage Data (I3D:bio) project to advance FAIR microscopy data management for the community</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-role-of-helmholtz-centers-in-nfdi4bioimage-a-national-consortium-enhancing-fair-data-management-for-microscopy-and-bioimage-analysis">The role of Helmholtz Centers in NFDI4BIOIMAGE - A national consortium enhancing FAIR data management for microscopy and bioimage analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#thinking-data-management-on-different-scales">Thinking data management on different scales</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#towards-preservation-of-life-science-data-with-nfdi4bioimage">Towards Preservation of Life Science Data with NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#towards-transparency-and-knowledge-exchange-in-ai-assisted-data-analysis-code-generation">Towards Transparency and Knowledge Exchange in AI-assisted Data Analysis Code Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-the-trainer-concept-on-research-data-management">Train-the-Trainer Concept on Research Data Management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#welcome-to-bioimage-town">Welcome to BioImage Town</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#who-you-gonna-call-data-stewards-to-the-rescue">Who you gonna call? - Data Stewards to the rescue</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter">Zeiss AxioZoom Stage Adapter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter-12-6well-plate">Zeiss AxioZoom Stage Adapter - 12/6Well Plate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter-em-block-holder">Zeiss AxioZoom Stage Adapter - EM block holder</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter-microscope-slides">Zeiss AxioZoom Stage Adapter - Microscope slides</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bina-cc-scalable-strategies-for-a-next-generation-of-fair-bioimaging">[BINA CC] Scalable strategies for a next-generation of FAIR bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cordi-2023-zarr-a-cloud-optimized-storage-for-interactive-access-of-large-arrays">[CORDI 2023] Zarr: A Cloud-Optimized Storage for Interactive Access of Large Arrays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#community-meeting-2024-overview-team-image-data-analysis-and-management">[Community Meeting 2024] Overview Team Image Data Analysis and Management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#community-meeting-2024-supporting-and-financing-rdm-projects-within-gerbi">[Community Meeting 2024] Supporting and financing RDM projects within GerBI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#elmi-2024-ai-s-dirty-little-secret-without">[ELMI 2024]  AI’s Dirty Little Secret: Without</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#elmi-2024-ai-s-dirty-little-secret-without-fair-data-it-s-just-fancy-math">[ELMI 2024] AI’s Dirty Little Secret: Without FAIR Data, It’s Just Fancy Math</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gbi-eoe-vii-five-or-ten-must-have-items-for-making-it-infrastructure-for-managing-bioimage-data">[GBI EOE VII] Five (or ten) must-have items for making IT infrastructure for managing bioimage data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gbi-eoe-ix-nfdi4bioimage">[GBI EoE IX] NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#i2k-scalable-strategies-for-a-next-generation-of-fair-bioimaging">[I2K] Scalable strategies for a next-generation of FAIR bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#n4bi-ahm-welcome-to-bioimage-town">[N4BI AHM] Welcome to BioImage Town</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#swat4hcls-2023-nfdi4bioimage-perspective-for-a-national-bioimage-standard">[SWAT4HCLS 2023] NFDI4BIOIMAGE: Perspective for a national bioimage standard</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#short-talk-nfdi4bioimage-a-consortium-in-the-national-research-data-infrastructure">[Short Talk] NFDI4BIOIMAGE - A consortium in the National Research Data Infrastructure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workshop-material-fit-for-omero-how-imaging-facilities-and-it-departments-work-together-to-enable-rdm-for-bioimaging-october-16-17-2024-heidelberg">[Workshop Material] Fit for OMERO - How imaging facilities and IT departments work together to enable RDM for bioimaging, October 16-17, 2024, Heidelberg</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workshop-bioimage-data-management-and-analysis-with-omero">[Workshop] Bioimage data management and analysis with OMERO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workshop-fair-data-handling-for-microscopy-structured-metadata-annotation-in-omero">[Workshop] FAIR data handling for microscopy: Structured metadata annotation in OMERO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ilastik-interactive-machine-learning-for-bio-image-analysis">ilastik: interactive machine learning for (bio)image analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#martinschatz-cz-scicount-v1-0-0-with-reusable-example-notebooks">martinschatz-cz/SciCount: v1.0.0 with reusable example notebooks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quantixed-thedigitalcell-first-complete-code-set">quantixed/TheDigitalCell: First complete code set</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Robert Haase, Clément Caporal,... and the NFDI4BioImage Initiative
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on 2024-12-10.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <p>
Copyright: Licensed <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">CC-BY 4.0</a> unless mentioned otherwise. 
Contributions and feedback are welcome.
</p>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>