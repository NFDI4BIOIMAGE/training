
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Cc-by-4.0 (258) &#8212; NFDI4BioImage Training Materials</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'licenses/cc-by-4.0';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Cc-by-sa-4.0 (5)" href="cc-by-sa-4.0.html" />
    <link rel="prev" title="Bsd-3-clause (27)" href="bsd-3-clause.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="2025-03-03"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../readme.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="NFDI4BioImage Training Materials - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="NFDI4BioImage Training Materials - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../readme.html">
                    NFDI4BioImage Training Materials
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">What's new</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../whats_new.html">Recently added (10)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Contributing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../contributing/index.html">How to contribute</a></li>

<li class="toctree-l1"><a class="reference internal" href="../contributing/submit_app.html">Using the Training Materials Submission App</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing/format.html">YML format</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">By tag</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tags/artificial_intelligence.html">Artificial intelligence (44)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/bioimage_analysis.html">Bioimage analysis (186)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/bioinformatics.html">Bioinformatics (18)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/data_stewardship.html">Data stewardship (6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/fair-principles.html">Fair-principles (27)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/imagej.html">Imagej (19)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/licensing.html">Licensing (6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/metadata.html">Metadata (15)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/napari.html">Napari (13)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/neubias.html">Neubias (27)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/nfdi4bioimage.html">Nfdi4bioimage (45)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/omero.html">Omero (33)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/open_science.html">Open science (9)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/open_source_software.html">Open source software (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/python.html">Python (70)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/reproducibility.html">Reproducibility (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/research_data_management.html">Research data management (132)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/sharing.html">Sharing (12)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/workflow.html">Workflow (9)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tags/workflow_engine.html">Workflow engine (13)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">By content type</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../content_types/blog%20post.html">Blog post (23)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/book.html">Book (19)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/code.html">Code (10)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/collection.html">Collection (82)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/data.html">Data (8)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/document.html">Document (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/documentation.html">Documentation (19)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/event.html">Event (8)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/github%20repository.html">Github repository (49)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/notebook.html">Notebook (55)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/online%20tutorial.html">Online tutorial (10)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/poster.html">Poster (10)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/preprint.html">Preprint (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/publication.html">Publication (62)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/slides.html">Slides (83)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/tutorial.html">Tutorial (45)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/video.html">Video (32)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/website.html">Website (10)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/workshop.html">Workshop (12)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">By license</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="all_rights_reserved.html">All rights reserved (13)</a></li>
<li class="toctree-l1"><a class="reference internal" href="apache-2.0.html">Apache-2.0 (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="bsd-2-clause.html">Bsd-2-clause (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="bsd-3-clause.html">Bsd-3-clause (27)</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Cc-by-4.0 (258)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cc-by-sa-4.0.html">Cc-by-sa-4.0 (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cc0-1.0.html">Cc0-1.0 (13)</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpl-2.0.html">Gpl-2.0 (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="gpl-3.0.html">Gpl-3.0 (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="mit.html">Mit (27)</a></li>
<li class="toctree-l1"><a class="reference internal" href="unknown.html">Unknown (98)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">By domain</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../domain/biapol.github.io.html">Biapol.github.io (6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/docs.google.com.html">Docs.google.com (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/doi.org.html">Doi.org (196)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/f1000research.com.html">F1000research.com (11)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/focalplane.biologists.com.html">Focalplane.biologists.com (14)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/git.mpi-cbg.de.html">Git.mpi-cbg.de (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/github.com.html">Github.com (127)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/www.biorxiv.org.html">Www.biorxiv.org (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/www.ebi.ac.uk.html">Www.ebi.ac.uk (10)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/www.nature.com.html">Www.nature.com (17)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/www.youtube.com.html">Www.youtube.com (25)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/zenodo.org.html">Zenodo.org (184)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../statistics/readme.html">Statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../export/readme.html">Open data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../imprint.html">Imprint</a></li>

</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/NFDI4BIOIMAGE/training" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/NFDI4BIOIMAGE/training/issues/new?title=Issue%20on%20page%20%2Flicenses/cc-by-4.0.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/licenses/cc-by-4.0.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Cc-by-4.0 (258)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zenodo-und-co-was-bringt-und-wer-braucht-ein-repositorium">“ZENODO und Co.” Was bringt und wer braucht ein Repositorium?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#frames-of-fluorescent-particles">10 frames of fluorescent particles</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#d-nuclei-annotations-and-stardist-3d-model-s-rat-brain">3D Nuclei annotations and StarDist 3D model(s) (rat brain)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#steps-towards-reproducible-research">6 Steps Towards Reproducible Research</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-cloud-optimized-storage-for-interactive-access-of-large-arrays">A Cloud-Optimized Storage for Interactive Access of Large Arrays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-glimpse-of-the-open-source-flim-analysis-software-tools-flimfit-flute-and-napari-flim-phasor-plotter">A Glimpse of the Open-Source FLIM Analysis Software Tools FLIMfit, FLUTE and napari-flim-phasor-plotter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-hitchhiker-s-guide-through-the-bio-image-analysis-software-universe">A Hitchhiker’s guide through the bio-image analysis software universe</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-journey-to-fair-microscopy-data">A journey to FAIR microscopy data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abdominal-imaging-window-aiw-for-intravital-imaging">Abdominal Imaging Window (AIW) for Intravital Imaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aberrated-bead-stack">Aberrated Bead Stack</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abstract-nfdi-basic-service-for-data-management-plans">Abstract - NFDI Basic Service for Data Management Plans</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#alles-meins-oder-urheberrechte-klaren-fur-forschungsdaten">Alles meins – oder!? Urheberrechte klären für Forschungsdaten</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#angebote-der-nfdi-fur-die-forschung-im-bereich-zoologie">Angebote der NFDI für die Forschung im Bereich Zoologie</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#artificial-blobs-and-labels-image">Artificial Blobs and Labels image</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#astigmatic-4pi-bead-stack">Astigmatic 4Pi bead stack</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bids-lecture-2024">BIDS-lecture-2024</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#biomero-a-scalable-and-extensible-image-analysis-framework">BIOMERO - A scalable and extensible image analysis framework</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bigdataprocessor2-a-free-and-open-source-fiji-plugin-for-inspection-and-processing-of-tb-sized-image-data">BigDataProcessor2: A free and open-source Fiji plugin for inspection and processing of TB sized image data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-data-strudel-for-workshop-on-research-data-management-in-tu-dresden-core-facilities">Bio-Image Data Strudel for Workshop on Research Data Management in TU Dresden Core Facilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis-code-generation">Bio-image Analysis Code Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis-code-generation-using-bia-bob">Bio-image Analysis Code Generation using bia-bob</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis-with-the-help-of-large-language-models">Bio-image Analysis with the Help of Large Language Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-data-science">Bio-image Data Science</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-data-science-lectures-uni-leipzig-scads-ai">Bio-image Data Science Lectures @ Uni Leipzig / ScaDS.AI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis-biostatistics-programming-and-machine-learning-for-computational-biology">Bio-image analysis, biostatistics, programming and machine learning for computational biology</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-tools-database">Bio.tools database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioformats-command-line-cli-tools">BioFormats Command line (CLI) tools</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimage-analysis-notebooks">BioImage Analysis Notebooks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimage-io-chatbot-globias-seminar">BioImage.IO Chatbot, GloBIAS Seminar</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#browsing-the-open-microscopy-image-data-resource-with-python">Browsing the Open Microscopy Image Data Resource with Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-fair-image-analysis-pipelines-for-high-content-screening-hcs-data-using-galaxy">Building FAIR image analysis pipelines for high-content-screening (HCS) data using Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-a-fair-image-data-ecosystem-for-microscopy-communities">Building a FAIR image data ecosystem for microscopy communities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#czi-carl-zeiss-image-dataset-with-artificial-test-camera-images-with-various-dimension-for-testing-libraries-reading">CZI (Carl Zeiss Image) dataset with artificial test camera images with various dimension for testing libraries reading</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#czi-file-examples">CZI file examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellpose-model-for-digital-phase-contrast-images">Cellpose model for Digital Phase Contrast images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellpose-models-for-label-prediction-from-brightfield-and-digital-phase-contrast-images">Cellpose models for Label Prediction from Brightfield and Digital Phase Contrast images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges-and-opportunities-for-bio-image-analysis-core-facilities">Challenges and opportunities for bio-image analysis core-facilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges-and-opportunities-for-bioimage-analysis-core-facilities">Challenges and opportunities for bioimage analysis core-facilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chatgpt-for-image-analysis">ChatGPT for Image Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#collaborative-working-and-version-control-with-git-hub">Collaborative Working and Version Control with git[hub]</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#collaborative-bio-image-analysis-script-editing-with-git">Collaborative bio-image analysis script editing with git</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#combining-the-bids-and-arc-directory-structures-for-multimodal-research-data-organization">Combining the BIDS and ARC Directory Structures for Multimodal Research Data Organization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conference-slides-4th-day-of-intravital-microscopy">Conference Slides - 4th Day of Intravital Microscopy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#crashkurs-forschungsdatenmanagement">Crashkurs Forschungsdatenmanagement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-workflows-and-advanced-workflow-options">Creating Workflows and Advanced Workflow Options</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-a-research-data-management-plan-using-chatgpt">Creating a Research Data Management Plan using chatGPT</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-open-computational-curricula">Creating open computational curricula</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cultivating-open-training">Cultivating Open Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cultivating-open-training-to-advance-bio-image-analysis">Cultivating Open Training to advance Bio-image Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dl4miceverywhere">DL4MicEverywhere</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-carpentry-for-biologists">Data Carpentry for Biologists</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-life-cycle">Data life cycle</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-stewardship-and-research-data-management-tools-for-multimodal-linking-of-imaging-data-in-plasma-medicine">Data stewardship and research data management tools for multimodal linking of imaging data in plasma medicine</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataplant-knowledge-base">DataPLANT knowledge base</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-from-incell-2200-microscope-misread-as-a-plate">Dataset from InCell 2200 microscope misread as a plate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datenmanagement">Datenmanagement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datenmanagement-im-fokus-organisation-speicherstrategien-und-datenschutz">Datenmanagement im Fokus: Organisation, Speicherstrategien und Datenschutz</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datenmanagementplane-erstellen-teil-1">Datenmanagementpläne erstellen - Teil 1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datenmanagementplane-erstellen-teil-2">Datenmanagementpläne erstellen - Teil 2</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deconvolution-test-dataset">Deconvolution Test Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#developing-semi-automatic-analysis-pipelines-and-technological-solutions-for-metadata-annotation-and-management-in-high-content-screening-hcs-bioimaging">Developing (semi)automatic analysis pipelines and technological solutions for metadata annotation and management in high-content screening (HCS) bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#developing-a-training-strategy">Developing a Training Strategy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#developing-open-source-software-for-bioimage-analysis-opportunities-and-challenges">Developing open-source software for bioimage analysis: opportunities and challenges</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#development-of-a-platform-for-advanced-optics-education-training-and-prototyping">Development of a platform for advanced optics education, training and prototyping</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#digital-phase-contrast-on-primary-dermal-human-fibroblasts-cells">Digital Phase Contrast on Primary Dermal Human Fibroblasts cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#edam-bioimaging-the-ontology-of-bioimage-informatics-operations-topics-data-and-formats">EDAM-bioimaging - The ontology of bioimage informatics operations, topics, data, and formats</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#edam-bioimaging-the-ontology-of-bioimage-informatics-operations-topics-data-and-formats-update-2020">EDAM-bioimaging: The ontology of bioimage informatics operations, topics, data, and formats (update 2020)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#efficiently-starting-institutional-research-data-management">Efficiently starting institutional research data management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#einblicke-ins-forschungsdatenmanagement-darf-ich-das-veroffentlichen-rechtsfragen-im-umgang-mit-forschungsdaten">Einblicke ins Forschungsdatenmanagement - Darf ich das veröffentlichen? Rechtsfragen im Umgang mit Forschungsdaten</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#erstellung-und-realisierung-einer-institutionellen-forschungsdaten-policy">Erstellung und Realisierung einer institutionellen Forschungsdaten-Policy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-scientific-ambassadors-program">Euro-BioImaging  Scientific Ambassadors Program</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-eric-annual-report-2022">Euro-BioImaging ERIC Annual Report 2022</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-s-guide-to-fair-bioimage-data-practical-tasks">Euro-BioImaging’s Guide to FAIR BioImage Data - Practical Tasks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-s-template-for-research-data-management-plans">Euro-BioImaging’s Template for Research Data Management Plans</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-batchconvert-v0-0-4">Euro-BioImaging/BatchConvert: v0.0.4</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evident-oir-sample-files-tiles-stitched-image-fv-4000">Evident OIR sample files tiles + stitched image - FV 4000</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evident-oir-sample-files-with-lambda-scan-fv-4000">Evident OIR sample files with lambda scan - FV 4000</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-imaris-ims-datasets">Example Imaris ims datasets.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-microscopy-metadata-json-files-produced-using-micro-meta-app-to-document-example-microscopy-experiments-performed-at-individual-core-facilities">Example Microscopy Metadata JSON files produced using Micro-Meta App to document example microscopy experiments performed at individual core facilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-operetta-dataset">Example Operetta Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#excel-template-for-adding-key-value-pairs-to-images">Excel template for adding Key-Value Pairs to images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fair-bioimage-data">FAIR BioImage Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fair-high-content-screening-in-bioimaging">FAIR High Content Screening in Bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fair-priciples">FAIR Priciples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fairy-deep-learning-for-bioimage-analysis">FAIRy deep-learning for bioImage analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#finding-and-using-publicly-available-data">Finding and using publicly available data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forschungsdaten-org">Forschungsdaten.org</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forschungsdatenmanagement-zukunftsfest-gestalten-impulse-fur-die-strukturevaluation-der-nationalen-forschungsdateninfrastruktur-nfdi">Forschungsdatenmanagement zukunftsfest gestalten – Impulse für die   Strukturevaluation der Nationalen Forschungsdateninfrastruktur (NFDI)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-cells-to-pixels-bridging-biologists-and-image-analysts-through-a-common-language">From Cells to Pixels: Bridging Biologists and  Image Analysts Through a Common Language</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-paper-to-pixels-navigation-through-your-research-data-presentations-of-speakers">From Paper to Pixels: Navigation through your Research Data - presentations of speakers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#galaxy-training">Galaxy Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-artificial-intelligence-for-bio-image-analysis">Generative artificial intelligence for bio-image analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gerbi-chat-teil-1-vom-bedarf-bis-zum-groszgerateantrag-schreiben">GerBI-Chat: Teil 1 - Vom Bedarf bis zum Großgeräteantrag-Schreiben</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gerbi-chat-teil-2-wie-schreibe-ich-am-besten-einen-groszegrateantrag">GerBI-Chat: Teil 2 - Wie schreibe ich am besten einen Großegräteantrag</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-started-with-mambaforge-and-python">Getting started with Mambaforge and Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-started-with-python-intro-and-set-up-a-conda-environment">Getting started with Python: intro and set-up a conda environment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#guidance-for-developing-a-research-data-management-rdm-policy">Guidance for Developing a Research Data Management (RDM) Policy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gut-analysis-toolbox">Gut Analysis Toolbox</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gut-analysis-toolbox-training-data-and-2d-models-for-segmenting-enteric-neurons-neuronal-subtypes-and-ganglia">Gut Analysis Toolbox: Training data and 2D models for segmenting enteric neurons, neuronal subtypes and ganglia</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hackaton-results-conversion-of-knime-image-analysis-workflows-to-galaxy">Hackaton Results - Conversion of KNIME image analysis workflows to Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hela-kyoto-cells-under-the-scope">HeLa “Kyoto” cells under the scope</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#high-throughput-automated-data-analysis-and-data-management-workflow-with-cellprofiler-and-omero">High throughput &amp; automated data analysis and data management workflow with Cellprofiler and OMERO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#highlights-from-the-2016-2020-neubias-training-schools-for-bioimage-analysts-a-success-story-and-key-asset-for-analysts-and-life-scientists">Highlights from the 2016-2020 NEUBIAS training schools for Bioimage Analysts: a success story and key asset for analysts and life scientists</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hitchhiking-through-a-diverse-bio-image-analysis-software-universe">Hitchhiking through a diverse Bio-image Analysis Software Universe</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#human-dab-staining-axioscan-bf-20x">Human DAB staining Axioscan BF 20x</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#i3d-bio-s-omero-training-material-re-usable-adjustable-multi-purpose-slides-for-local-user-training">I3D:bio’s OMERO training material: Re-usable, adjustable, multi-purpose slides for local user training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ics-ids-stitched-file">ICS/IDS stitched file</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#if-you-license-it-itll-be-harder-to-steal-it-why-we-should-license-our-work">If you license it, it’ll be harder to steal it. Why we should license our work</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-analysis-training-resources">Image Analysis Training Resources</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-processing-with-python">Image Processing with Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-repository-decision-tree-where-do-i-deposit-my-imaging-data">Image Repository Decision Tree - Where do I deposit my imaging data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imagej-tool-for-percentage-estimation-of-pneumonia-in-lungs">ImageJ tool for percentage estimation of pneumonia in lungs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#incell-datasets-with-mix-of-2d-and-3d-failed-to-be-read">InCell datasets with mix of 2D and 3D failed to be read</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#insights-and-impact-from-five-cycles-of-essential-open-source-software-for-science">Insights and Impact From Five Cycles of Essential Open Source Software for Science</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#insights-from-acquiring-open-medical-imaging-datasets-for-foundation-model-development">Insights from Acquiring Open Medical Imaging  Datasets for Foundation Model Development</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Insights from Acquiring Open Medical Imaging Datasets for Foundation Model Development</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#institutionalization-and-collaboration-as-a-way-of-addressing-the-challenges-open-science-presents-to-libraries-the-university-of-konstanz-as-a-national-pioneer">Institutionalization and Collaboration as a Way of Addressing the Challenges Open Science Presents to Libraries: The University of Konstanz as a National Pioneer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interactive-image-data-flow-graphs">Interactive Image Data Flow Graphs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#intravital-microscopy-contrasting-agents-for-application-database">Intravital microscopy contrasting agents for application - Database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introducing-omero-vitessce-an-omero-web-plugin-for-multi-modal-data">Introducing OMERO-vitessce: an OMERO.web plugin for multi-modal data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-bioimage-analysis">Introduction to Bioimage Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-research-data-management-and-open-research">Introduction to Research Data Management and Open Research</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pair-template-for-annotation-in-omero-for-light-microscopy-data-acquired-with-axioscan7-core-facility-cellular-imaging-cfci">Key-Value pair template for annotation in OMERO for light microscopy data acquired with AxioScan7 - Core Facility Cellular Imaging (CFCI)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pair-template-for-annotation-of-datasets-in-omero-perikles-study">Key-Value pair template for annotation of datasets in OMERO (PERIKLES study)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pair-template-for-annotation-of-datasets-in-omero-for-light-and-electron-microscopy-data-within-the-research-group-of-prof-muller-reichert">Key-Value pair template for annotation of datasets in OMERO for light- and electron microscopy data within the research group of Prof. Müller-Reichert</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kollaboratives-arbeiten-und-versionskontrolle-mit-git">Kollaboratives Arbeiten und Versionskontrolle mit Git</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kriterienkatalog-fur-materialien-aus-dem-themenbereich-forschungsdatenmanagement">Kriterienkatalog für Materialien aus dem Themenbereich Forschungsdatenmanagement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#leo-linking-eln-with-omero">LEO: Linking ELN with OMERO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lsm-example-j-dubrulle">LSM example J. Dubrulle</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lz4-compressed-imaris-ims-example-datasets">LZ4-compressed Imaris ims example datasets.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#large-language-models-an-introduction-for-life-scientists">Large Language Models: An Introduction for Life Scientists</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#large-tiling-confocal-acquisition-rat-brain">Large tiling confocal acquisition (rat brain)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#leitfaden-zur-digitalen-datensparsamkeit-mit-praxisbeispielen">Leitfaden zur digitalen Datensparsamkeit (mit Praxisbeispielen)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#leitlinie-grundsatze-policy-richtlinie-forschungsdaten-policies-an-deutschen-universitaten">Leitlinie? Grundsätze? Policy? Richtlinie? – Forschungsdaten-Policies an deutschen Universitäten</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limeseg-test-datasets">LimeSeg Test Datasets</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linked-open-data-for-microbial-population-biology">Linked (Open) Data for Microbial Population Biology</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#liver-micrometastases-area-quantification-using-qupath-and-pixel-classifier">Liver Micrometastases area quantification using QuPath and pixel classifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#making-the-most-of-bioimaging-data-through-interdisciplinary-interactions">Making the most of bioimaging data through interdisciplinary interactions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#making-your-package-available-on-conda-forge">Making your package available on conda-forge</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#managing-scientific-python-environments-using-conda-mamba-and-friends">Managing Scientific Python environments using Conda, Mamba and friends</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#measuring-reporter-activity-domain-in-epi-aggregates-and-gastruloids-ijm">Measuring reporter activity domain in EPI aggregates and Gastruloids.ijm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#meeting-in-the-middle-towards-successful-multidisciplinary-bioimage-analysis-collaboration">Meeting in the Middle: Towards Successful Multidisciplinary Bioimage Analysis Collaboration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metadata-annotation-workflow-for-omero-with-tabbles">Metadata Annotation Workflow for OMERO with Tabbles</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#methods-in-bioimage-analysis">Methods in bioimage analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microsam-talks">MicroSam-Talks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microscopy-data-analysis-machine-learning-and-the-bioimage-archive">Microscopy data analysis: machine learning and the BioImage Archive</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microscopy-bids-an-extension-to-the-brain-imaging-data-structure-for-microscopy-data">Microscopy-BIDS - An Extension to the Brain Imaging Data Structure for Microscopy Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling-community-standards-for-metadata-as-templates-makes-data-fair">Modeling community standards for metadata as templates makes data FAIR</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modular-training-resources-for-bioimage-analysis">Modular training resources for bioimage analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#morphological-analysis-of-neural-cells-with-weka-and-snt-fiji-plugins">Morphological analysis of neural cells with WEKA and SNT Fiji plugins</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-template-matching-for-object-detection-slides">Multi-Template-Matching for object-detection (slides)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiplexed-histology-of-covid-19-post-mortem-lung-samples-control-case-1-fov1">Multiplexed histology of COVID-19 post-mortem lung samples - CONTROL CASE 1 FOV1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiplexed-tissue-imaging-tools-and-approaches">Multiplexed tissue imaging - tools and approaches</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#my-journey-through-bioimage-analysis-teaching-methods-from-classroom-to-cloud">My Journey Through Bioimage Analysis Teaching Methods From Classroom to Cloud</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage">NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis-online-kick-off-2023">NFDI4BIOIMAGE - National Research Data Infrastructure for Microscopy and BioImage Analysis - Online Kick-Off 2023</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis-conference-talk-the-pelagic-imaging-consortium-meets-helmholtz-imaging-5-10-2023-hamburg">NFDI4BIOIMAGE - National Research Data Infrastructure for Microscopy and BioImage Analysis [conference talk: The Pelagic Imaging Consortium meets Helmholtz Imaging, 5.10.2023, Hamburg]</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis">NFDI4BIOIMAGE - National Research Data Infrastructure for Microscopy and Bioimage Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-data-management-illustrations-by-henning-falk">NFDI4BIOIMAGE data management illustrations by Henning Falk</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-perspective-for-a-national-bioimaging-standard">NFDI4BIOIMAGE: Perspective for a national bioimaging standard</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon">NFDI4Bioimage - TA3-Hackathon - UoC-2023 (Cologne Hackathon)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon-2023-github-repository">NFDI4Bioimage - TA3-Hackathon - UoC-2023 (Cologne-Hackathon-2023, GitHub repository)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-2024-october-original-image">NFDI4Bioimage Calendar 2024 October; original image</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#new-kid-on-the-nfdi-block-nfdi4bioimage-a-national-initiative-for-fair-data-management-in-bioimaging-and-bioimage-analysis">New Kid on the (NFDI) Block: NFDI4BIOIMAGE  - A National Initiative for FAIR Data Management in Bioimaging and Bioimage Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nextflow-scalable-and-reproducible-scientific-workflows">Nextflow: Scalable and reproducible scientific workflows</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome-documentation">OME Documentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome-ngff-a-next-generation-file-format-for-expanding-bioimaging-data-access-strategies">OME-NGFF: a next-generation file format for expanding bioimaging data-access strategies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome2024-ngff-challenge-results">OME2024 NGFF Challenge Results</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omero-tools">Omero-tools</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-image-data-handbook">Open Image Data Handbook</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-micoscropy-environment-ome-youtube-channel">Open Micoscropy Environment (OME) Youtube Channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-science-sharing-licensing">Open Science, Sharing &amp; Licensing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimisation-and-validation-of-a-swarm-intelligence-based-segmentation-algorithm-for-low-contrast-positron-emission-tomography">Optimisation and Validation of a Swarm Intelligence based Segmentation Algorithm for low Contrast Positron Emission Tomography</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimized-cranial-window-implantation-for-subcellular-and-functional-imaging-in-vivo">Optimized cranial window implantation for subcellular and functional imaging in vivo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview-of-the-galaxy-omero-suite-upload-images-and-metadata-in-omero-using-galaxy">Overview of the Galaxy OMERO-suite - Upload images and metadata in OMERO using Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parallelization-and-heterogeneous-computing-from-pure-cpu-to-gpu-accelerated-image-processing">Parallelization and heterogeneous computing: from pure CPU to GPU-accelerated image processing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#photonic-data-analysis-in-2050">Photonic data analysis in 2050</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pol-bio-image-analysis-training-school-on-gpu-accelerated-image-analysis">PoL Bio-Image Analysis Training School on GPU-Accelerated Image Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practical-guide-to-the-international-alignment-of-research-data-management-extended-edition">Practical Guide to the International Alignment of Research Data Management - Extended Edition</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprint-be-sustainable-recommendations-for-fair-resources-in-life-sciences-research-eosc-life-s-lessons">Preprint: “Be Sustainable”, Recommendations for FAIR Resources in Life Sciences research: EOSC-Life’s Lessons</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-engineering-agentic-workflows-and-multi-modal-large-language-models">Prompt Engineering, Agentic Workflows and Multi-modal Large Language Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qi-2024-analysis-lab-manual">QI 2024 Analysis Lab Manual</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qm-course-lectures-on-bio-image-analysis-with-napari-2024">QM Course Lectures on Bio-Image Analysis with napari 2024</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quarep-limi-a-community-driven-initiative-to-establish-guidelines-for-quality-assessment-and-reproducibility-for-instruments-and-images-in-light-microscopy">QUAREP-LiMi: A community-driven initiative to establish guidelines for quality assessment and reproducibility for instruments and images in light microscopy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qupath-open-source-software-for-analysing-awkward-images">QuPath: Open source software for analysing (awkward) images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdf-as-a-bridge-to-domain-platforms-like-omero-or-there-and-back-again">RDF as a bridge to domain-platforms like OMERO, or There and back again.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdm-starter-kit">RDM Starter Kit</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdm4mic-presentations">RDM4Mic Presentations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdmkit-training-resources">RDMKit Training Resources</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-management-on-campus-and-in-nfdi4bioimage">RESEARCH DATA MANAGEMENT on Campus and in NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rechtsfragen-bei-open-science-ein-leitfaden">Rechtsfragen bei Open Science - Ein Leitfaden</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reconstructed-images-of-a-2dsim-multiposition-acquisition">Reconstructed images of a 2DSIM multiposition acquisition.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#report-on-a-pilot-study-implementation-of-omero-for-microscopy-data-management">Report on a pilot study:  Implementation of OMERO for  microscopy data management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-management-seminar-slides">Research Data Management Seminar - Slides</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-managemet-and-how-not-to-get-overwhelmed-with-data">Research Data Managemet and how not to get overwhelmed with data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-reusability-conceptual-foundations-barriers-and-enabling-technologies">Research Data Reusability - Conceptual Foundations, Barriers and Enabling Technologies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-management-for-bioimaging-the-2021-nfdi4bioimage-community-survey">Research data management for bioimaging - the 2021 NFDI4BIOIMAGE community survey</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Research data management for bioimaging: the 2021 NFDI4BIOIMAGE community survey</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#round-table-workshop-1-sample-stabilization-in-intravital-imaging">Round Table Workshop 1 - Sample Stabilization in intravital Imaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#round-table-workshop-2-correction-of-drift-and-movement">Round Table Workshop 2 - Correction of Drift and Movement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#running-deep-learning-scripts-in-the-bia-pol-omero-server">Running Deep-Learning Scripts in the BiA-PoL Omero Server</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#swc-gcnu-software-skills">SWC/GCNU Software Skills</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sharing-and-licensing-material">Sharing and licensing material</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sharing-research-data-with-zenodo">Sharing research data with Zenodo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#slides-about-flute-a-python-gui-for-interactive-phasor-analysis-of-flim-data">Slides about FLUTE: a Python GUI for interactive phasor analysis of FLIM data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#so-geschlossen-wie-notig-so-offen-wie-moglich-datenschutz-beim-umgang-mit-forschungsdaten">So geschlossen wie nötig, so offen wie möglich - Datenschutz beim Umgang mit Forschungsdaten</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spatialdata-an-open-and-universal-data-framework-for-spatial-omics">SpatialData: an open and universal data framework for spatial omics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stackview-sliceplot-example-data">Stackview sliceplot example data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#structuring-of-data-and-metadata-in-bioimaging-concepts-and-technical-solutions-in-the-context-of-linked-data">Structuring of Data and Metadata in Bioimaging: Concepts and technical Solutions in the Context of Linked Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sustainable-data-stewardship">Sustainable Data Stewardship</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ten-simple-rules-for-making-training-materials-fair">Ten simple rules for making training materials FAIR</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#terminology-service-for-research-data-management-and-knowledge-discovery-in-low-temperature-plasma-physics">Terminology service for research data management and knowledge discovery in low-temperature plasma physics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-dataset-for-whole-slide-image-registration">Test Dataset for Whole Slide Image Registration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-fair-guiding-principles-for-scientific-data-management-and-stewardship">The FAIR Guiding Principles for scientific data management and stewardship</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-fair-guiding-principles-for-data-stewardship-fair-enough">The FAIR guiding principles for data stewardship - fair enough?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-information-infrastructure-for-bioimage-data-i3d-bio-project-to-advance-fair-microscopy-data-management-for-the-community">The Information Infrastructure for BioImage Data (I3D:bio) project to advance FAIR microscopy data management for the community</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-open-microscopy-environment-ome-data-model-and-xml-file-open-tools-for-informatics-and-quantitative-analysis-in-biological-imaging">The Open Microscopy Environment (OME) Data Model and XML file - open tools for informatics and quantitative analysis in biological imaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-turing-way-guide-for-reproducible-research">The Turing Way: Guide for reproducible research</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-role-of-helmholtz-centers-in-nfdi4bioimage-a-national-consortium-enhancing-fair-data-management-for-microscopy-and-bioimage-analysis">The role of Helmholtz Centers in NFDI4BIOIMAGE - A national consortium enhancing FAIR data management for microscopy and bioimage analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#thinking-data-management-on-different-scales">Thinking data management on different scales</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#towards-preservation-of-life-science-data-with-nfdi4bioimage">Towards Preservation of Life Science Data with NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#towards-transparency-and-knowledge-exchange-in-ai-assisted-data-analysis-code-generation">Towards Transparency and Knowledge Exchange in AI-assisted Data Analysis Code Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tracking-of-mitochondria-and-capturing-mitoflashes">Tracking of mitochondria and capturing mitoflashes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-the-trainer-concept-on-research-data-management">Train-the-Trainer Concept on Research Data Management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-computational-skills-in-the-age-of-ai">Training Computational Skills in the Age of AI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-glittr-org-to-find-compare-and-re-use-online-training-materials">Using Glittr.org to find, compare and re-use online training materials</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#welcome-to-bioimage-town">Welcome to BioImage Town</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-open-data">What is Open Data?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#who-you-gonna-call-data-stewards-to-the-rescue">Who you gonna call? - Data Stewards to the rescue</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#working-group-charter-rdm-helpdesk-network">Working Group Charter. RDM Helpdesk Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter">Zeiss AxioZoom Stage Adapter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter-12-6well-plate">Zeiss AxioZoom Stage Adapter - 12/6Well Plate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter-em-block-holder">Zeiss AxioZoom Stage Adapter - EM block holder</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter-microscope-slides">Zeiss AxioZoom Stage Adapter - Microscope slides</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bina-cc-scalable-strategies-for-a-next-generation-of-fair-bioimaging">[BINA CC] Scalable strategies for a next-generation of FAIR bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cidas-scalable-strategies-for-a-next-generation-of-fair-bioimaging">[CIDAS] Scalable strategies for a next-generation of FAIR bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cmcb-scalable-strategies-for-a-next-generation-of-fair-bioimaging">[CMCB] Scalable strategies for a next-generation of FAIR bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cordi-2023-zarr-a-cloud-optimized-storage-for-interactive-access-of-large-arrays">[CORDI 2023] Zarr: A Cloud-Optimized Storage for Interactive Access of Large Arrays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#community-meeting-2024-overview-team-image-data-analysis-and-management">[Community Meeting 2024] Overview Team Image Data Analysis and Management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#community-meeting-2024-supporting-and-financing-rdm-projects-within-gerbi">[Community Meeting 2024] Supporting and financing RDM projects within GerBI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#elmi-2024-ai-s-dirty-little-secret-without">[ELMI 2024]  AI’s Dirty Little Secret: Without</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#elmi-2024-ai-s-dirty-little-secret-without-fair-data-it-s-just-fancy-math">[ELMI 2024] AI’s Dirty Little Secret: Without FAIR Data, It’s Just Fancy Math</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gbi-eoe-vii-five-or-ten-must-have-items-for-making-it-infrastructure-for-managing-bioimage-data">[GBI EOE VII] Five (or ten) must-have items for making IT infrastructure for managing bioimage data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gbi-eoe-ix-nfdi4bioimage">[GBI EoE IX] NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#i2k-scalable-strategies-for-a-next-generation-of-fair-bioimaging">[I2K] Scalable strategies for a next-generation of FAIR bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#n4bi-ahm-welcome-to-bioimage-town">[N4BI AHM] Welcome to BioImage Town</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#swat4hcls-2023-nfdi4bioimage-perspective-for-a-national-bioimage-standard">[SWAT4HCLS 2023] NFDI4BIOIMAGE: Perspective for a national bioimage standard</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#short-talk-nfdi4bioimage-a-consortium-in-the-national-research-data-infrastructure">[Short Talk] NFDI4BIOIMAGE - A consortium in the National Research Data Infrastructure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workshop-material-fit-for-omero-how-imaging-facilities-and-it-departments-work-together-to-enable-rdm-for-bioimaging-october-16-17-2024-heidelberg">[Workshop Material] Fit for OMERO - How imaging facilities and IT departments work together to enable RDM for bioimaging, October 16-17, 2024, Heidelberg</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workshop-bioimage-data-management-and-analysis-with-omero">[Workshop] Bioimage data management and analysis with OMERO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workshop-fair-data-handling-for-microscopy-structured-metadata-annotation-in-omero">[Workshop] FAIR data handling for microscopy: Structured metadata annotation in OMERO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workshop-research-data-management-for-microscopy-and-bioimage-analysis">[Workshop] Research Data Management for Microscopy and BioImage Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ilastik-interactive-machine-learning-for-bio-image-analysis">ilastik: interactive machine learning for (bio)image analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-generative-ai">introduction-to-generative-ai</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nextflow-workshop">nextflow-workshop</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#re3data-org-registry-of-research-data-repositories">re3data.org - registry of Research Data Repositories</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scikit-learn-mooc">scikit-learn MOOC</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-resources">training-resources</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="cc-by-4-0-258">
<h1>Cc-by-4.0 (258)<a class="headerlink" href="#cc-by-4-0-258" title="Link to this heading">#</a></h1>
<section id="zenodo-und-co-was-bringt-und-wer-braucht-ein-repositorium">
<h2>“ZENODO und Co.” Was bringt und wer braucht ein Repositorium?<a class="headerlink" href="#zenodo-und-co-was-bringt-und-wer-braucht-ein-repositorium" title="Link to this heading">#</a></h2>
<p>Elfi Hesse, Jan-Christoph Deinert, Christian Löschen</p>
<p>Published 2021-01-25</p>
<p>Licensed CC-BY-4.0</p>
<p>Die Online-Veranstaltung fand am 21.01.2021 im Rahmen der SaxFDM-Veranstaltungsreihe “Digital Kitchen - Küchengespräche mit SaxFDM” statt. SaxFDM-Sprecherin Elfi Hesse (HTW Dresden) erläuterte zunächst Grundsätzliches zum Thema Repositorien. Anschließend teilten Nutzer (Jan Deinert – HZDR) und Anbieter (Christian Löschen – TU Dresden/ZIH) lokaler Repositorien ihre Erfahrungen mit uns.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/4461261">https://zenodo.org/records/4461261</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4461261">https://doi.org/10.5281/zenodo.4461261</a></p>
</section>
<hr class="docutils" />
<section id="frames-of-fluorescent-particles">
<h2>10 frames of fluorescent particles<a class="headerlink" href="#frames-of-fluorescent-particles" title="Link to this heading">#</a></h2>
<p>Zach Marin, Maohan Su</p>
<p>Published 2024-12-05</p>
<p>Licensed CC-BY-4.0</p>
<p>10 frames of fluorescent particles. They don’t do much, but they are a DCIMG version 0x7 file example.</p>
<p><a class="reference external" href="https://zenodo.org/records/14281237">https://zenodo.org/records/14281237</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14281237">https://doi.org/10.5281/zenodo.14281237</a></p>
</section>
<hr class="docutils" />
<section id="d-nuclei-annotations-and-stardist-3d-model-s-rat-brain">
<h2>3D Nuclei annotations and StarDist 3D model(s) (rat brain)<a class="headerlink" href="#d-nuclei-annotations-and-stardist-3d-model-s-rat-brain" title="Link to this heading">#</a></h2>
<p>Romain Guiet</p>
<p>Published 2022-06-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: 3D Nuclei annotations and StarDist3D model(s) (rat brain)</p>
<p>Images:  From a large tiling acquisition ( <a class="reference external" href="https://doi.org/10.5281/zenodo.6646128">https://doi.org/10.5281/zenodo.6646128</a> ) individual Tile (xyz : 1024x1024x62) were downsampled and cropped (128x128x62). Four crops, from different tiles (./annotations_BIOP/images/) were manually annotated with ITK-SNAP (./annotations_BIOP/masks/)</p>
<p>These four images, and their corresponding masks, were cropped into four quadrants (./crops_BIOP_v1/) in order to get 16 different images (64x64x62).</p>
<p>Conda environment: A conda environment was created using the yml file  stardist0.8_TF1.15.yml</p>
<p>Training : Training was performed using the jupyter notebook 1-Training_notebook.ipynb.
Three different trainings (with the same random seed, same anisotropy, patch size and grid) were performed and produced three different models (./models/)</p>
<p>Validation images (from the random seed used) were exported to ease the visual inspection of the results(./val_rdm42/).</p>
<p>Validation:  To save metrics in a csv file and compare predictions to the annotations the jupyter notebook 2-QC_notebook.ipynb can be used on the validation folder.</p>
<p>Large images: To test the model on larger images one can use Whole_ds441.tif (or Crop_ds441.tif )
These images were obtained using the plugin BigSticher on the raw data ( <a class="reference external" href="https://doi.org/10.5281/zenodo.6646128">https://doi.org/10.5281/zenodo.6646128</a> ), resaved as h5 and exported the downsample by 4 version.</p>
<p> </p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/6645978">https://zenodo.org/records/6645978</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6645978">https://doi.org/10.5281/zenodo.6645978</a></p>
</section>
<hr class="docutils" />
<section id="steps-towards-reproducible-research">
<h2>6 Steps Towards Reproducible Research<a class="headerlink" href="#steps-towards-reproducible-research" title="Link to this heading">#</a></h2>
<p>Heidi Seibold</p>
<p>Licensed CC-BY-4.0</p>
<p>A short book with 6 steps that get you closer to making your work reproducible.</p>
<p>Tags: Reproducibility, Research Data Management</p>
<p>Content type: Book</p>
<p><a class="reference external" href="https://zenodo.org/records/12744715">https://zenodo.org/records/12744715</a></p>
</section>
<hr class="docutils" />
<section id="a-cloud-optimized-storage-for-interactive-access-of-large-arrays">
<h2>A Cloud-Optimized Storage for Interactive Access of Large Arrays<a class="headerlink" href="#a-cloud-optimized-storage-for-interactive-access-of-large-arrays" title="Link to this heading">#</a></h2>
<p>Josh Moore, Susanne Kunis</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Nfdi4Bioimage, Research Data Management</p>
<p>Content type: Publication, Conference Abstract</p>
<p><a class="reference external" href="https://doi.org/10.52825/cordi.v1i.285">https://doi.org/10.52825/cordi.v1i.285</a></p>
</section>
<hr class="docutils" />
<section id="a-glimpse-of-the-open-source-flim-analysis-software-tools-flimfit-flute-and-napari-flim-phasor-plotter">
<h2>A Glimpse of the Open-Source FLIM Analysis Software Tools FLIMfit, FLUTE and napari-flim-phasor-plotter<a class="headerlink" href="#a-glimpse-of-the-open-source-flim-analysis-software-tools-flimfit-flute-and-napari-flim-phasor-plotter" title="Link to this heading">#</a></h2>
<p>Anca Margineanu, Chiara Stringari, Marcelo Zoccoler, Cornelia Wetzker</p>
<p>Published 2024-03-27</p>
<p>Licensed CC-BY-4.0</p>
<p>The presentations introduce open-source software to read in, visualize and analyse fluorescence lifetime imaging microscopy (FLIM) raw data developed for life scientists. The slides were presented at German Bioimaging (GerBI) FLIM Workshop held February 26 to 29 2024 at the Biomedical Center of LMU München by Anca Margineanu, Chiara Stringari and Conni Wetzker. </p>
<p><a class="reference external" href="https://zenodo.org/records/10886750">https://zenodo.org/records/10886750</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10886750">https://doi.org/10.5281/zenodo.10886750</a></p>
</section>
<hr class="docutils" />
<section id="a-hitchhiker-s-guide-through-the-bio-image-analysis-software-universe">
<h2>A Hitchhiker’s guide through the bio-image analysis software universe<a class="headerlink" href="#a-hitchhiker-s-guide-through-the-bio-image-analysis-software-universe" title="Link to this heading">#</a></h2>
<p>Robert Haase, Elnaz Fazeli, David Legland, Michael Doube, Siân Culley, Ilya Belevich, Eija Jokitalo, Martin Schorb, Anna Klemm, Christian Tischer</p>
<p>Licensed CC-BY-4.0</p>
<p>This article gives an overview about commonly used bioimage analysis software and which aspects to consider when choosing a software for a specific project.</p>
<p>Tags: Bioimage Analysis</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://febs.onlinelibrary.wiley.com/doi/full/10.1002/1873-3468.14451">https://febs.onlinelibrary.wiley.com/doi/full/10.1002/1873-3468.14451</a></p>
</section>
<hr class="docutils" />
<section id="a-journey-to-fair-microscopy-data">
<h2>A journey to FAIR microscopy data<a class="headerlink" href="#a-journey-to-fair-microscopy-data" title="Link to this heading">#</a></h2>
<p>Stefanie Weidtkamp-Peters, Janina Hanne, Christian Schmidt</p>
<p>Published 2023-05-03</p>
<p>Licensed CC-BY-4.0</p>
<p>Oral presentation, 32nd MoMAN “From Molecules to Man” Seminar, Ulm, online. Monday February 6th, 2023</p>
<p>Abstract:</p>
<p>Research data management is essential in nowadays research, and one of the big opportunities to accelerate collaborative and innovative scientific projects. To achieve this goal, all our data needs to be FAIR (findable, accessible, interoperable, reproducible). For data acquired on microscopes, however, a common ground for FAIR data sharing is still to be established. Plenty of work on file formats, data bases, and training needs to be performed to highlight the value of data sharing and exploit its potential for bioimaging data.</p>
<p>In this presentation, Stefanie Weidtkamp-Peters will introduce the challenges for bioimaging data management, and the necessary steps to achieve data FAIRification. German BioImaging - GMB e.V., together with other institutions, contributes to this endeavor. Janina Hanne will present how the network of imaging core facilities, research groups and industry partners is key to the German bioimaging community’s aligned collaboration toward FAIR bioimaging data. These activities have paved the way for two data management initiatives in Germany: I3D:bio (Information Infrastructure for BioImage Data) and NFDI4BIOIMAGE, a consortium of the National Research Data Infrastructure. Christian Schmidt will introduce the goals and measures of these initiatives to the benefit of imaging scientist’s work and everyday practice.  </p>
<p>Tags: Nfdi4Bioimage, Research Data Management</p>
<p><a class="reference external" href="https://zenodo.org/records/7890311">https://zenodo.org/records/7890311</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7890311">https://doi.org/10.5281/zenodo.7890311</a></p>
</section>
<hr class="docutils" />
<section id="abdominal-imaging-window-aiw-for-intravital-imaging">
<h2>Abdominal Imaging Window (AIW) for Intravital Imaging<a class="headerlink" href="#abdominal-imaging-window-aiw-for-intravital-imaging" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-11-15</p>
<p>Licensed CC-BY-4.0</p>
<p>This upload features a simple model for the creation (Manufacturing/Prototyping) of an abdominal imaging window (AIW) for use in mice intravital microscopy.
Manufacture in titanium for chronic implantation. Measures in mm.</p>
<p><a class="reference external" href="https://zenodo.org/records/14168603">https://zenodo.org/records/14168603</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14168603">https://doi.org/10.5281/zenodo.14168603</a></p>
</section>
<hr class="docutils" />
<section id="aberrated-bead-stack">
<h2>Aberrated Bead Stack<a class="headerlink" href="#aberrated-bead-stack" title="Link to this heading">#</a></h2>
<p>Zach Marin</p>
<p>Published 2024-12-03</p>
<p>Licensed CC-BY-4.0</p>
<p>Bead stack taken on lower path of a 4Pi without deformable mirror corrections. DCIMG examples, not for other purposes.</p>
<p><a class="reference external" href="https://zenodo.org/records/14268554">https://zenodo.org/records/14268554</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14268554">https://doi.org/10.5281/zenodo.14268554</a></p>
</section>
<hr class="docutils" />
<section id="abstract-nfdi-basic-service-for-data-management-plans">
<h2>Abstract - NFDI Basic Service for Data Management Plans<a class="headerlink" href="#abstract-nfdi-basic-service-for-data-management-plans" title="Link to this heading">#</a></h2>
<p>Licensed CC-BY-4.0</p>
<p>The NFDI Basic Service DMP4NFDI supports consortia in developing and providing data management plans (DMP) services for their community.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Document</p>
<p><a class="reference external" href="https://base4nfdi.de/images/AbstractDMP4NFDI.pdf">https://base4nfdi.de/images/AbstractDMP4NFDI.pdf</a></p>
</section>
<hr class="docutils" />
<section id="alles-meins-oder-urheberrechte-klaren-fur-forschungsdaten">
<h2>Alles meins – oder!? Urheberrechte klären für Forschungsdaten<a class="headerlink" href="#alles-meins-oder-urheberrechte-klaren-fur-forschungsdaten" title="Link to this heading">#</a></h2>
<p>Stephan Wünsche</p>
<p>Published 2024-06-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Wem gehören Forschungsdaten? Diese Frage stellt sich bei Daten, an deren Entstehung mehrere Personen beteiligt waren, und besonders bei Textdaten, Bildern und Videos. Hier lernen Sie, für Ihr eigenes Forschungsvorhaben zu erkennen, wessen Urheber- und Leistungsschutzrechte zu berücksichtigen sind. Sie erfahren, wie Sie mit Hilfe von Vereinbarungen frühzeitig Rechtssicherheit herstellen, etwa um Daten weitergeben oder publizieren zu können.
 
 </p>
<p>Tags: Research Data Management, Licensing</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/11472148">https://zenodo.org/records/11472148</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11472148">https://doi.org/10.5281/zenodo.11472148</a></p>
</section>
<hr class="docutils" />
<section id="angebote-der-nfdi-fur-die-forschung-im-bereich-zoologie">
<h2>Angebote der NFDI für die Forschung im Bereich Zoologie<a class="headerlink" href="#angebote-der-nfdi-fur-die-forschung-im-bereich-zoologie" title="Link to this heading">#</a></h2>
<p>Birgitta König-Ries, Robert Haase, Daniel Nüst, Konrad Förstner, Judith Sophie Engel</p>
<p>Published 2024-12-04</p>
<p>Licensed CC-BY-4.0</p>
<p>In diesem Slidedeck geben wir einen Einblick in Angebote und Dienste der Nationalen Forschungsdaten Infrastruktur (NFDI), die Relevant für die Zoologie und angrenzende Disziplinen relevant sein könnten.</p>
<p>Tags: Nfdi4Bioimage, Research Data Management</p>
<p><a class="reference external" href="https://zenodo.org/records/14278058">https://zenodo.org/records/14278058</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14278058">https://doi.org/10.5281/zenodo.14278058</a></p>
</section>
<hr class="docutils" />
<section id="artificial-blobs-and-labels-image">
<h2>Artificial Blobs and Labels image<a class="headerlink" href="#artificial-blobs-and-labels-image" title="Link to this heading">#</a></h2>
<p>Romain</p>
<p>Published 2023-05-10</p>
<p>Licensed CC-BY-4.0</p>
<p>A groovy script to use in Fiji to generate artificial images and labels, with example images.</p>
<p><a class="reference external" href="https://zenodo.org/records/7919117">https://zenodo.org/records/7919117</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7919117">https://doi.org/10.5281/zenodo.7919117</a></p>
</section>
<hr class="docutils" />
<section id="astigmatic-4pi-bead-stack">
<h2>Astigmatic 4Pi bead stack<a class="headerlink" href="#astigmatic-4pi-bead-stack" title="Link to this heading">#</a></h2>
<p>Zach Marin, Maohan Su</p>
<p>Published 2024-12-06</p>
<p>Licensed CC-BY-4.0</p>
<p>Bead stack taken on a 4Pi. DCIMG 0x1000000 file with a 4-pixel correction requirement.</p>
<p><a class="reference external" href="https://zenodo.org/records/14287640">https://zenodo.org/records/14287640</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14287640">https://doi.org/10.5281/zenodo.14287640</a></p>
</section>
<hr class="docutils" />
<section id="bids-lecture-2024">
<h2>BIDS-lecture-2024<a class="headerlink" href="#bids-lecture-2024" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Licensed CC-BY-4.0</p>
<p>Training resources for Students at Uni Leipzig who want to dive into bio-image data science with Python. The material developed here between April and July 2024.</p>
<p>Tags: Bioimage Analysis, Artificial Intelligence, Python</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/ScaDS/BIDS-lecture-2024/">ScaDS/BIDS-lecture-2024</a></p>
</section>
<hr class="docutils" />
<section id="biomero-a-scalable-and-extensible-image-analysis-framework">
<h2>BIOMERO - A scalable and extensible image analysis framework<a class="headerlink" href="#biomero-a-scalable-and-extensible-image-analysis-framework" title="Link to this heading">#</a></h2>
<p>Torec T. Luik, Rodrigo Rosas-Bertolini, Eric A.J. Reits, Ron A. Hoebe, Przemek M. Krawczyk</p>
<p>Published None</p>
<p>Licensed CC-BY-4.0</p>
<p>The authors introduce BIOMERO (bioimage analysis in OMERO), a bridge connecting OMERO, a renowned bioimaging data management platform, FAIR workflows, and high-performance computing (HPC) environments.</p>
<p>Tags: OMERO, Workflow, Bioimage Analysis</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://doi.org/10.1016/j.patter.2024.101024">https://doi.org/10.1016/j.patter.2024.101024</a></p>
</section>
<hr class="docutils" />
<section id="bigdataprocessor2-a-free-and-open-source-fiji-plugin-for-inspection-and-processing-of-tb-sized-image-data">
<h2>BigDataProcessor2: A free and open-source Fiji plugin for inspection and processing of TB sized image data<a class="headerlink" href="#bigdataprocessor2-a-free-and-open-source-fiji-plugin-for-inspection-and-processing-of-tb-sized-image-data" title="Link to this heading">#</a></h2>
<p>Christian Tischer, Ashis Ravindran, Sabine Reither, Nicolas Chiaruttini, Rainer Pepperkok, Nils Norlin</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Research Data Management, Bioimage Analysis</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://doi.org/10.1093/bioinformatics/btab106">https://doi.org/10.1093/bioinformatics/btab106</a></p>
</section>
<hr class="docutils" />
<section id="bio-image-data-strudel-for-workshop-on-research-data-management-in-tu-dresden-core-facilities">
<h2>Bio-Image Data Strudel for Workshop on Research Data Management in TU Dresden Core Facilities<a class="headerlink" href="#bio-image-data-strudel-for-workshop-on-research-data-management-in-tu-dresden-core-facilities" title="Link to this heading">#</a></h2>
<p>Cornelia Wetzker</p>
<p>Published 2023-11-08</p>
<p>Licensed CC-BY-4.0</p>
<p>This presentation gives a short outline of the complexity of data and metadata in the bioimaging universe. It introduces NFDI4BIOIMAGE as a newly formed consortium as part of the German ‘Nationale Forschungsdateninfrastruktur’ (NFDI) and its goals and tools for data management including its current members on TU Dresden campus.  </p>
<p>Tags: Research Data Management, Nfdi4Bioimage</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/10083555">https://zenodo.org/records/10083555</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10083555">https://doi.org/10.5281/zenodo.10083555</a></p>
</section>
<hr class="docutils" />
<section id="bio-image-analysis-code-generation">
<h2>Bio-image Analysis Code Generation<a class="headerlink" href="#bio-image-analysis-code-generation" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-10-28</p>
<p>Licensed CC-BY-4.0</p>
<p>Large Language Models are changing the way we interact with computers, especially how we write code. In this tutorial, we will generate bio-image analysis code using two LLM-based code generators, bia-bob and git-bob.
<a class="github reference external" href="https://github.com/haesleinhuepf/bia-bob">haesleinhuepf/bia-bob</a>
<a class="github reference external" href="https://github.com/haesleinhuepf/git-bob">haesleinhuepf/git-bob</a>
 </p>
<p><a class="reference external" href="https://zenodo.org/records/14001044">https://zenodo.org/records/14001044</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14001044">https://doi.org/10.5281/zenodo.14001044</a></p>
</section>
<hr class="docutils" />
<section id="bio-image-analysis-code-generation-using-bia-bob">
<h2>Bio-image Analysis Code Generation using bia-bob<a class="headerlink" href="#bio-image-analysis-code-generation-using-bia-bob" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-10-09</p>
<p>Licensed CC-BY-4.0</p>
<p>In this presentation I introduce bia-bob, an AI-based code generator that integrates into Jupyter Lab and allows for easy generation of Bio-Image Analysis Python code. It highlights how to get started with using large language models and prompt engineering to get high-quality bio-image analysis code.</p>
<p>Tags: Artificial Intelligence, Bioimage Analysis</p>
<p><a class="reference external" href="https://zenodo.org/records/13908108">https://zenodo.org/records/13908108</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13908108">https://doi.org/10.5281/zenodo.13908108</a></p>
</section>
<hr class="docutils" />
<section id="bio-image-analysis-with-the-help-of-large-language-models">
<h2>Bio-image Analysis with the Help of Large Language Models<a class="headerlink" href="#bio-image-analysis-with-the-help-of-large-language-models" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-03-13</p>
<p>Licensed CC-BY-4.0</p>
<p>Large Language Models (LLMs) change the way how we use computers. This also has impact on the bio-image analysis community. We can generate code that analyzes biomedical image data if we ask the right prompts. This talk outlines introduces basic principles, explains prompt engineering and how to apply it to bio-image analysis. We also compare how different LLM vendors perform on code generation tasks and which challenges are ahead for the bio-image analysis community.</p>
<p>Tags: Artificial Intelligence, Python</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/10815329">https://zenodo.org/records/10815329</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10815329">https://doi.org/10.5281/zenodo.10815329</a></p>
</section>
<hr class="docutils" />
<section id="bio-image-data-science">
<h2>Bio-image Data Science<a class="headerlink" href="#bio-image-data-science" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository contains training resources for Students at Uni Leipzig who want to dive into bio-image data science with Python.</p>
<p>Tags: Research Data Management, Artificial Intelligence, Bioimage Analysis, Python</p>
<p>Content type: Notebook</p>
<p><a class="github reference external" href="https://github.com/ScaDS/BIDS-lecture-2024">ScaDS/BIDS-lecture-2024</a></p>
</section>
<hr class="docutils" />
<section id="bio-image-data-science-lectures-uni-leipzig-scads-ai">
<h2>Bio-image Data Science Lectures &#64; Uni Leipzig / <a class="reference external" href="http://ScaDS.AI">ScaDS.AI</a><a class="headerlink" href="#bio-image-data-science-lectures-uni-leipzig-scads-ai" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Licensed CC-BY-4.0</p>
<p>These are the PPTx training resources for Students at Uni Leipzig who want to dive into bio-image data science with Python. The material developed here between April and July 2024.</p>
<p>Tags: Bioimage Analysis, Artificial Intelligence, Python</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/12623730">https://zenodo.org/records/12623730</a></p>
</section>
<hr class="docutils" />
<section id="bio-image-analysis-biostatistics-programming-and-machine-learning-for-computational-biology">
<h2>Bio-image analysis, biostatistics, programming and machine learning for computational biology<a class="headerlink" href="#bio-image-analysis-biostatistics-programming-and-machine-learning-for-computational-biology" title="Link to this heading">#</a></h2>
<p>Anna Poetsch, Biotec Dresden, Marcelo Leomil Zoccoler, Johannes Richard Müller, Robert Haase</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Python, Bioimage Analysis, Napari</p>
<p>Content type: Notebook</p>
<p><a class="github reference external" href="https://github.com/BiAPoL/Bio-image_Analysis_with_Python">BiAPoL/Bio-image_Analysis_with_Python</a></p>
</section>
<hr class="docutils" />
<section id="bio-tools-database">
<h2>Bio.tools database<a class="headerlink" href="#bio-tools-database" title="Link to this heading">#</a></h2>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Bioinformatics</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://bio.tools/">https://bio.tools/</a></p>
</section>
<hr class="docutils" />
<section id="bioformats-command-line-cli-tools">
<h2>BioFormats Command line (CLI) tools<a class="headerlink" href="#bioformats-command-line-cli-tools" title="Link to this heading">#</a></h2>
<p>Published 2024-10-24</p>
<p>Licensed CC-BY-4.0</p>
<p>Bio-Formats is a standalone Java library for reading and writing life sciences image file formats. There are several scripts for using Bio-Formats on the command line, which are listed here.</p>
<p>Content type: Documentation</p>
<p><a class="reference external" href="https://bio-formats.readthedocs.io/en/v8.0.0/users/comlinetools/index.html">https://bio-formats.readthedocs.io/en/v8.0.0/users/comlinetools/index.html</a></p>
</section>
<hr class="docutils" />
<section id="bioimage-analysis-notebooks">
<h2>BioImage Analysis Notebooks<a class="headerlink" href="#bioimage-analysis-notebooks" title="Link to this heading">#</a></h2>
<p>Robert Haase et al.</p>
<p>Licensed [‘CC-BY-4.0’, ‘BSD-3-CLAUSE’]</p>
<p>Tags: Python, Bioimage Analysis</p>
<p>Content type: Book, Notebook</p>
<p><a class="reference external" href="https://haesleinhuepf.github.io/BioImageAnalysisNotebooks/intro.html">https://haesleinhuepf.github.io/BioImageAnalysisNotebooks/intro.html</a></p>
</section>
<hr class="docutils" />
<section id="bioimage-io-chatbot-globias-seminar">
<h2><a class="reference external" href="http://BioImage.IO">BioImage.IO</a> Chatbot, GloBIAS Seminar<a class="headerlink" href="#bioimage-io-chatbot-globias-seminar" title="Link to this heading">#</a></h2>
<p>Caterina Fuster-Barcelo</p>
<p>Published 2024-10-02</p>
<p>Licensed CC-BY-4.0</p>
<p>The dynamic field of bioimage analysis continually seeks innovative tools to democratize access to analysis tools and its documentation. The <a class="reference external" href="http://BioImage.IO">BioImage.IO</a> Chatbot, leveraging state-of-the-art AI technologies including Large Language Models (LLMs) and Retrieval Augmented Generation (RAG), provides an interactive platform that significantly integrates the exploration and application of bioimage analysis tools and models. This seminar will introduce the <a class="reference external" href="http://BioImage.IO">BioImage.IO</a> Chatbot’s capabilities, focusing on how it facilitates access to advanced analysis tools and documentation, allows for the execution of complex models, and enables users to create customized extensions adjusted to specific research needs. In a live demo, attendees will see how to interact with the chatbot and all its assistants and capabilities. Join us to explore how the <a class="reference external" href="http://BioImage.IO">BioImage.IO</a> Chatbot ca transform your research by making sophisticated analysis more intuitive and accessible.</p>
<p><a class="reference external" href="https://zenodo.org/records/13880367">https://zenodo.org/records/13880367</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13880367">https://doi.org/10.5281/zenodo.13880367</a></p>
</section>
<hr class="docutils" />
<section id="browsing-the-open-microscopy-image-data-resource-with-python">
<h2>Browsing the Open Microscopy Image Data Resource with Python<a class="headerlink" href="#browsing-the-open-microscopy-image-data-resource-with-python" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: OMERO, Python</p>
<p>Content type: Blog Post</p>
<p><a class="reference external" href="https://biapol.github.io/blog/robert_haase/browsing_idr/readme.html">https://biapol.github.io/blog/robert_haase/browsing_idr/readme.html</a></p>
</section>
<hr class="docutils" />
<section id="building-fair-image-analysis-pipelines-for-high-content-screening-hcs-data-using-galaxy">
<h2>Building FAIR image analysis pipelines for high-content-screening (HCS) data using Galaxy<a class="headerlink" href="#building-fair-image-analysis-pipelines-for-high-content-screening-hcs-data-using-galaxy" title="Link to this heading">#</a></h2>
<p>Riccardo Massei, Matthias Berndt, Beatriz Serrano-Solano, Wibke Busch, Stefan Scholz, Hannes Bohring, Jo Nyffeler, Luise Reger, Jan Bumberger, Lucille Lopez-Delisle</p>
<p>Published 2024-11-06</p>
<p>Licensed CC-BY-4.0</p>
<p>Imaging is crucial across various scientific disciplines, particularly in life sciences, where it plays a key role in studies ranging from single molecules to whole organisms. However, the complexity and sheer volume of image data, especially from high-content screening (HCS) experiments involving cell lines or other organisms, present significant challenges. Managing and analysing this data efficiently requires well-defined image processing tools and analysis pipelines that align with the FAIR principles—ensuring they are findable, accessible, interoperable, and reusable across different domains.
In the frame of NFDI4BioImaging (the National Research Data Infrastructure focusing on bioimaging in Germany), we want to find viable solutions for storing, processing, analysing, and sharing HCS data. In particular, we want to develop solutions to make findable and machine-readable metadata using (semi)automatic analysis pipelines. In scientific research, such pipelines are crucial for maintaining data integrity, supporting reproducibility, and enabling interdisciplinary collaboration. These tools can be used by different users to retrieve images based on specific attributes as well as support quality control by identifying appropriate metadata.
Galaxy, an open-source, web-based platform for data-intensive research, offers a solution by enabling the construction of reproducible pipelines for image analysis. By integrating popular analysis software like CellProfiler and connecting with cloud services such as OMERO and IDR, Galaxy facilitates the seamless access and management of image data. This capability is particularly valuable in bioimaging, where automated pipelines can streamline the handling of complex metadata, ensuring data integrity and fostering interdisciplinary collaboration. This approach not only increases the efficiency of HCS bioimaging but also contributes to the broader scientific community’s efforts to embrace FAIR principles, ultimately advancing scientific discovery and innovation.
In the present study, we proposed an automated analysis pipeline for storing, processing, analysing, and sharing HCS bioimaging data. The (semi)automatic workflow was developed by taking as a case study a dataset of zebrafish larvae and cell lines images previously obtained from an automated imaging system generating data in an HCS fashion. In our workflows, images are automatically enriched with metadata (i.e. key-value pairs, tags, raw data, regions of interest) and uploaded to the UFZ-OME Remote Objects (OMERO) server using a novel OMERO tool suite developed with GALAXY. Workflows give the possibility to the user to intuitively fetch images from the local server and perform image analysis (i.e. annotation) or even more complex toxicological analyses (dose response modelling). Furthermore, we want to improve the FAIRness of the protocol by adding a direct upload link to the Image Data Resource (IDR) repository to automatically prepare the data for publication and sharing.</p>
<p><a class="reference external" href="https://zenodo.org/records/14044640">https://zenodo.org/records/14044640</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14044640">https://doi.org/10.5281/zenodo.14044640</a></p>
<p><a class="reference external" href="https://galaxyproject.org/news/2024-11-08-galaxy-imaging-fair-pipelines/">https://galaxyproject.org/news/2024-11-08-galaxy-imaging-fair-pipelines/</a></p>
</section>
<hr class="docutils" />
<section id="building-a-fair-image-data-ecosystem-for-microscopy-communities">
<h2>Building a FAIR image data ecosystem for microscopy communities<a class="headerlink" href="#building-a-fair-image-data-ecosystem-for-microscopy-communities" title="Link to this heading">#</a></h2>
<p>Isabel Kemmer, Antje Keppler, Beatriz Serrano-Solano, Arina Rybina, Bugra Özdemir, Johanna Bischof, Ayoub El Ghadraoui, John E. Eriksson, Aastha Mathur</p>
<p>Published 2023-03-31</p>
<p>Licensed CC-BY-4.0</p>
<p>Bioimaging has now entered the era of big data with faster than ever development of complex microscopy technologies leading to increasingly complex datasets. This enormous increase in data size and informational complexity within those datasets has brought with it several difficulties in terms of common and harmonized data handling, analysis and management practices, which are currently hampering the full potential of image data being realized. Here we outline a wide range of efforts and solutions currently being developed by the microscopy community to address these challenges on the path towards FAIR bioimage data. We also highlight how different actors in the microscopy ecosystem are working together, creating synergies that develop new approaches, and how research infrastructures, such as Euro-BioImaging, are fostering these interactions to shape the field. </p>
<p><a class="reference external" href="https://zenodo.org/records/7788899">https://zenodo.org/records/7788899</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7788899">https://doi.org/10.5281/zenodo.7788899</a></p>
</section>
<hr class="docutils" />
<section id="czi-carl-zeiss-image-dataset-with-artificial-test-camera-images-with-various-dimension-for-testing-libraries-reading">
<h2>CZI (Carl Zeiss Image) dataset with artificial test camera images with various dimension for testing libraries reading<a class="headerlink" href="#czi-carl-zeiss-image-dataset-with-artificial-test-camera-images-with-various-dimension-for-testing-libraries-reading" title="Link to this heading">#</a></h2>
<p>Sebastian Rhode</p>
<p>Published 2022-08-22</p>
<p>Licensed CC-BY-4.0</p>
<p>Set of CZI test images created by using a simulated microscope with a test grayscale camera (no LSM or AiryScan or RGB). The filename indicates the used dimension(s) for the acquisition experiment. The files can be used to test the basic functionality of libraries reading CZI files.</p>
<p>Examples:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>S=2_T=3_CH=1.czi = 2 Scenes, 3 TimePoints and 1 Channel

	Z-Stack was not activated inside acquisition experiment


S=2_T=3_Z=5_CH=2.czi = 2 Scenes, 3 TimePoints, 5-Z-Planes and 1 Channels

	Z-Stack was activated inside acquisition experiment
</pre></div>
</div>
<p>The test files (so far) contain not any data with more “advanced” dimensions like AiryScan rawdata, illumination angles etc. Also no CZI files with pixel type RGB are included yet.</p>
<p> </p>
<p> </p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/7015307">https://zenodo.org/records/7015307</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7015307">https://doi.org/10.5281/zenodo.7015307</a></p>
</section>
<hr class="docutils" />
<section id="czi-file-examples">
<h2>CZI file examples<a class="headerlink" href="#czi-file-examples" title="Link to this heading">#</a></h2>
<p>Nicolas Chiaruttini</p>
<p>Published 2023-08-18</p>
<p>Licensed CC-BY-4.0</p>
<p>A set of public CZI files. These can be used for testing CZI readers.</p>
<ul class="simple">
<li><p>Demo LISH 4x8 15pct 647.czi: A cleared mouse brain acquired with a Zeiss LightSheet Z1 with 32 tiles. Courtesy of the Carl Petersen lab LSENS (<a class="reference external" href="https://www.epfl.ch/labs/lsens">https://www.epfl.ch/labs/lsens</a>). Sampled prepared by Yanqi Liu an imaged by Olivier Burri.</p></li>
<li><p>test_gray.czi: a synthetically generated CZI file without metadata, made by Sebastian Rhode</p></li>
<li><p>Image_1_2023_08_18__14_32_31_964.czi: an example multi-part CZI file, containing only camera noise</p></li>
<li><p>a xt scan, xz scan, xzt scan</p></li>
<li><p>a set of multi angle, multi illumination, mutli tile acquisition, taken on the LightSheet Z1 microscope of the PTBIOP by Lorenzo Talà</p></li>
</ul>
<p><a class="reference external" href="https://zenodo.org/records/8305531">https://zenodo.org/records/8305531</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8305531">https://doi.org/10.5281/zenodo.8305531</a></p>
</section>
<hr class="docutils" />
<section id="cellpose-model-for-digital-phase-contrast-images">
<h2>Cellpose model for Digital Phase Contrast images<a class="headerlink" href="#cellpose-model-for-digital-phase-contrast-images" title="Link to this heading">#</a></h2>
<p>Laura Capolupo, Olivier Burri, Romain Guiet</p>
<p>Published 2022-02-09</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: Cellpose model for Digital Phase Contrast images</p>
<p>Data type: Cellpose model, trained via transfer learning from ‘cyto’ model.</p>
<p>Training Dataset: Light microscopy (Digital Phase Contrast) and Manual annotations (10.5281/zenodo.5996883)</p>
<p>Training Procedure: Model was trained using a Cellpose version 0.6.5 with GPU support (NVIDIA GeForce RTX 2080) using default settings as per the Cellpose documentation </p>
<p>python -m cellpose –train –dir TRAINING/DATASET/PATH/train –test_dir TRAINING/DATASET/PATH/test –pretrained_model cyto –chan 0 –chan2 0</p>
<p>The model file (MODEL NAME) in this repository is the result of this training.</p>
<p>Prediction Procedure: Using this model, a label image can be obtained from new unseen images in a given folder with</p>
<p>python -m cellpose –dir NEW/DATASET/PATH –pretrained_model FULL_MODEL_PATH –chan 0 –chan2 0 –save_tif –no_npy</p>
<p><a class="reference external" href="https://zenodo.org/records/6023317">https://zenodo.org/records/6023317</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6023317">https://doi.org/10.5281/zenodo.6023317</a></p>
</section>
<hr class="docutils" />
<section id="cellpose-models-for-label-prediction-from-brightfield-and-digital-phase-contrast-images">
<h2>Cellpose models for Label Prediction from Brightfield and Digital Phase Contrast images<a class="headerlink" href="#cellpose-models-for-label-prediction-from-brightfield-and-digital-phase-contrast-images" title="Link to this heading">#</a></h2>
<p>Romain Guiet, Olivier Burri</p>
<p>Published 2022-02-25</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: Cellpose models for Brightfield and Digital Phase Contrast images</p>
<p>Data type: Cellpose models trained via transfer learning from the ‘nuclei’ and ‘cyto2’ pretrained model with additional Training Dataset . Includes corresponding csv files with ‘Quality Control’ metrics(§) (model.zip).</p>
<p>Training Dataset: Light microscopy (Digital Phase Contrast or Brightfield) and automatic annotations (nuclei or cyto) (<a class="reference external" href="https://doi.org/10.5281/zenodo.6140064">https://doi.org/10.5281/zenodo.6140064</a>)</p>
<p>Training Procedure: The cellpose models were trained using cellpose version 1.0.0 with GPU support (NVIDIA GeForce K40) using default settings as per the Cellpose documentation . Training was done using a Renku environment (renku template).</p>
<p> </p>
<p>Command Line Execution for the different trained models</p>
<p>nuclei_from_bf:</p>
<p>cellpose –train –dir ‘data/train/’ –test_dir ‘data/test/’ –pretrained_model nuclei  –img_filter _bf –mask_filter _nuclei –chan 0 –chan2 0 –use_gpu –verbose</p>
<p>cyto_from_bf:</p>
<p>cellpose –train –dir ‘data/train/’ –test_dir ‘data/test/’ –pretrained_model cyto2 –img_filter _bf –mask_filter _cyto –chan 0 –chan2 0 –use_gpu –verbose</p>
<p> </p>
<p>nuclei_from_dpc:</p>
<p>cellpose –train –dir ‘data/train/’ –test_dir ‘data/test/’ –pretrained_model nuclei  –img_filter _dpc –mask_filter _nuclei –chan 0 –chan2 0 –use_gpu –verbose</p>
<p>cyto_from_dpc:</p>
<p>cellpose –train –dir ‘data/train/’ –test_dir ‘data/test/’ –pretrained_model cyto2 –img_filter _dpc –mask_filter _cyto –chan 0 –chan2 0 –use_gpu –verbose</p>
<p> </p>
<p>nuclei_from_sqrdpc:</p>
<p>cellpose –train –dir ‘data/train/’ –test_dir ‘data/test/’ –pretrained_model nuclei –img_filter _sqrdpc –mask_filter _nuclei –chan 0 –chan2 0 –use_gpu –verbose</p>
<p>cyto_from_sqrdpc:</p>
<p>cellpose –train –dir ‘data/train/’ –test_dir ‘data/test/’ –pretrained_model cyto2 –img_filter _sqrdpc –mask_filter _cyto –chan 0 –chan2 0 –use_gpu –verbose</p>
<p> </p>
<p>NOTE (§): We provide a notebook for Quality Control, which is an adaptation of the “Cellpose (2D and 3D)” notebook from ZeroCostDL4Mic .</p>
<p>NOTE: This dataset used a training dataset from the Zenodo entry(<a class="reference external" href="https://doi.org/10.5281/zenodo.6140064">https://doi.org/10.5281/zenodo.6140064</a>) generated from the “HeLa “Kyoto” cells under the scope”  dataset Zenodo entry(<a class="reference external" href="https://doi.org/10.5281/zenodo.6139958">https://doi.org/10.5281/zenodo.6139958</a>) in order to automatically generate the label images.</p>
<p>NOTE: Make sure that you delete the “_flow” images that are auto-computed when running the training. If you do not, then the flows from previous runs will be used for the new training, which might yield confusing results.</p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/6140111">https://zenodo.org/records/6140111</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6140111">https://doi.org/10.5281/zenodo.6140111</a></p>
</section>
<hr class="docutils" />
<section id="challenges-and-opportunities-for-bio-image-analysis-core-facilities">
<h2>Challenges and opportunities for bio-image analysis core-facilities<a class="headerlink" href="#challenges-and-opportunities-for-bio-image-analysis-core-facilities" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Research Data Management, Bioimage Analysis, Nfdi4Bioimage</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://f1000research.com/slides/12-1054">https://f1000research.com/slides/12-1054</a></p>
</section>
<hr class="docutils" />
<section id="challenges-and-opportunities-for-bioimage-analysis-core-facilities">
<h2>Challenges and opportunities for bioimage analysis core-facilities<a class="headerlink" href="#challenges-and-opportunities-for-bioimage-analysis-core-facilities" title="Link to this heading">#</a></h2>
<p>Johannes Richard Soltwedel, Robert Haase</p>
<p>Licensed CC-BY-4.0</p>
<p>This article outlines common reasons for founding bioimage analysis core-facilities, services they can provide to fulfill certain need and conflicts of interest that arise from these services.</p>
<p>Tags: Bioimage Analysis, Research Data Management</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://onlinelibrary.wiley.com/doi/full/10.1111/jmi.13192">https://onlinelibrary.wiley.com/doi/full/10.1111/jmi.13192</a></p>
</section>
<hr class="docutils" />
<section id="chatgpt-for-image-analysis">
<h2>ChatGPT for Image Analysis<a class="headerlink" href="#chatgpt-for-image-analysis" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-08-25</p>
<p>Licensed CC-BY-4.0</p>
<p>Large Language Models (LLMs) such as ChatGPT are changing the way we interact with computers, including how we analye microscopy imaging data. In this talk I introduce basic concepts of asking LLMs to write code and how to modify the questions to get the best out of it. For trying out these prompt engineering basics there are additional online resources available: <a class="reference external" href="https://scads.github.io/prompt-engineering-basics-2024/intro.html">https://scads.github.io/prompt-engineering-basics-2024/intro.html</a></p>
<p><a class="reference external" href="https://zenodo.org/records/13371196">https://zenodo.org/records/13371196</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13371196">https://doi.org/10.5281/zenodo.13371196</a></p>
</section>
<hr class="docutils" />
<section id="collaborative-working-and-version-control-with-git-hub">
<h2>Collaborative Working and Version Control with git[hub]<a class="headerlink" href="#collaborative-working-and-version-control-with-git-hub" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-01-10</p>
<p>Licensed CC-BY-4.0</p>
<p>This slide deck introduces the version control tool git, related terminology and the Github Desktop app for managing files in Git[hub] repositories. We furthermore dive into:* Working with repositories* Collaborative with others* Github-Zenodo integration* Github pages* Artificial Intelligence answering Github Issues</p>
<p>Tags: Nfdi4Bioimage, Globias, Research Data Management, Research Software Management</p>
<p><a class="reference external" href="https://zenodo.org/records/14626054">https://zenodo.org/records/14626054</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14626054">https://doi.org/10.5281/zenodo.14626054</a></p>
</section>
<hr class="docutils" />
<section id="collaborative-bio-image-analysis-script-editing-with-git">
<h2>Collaborative bio-image analysis script editing with git<a class="headerlink" href="#collaborative-bio-image-analysis-script-editing-with-git" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Licensed CC-BY-4.0</p>
<p>Introduction to version control using git for collaborative, reproducible script editing.</p>
<p>Tags: Sharing, Research Data Management</p>
<p>Content type: Blog Post</p>
<p><a class="reference external" href="https://focalplane.biologists.com/2021/09/04/collaborative-bio-image-analysis-script-editing-with-git/">https://focalplane.biologists.com/2021/09/04/collaborative-bio-image-analysis-script-editing-with-git/</a></p>
</section>
<hr class="docutils" />
<section id="combining-the-bids-and-arc-directory-structures-for-multimodal-research-data-organization">
<h2>Combining the BIDS and ARC Directory Structures for Multimodal Research Data Organization<a class="headerlink" href="#combining-the-bids-and-arc-directory-structures-for-multimodal-research-data-organization" title="Link to this heading">#</a></h2>
<p>Torsten Stöter, Tobias Gottschall, Andrea Schrader, Peter Zentis, Monica Valencia-Schneider, Niraj Kandpal, Werner Zuschratter, Astrid Schauss, Timo Dickscheid, Timo Mühlhaus, Dirk von Suchodoletz</p>
<p>Licensed CC-BY-4.0</p>
<p>Interdisciplinary collaboration and integrating large, diverse datasets are crucial for answering complex research questions, requiring multimodal data analysis and adherence to FAIR principles. To address challenges in capturing the full research cycle and contextualizing data, DataPLANT developed the Annotated Research Context (ARC), while the neuroimaging community extended the Brain Imaging Data Structure (BIDS) for microscopic image data, both providing standardized, file system-based storage structures for organizing and sharing data with metadata.</p>
<p>Tags: Research Data Management, FAIR-Principles</p>
<p>Content type: Poster</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.8349562">https://zenodo.org/doi/10.5281/zenodo.8349562</a></p>
</section>
<hr class="docutils" />
<section id="conference-slides-4th-day-of-intravital-microscopy">
<h2>Conference Slides - 4th Day of Intravital Microscopy<a class="headerlink" href="#conference-slides-4th-day-of-intravital-microscopy" title="Link to this heading">#</a></h2>
<p>Dr. Hellen Ishikawa-Ankerhold</p>
<p>Published 2024-11-13</p>
<p>Licensed CC-BY-4.0</p>
<p>Conference Slides for the presentation of GerBI e.V. at the 4th Day of Intravital Microscopy in Leuven, Belgium.
Features Structure, activities and Links to join GerBI e.V.</p>
<p><a class="reference external" href="https://zenodo.org/records/14113714">https://zenodo.org/records/14113714</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14113714">https://doi.org/10.5281/zenodo.14113714</a></p>
</section>
<hr class="docutils" />
<section id="crashkurs-forschungsdatenmanagement">
<h2>Crashkurs Forschungsdatenmanagement<a class="headerlink" href="#crashkurs-forschungsdatenmanagement" title="Link to this heading">#</a></h2>
<p>Barbara Weiner, Stephan Wünsche, Stefan Kühne, Pia Voigt, Sebastian Frericks, Clemens Hoffmann, Romy Elze, Ronny Gey</p>
<p>Published 2020-04-30</p>
<p>Licensed CC-BY-4.0</p>
<p>Diese Präsentation bietet einen Einstieg in alle relevanten Bereiche des Forschungsdatenmanagements an der Universität Leipzig. Behandelt werden Grundlagen des Forschungsdatenmanagements, technische, ethische und rechtliche Aspekte sowie die Archivierung und Publikation von Forschungsdaten. Die Präsentation enthält zahlreiche weiterführende Links (rot) und Literaturhinweise.</p>
<p>Ergänzend hierzu wird eine Präsentation mit Übungsaufgaben angeboten, die helfen soll, das Gelernte zu festigen und in der eigenen Forschungspraxis umzusetzen. Den Aufgaben folgen jeweils eine Antwortfolie sowie deren Auflösung.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/3778431">https://zenodo.org/records/3778431</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.3778431">https://doi.org/10.5281/zenodo.3778431</a></p>
</section>
<hr class="docutils" />
<section id="creating-workflows-and-advanced-workflow-options">
<h2>Creating Workflows and Advanced Workflow Options<a class="headerlink" href="#creating-workflows-and-advanced-workflow-options" title="Link to this heading">#</a></h2>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Workflow</p>
<p>Content type: Tutorial, Online Tutorial</p>
<p><a class="reference external" href="https://galaxyproject.org/learn/advanced-workflow/">https://galaxyproject.org/learn/advanced-workflow/</a></p>
</section>
<hr class="docutils" />
<section id="creating-a-research-data-management-plan-using-chatgpt">
<h2>Creating a Research Data Management Plan using chatGPT<a class="headerlink" href="#creating-a-research-data-management-plan-using-chatgpt" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2023-11-06</p>
<p>Licensed CC-BY-4.0</p>
<p>In this blog post the author demonstrates how chatGPT can be used to combine a fictive project description with a DMP specification to produce a project-specific DMP.</p>
<p>Tags: Research Data Management, Artificial Intelligence</p>
<p>Content type: Blog Post</p>
<p><a class="reference external" href="https://focalplane.biologists.com/2023/11/06/creating-a-research-data-management-plan-using-chatgpt/">https://focalplane.biologists.com/2023/11/06/creating-a-research-data-management-plan-using-chatgpt/</a></p>
</section>
<hr class="docutils" />
<section id="creating-open-computational-curricula">
<h2>Creating open computational curricula<a class="headerlink" href="#creating-open-computational-curricula" title="Link to this heading">#</a></h2>
<p>Kari Jordan, Zhian Kamvar, Toby Hodges</p>
<p>Published 2020-12-11</p>
<p>Licensed CC-BY-4.0</p>
<p>In this interactive session, Carpentries team members will guide attendees through three stages of the backward design process to create a lesson development plan for the open source tool of their choosing. Attendees will leave having identified what practical skills they aim to teach (learning objectives), an approach for designing challenge questions (formative assessment), and mechanisms to give and receive feedback.</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/4317149">https://zenodo.org/records/4317149</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4317149">https://doi.org/10.5281/zenodo.4317149</a></p>
</section>
<hr class="docutils" />
<section id="cultivating-open-training">
<h2>Cultivating Open Training<a class="headerlink" href="#cultivating-open-training" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-03-14</p>
<p>Licensed CC-BY-4.0</p>
<p>In this SaxFDM Digital Kitchen, I introduced current challenges and potential solutions for openly sharing training materials, softly focusing on bio-image analysis. In this field a lot of training materials circulate in private channels, but openly shared, reusable materials, according to the FAIR-principles, are still rare. Using the CC-BY license and uploading materials to publicly acessible repositories are proposed to fill this gap.</p>
<p>Tags: Open Science, Research Data Management, FAIR-Principles, Bioimage Analysis, Licensing</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/10816895">https://zenodo.org/records/10816895</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10816895">https://doi.org/10.5281/zenodo.10816895</a></p>
</section>
<hr class="docutils" />
<section id="cultivating-open-training-to-advance-bio-image-analysis">
<h2>Cultivating Open Training to advance Bio-image Analysis<a class="headerlink" href="#cultivating-open-training-to-advance-bio-image-analysis" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-04-25</p>
<p>Licensed CC-BY-4.0</p>
<p>These slides introduce current challenges and potential solutions for openly sharing training materials, focusing on bio-image analysis. In this field a lot of training materials circulate in private channels, but openly shared, reusable materials, according to the FAIR-principles, are still rare. Using the CC-BY license and publicly acessible repositories are proposed to fill this gap.</p>
<p>Tags: Research Data Management, Licensing, FAIR-Principles</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/11066250">https://zenodo.org/records/11066250</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11066250">https://doi.org/10.5281/zenodo.11066250</a></p>
</section>
<hr class="docutils" />
<section id="dl4miceverywhere">
<h2>DL4MicEverywhere<a class="headerlink" href="#dl4miceverywhere" title="Link to this heading">#</a></h2>
<p>Iván Hidalgo, et al.</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Bioimage Analysis</p>
<p>Content type: Notebook, Collection</p>
<p><a class="github reference external" href="https://github.com/HenriquesLab/DL4MicEverywhere">HenriquesLab/DL4MicEverywhere</a></p>
</section>
<hr class="docutils" />
<section id="data-carpentry-for-biologists">
<h2>Data Carpentry for Biologists<a class="headerlink" href="#data-carpentry-for-biologists" title="Link to this heading">#</a></h2>
<p>Licensed [‘CC-BY-4.0’, ‘MIT’]</p>
<p>Content type: Tutorial, Code</p>
<p><a class="reference external" href="https://datacarpentry.org/semester-biology/">https://datacarpentry.org/semester-biology/</a></p>
</section>
<hr class="docutils" />
<section id="data-life-cycle">
<h2>Data life cycle<a class="headerlink" href="#data-life-cycle" title="Link to this heading">#</a></h2>
<p>ELIXIR (2021) Research Data Management Kit</p>
<p>Licensed CC-BY-4.0</p>
<p>In this section, information is organised according to the stages of the research data life cycle.</p>
<p>Tags: Data Life Cycle, Research Data Management</p>
<p>Content type: Collection, Website, Online Tutorial</p>
<p><a class="reference external" href="https://rdmkit.elixir-europe.org/data_life_cycle">https://rdmkit.elixir-europe.org/data_life_cycle</a></p>
</section>
<hr class="docutils" />
<section id="data-stewardship-and-research-data-management-tools-for-multimodal-linking-of-imaging-data-in-plasma-medicine">
<h2>Data stewardship and research data management tools for multimodal linking of imaging data in plasma medicine<a class="headerlink" href="#data-stewardship-and-research-data-management-tools-for-multimodal-linking-of-imaging-data-in-plasma-medicine" title="Link to this heading">#</a></h2>
<p>Mohsen Ahmadi, Robert Wagner, Philipp Mattern, Nick Plathe, Sander Bekeschus, Markus M. Becker, Torsten Stöter, Stefanie Weidtkamp-Peters</p>
<p>Published 2023-11-03</p>
<p>Licensed CC-BY-4.0</p>
<p>A more detailed understanding of the effect of plasmas on biological systems can be fostered by combining data from different imaging modalities, such as optical imaging, fluorescence imaging, and mass spectrometry imaging. This, however, requires the implementation and use of sophisticated research data management (RDM) solutions to incorporate the influence of plasma parameters and treatment procedures as well as the effects of plasma on the treated targets. In order to address this, RDM activities on different levels and from different perspectives are started and brought together within the framework of the NFDI consortium NFDI4BIOIMAGE.</p>
<p><a class="reference external" href="https://zenodo.org/records/10069368">https://zenodo.org/records/10069368</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10069368">https://doi.org/10.5281/zenodo.10069368</a></p>
</section>
<hr class="docutils" />
<section id="dataplant-knowledge-base">
<h2>DataPLANT knowledge base<a class="headerlink" href="#dataplant-knowledge-base" title="Link to this heading">#</a></h2>
<p>Published 2022-12-14</p>
<p>Licensed CC-BY-4.0</p>
<p>Explore fundamental topics on research data management (RDM), how DataPLANT implements these aspects to support plant researchers with RDM tools and services, read guides and manuals or search for some teaching materials.</p>
<p>Tags: Research Data Management, Dataplant</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://nfdi4plants.org/nfdi4plants.knowledgebase/index.html">https://nfdi4plants.org/nfdi4plants.knowledgebase/index.html</a></p>
</section>
<hr class="docutils" />
<section id="dataset-from-incell-2200-microscope-misread-as-a-plate">
<h2>Dataset from InCell 2200 microscope misread as a plate<a class="headerlink" href="#dataset-from-incell-2200-microscope-misread-as-a-plate" title="Link to this heading">#</a></h2>
<p>Fabien Kuttler, Rémy Dornier</p>
<p>Published 2025-01-30</p>
<p>Licensed CC-BY-4.0</p>
<p>Two dummy datasets are provided in this repository : </p>
<p>Dataset_Ok : 96 wells, 9 fields of view per well, 4 different channels (DAPI, Cy3, FITC, Brightfield), no Z, no T. The .xcde file of this dataset is correctly read by BioFormats, as the dataset is recognized as a plate, and can be imported on OMERO
Dataset_fail: 20 wells, 4 fields of view per well, 5 channels, with one duplicate (DAPI, FITC, Cy3, Cy5 wix 4 , Cy5 wix 5), no Z, no T. The .xcde file of this dataset is not correctly read by BioFormats and no images are imported on OMERO.</p>
<p>BioFormats version: 8.0.1
A discussion thread has been open on this topic.</p>
<p><a class="reference external" href="https://zenodo.org/records/14769820">https://zenodo.org/records/14769820</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14769820">https://doi.org/10.5281/zenodo.14769820</a></p>
</section>
<hr class="docutils" />
<section id="datenmanagement">
<h2>Datenmanagement<a class="headerlink" href="#datenmanagement" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-04-14</p>
<p>Licensed CC-BY-4.0</p>
<p>In dieser Data Management Session wird der Lebenszyklus von Daten näher beleuchtet. Wie entstehen Daten, was passiert mit ihnen, wenn sie verarbeitet werden? Wem gehören die Daten und wer ist dafür verantwortlich, sie zu veröffentlichen, zu archivieren und gegebenenfalls wiederzuverwenden? Wir werden einen Datenmanagementplan in Gruppenarbeit entwerfen, ggf. mit Hilfe von ChatGPT.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/10970869">https://zenodo.org/records/10970869</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10970869">https://doi.org/10.5281/zenodo.10970869</a></p>
</section>
<hr class="docutils" />
<section id="datenmanagement-im-fokus-organisation-speicherstrategien-und-datenschutz">
<h2>Datenmanagement im Fokus: Organisation, Speicherstrategien und Datenschutz<a class="headerlink" href="#datenmanagement-im-fokus-organisation-speicherstrategien-und-datenschutz" title="Link to this heading">#</a></h2>
<p>Pia Voigt, Carolin Hundt</p>
<p>Published 2024-04-19</p>
<p>Licensed CC-BY-4.0</p>
<p>Workshop zum Thema „Datenmanagement im Fokus: Organisation, Speicherstrategien und Datenschutz“ auf der Data Week Leipzig
Der Umgang mit Daten ist im Alltag nicht immer leicht: Wie und wo speichert man Daten idealerweise? Welche Strategien helfen, den Überblick zu behalten und wie geht man mit personenbezogenen Daten um? Diese Fragen möchten wir gemeinsam mit Ihnen anhand individueller Datenprobleme besprechen und Ihnen Lösungen aufzeigen, wie Sie ihr Datenmanagement effizient gestalten können.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/11107798">https://zenodo.org/records/11107798</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11107798">https://doi.org/10.5281/zenodo.11107798</a></p>
</section>
<hr class="docutils" />
<section id="datenmanagementplane-erstellen-teil-1">
<h2>Datenmanagementpläne erstellen - Teil 1<a class="headerlink" href="#datenmanagementplane-erstellen-teil-1" title="Link to this heading">#</a></h2>
<p>Pia Voigt, Barbara Weiner</p>
<p>Published 2021-03-23</p>
<p>Licensed CC-BY-4.0</p>
<p>Was ist ein Datenmanagementplan? Welche Vorgaben sollte ich beachten? Wie erstelle ich einen solchen für mein Forschungsprojekt und welche nützlichen Tools kann ich hierfür verwenden?</p>
<p>Die Anforderungen der Forschungsförderer zum Datenmanagement steigen stetig. Damit verbunden ist häufig auch das Erstellen eines Datenmanagementplans. Dabei erwarten DFG, BMBF oder die EU jeweils unterschiedliche Angaben zur Erhebung, Speicherung und Veröffentlichung von projektbezogenen Forschungsdaten. Zudem bietet das Erstellen eines Datenmanagementplans viele Vorteile und hilft Ihnen nicht zuletzt, die Anforderungen der guten wissenschaftlichen Praxis strukturiert umzusetzen.</p>
<p>Was im ersten Moment unübersichtlich und überfordernd wirkt, soll in diesem Kurs anhand einer grundlegenden theoretischen Einführung im ersten und praxisorientierter Beispiele im zweiten Teil der Veranstaltung handhabbar gemacht werden. Sie lernen, was hinter den Anforderungen der Forschungsförderer steckt, welche Elemente ein Datenmanagementplan enthalten sollte und wie sie einen solchen mithilfe interaktiver Tools selbst erstellen können.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/4630788">https://zenodo.org/records/4630788</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4630788">https://doi.org/10.5281/zenodo.4630788</a></p>
</section>
<hr class="docutils" />
<section id="datenmanagementplane-erstellen-teil-2">
<h2>Datenmanagementpläne erstellen - Teil 2<a class="headerlink" href="#datenmanagementplane-erstellen-teil-2" title="Link to this heading">#</a></h2>
<p>Pia Voigt, Barbara Weiner</p>
<p>Published 2021-03-30</p>
<p>Licensed CC-BY-4.0</p>
<p>Was ist ein Datenmanagementplan? Welche Vorgaben sollte ich beachten? Wie erstelle ich einen solchen für mein Forschungsprojekt und welche nützlichen Tools kann ich hierfür verwenden?</p>
<p>Die Anforderungen der Forschungsförderer zum Datenmanagement steigen stetig. Damit verbunden ist häufig auch das Erstellen eines Datenmanagementplans. Dabei erwarten DFG, BMBF oder die EU jeweils unterschiedliche Angaben zur Erhebung, Speicherung und Veröffentlichung von projektbezogenen Forschungsdaten. Zudem bietet das Erstellen eines Datenmanagementplans viele Vorteile und hilft Ihnen nicht zuletzt, die Anforderungen der guten wissenschaftlichen Praxis strukturiert umzusetzen.</p>
<p>Was im ersten Moment unübersichtlich und überfordernd wirkt, soll in diesem Kurs anhand einer grundlegenden theoretischen Einführung im ersten und praxisorientierter Beispiele im zweiten Teil der Veranstaltung handhabbar gemacht werden. Sie lernen, was hinter den Anforderungen der Forschungsförderer steckt, welche Elemente ein Datenmanagementplan enthalten sollte und wie sie einen solchen mithilfe interaktiver Tools selbst erstellen können.</p>
<p>Version 2 enthält aktuelle Links und weiterführende Hinweise zu einzelnen Aspekten eines Datenmanagementplans.</p>
<p>Version 3 ist die überarbeitete und aktualisierte Version der ersten beiden und enthält u.a. Hinweise zur Lizenzierung und zu Nutzungsrechten an Forschungsdaten.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/4748534">https://zenodo.org/records/4748534</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4748534">https://doi.org/10.5281/zenodo.4748534</a></p>
</section>
<hr class="docutils" />
<section id="deconvolution-test-dataset">
<h2>Deconvolution Test Dataset<a class="headerlink" href="#deconvolution-test-dataset" title="Link to this heading">#</a></h2>
<p>Romain Guiet</p>
<p>Published 2021-07-14</p>
<p>Licensed CC-BY-4.0</p>
<p>This a test dataset, HeLa cells stained for action using Phalloidin-488 acquired on confocal Zeiss LSM710, which contains</p>
<ul class="simple">
<li><p>Ph488.czi (contains all raw metadata)</p></li>
<li><p>Raw_large.tif ( is the tif version of Ph488.czi, provided for conveninence as tif doesn’t need Bio-Formats to be open in Fiji )</p></li>
<li><p>Raw.tif , is a crop of the large image</p></li>
</ul>
<p>- PSFHuygens_confocal_Theopsf.tif , is a theoretical PSF generated with HuygensPro</p>
<p>- PSFgen_WF_WBpsf.tif  , is a theoretical PSF generated with PSF generator</p>
<ul class="simple">
<li><p>PSFgen_WFsquare_WBpsf.tif, is the result of the square operation on PSFgen_WF_WBpsf.tif , to approximate a confocal PSF</p></li>
</ul>
<p><a class="reference external" href="https://zenodo.org/records/5101351">https://zenodo.org/records/5101351</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5101351">https://doi.org/10.5281/zenodo.5101351</a></p>
</section>
<hr class="docutils" />
<section id="developing-semi-automatic-analysis-pipelines-and-technological-solutions-for-metadata-annotation-and-management-in-high-content-screening-hcs-bioimaging">
<h2>Developing (semi)automatic analysis pipelines and technological solutions for metadata annotation and management in high-content screening (HCS) bioimaging<a class="headerlink" href="#developing-semi-automatic-analysis-pipelines-and-technological-solutions-for-metadata-annotation-and-management-in-high-content-screening-hcs-bioimaging" title="Link to this heading">#</a></h2>
<p>Riccardo Massei, Stefan Scholz, Wibke Busch, Thomas Schnike, Hannes Bohring, Jan Bumberger</p>
<p>Licensed CC-BY-4.0</p>
<p>High-content screening (HCS) bioimaging automates the imaging and analysis of numerous biological samples, generating extensive metadata that is crucial for effective image management and interpretation. Efficiently handling this complex data is essential to implementing FAIR principles and realizing HCS’s full potential for scientific discoveries.</p>
<p>Tags: Bioimage Analysis</p>
<p>Content type: Poster</p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8434325">https://doi.org/10.5281/zenodo.8434325</a></p>
</section>
<hr class="docutils" />
<section id="developing-a-training-strategy">
<h2>Developing a Training Strategy<a class="headerlink" href="#developing-a-training-strategy" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-11-08</p>
<p>Licensed CC-BY-4.0</p>
<p>When training people in topics such as programming, bio-image analysis or data science, it makes sense to define a training strategy with a wider perspective than just trainees needs. This slide deck gives insights into aspects to consider when defining a training strategy. It considers funder’s interests, financial aspects, metrics / goals, steps towards sustainability and opportunities for outreach and for founding future collaborations.</p>
<p><a class="reference external" href="https://zenodo.org/records/14053758">https://zenodo.org/records/14053758</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14053758">https://doi.org/10.5281/zenodo.14053758</a></p>
</section>
<hr class="docutils" />
<section id="developing-open-source-software-for-bioimage-analysis-opportunities-and-challenges">
<h2>Developing open-source software for bioimage analysis: opportunities and challenges<a class="headerlink" href="#developing-open-source-software-for-bioimage-analysis-opportunities-and-challenges" title="Link to this heading">#</a></h2>
<p>Florian Levet, Anne E. Carpenter, Kevin W. Eliceiri, Anna Kreshuk, Peter Bankhead, Robert Haase</p>
<p>Licensed CC-BY-4.0</p>
<p>This article outlines common challenges and practices when developing open-source software for bio-image analysis.</p>
<p>Tags: Neubias</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://f1000research.com/articles/10-302">https://f1000research.com/articles/10-302</a></p>
</section>
<hr class="docutils" />
<section id="development-of-a-platform-for-advanced-optics-education-training-and-prototyping">
<h2>Development of a platform for advanced optics education, training and prototyping<a class="headerlink" href="#development-of-a-platform-for-advanced-optics-education-training-and-prototyping" title="Link to this heading">#</a></h2>
<p>Nadine Utz, Sabine Reither, Ruth Hans, Christian Feldhaus</p>
<p>Published 2023-10-05</p>
<p>Licensed CC-BY-4.0</p>
<p>In bio-medical research we often need to combine a broad range of expertise to run complex experiments and analyse and interpret their results. Also, it is desirable that all stakeholders of a project understand all parts of the experiment and analysis to draw and support the right conclusions. For imaging experiments this usually requires a basic understanding of the underlying physics. This has not necessarily been part of the professional training of all stakeholders, e.g. biologists or data scientists. Therefore an affordable platform for easily demonstrating and explaining imaging principles would be desirable.
Building up on a commercially available STEM Optics kit we developed extensions with widely available and affordable components to demonstrate advanced imaging techniques like e.g. confocal, lightsheet, OPT, spectral imaging. All models are quick and easy to build, yet demonstrate the important physical principles each imaging technique is based on.
Further use cases for this kit are training courses, demonstrations for imaging newbies when designing an experiment and outreach activities but also basic level prototyping.</p>
<p><a class="reference external" href="https://zenodo.org/records/10925217">https://zenodo.org/records/10925217</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10925217">https://doi.org/10.5281/zenodo.10925217</a></p>
</section>
<hr class="docutils" />
<section id="digital-phase-contrast-on-primary-dermal-human-fibroblasts-cells">
<h2>Digital Phase Contrast on Primary Dermal Human Fibroblasts cells<a class="headerlink" href="#digital-phase-contrast-on-primary-dermal-human-fibroblasts-cells" title="Link to this heading">#</a></h2>
<p>Laura Capolupo</p>
<p>Published 2022-02-09</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: Digital Phase Contrast on Primary Dermal Human Fibroblasts cells </p>
<p>Data type: Paired microscopy images (Digital Phase Contrast, square rooted) and corresponding labels/masks used for cellpose training (the corresponding Brightfield images are also present), organized as recommended by cellpose documentation.</p>
<p>Microscopy data type: Light microscopy (Digital Phase Contrast and Brighfield )</p>
<p>Manual annotations: Labels/masks obtained via manual segmentation. For each region, all cells were annotated manually. Uncertain objects (Dust, fused cells) were left unannotated, so that the cellpose model (10.5281/zenodo.6023317) may mimic the same user bias during prediction. This was particularly necessary due to the accumulation of floating debris in the center of the well.</p>
<p>Microscope: Perkin Elmer Operetta microscope with a 10x 0.35 NA objective</p>
<p>Cell type: Primary Dermal Human Fibroblasts cells</p>
<p>File format: .tif (16-bit for DPC and 16-bit for the masks)</p>
<p>Image size: 1024x1024 (Pixel size: 634 nm)</p>
<p>NOTE : This dataset was used to train cellpose model ( 10.5281/zenodo.6023317 )</p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/5996883">https://zenodo.org/records/5996883</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5996883">https://doi.org/10.5281/zenodo.5996883</a></p>
</section>
<hr class="docutils" />
<section id="edam-bioimaging-the-ontology-of-bioimage-informatics-operations-topics-data-and-formats">
<h2>EDAM-bioimaging - The ontology of bioimage informatics operations, topics, data, and formats<a class="headerlink" href="#edam-bioimaging-the-ontology-of-bioimage-informatics-operations-topics-data-and-formats" title="Link to this heading">#</a></h2>
<p>Matúš Kalaš et al.</p>
<p>Licensed CC-BY-4.0</p>
<p>EDAM-bioimaging is an extension of the EDAM ontology, dedicated to bioimage analysis, bioimage informatics, and bioimaging.</p>
<p>Tags: Ontology, Bioimage Analysis</p>
<p>Content type: Poster</p>
<p><a class="reference external" href="https://hal.science/hal-02267597/document">https://hal.science/hal-02267597/document</a></p>
</section>
<hr class="docutils" />
<section id="edam-bioimaging-the-ontology-of-bioimage-informatics-operations-topics-data-and-formats-update-2020">
<h2>EDAM-bioimaging: The ontology of bioimage informatics operations, topics, data, and formats (update 2020)<a class="headerlink" href="#edam-bioimaging-the-ontology-of-bioimage-informatics-operations-topics-data-and-formats-update-2020" title="Link to this heading">#</a></h2>
<p>Matúš Kalaš, Laure Plantard, Joakim Lindblad, Martin Jones, Nataša Sladoje, Moritz A Kirschmann, Anatole Chessel, Leandro Scholz, Fabianne Rössler, Laura Nicolás Sáenz, Estibaliz Gómez de Mariscal, John Bogovic, Alexandre Dufour, Xavier Heiligenstein, Dominic Waithe, Marie-Charlotte Domart, Matthia Karreman, Raf Van de Plas, Robert Haase, David Hörl, Lassi Paavolainen, Ivana Vrhovac Madunić, Dean Karaica, Arrate Muñoz-Barrutia, Paula Sampaio, Daniel Sage, Sebastian Munck, Ofra Golani, Josh Moore, Florian Levet, Jon Ison, Alban Gaignard, Hervé Ménager, Chong Zhang, Kota Miura, Julien Colombelli, Perrine Paul-Gilloteaux</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Metadata</p>
<p>Content type: Publication, Poster</p>
<p><a class="reference external" href="https://f1000research.com/posters/9-162">https://f1000research.com/posters/9-162</a></p>
</section>
<hr class="docutils" />
<section id="efficiently-starting-institutional-research-data-management">
<h2>Efficiently starting institutional research data management<a class="headerlink" href="#efficiently-starting-institutional-research-data-management" title="Link to this heading">#</a></h2>
<p>Katarzyna Biernacka, Katrin Cortez, Kerstin Helbig</p>
<p>Published 2019-10-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Researchers are increasingly often confronted with research data management (RDM) topics during their work. Higher education institutions therefore begin to offer services for RDM at some point to give support and advice. However, many groundbreaking decisions have to be made at the very beginning of RDM services. Priorities must be set and policies formulated. Likewise, the staff must first be qualified in order to provide advice and adequately deal with the manifold problems awaiting.
The FDMentor project has therefore bundled the expertise of five German universities with different experiences and levels of RDM knowledge to jointly develop strategies, roadmaps, guidelines, and open access training material. Humboldt-Universität zu Berlin, Freie Universität Berlin, Technische Universität Berlin, University of Potsdam, and European University Viadrina Frankfurt (Oder) have worked together on common solutions that are easy to adapt. With funding of the German Federal Ministry of Education and Research, the collaborative project addressed four problem areas: strategy development, legal issues, policy development, and competence enhancement. The aim of the project outcomes is to provide other higher education institutions with the best possible support for the efficient introduction of research data management. Therefore, all project results are freely accessible under the CC-BY 4.0 international license. The early involvement of the community in the form of workshops and the collection of feedback has proven its worth: the FDMentor strategies, roadmaps, guidelines, and training materials are applied and adapted beyond the partner universities.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Document</p>
<p><a class="reference external" href="https://zenodo.org/record/3490058">https://zenodo.org/record/3490058</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.3490058">https://doi.org/10.5281/zenodo.3490058</a></p>
</section>
<hr class="docutils" />
<section id="einblicke-ins-forschungsdatenmanagement-darf-ich-das-veroffentlichen-rechtsfragen-im-umgang-mit-forschungsdaten">
<h2>Einblicke ins Forschungsdatenmanagement - Darf ich das veröffentlichen? Rechtsfragen im Umgang mit Forschungsdaten<a class="headerlink" href="#einblicke-ins-forschungsdatenmanagement-darf-ich-das-veroffentlichen-rechtsfragen-im-umgang-mit-forschungsdaten" title="Link to this heading">#</a></h2>
<p>Stephan Wünsche, Pia Voigt</p>
<p>Published 2021-05-11</p>
<p>Licensed CC-BY-4.0</p>
<p>Diese Präsentation wurde im Zuge der digitalen Veranstaltungsreihe “Einblicke ins Forschungsdatenmanagement” erstellt. Diese findet seit dem SS 2020 an der Universität Leipzig für alle Interessierten zu verschiedenen Themen des Forschungsdatenmanagements statt.</p>
<p>Dieser Teil der Reihe dreht sich um Rechtsfragen im Umgang mit Forschungsdaten und deren Bedeutung für die wissenschaftliche Praxis. Sie finden in der vorliegenden Präsentation einen Überblick über relevante Rechtsbereiche sowie Erläuterungen zum Datenschutz, Urheberrecht und den Grundsätzen der guten wissenschaftlichen Praxis mit Fokus auf deren Bedeutung im Forschungsdatenmanagement.</p>
<p>Tags: Research Data Management, Data Protection</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/4748510">https://zenodo.org/records/4748510</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4748510">https://doi.org/10.5281/zenodo.4748510</a></p>
</section>
<hr class="docutils" />
<section id="erstellung-und-realisierung-einer-institutionellen-forschungsdaten-policy">
<h2>Erstellung und Realisierung einer institutionellen Forschungsdaten-Policy<a class="headerlink" href="#erstellung-und-realisierung-einer-institutionellen-forschungsdaten-policy" title="Link to this heading">#</a></h2>
<p>Uli Hahn, Kerstin Helbig, Gerald Jagusch, Jessica Rex</p>
<p>Published  2018-10-22</p>
<p>Licensed CC-BY-4.0</p>
<p>Die vorliegende Empfehlung sowie die zugehörigen Erfahrungsberichte geben einen Überblick über die verschiedenen Möglichkeiten der Gestaltung einer Forschungsdatenmanagement Policy sowie Wege zu deren Erstellung.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://bausteine-fdm.de/article/view/7945">https://bausteine-fdm.de/article/view/7945</a></p>
<p><a class="reference external" href="https://doi.org/10.17192/bfdm.2018.1.7945">https://doi.org/10.17192/bfdm.2018.1.7945</a></p>
</section>
<hr class="docutils" />
<section id="euro-bioimaging-scientific-ambassadors-program">
<h2>Euro-BioImaging  Scientific Ambassadors Program<a class="headerlink" href="#euro-bioimaging-scientific-ambassadors-program" title="Link to this heading">#</a></h2>
<p>Beatriz Serrano-Solano</p>
<p>Published 2023-07-25</p>
<p>Licensed CC-BY-4.0</p>
<p>Graduation presentation for the 7th cohort of the Open Seeds mentoring &amp; training program for Open Science ambassadors. The project presented is called “Euro-BioImaging  Scientific Ambassadors Program”.</p>
<p><a class="reference external" href="https://zenodo.org/records/8182154">https://zenodo.org/records/8182154</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8182154">https://doi.org/10.5281/zenodo.8182154</a></p>
</section>
<hr class="docutils" />
<section id="euro-bioimaging-eric-annual-report-2022">
<h2>Euro-BioImaging ERIC Annual Report 2022<a class="headerlink" href="#euro-bioimaging-eric-annual-report-2022" title="Link to this heading">#</a></h2>
<p>Euro-BioImaging ERIC</p>
<p>Published 2023-07-14</p>
<p>Licensed CC-BY-4.0</p>
<p>Euro-BioImaging ERIC is the European landmark research infrastructure for biological and biomedical imaging as recognized by the European Strategy Forum on Research Infrastructures (ESFRI). Euro-BioImaging is the gateway to world-class imaging facilities across Europe. This document is the Euro-BioImaging Annual Report for the year 2022.</p>
<p><a class="reference external" href="https://zenodo.org/records/8146412">https://zenodo.org/records/8146412</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8146412">https://doi.org/10.5281/zenodo.8146412</a></p>
</section>
<hr class="docutils" />
<section id="euro-bioimaging-s-guide-to-fair-bioimage-data-practical-tasks">
<h2>Euro-BioImaging’s Guide to FAIR BioImage Data - Practical Tasks<a class="headerlink" href="#euro-bioimaging-s-guide-to-fair-bioimage-data-practical-tasks" title="Link to this heading">#</a></h2>
<p>Isabel Kemmer, Euro-BioImaging ERIC</p>
<p>Published 2024-06-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Hands-on exercises on FAIR Bioimage Data from the interactive online workshop “Euro-BioImaging’s Guide to FAIR BioImage Data 2024” (<a class="reference external" href="https://www.eurobioimaging.eu/news/a-guide-to-fair-bioimage-data-2024/">https://www.eurobioimaging.eu/news/a-guide-to-fair-bioimage-data-2024/</a>).  Types of tasks included: FAIR characteristics of a real world dataset Data Management Plan (DMP) Journal Policies on FAIR data sharing Ontology search Metadata according to REMBI scheme (Image from: Sarkans, U., Chiu, W., Collinson, L. et al. REMBI: Recommended Metadata for Biological Images—enabling reuse of microscopy data in biology. Nat Methods 18, 1418–1422 (2021). <a class="reference external" href="https://doi.org/10.1038/s41592-021-01166-8">https://doi.org/10.1038/s41592-021-01166-8</a>) Matching datasets to bioimage repositories Browsing bioimage repositories</p>
<p>Tags: Bioimage Analysis, FAIR-Principles, Research Data Management</p>
<p>Content type: Slides, Tutorial</p>
<p><a class="reference external" href="https://zenodo.org/records/11474407">https://zenodo.org/records/11474407</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11474407">https://doi.org/10.5281/zenodo.11474407</a></p>
</section>
<hr class="docutils" />
<section id="euro-bioimaging-s-template-for-research-data-management-plans">
<h2>Euro-BioImaging’s Template for Research Data Management Plans<a class="headerlink" href="#euro-bioimaging-s-template-for-research-data-management-plans" title="Link to this heading">#</a></h2>
<p>Isabel Kemmer, Euro-BioImaging ERIC</p>
<p>Published 2024-06-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Euro-BioImaging has developed a Data Management Plan (DMP) template with questions tailored to bioimaging research projects. Outlining data management practices in this way ensures traceability of project data, allowing for a continuous and unambiguous flow of information throughout the research project. This template can be used to satisfy the requirement to submit a DMP to certain funders. Regardless of the funder, Euro-BioImaging users are encouraged to provide a DMP and can use this template accordingly. 
This DMP template is available as a fillable PDF with further instructions and sample responses available by hovering over the fillable fields. </p>
<p>Tags: Bioimage Analysis, FAIR-Principles, Research Data Management</p>
<p>Content type: Collection, Tutorial</p>
<p><a class="reference external" href="https://zenodo.org/records/11473803">https://zenodo.org/records/11473803</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11473803">https://doi.org/10.5281/zenodo.11473803</a></p>
</section>
<hr class="docutils" />
<section id="euro-bioimaging-batchconvert-v0-0-4">
<h2>Euro-BioImaging/BatchConvert: v0.0.4<a class="headerlink" href="#euro-bioimaging-batchconvert-v0-0-4" title="Link to this heading">#</a></h2>
<p>bugraoezdemir</p>
<p>Published 2024-02-19</p>
<p>Licensed CC-BY-4.0</p>
<p>Changes implemented since v0.0.3</p>
<p>Support provided for file paths with spaces.
Support provided for globbing filenames from s3 for one-to-one conversion (parse_s3_filenames.py modified).
Support provided for single file import from s3 (parse_s3_filenames.py modified).
run_conversion.py replaces batchconvert_cli.sh and construct_cli.py, uniting them.
Error handling updated for each process</p>
<p><a class="reference external" href="https://zenodo.org/records/10679318">https://zenodo.org/records/10679318</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10679318">https://doi.org/10.5281/zenodo.10679318</a></p>
</section>
<hr class="docutils" />
<section id="evident-oir-sample-files-tiles-stitched-image-fv-4000">
<h2>Evident OIR sample files tiles + stitched image - FV 4000<a class="headerlink" href="#evident-oir-sample-files-tiles-stitched-image-fv-4000" title="Link to this heading">#</a></h2>
<p>Nicolas Chiaruttini</p>
<p>Published 2024-09-04</p>
<p>Licensed CC-BY-4.0</p>
<p>The files contained in this repository are confocal images taken with the Evident FV 4000 of a sample containing DAPI and mCherry stains, excited with a 405 nm laser and a 561 nm laser</p>
<p>individual tiles are named <code class="docutils literal notranslate"><span class="pre">tiling-sample-brain-section_A01_G001_{i}.oir</span></code>
The stiched image is named <code class="docutils literal notranslate"><span class="pre">Stitch_A01_G001</span></code> and contains an extra file <code class="docutils literal notranslate"><span class="pre">Stitch_A01_G001_00001</span></code>
Some metadata like the tiles positions are stored in the extra files (omp2info)</p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/13680725">https://zenodo.org/records/13680725</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13680725">https://doi.org/10.5281/zenodo.13680725</a></p>
</section>
<hr class="docutils" />
<section id="evident-oir-sample-files-with-lambda-scan-fv-4000">
<h2>Evident OIR sample files with lambda scan - FV 4000<a class="headerlink" href="#evident-oir-sample-files-with-lambda-scan-fv-4000" title="Link to this heading">#</a></h2>
<p>Nicolas Chiaruttini</p>
<p>Published 2024-07-18</p>
<p>Licensed CC-BY-4.0</p>
<p>The files contained in this repository are confocal images taken with the Evident FV 4000 of a sample containing DAPI and mCherry stains, excited with the 405 nm laser and images for different emission windows (lambda scan).
They are public sample files which goal is to help test edge cases of the bio-formats library (<a class="reference external" href="https://www.openmicroscopy.org/bio-formats/">https://www.openmicroscopy.org/bio-formats/</a>), in particular for the proper handling of lambda scans.</p>
<p>DAPI_mCherry_22Lambda-420-630-w10nm-s10nm.oir : 22 planes, each plane is an emission window, starting from 420 nm up to 630 nm by steps of 10 nm
DAPI_mCherry_4T_5Lambda-420-630-w10nm-s50nm.oir : 20 planes, 5 lambdas from 420 to 630 nm by steps of 50 nm, 4 timepoints
DAPI_mCherry_4Z_5Lambda-420-630-w10nm-s50nm.oir : 20 planes, 5 lambdas from 420 to 630 nm by steps of 50 nm, 4 slices
DAPI-mCherry_3T_4Z_5Lambda-420-630-w10nm-s50nm.oir : 60 planes, 5 lambdas from 420 to 630 nm by steps of 50 nm, 4 slices, 3 timepoints</p>
<p><a class="reference external" href="https://zenodo.org/records/12773657">https://zenodo.org/records/12773657</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12773657">https://doi.org/10.5281/zenodo.12773657</a></p>
</section>
<hr class="docutils" />
<section id="example-imaris-ims-datasets">
<h2>Example Imaris ims datasets.<a class="headerlink" href="#example-imaris-ims-datasets" title="Link to this heading">#</a></h2>
<p>Marco Stucchi</p>
<p>Published 2024-11-28</p>
<p>Licensed CC-BY-4.0</p>
<p>The files contained in this repository are example Imaris ims images.
 
Initially related to <a class="github reference external" href="https://github.com/ome/bioformats/pull/4249">ome/bioformats#4249</a></p>
<p><a class="reference external" href="https://zenodo.org/records/14235726">https://zenodo.org/records/14235726</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14235726">https://doi.org/10.5281/zenodo.14235726</a></p>
</section>
<hr class="docutils" />
<section id="example-microscopy-metadata-json-files-produced-using-micro-meta-app-to-document-example-microscopy-experiments-performed-at-individual-core-facilities">
<h2>Example Microscopy Metadata JSON files produced using Micro-Meta App to document example microscopy experiments performed at individual core facilities<a class="headerlink" href="#example-microscopy-metadata-json-files-produced-using-micro-meta-app-to-document-example-microscopy-experiments-performed-at-individual-core-facilities" title="Link to this heading">#</a></h2>
<p>Alessandro Rigano, Ulrike Boehm, Claire M. Brown, Joel Ryan, James J. Chambers, Robert A. Coleman, Orestis Faklaris, Thomas Guilbert, Michelle S. Itano, Judith Lacoste, Alex Laude, Marco Marcello, Paula Montero-Llopis, Glyn Nelson, Roland Nitschke, Jaime A. Pimentel, Stefanie Weidtkamp-Peters, Caterina Strambio-De-Castillia</p>
<p>Published 2022-01-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Example Microscopy Metadata (Microscope.JSON and Settings.JSON) files produced using Micro-Meta App to document the Hardware Specifications of example Microscopes and the Image Acquisition Settings utilized to acquire example images as listed in the table below.</p>
<p>For each facility, the dataset contains two JSON files:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Microscope.JSON file (e.g., 01_marcello_uliverpool_cci_zeiss_axioobserz1_lsm710.json)
Settings.JSON file (indicated with the name of the image and with the _AS suffix)
</pre></div>
</div>
<p>Micro-Meta App was developed as part of a global community initiative including the 4D Nucleome (4DN) Imaging Working Group, BioImaging North America (BINA) Quality Control and Data Management Working Group, and QUAlity and REProducibility for Instrument and Images in Light Microscopy (QUAREP-LiMi), to extend the Open Microscopy Environment (OME) data model.</p>
<p>The works of this global community effort resulted in multiple publications featured on a recent Nature Methods FOCUS ISSUE dedicated to Reporting and reproducibility in microscopy.</p>
<p>Learn More! For a thorough description of Micro-Meta App consult our recent Nature Methods and <a class="reference external" href="http://BioRxiv.org">BioRxiv.org</a> publications!</p>
<p> </p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>		Nr.
		Manufacturer
		Model
		Tier
		&amp;Epsilon;xperiment Type
		Facility Name
		Department and Institution
		URL
		References
	
	
		1
		Carl Zeiss Microscopy
		Axio Observer Z1 (with LSM 710 scan head)
		1
		3D visualization of superhydrophobic polymer-nanoparticles
		Centre for Cell Imaging (CCI)
		University of Liverpool
		https://cci.liv.ac.uk/equipment_710.html
		Upton et al., 2020
	
	
		2
		Carl Zeiss Microscopy
		Axio Observer (Axiovert 200M)
		2
		&amp;Mu;easurement of illumination stability on Chinese Hamster Ovary cells expressing Paxillin-EGFP
		Advanced BioImaging Facility (ABIF).
		McGill University
		https://www.mcgill.ca/abif/equipment/axiovert-1
		Kiepas et al., 2020
	
	
		3
		Carl Zeiss Microscopy
		Axio Observer Z1 (with Spinning Disk)
		2
		Immunofluorescence imaging of cryosection of Mouse kidney
		Imagerie Cellulaire; Quality Control managed by Miacellavie (https://miacellavie.com/)
		Centre de recherche du Centre Hospitalier Universit&amp;eacute; de Montr&amp;eacute;al (CR CHUM), University of Montreal
		https://www.chumontreal.qc.ca/crchum/plateformes-et-services&amp;nbsp; (the web site is for all core facilities, not specifically for the core facility hosting this microscope)
		Pilliod et al., 2020
	
	
		4
		Carl Zeiss Microscopy
		Axio Imager Z2 (with Apotome)
		2
		Immunofluorescence imaging of mitotic division in Hela cells using&amp;nbsp;&amp;nbsp;
		Bioimaging Unit
		Newcastle University
		https://www.ncl.ac.uk/bioimaging/
		Watson et al., 2020
	
	
		5
		Carl Zeiss Microscopy
		Axio Observer Z1
		2
		Fluorescence microscopy of human skin fibroblasts from Glycogen Storage Disease patients.
		Life Imaging Center (LIC)
		Centre for Integrative Signalling Analysis (CISA), University of Freiburg
		https://miap.eu/equipments/sd-i-abl/
		Hannibal et al., 2020
	
	
		6
		Leica Microsystems
		DMI6000B
		2
		3D immunofluorescence imaging&amp;nbsp; rhinovirus infected macrophages&amp;nbsp;
		IMAG&amp;#39;IC Confocal Microscopy Facility
		Institut Cochin, CNRS, INSERM, Universit&amp;eacute; de Paris
		https://www.institutcochin.fr/core_facilities/confocal-microscopy/cochin-imaging-photonic-microscopy/organigram_team/10054/view
		Jubrail et al., 2020
	
	
		7
		Leica Microsystems
		DM5500B
		2
		Immunofluorescence analysis of the colocalization of PML bodies with DNA double-strand breaks
		Bioimaging Unit
		Edwardson Building on the Campus for Ageing and Vitality, Newcastle University
		https://www.ncl.ac.uk/bioimaging/equipment/leica-dm5500/#overview
		da Silva et al., 2019; Nelson et al., 2012
		&amp;nbsp;&amp;nbsp;
	
	
		8
		Leica Microsystems
		DMI8-CS (with TCS SP8 STED 3X)
		2
		Live-cell imaging of N. benthamiana leaves cells-derived protoplasts
		Center for Advanced Imaging (CAi)
		School of Mathematics/Natural Sciences, Heinrich-Heine-Universit&amp;auml;t D&amp;uuml;sseldorf
		https://www.cai.hhu.de/en/equipment/super-resolution-microscopy/leica-tcs-sp8-sted-3x
		Singer et al., 2017; H&amp;auml;nsch et al., 2020
	
	
		9
		Nikon Instruments
		Eclipse Ti
		2
		Immunofluorescence analysis of the cytoskeleton structure in COS cells
		Advanced Imaging Center (AIC)
		Janelia Research Campus, Howard Hughes Medical Institute
		https://www.janelia.org/support-team/light-microscopy/equipment
		Abdelfattah et al., 2019; Qian et al., 2019; Grimm et al., 2020
	
	
		10
		Nikon Instruments
		Eclipse Ti-E (HCA)
		2
		&amp;Tau;ime-lapse analysis of the bursting behavior of amine-functionalized vesicular assemblies
		Light Microscopy Facility (IALS-LIF)
		Institute for Applied Life Sciences, University of Massachusetts at Amherst
		https://www.umass.edu/ials/light-microscopy
		Fernandez et al., 2020
	
	
		11
		Nikon Instruments/Coleman laboratory (customized)
		TIRF HILO Epifluorescence light Microscope (THEM)/ Eclipse Ti
		2
		Single-particle tracking of Halo-tagged PCNA in Lox cells
		Coleman laboratory
		Anatomy and Structural Biology Department, The Albert Einstein College of Medicine
		https://einsteinmed.org/faculty/12252/robert-coleman/
		Drosopoulos et al., 2020
	
	
		12
		Nikon Instruments
		Eclipse Ti (with Andor Dragon Fly Spinning Disk)
		2
		Investigation of the 3D structure of cerebral organoids
		Montpellier Resources Imagerie
		Centre de Recherche de Biologie cellulaire de Montpellier (MRI-CRBM), CNRS, Univerity of Montpellier
		https://www.mri.cnrs.fr/en/optical-imaging/our-facilities/mri-crbm.html
		Ayala-Nunez et al., 2019
	
	
		13
		Nikon Instruments
		Eclipse Ti2
		2
		&amp;Iota;mmunofluorescence imaging of cryosections of mouse hearth myocardium&amp;nbsp;
		Neuroscience Center Microscopy Core
		Neuroscience Center, University of North Carolina
		https://www.med.unc.edu/neuroscience/core-facilities/neuro-microscopy/
		Aghajanian et al., 2021
	
	
		14
		Nikon Instruments
		Eclipse Ti2
		2
		Live-cell imaging of bacterial cells expressing GFP-PopZ
		Microscopy Resources on the North Quad (MicRoN)
		Harvard Medical School&amp;nbsp;
		https://micron.hms.harvard.edu/
		Lim and Bernhardt 2019; Lim et al., 2019
	
	
		15
		Olympus/Biomedical Imaging Group (customized)
		TIRF Epifluorescence Structured light Microscope (TESM)/IX71
		3
		3D distribution of HIV-1 in the nucleus of human cells
		Biomedical Imaging Group
		Program in Molecular Medicine, University of Massachusetts Medical School
		https://trello.com/b/BQ8zCcQC/tirf-epi-fluorescence-structured-light-microscope
		Navaroli et al., 2012
	
	
		16
		Olympus/Computer Vision Laboratory (customized)
		3D BrightField Scanner/IX71
		3
		Transmitted light brightfield visualization of swimming spermatocytes
		Laboratorio Nacional de Microscopia Avanzada (LNMA) and Computer Vision Laboratory of the Institute of Biotechnology
		Universidad Nacional Autonoma de Mexico (UNAM)
		https://lnma.unam.mx/wp/
		Pimentel et al., 2012; Silva-Villalobos et al., 2014
</pre></div>
</div>
<p>Getting started</p>
<p>Use these videos to get started with using Micro-Meta App after installation into OMERO and downloading the example data files:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Video 1
Video 2
</pre></div>
</div>
<p>More information</p>
<p>For full information on how to use Micro-Meta App please utilize the following resources:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Micro-Meta App website
Full documentation
Installation instructions
Step-by-Step Instructions
Tutorial Videos
</pre></div>
</div>
<p>Background</p>
<p>If you want to learn more about the importance of metadata and quality control to ensure full reproducibility, quality and scientific value in light microscopy, please take a look at our recent publications describing the development of community-driven light 4DN-BINA-OME Microscopy Metadata specifications Nature Methods and <a class="reference external" href="http://BioRxiv.org">BioRxiv.org</a> and our overview manuscript entitled A perspective on Microscopy Metadata: data provenance and quality control.</p>
<p> </p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/5847477">https://zenodo.org/records/5847477</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5847477">https://doi.org/10.5281/zenodo.5847477</a></p>
</section>
<hr class="docutils" />
<section id="example-operetta-dataset">
<h2>Example Operetta Dataset<a class="headerlink" href="#example-operetta-dataset" title="Link to this heading">#</a></h2>
<p>Nicolas Chiaruttini</p>
<p>Published 2023-07-17</p>
<p>Licensed CC-BY-4.0</p>
<p>This is a microscopy image dataset generated by the Perkin Elmer Operetta HCS microscope by of the user of the PTBIOP EPFL facility.
As of the 17th of July 2023, opening this file in ImageJ/Fiji using the BioFormats 6.14 library, this dataset generates a Null Pointer Exception.</p>
<p>A post on <a class="reference external" href="http://forum.image.sc">forum.image.sc</a> is linked to this issue:</p>
<p><a class="reference external" href="https://forum.image.sc/t/null-pointer-exception-in-perkin-elmer-operetta-dataset-with-bio-formats-6-14/83784">https://forum.image.sc/t/null-pointer-exception-in-perkin-elmer-operetta-dataset-with-bio-formats-6-14/83784</a></p>
<p> </p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/8153907">https://zenodo.org/records/8153907</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8153907">https://doi.org/10.5281/zenodo.8153907</a></p>
</section>
<hr class="docutils" />
<section id="excel-template-for-adding-key-value-pairs-to-images">
<h2>Excel template for adding Key-Value Pairs to images<a class="headerlink" href="#excel-template-for-adding-key-value-pairs-to-images" title="Link to this heading">#</a></h2>
<p>Thomas Zobel, Jens Wendt</p>
<p>Published 2024-10-30</p>
<p>Licensed CC-BY-4.0</p>
<p>This Excel Workbook contains some simple Macros to help with the generation of a .csv in the necessary format for Key-Value pair annotations of images in OMERO.
The format is tailored for the <a class="reference external" href="http://OMERO.web">OMERO.web</a> script “KeyVal_from_csv.py”  (from the version &lt;=5.8.3 of the core omero-scripts).
Attached is also a video of Thomas Zobel, the head of the imaging core facility Uni Münster, showcasing the use of the Excel workbook.The video uses a slightly older version of the workbook and OMERO, but the core functionality remains unchanged.
Please keep in mind, that the <a class="reference external" href="http://OMERO.web">OMERO.web</a> script(s) to handle Key-Value Pairs from/to .csv files will undergo a major change very soon.This might break the compatibility with the format used now for the generated .csv from the workbook.</p>
<p><a class="reference external" href="https://zenodo.org/records/14014252">https://zenodo.org/records/14014252</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14014252">https://doi.org/10.5281/zenodo.14014252</a></p>
</section>
<hr class="docutils" />
<section id="fair-bioimage-data">
<h2>FAIR BioImage Data<a class="headerlink" href="#fair-bioimage-data" title="Link to this heading">#</a></h2>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Research Data Management, Fair, Bioimage Analysis</p>
<p>Content type: Collection, Video</p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=8zd4KTy-oYI&amp;amp;list=PLW-oxncaXRqU4XqduJzwFHvWLF06PvdVm">https://www.youtube.com/watch?v=8zd4KTy-oYI&amp;list=PLW-oxncaXRqU4XqduJzwFHvWLF06PvdVm</a></p>
</section>
<hr class="docutils" />
<section id="fair-high-content-screening-in-bioimaging">
<h2>FAIR High Content Screening in Bioimaging<a class="headerlink" href="#fair-high-content-screening-in-bioimaging" title="Link to this heading">#</a></h2>
<p>Rohola Hosseini, Matthijs Vlasveld, Joost Willemse, Bob van de Water, Sylvia E. Le Dévédec, Katherine J. Wolstencroft</p>
<p>Published 2023-07-17</p>
<p>Licensed CC-BY-4.0</p>
<p>The authors show the utility of Minimum Information for High Content Screening Microscopy Experiments (MIHCSME) for High Content Screening (HCS) data using multiple examples from the Leiden FAIR Cell Observatory, a Euro-Bioimaging flagship node for high content screening and the pilot node for implementing FAIR bioimaging data throughout the Netherlands Bioimaging network.</p>
<p>Tags: FAIR-Principles, Metadata, Research Data Management</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.nature.com/articles/s41597-023-02367-w">https://www.nature.com/articles/s41597-023-02367-w</a></p>
</section>
<hr class="docutils" />
<section id="fair-priciples">
<h2>FAIR Priciples<a class="headerlink" href="#fair-priciples" title="Link to this heading">#</a></h2>
<p>Licensed CC-BY-4.0</p>
<p>In 2016, the ‘FAIR Guiding Principles for scientific data management and stewardship’ were published in Scientific Data. The authors intended to provide guidelines to improve the Findability, Accessibility, Interoperability, and Reuse of digital assets.</p>
<p>Tags: FAIR-Principles, Data Stewardship, Research Data Management</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://www.go-fair.org/fair-principles/">https://www.go-fair.org/fair-principles/</a></p>
</section>
<hr class="docutils" />
<section id="fairy-deep-learning-for-bioimage-analysis">
<h2>FAIRy deep-learning for bioImage analysis<a class="headerlink" href="#fairy-deep-learning-for-bioimage-analysis" title="Link to this heading">#</a></h2>
<p>Estibaliz Gómez de Mariscal</p>
<p>Licensed CC-BY-4.0</p>
<p>Introduction to FAIR deep learning. Furthermore, tools to deploy trained DL models (deepImageJ), easily train and evaluate them (ZeroCostDL4Mic and DeepBacs) ensure reproducibility (DL4MicEverywhere), and share this technology in an open-source and reproducible manner (BioImage Model Zoo) are introduced.</p>
<p>Tags: Artificial Intelligence, FAIR-Principles, Bioimage Analysis</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://f1000research.com/slides/13-147">https://f1000research.com/slides/13-147</a></p>
</section>
<hr class="docutils" />
<section id="finding-and-using-publicly-available-data">
<h2>Finding and using publicly available data<a class="headerlink" href="#finding-and-using-publicly-available-data" title="Link to this heading">#</a></h2>
<p>Anna Swan</p>
<p>Published 2024-01-01</p>
<p>Licensed CC-BY-4.0</p>
<p>Sharing knowledge and data in the life sciences allows us to learn from each other and built on what others have discovered. This collection of online courses brings together a variety of training, covering topics such as biocuration, open data, restricted access data and finding publicly available data, to help you discover and make the most of publicly available data in the life sciences.</p>
<p>Tags: Open Science, Teaching, Sharing</p>
<p>Content type: Collection, Tutorial, Video</p>
<p><a class="reference external" href="https://www.ebi.ac.uk/training/online/courses/finding-using-public-data/">https://www.ebi.ac.uk/training/online/courses/finding-using-public-data/</a></p>
</section>
<hr class="docutils" />
<section id="forschungsdaten-org">
<h2><a class="reference external" href="http://Forschungsdaten.org">Forschungsdaten.org</a><a class="headerlink" href="#forschungsdaten-org" title="Link to this heading">#</a></h2>
<p>Licensed CC-BY-4.0</p>
<p>Research Data Management Wiki in German</p>
<p>Tags: Research Data Management</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://www.forschungsdaten.org/">https://www.forschungsdaten.org/</a></p>
</section>
<hr class="docutils" />
<section id="forschungsdatenmanagement-zukunftsfest-gestalten-impulse-fur-die-strukturevaluation-der-nationalen-forschungsdateninfrastruktur-nfdi">
<h2>Forschungsdatenmanagement zukunftsfest gestalten – Impulse für die   Strukturevaluation der Nationalen Forschungsdateninfrastruktur (NFDI)<a class="headerlink" href="#forschungsdatenmanagement-zukunftsfest-gestalten-impulse-fur-die-strukturevaluation-der-nationalen-forschungsdateninfrastruktur-nfdi" title="Link to this heading">#</a></h2>
<p>Steuerungsgremium Allianz-Schwerpunkt, Alexander von Humboldt Foundation, Deutsche Forschungsgemeinschaft, Fraunhofer Society, German Rectors’ Conference, Leibniz Association, German National Academy of Sciences Leopoldina, German Academic Exchange Service, Helmholtz Association of German Research Centres, Max Planck Society</p>
<p>Published 2024-11-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Arbeitspapier des Steuerungsgremiums des Allianz-Schwerpunkts “Digitalität in der Wissenschaft”</p>
<p><a class="reference external" href="https://zenodo.org/records/14032908">https://zenodo.org/records/14032908</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14032908">https://doi.org/10.5281/zenodo.14032908</a></p>
</section>
<hr class="docutils" />
<section id="from-cells-to-pixels-bridging-biologists-and-image-analysts-through-a-common-language">
<h2>From Cells to Pixels: Bridging Biologists and  Image Analysts Through a Common Language<a class="headerlink" href="#from-cells-to-pixels-bridging-biologists-and-image-analysts-through-a-common-language" title="Link to this heading">#</a></h2>
<p>Elnaz Fazeli, Haase Robert, Doube Michael, Miura Kota, Legland David</p>
<p>Published 2024-08-16</p>
<p>Licensed CC-BY-4.0</p>
<p>Bioimaging has transformed our understanding of biological processes, yet extracting meaningful information from complex datasets remains a challenge, particularly for early career scientists. This paper proposes a simplified, systematic approach to bioimage analysis, focusing on categorizing commonly observed structures and shapes, and providing relevant analysis methods. Our approach includes illustrative examples and a visual flowchart, enabling researchers to define analysis objectives clearly. By understanding the diversity of bioimage structures and aligning them with appropriate analysis approaches, the framework empowers researchers to navigate bioimage datasets more efficiently. It also aims to foster a common language between researchers and analysts, thereby enhancing mutual understanding and facilitating effective communication.</p>
<p><a class="reference external" href="https://zenodo.org/records/13331351">https://zenodo.org/records/13331351</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13331351">https://doi.org/10.5281/zenodo.13331351</a></p>
</section>
<hr class="docutils" />
<section id="from-paper-to-pixels-navigation-through-your-research-data-presentations-of-speakers">
<h2>From Paper to Pixels: Navigation through your Research Data - presentations of speakers<a class="headerlink" href="#from-paper-to-pixels-navigation-through-your-research-data-presentations-of-speakers" title="Link to this heading">#</a></h2>
<p>Marcelo Zoccoler, Simon Bekemeier, Tom Boissonnet, Simon Parker, Luca Bertinetti, Marc Gentzel, Riccardo Massei, Cornelia Wetzker</p>
<p>Published 2024-06-10</p>
<p>Licensed CC-BY-4.0</p>
<p>The workshop introduced key topics of research data management (RDM) and the implementation thereof on a life science campus. Internal and external experts of RDM including scientists that apply chosen software tools presented the basic concepts and their implementation to a broad audience. 
Talks covered general aspects of data handling and sorting, naming conventions, data storage repositories and archives, licensing of material, data and code management using git, data protection particularly regarding patient data and in genome sequencing and more. Two data management concepts and exemplary tools were highlighted in particular, being electronic lab notebooks with eLabFTW and the bio-image management software OMERO. Those were chosen because of three aspects: the large benefit of these management tools for a life science campus, their free availability as open source tools with the option of contribution of required functionalities and first existing use cases on campus already supported by CMCB/PoL IT.
Two talks by Robert Haase (<a class="reference external" href="http://ScaDS.AI/">ScaDS.AI/</a> Uni Leipzig) and Robert Müller (Kontaktstelle Forschungsdaten, TU Dresden with contributions from Denise Dörfel) that opened the symposium were shared independently:
<a class="reference external" href="https://zenodo.org/records/11382341">https://zenodo.org/records/11382341</a>
<a class="reference external" href="https://zenodo.org/records/11261115">https://zenodo.org/records/11261115</a>
The workshop organization was funded by the CMCB/PoL Networking Grant and supported by the consortium NFDI4BIOIMAGE (funded by DFG grant number NFDI 46/1, project number 501864659).</p>
<p>Tags: Research Data Management</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/11548617">https://zenodo.org/records/11548617</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11548617">https://doi.org/10.5281/zenodo.11548617</a></p>
</section>
<hr class="docutils" />
<section id="galaxy-training">
<h2>Galaxy Training<a class="headerlink" href="#galaxy-training" title="Link to this heading">#</a></h2>
<p>Published None</p>
<p>Licensed CC-BY-4.0</p>
<p>Collection of tutorials developed and maintained by the worldwide Galaxy community.</p>
<p>Tags: Bioimage Analysis, Data Analysis</p>
<p>Content type: Collection, Tutorial</p>
<p><a class="reference external" href="https://training.galaxyproject.org/">https://training.galaxyproject.org/</a></p>
</section>
<hr class="docutils" />
<section id="generative-artificial-intelligence-for-bio-image-analysis">
<h2>Generative artificial intelligence for bio-image analysis<a class="headerlink" href="#generative-artificial-intelligence-for-bio-image-analysis" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Python, Bioimage Analysis, Artificial Intelligence</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://f1000research.com/slides/12-971">https://f1000research.com/slides/12-971</a></p>
</section>
<hr class="docutils" />
<section id="gerbi-chat-teil-1-vom-bedarf-bis-zum-groszgerateantrag-schreiben">
<h2>GerBI-Chat: Teil 1 - Vom Bedarf bis zum Großgeräteantrag-Schreiben<a class="headerlink" href="#gerbi-chat-teil-1-vom-bedarf-bis-zum-groszgerateantrag-schreiben" title="Link to this heading">#</a></h2>
<p>Financial &amp; Legal Framework of Core Facilities, Elmar Endl, Jana Hedrich, Juliane Hoth, Julia Nagy, Astrid Schauss, Nina Schulze, Silke Tulok</p>
<p>Published 2024-09-11</p>
<p>Licensed CC-BY-4.0</p>
<p>Die GermanBioImaging (GerBI-GMB) - Deutsche Gesellschaft für Mikroskopie und Bildanalyse e.V. bietet über regelmäßig stattfindende Treffen (GerBI-Chats) die Möglichkeit zum aktiven Austausch der Mitglieder untereinander. Das GerBI-GMB Team “Legal und Finacial Framwork”, welches sich mit administrativen Aufgaben rund um das Core Facility Management beschäftigt, nutzt diese Möglichkeit zum aktiven Austausch innerhalb des Netzwerkes und darüber hinaus. 
Der Beschaffungsprozess von Forschungsgroßgeräten ist komplex und je nach Institution unterschiedlich geregelt. Aus unserer Sicht lässt sich dieser Prozess grob in drei Stufen aufteilen:</p>
<p>Bedarfsanmeldung
Antragsvorbereitung und -fertigstellung
Antragsbewilligung und Nutzung </p>
<p>Dieser hier enthaltene Beitrag ist der Initialvortrag des GerBi-Chats zum Teil 1 - Von der Bedarfsanmeldung bis zum Beginn der Antragststellung. Die weiteren Stufen der Großgerätebeschaffung werden in nachfolgenden Beiträgen behandelt.</p>
<p><a class="reference external" href="https://zenodo.org/records/13810879">https://zenodo.org/records/13810879</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13810879">https://doi.org/10.5281/zenodo.13810879</a></p>
</section>
<hr class="docutils" />
<section id="gerbi-chat-teil-2-wie-schreibe-ich-am-besten-einen-groszegrateantrag">
<h2>GerBI-Chat: Teil 2 - Wie schreibe ich am besten einen Großegräteantrag<a class="headerlink" href="#gerbi-chat-teil-2-wie-schreibe-ich-am-besten-einen-groszegrateantrag" title="Link to this heading">#</a></h2>
<p>Financial &amp; Legal Framework of Core Facilities, Elmar Endl, Jana Hedrich, Juliane Hoth, Julia Nagy, Astrid Schauss, Nina Schulze, Silke Tulok</p>
<p>Published 2024-10-02</p>
<p>Licensed CC-BY-4.0</p>
<p>Die GermanBioImaging (GerBI-GMB) - Deutsche Gesellschaft für Mikroskopie und Bildanalyse e.V. bietet über regelmäßig stattfindende Treffen (GerBI-Chats) die Möglichkeit zum aktiven Austausch der Mitglieder untereinander. Das GerBI-GMB Team “Legal und Finacial Framwork”, welches sich mit administrativen Aufgaben rund um das Core Facility Management beschäftigt, nutzt diese Möglichkeit zum aktiven Austausch innerhalb des Netzwerkes und darüber hinaus. 
Der Beschaffungsprozess von Forschungsgroßgeräten ist komplex und je nach Institution unterschiedlich geregelt. Aus unserer Sicht lässt sich dieser Prozess grob in drei Stufen aufteilen:</p>
<p>Bedarfsanmeldung
Antragsvorbereitung und -fertigstellung
Antragsbewilligung und Nutzung </p>
<p>Nach dem Initialvortrag der GerBI-Chat Reihe, in dem das Thema Bedarfsanmeldung im Fokus stand, geht es im hier enthaltenen zweiten Teil „Antragsvorbereitung und -fertigstellung: Wie schreibe ich am besten einen Großgeräteantrag?“ um die Beantragung von Forschungsgroßgeräten nach Art. 91b GG.</p>
<p><a class="reference external" href="https://zenodo.org/records/13807114">https://zenodo.org/records/13807114</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13807114">https://doi.org/10.5281/zenodo.13807114</a></p>
</section>
<hr class="docutils" />
<section id="getting-started-with-mambaforge-and-python">
<h2>Getting started with Mambaforge and Python<a class="headerlink" href="#getting-started-with-mambaforge-and-python" title="Link to this heading">#</a></h2>
<p>Mara Lampert</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Python, Conda, Mamba</p>
<p>Content type: Blog Post</p>
<p><a class="reference external" href="https://biapol.github.io/blog/mara_lampert/getting_started_with_mambaforge_and_python/readme.html">https://biapol.github.io/blog/mara_lampert/getting_started_with_mambaforge_and_python/readme.html</a></p>
</section>
<hr class="docutils" />
<section id="getting-started-with-python-intro-and-set-up-a-conda-environment">
<h2>Getting started with Python: intro and set-up a conda environment<a class="headerlink" href="#getting-started-with-python-intro-and-set-up-a-conda-environment" title="Link to this heading">#</a></h2>
<p>Riccardo Massei</p>
<p>Published 2024-10-09</p>
<p>Licensed CC-BY-4.0</p>
<p>YMIA python event 2024
Presentation :  “Getting started with Python: intro and set-up a conda environment with Dr. Riccardo Massei”</p>
<p><a class="reference external" href="https://zenodo.org/records/13908480">https://zenodo.org/records/13908480</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13908480">https://doi.org/10.5281/zenodo.13908480</a></p>
</section>
<hr class="docutils" />
<section id="guidance-for-developing-a-research-data-management-rdm-policy">
<h2>Guidance for Developing a Research Data Management (RDM) Policy<a class="headerlink" href="#guidance-for-developing-a-research-data-management-rdm-policy" title="Link to this heading">#</a></h2>
<p>Published 2017</p>
<p>Licensed CC-BY-4.0</p>
<p>This document provides the essential elements of a Research Data Management (RDM) Policy and is part of the LEARN Toolkit containing the Model Policy for Research Data Management (RDM) at Research Institutions/Institutes.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Book</p>
<p><a class="reference external" href="https://discovery.ucl.ac.uk/id/eprint/1546596/1/26_Learn_Guidance_137-140.pdf">https://discovery.ucl.ac.uk/id/eprint/1546596/1/26_Learn_Guidance_137-140.pdf</a></p>
<p><a class="reference external" href="https://doi.org/10.14324/000.learn.27">https://doi.org/10.14324/000.learn.27</a></p>
</section>
<hr class="docutils" />
<section id="gut-analysis-toolbox">
<h2>Gut Analysis Toolbox<a class="headerlink" href="#gut-analysis-toolbox" title="Link to this heading">#</a></h2>
<p>Luke Sorensen, Ayame Saito, Sabrina Poon, Myat Noe Han, Ryan Hamnett, Peter Neckel, Adam Humenick, Keith Mutunduwe, Christie Glennan, Narges Mahdavian, Simon JH Brookes, Rachel M McQuade, Jaime PP Foong, Estibaliz Gómez-de-Mariscal, Arrate Muñoz Barrutia, Julia A. Kaltschmidt, Sebastian K. King, Robert Haase, Simona Carbone, Nicholas A. Veldhuis, Daniel P. Poole, Pradeep Rajasekhar</p>
<p>Published 2024-09-10</p>
<p>Licensed CC-BY-4.0</p>
<p>What’s Changed</p>
<p>Updating User Dialogs by &#64;mattyrowey in <a class="github reference external" href="https://github.com/pr4deepr/GutAnalysisToolbox/pull/18">pr4deepr/GutAnalysisToolbox#18</a>
Added Dialog Boxes and Grammar Corrections by &#64;mattyrowey in <a class="github reference external" href="https://github.com/pr4deepr/GutAnalysisToolbox/pull/19">pr4deepr/GutAnalysisToolbox#19</a>
Updated Dialog Prompts for Clarity by &#64;mattyrowey in <a class="github reference external" href="https://github.com/pr4deepr/GutAnalysisToolbox/pull/20">pr4deepr/GutAnalysisToolbox#20</a>
Batch analysis option added.
fixed a bunch of bugs related to ganglia segmentation and user workflow</p>
<p>New Contributors</p>
<p>&#64;mattyrowey made their first contribution in <a class="github reference external" href="https://github.com/pr4deepr/GutAnalysisToolbox/pull/18">pr4deepr/GutAnalysisToolbox#18</a></p>
<p>Full Changelog: <a class="reference external" href="https://github.com/pr4deepr/GutAnalysisToolbox/compare/v0.6...v0.7">https://github.com/pr4deepr/GutAnalysisToolbox/compare/v0.6…v0.7</a></p>
<p><a class="reference external" href="https://zenodo.org/records/13739137">https://zenodo.org/records/13739137</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13739137">https://doi.org/10.5281/zenodo.13739137</a></p>
</section>
<hr class="docutils" />
<section id="gut-analysis-toolbox-training-data-and-2d-models-for-segmenting-enteric-neurons-neuronal-subtypes-and-ganglia">
<h2>Gut Analysis Toolbox: Training data and 2D models for segmenting enteric neurons, neuronal subtypes and ganglia<a class="headerlink" href="#gut-analysis-toolbox-training-data-and-2d-models-for-segmenting-enteric-neurons-neuronal-subtypes-and-ganglia" title="Link to this heading">#</a></h2>
<p>Luke Sorensen, Ayame Saito, Sabrina Poon, Myat Noe Han, Adam Humenick, Peter Neckel, Keith Mutunduwe, Christie Glennan, Narges Mahdavian, Simon JH Brookes, Rachel M McQuade, Jaime PP Foong, Sebastian K. King, Estibaliz  Gómez-de-Mariscal, Arrate Muñoz-Barrutia, Robert Haase, Simona Carbone, Nicholas A. Veldhuis, Daniel P. Poole, Pradeep Rajasekhar</p>
<p>Published 2022-02-15</p>
<p>Licensed CC-BY-4.0</p>
<p>This upload is associated with the software, Gut Analysis Toolbox (GAT).
If you use it please cite:
Sorensen et al. Gut Analysis Toolbox: Automating quantitative analysis of enteric neurons. J Cell Sci 2024; jcs.261950. doi: <a class="reference external" href="https://doi.org/10.1242/jcs.261950">https://doi.org/10.1242/jcs.261950</a>
The upload contains StarDist models for segmenting enteric neurons in 2D, enteric neuronal subtypes in 2D and UNet model for enteric ganglia in 2D in gut wholemount tissue. GAT is implemented in Fiji, but the models can be used in any software that supports StarDist and the use of 2D UNet models. The files here also consist of Python notebooks (Google Colab), training and test data as well as reports on model performance.
The model files are located in the respective folders as zip files. The folders have also been zipped:</p>
<p>Neuron (Hu; StarDist model):</p>
<p>Main folder: 2D_enteric_neuron_model_QA.zip
Model File:2D_enteric_neuron_v4_1.zip </p>
<p>Neuronal subtype (StarDist model): </p>
<p>Main folder: 2D_enteric_neuron_subtype_model_QA.zip
Model File: 2D_enteric_neuron_subtype_v4.zip</p>
<p>Enteric ganglia (2D UNet model; Use in FIJI with deepImageJ)</p>
<p>Main folder: 2D_enteric_ganglia_model_QA.zip
Model File: 2D_Ganglia_RGB_v2.bioimage.io.model.zip (Compatible with deepimageJ v3)</p>
<p>For the all models, files included are:</p>
<p>Model for segmenting cells or ganglia in 2D FIJI. StarDist or 2D UNet.
Training and Test datasets used for training.
Google Colab notebooks used for training and quality assurance (ZeroCost DL4Mic notebooks).
Quality assurance reports generated from above notebooks.
StarDist model exported for use in QuPath.</p>
<p>The model files can be used within can be used within the software, StarDist. They are intended to be used within FIJI or QuPath, but can be used in any software that supports the implementation of StarDist in 2D.
Data:
All the images were collected from 4 different research labs and a public database (SPARC database) to account for variations in image acquisition, sample preparation and immunolabelling.
For enteric neurons the pan-neuronal marker, Hu has been used and the  2D wholemounts images from mouse, rat and human tissue.
For enteric neuronal subtypes, 2D images for nNOS, MOR, DOR, ChAT, Calretinin, Calbindin, Neurofilament, CGRP and SST from mouse tissue have been used..
25 images were used from the following entries in the SPARC database:</p>
<p>Howard, M. (2021). 3D imaging of enteric neurons in mouse (Version 1) [Data set]. SPARC Consortium.
Graham, K. D., Huerta-Lopez, S., Sengupta, R., Shenoy, A., Schneider, S., Wright, C. M., Feldman, M., Furth, E., Lemke, A., Wilkins, B. J., Naji, A., Doolin, E., Howard, M., &amp; Heuckeroth, R. (2020). Robust 3-Dimensional visualization of human colon enteric nervous system without tissue sectioning (Version 1) [Data set]. SPARC Consortium.
Wang, L., Yuan, P.-Q., Gould, T. and Tache, Y. (2021). Antibodies Tested in theColon – Mouse (Version 1) [Data set]. SPARC Consortium. doi:10.26275/i7dl-58h</p>
<p>The images have been acquired using a combination different microscopes. The images for the mouse tissue were acquired using: </p>
<p>Leica TCS-SP8 confocal system (20x HC PL APO NA 1.33, 40 x HC PL APO NA 1.3) </p>
<p>Leica TCS-SP8 lightning confocal system (20x HC PL APO NA 0.88) </p>
<p>Zeiss Axio Imager M2 (20X HC PL APO NA 0.3) </p>
<p>Zeiss Axio Imager Z1 (10X HC PL APO NA 0.45) </p>
<p>Human tissue images were acquired using: </p>
<p>IX71 Olympus microscope (10X HC PL APO NA 0.3) </p>
<p>For more information, visit the Documentation website.
NOTE: The images for enteric neurons and neuronal subtypes have been rescaled to 0.568 µm/pixel for mouse and rat. For human neurons, it has been rescaled to 0.9 µm/pixel . This is to ensure the neuronal cell bodies have similar pixel area across images. The area of cells in pixels can vary based on resolution of image, magnification of objective used, animal species (larger animals -&gt; larger neurons) and potentially how the tissue is stretched during wholemount preparation 
Average neuron area for neuronal model: 701.2 ± 195.9 pixel2 (Mean ± SD, 6267 cells)
Average neuron area for neuronal subtype model: 880.9 ± 316 pixel2 (Mean ± SD, 924 cells)
Software References:
Stardist
Schmidt, U., Weigert, M., Broaddus, C., &amp; Myers, G. (2018, September). Cell detection with star-convex polygons. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 265-273). Springer, Cham.
deepImageJ
Gómez-de-Mariscal, E., García-López-de-Haro, C., Ouyang, W., Donati, L., Lundberg, E., Unser, M., Muñoz-Barrutia, A. and Sage, D., 2021. DeepImageJ: A user-friendly environment to run deep learning models in ImageJ. Nature Methods, 18(10), pp.1192-1195.
ZeroCost DL4Mic
von Chamier, L., Laine, R.F., Jukkala, J., Spahn, C., Krentzel, D., Nehme, E., Lerche, M., Hernández-Pérez, S., Mattila, P.K., Karinou, E. and Holden, S., 2021. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nature communications, 12(1), pp.1-18.</p>
<p><a class="reference external" href="https://zenodo.org/records/10460434">https://zenodo.org/records/10460434</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10460434">https://doi.org/10.5281/zenodo.10460434</a></p>
</section>
<hr class="docutils" />
<section id="hackaton-results-conversion-of-knime-image-analysis-workflows-to-galaxy">
<h2>Hackaton Results - Conversion of KNIME image analysis workflows to Galaxy<a class="headerlink" href="#hackaton-results-conversion-of-knime-image-analysis-workflows-to-galaxy" title="Link to this heading">#</a></h2>
<p>Riccardo Massei</p>
<p>Published 2024-03-07</p>
<p>Licensed CC-BY-4.0</p>
<p>Results of the project “Conversion of KNIME image analysis workflows to Galaxy” during the Hackathon “Image Analysis in Galaxy” (Freiburg 26 Feb - 01 Mar 2024)
 </p>
<p><a class="reference external" href="https://zenodo.org/records/10793700">https://zenodo.org/records/10793700</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10793700">https://doi.org/10.5281/zenodo.10793700</a></p>
</section>
<hr class="docutils" />
<section id="hela-kyoto-cells-under-the-scope">
<h2>HeLa “Kyoto” cells under the scope<a class="headerlink" href="#hela-kyoto-cells-under-the-scope" title="Link to this heading">#</a></h2>
<p>Romain Guiet</p>
<p>Published 2022-02-25</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: HeLa “Kyoto” cells under the scope</p>
<p>Microscope: Perkin Elmer Operetta microscope with a 20x N.A. 0.8 objective and an Andor Zyla 5.5 camera.</p>
<p>Microscopy data type: The time-lapse datasets were acquired every 15 minutes, for 60 hours. From the individual plan images (channels, time-points, field of view exported by the PerkinElmer software Harmony) multi-dimension images were generated using the Operetta_Importer-0.1.21  with a downscaling of 4. </p>
<p>Channel 1 : Low Contrast DPC (Digital Phase Contrast)</p>
<p>Channel 2 : High Contrast DPC</p>
<p>Channel 3 : Brightfield</p>
<p>Channel 4 : EGFP-α-tubulin</p>
<p>Channel 5 : mCherry-H2B</p>
<p>File format: .tif (16-bit)</p>
<p>Image size: 540x540 (Pixel size: 0.299 nm), 5c, 1z , 240t</p>
<p> </p>
<p>Cell type: HeLa “Kyoto” cells, expressing EGFP-α-tubulin and mCherry-H2B ( Schmitz et al, 2010 )</p>
<p>Protocol: Cells were resuspended in Imaging media and were seeded in a microscopy grade 96 wells plate ( CellCarrier Ultra 96, Perkin Elmer). The day after seeding, and for 60 hours, images were acquired in 3 wells, in 25 different fields of view, every 15 minutes.</p>
<p>Imaging media: DMEM red-phenol-free media (FluoroBrite™ DMEM, Gibco) complemented with Fetal Calf Serum and Glutamax.</p>
<p> </p>
<p>NOTE: This dataset was used to automatically generate label images in the following Zenodo entry:  <a class="reference external" href="https://doi.org/10.5281/zenodo.6140064">https://doi.org/10.5281/zenodo.6140064</a></p>
<p>NOTE: This dataset was used to train the cellpose models in the following Zenodo entry: <a class="reference external" href="https://doi.org/10.5281/zenodo.6140111">https://doi.org/10.5281/zenodo.6140111</a></p>
<p><a class="reference external" href="https://zenodo.org/records/6139958">https://zenodo.org/records/6139958</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6139958">https://doi.org/10.5281/zenodo.6139958</a></p>
</section>
<hr class="docutils" />
<section id="high-throughput-automated-data-analysis-and-data-management-workflow-with-cellprofiler-and-omero">
<h2>High throughput &amp; automated data analysis and data management workflow with Cellprofiler and OMERO<a class="headerlink" href="#high-throughput-automated-data-analysis-and-data-management-workflow-with-cellprofiler-and-omero" title="Link to this heading">#</a></h2>
<p>Sarah Weischer, Jens Wendt, Thomas Zobel</p>
<p>Licensed CC-BY-4.0</p>
<p>In this workshop a fully integrated data analysis solutions employing OMERO and commonly applied image analysis tools (e.g., CellProfiler, Fiji) using existing python interfaces (OMERO Python language bindings, ezOmero, Cellprofiler Python API) is presented.</p>
<p>Tags: OMERO, Data Analysis, Bioimage Analysis</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.8139353">https://zenodo.org/doi/10.5281/zenodo.8139353</a></p>
</section>
<hr class="docutils" />
<section id="highlights-from-the-2016-2020-neubias-training-schools-for-bioimage-analysts-a-success-story-and-key-asset-for-analysts-and-life-scientists">
<h2>Highlights from the 2016-2020 NEUBIAS training schools for Bioimage Analysts: a success story and key asset for analysts and life scientists<a class="headerlink" href="#highlights-from-the-2016-2020-neubias-training-schools-for-bioimage-analysts-a-success-story-and-key-asset-for-analysts-and-life-scientists" title="Link to this heading">#</a></h2>
<p>Gabriel G. Martins, Fabrice P. Cordelières, Julien Colombelli, Rocco D’Antuono, Ofra Golani, Romain Guiet, Robert Haase, Anna H. Klemm, Marion Louveaux, Perrine Paul-Gilloteaux, Jean-Yves Tinevez, Kota Miura</p>
<p>Published 2021</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Bioimage Analysis, Neubias</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://f1000research.com/articles/10-334/v1">https://f1000research.com/articles/10-334/v1</a></p>
</section>
<hr class="docutils" />
<section id="hitchhiking-through-a-diverse-bio-image-analysis-software-universe">
<h2>Hitchhiking through a diverse Bio-image Analysis Software Universe<a class="headerlink" href="#hitchhiking-through-a-diverse-bio-image-analysis-software-universe" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2022-07-22</p>
<p>Licensed CC-BY-4.0</p>
<p>Overview about decision making and how to influence decisions in the bio-image analysis software context.</p>
<p>Tags: Bioimage Analysis</p>
<p>Content type: Slides, Presentation</p>
<p><a class="reference external" href="https://f1000research.com/slides/11-746">https://f1000research.com/slides/11-746</a></p>
<p><a class="reference external" href="https://doi.org/10.7490/f1000research.1119026.1">https://doi.org/10.7490/f1000research.1119026.1</a></p>
</section>
<hr class="docutils" />
<section id="human-dab-staining-axioscan-bf-20x">
<h2>Human DAB staining Axioscan BF 20x<a class="headerlink" href="#human-dab-staining-axioscan-bf-20x" title="Link to this heading">#</a></h2>
<p>Mario Garcia</p>
<p>Published 2024-05-21</p>
<p>Licensed CC-BY-4.0</p>
<p>Human brain tissue with DAB immunostaining. Image acquired by BF microscopy in  Zeiss Axioscan at 20x. </p>
<p><a class="reference external" href="https://zenodo.org/records/11234863">https://zenodo.org/records/11234863</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11234863">https://doi.org/10.5281/zenodo.11234863</a></p>
</section>
<hr class="docutils" />
<section id="i3d-bio-s-omero-training-material-re-usable-adjustable-multi-purpose-slides-for-local-user-training">
<h2>I3D:bio’s OMERO training material: Re-usable, adjustable, multi-purpose slides for local user training<a class="headerlink" href="#i3d-bio-s-omero-training-material-re-usable-adjustable-multi-purpose-slides-for-local-user-training" title="Link to this heading">#</a></h2>
<p>Christian Schmidt, Michele Bortolomeazzi, Tom Boissonnet, Carsten Fortmann-Grote, Julia Dohle, Peter Zentis, Niraj Kandpal, Susanne Kunis, Thomas Zobel, Stefanie Weidtkamp-Peters, Elisa Ferrando-May</p>
<p>Published 2023-11-13</p>
<p>Licensed CC-BY-4.0</p>
<p>The open-source software OME Remote Objects (OMERO) is a data management software that allows storing, organizing, and annotating bioimaging/microscopy data. OMERO has become one of the best-known systems for bioimage data management in the bioimaging community. The Information Infrastructure for BioImage Data (I3D:bio) project facilitates the uptake of OMERO into research data management (RDM) practices at universities and research institutions in Germany. Since the adoption of OMERO into researchers’ daily routines requires intensive training, a broad portfolio of training resources for OMERO is an asset. On top of using the OMERO guides curated by the Open Microscopy Environment Consortium (OME) team, imaging core facility staff at institutions where OMERO is used often prepare additional material tailored to be applicable for their own OMERO instances. Based on experience gathered in the Research Data Management for Microscopy group (RDM4mic) in Germany, and in the use cases in the I3D:bio project, we created a set of reusable, adjustable, openly available slide decks to serve as the basis for tailored training lectures, video tutorials, and self-guided instruction manuals directed at beginners in using OMERO. The material is published as an open educational resource complementing the existing resources for OMERO contributed by the community.</p>
<p>Tags: OMERO, Research Data Management, Nfdi4Bioimage, I3Dbio</p>
<p>Content type: Slides, Video</p>
<p><a class="reference external" href="https://zenodo.org/records/8323588">https://zenodo.org/records/8323588</a></p>
<p><a class="reference external" href="https://www.youtube.com/playlist?list=PL2k-L-zWPoR7SHjG1HhDIwLZj0MB_stlU">https://www.youtube.com/playlist?list=PL2k-L-zWPoR7SHjG1HhDIwLZj0MB_stlU</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8323588">https://doi.org/10.5281/zenodo.8323588</a></p>
</section>
<hr class="docutils" />
<section id="ics-ids-stitched-file">
<h2>ICS/IDS stitched file<a class="headerlink" href="#ics-ids-stitched-file" title="Link to this heading">#</a></h2>
<p>IMCF</p>
<p>Published 2024-06-13</p>
<p>Licensed CC-BY-4.0</p>
<p>Hi &#64;ome team !
We usually use ICS/IDS file formats as an output to our stitching pipeline as the reading and writing is pretty fast. However, it seems that since Bio-Formats 7.x opening the files is not working anymore.
I tried with a Fiji with Bio-Formats 6.10.1 and the files open, but more recent versions give an issue.
 
java.lang.NullPointerException
at loci.formats.in.ICSReader.initFile(ICSReader.java:1481)
at loci.formats.FormatReader.setId(FormatReader.java:1480)
at loci.plugins.in.ImportProcess.initializeFile(ImportProcess.java:498)
at loci.plugins.in.ImportProcess.execute(ImportProcess.java:141)
at loci.plugins.in.Importer.showDialogs(Importer.java:156)
at loci.plugins.in.Importer.run(Importer.java:77)
at loci.plugins.LociImporter.run(LociImporter.java:78)
at ij.IJ.runUserPlugIn(IJ.java:244)
at ij.IJ.runPlugIn(IJ.java:210)
at ij.Executer.runCommand(Executer.java:152)
at ij.Executer.run(Executer.java:70)
at ij.IJ.run(IJ.java:326)
at ij.IJ.run(IJ.java:337)
at ij.macro.Functions.doRun(Functions.java:703)
at ij.macro.Functions.doFunction(Functions.java:99)
at ij.macro.Interpreter.doStatement(Interpreter.java:281)
at ij.macro.Interpreter.doStatements(Interpreter.java:267)
at ij.macro.Interpreter.run(Interpreter.java:163)
at ij.macro.Interpreter.run(Interpreter.java:93)
at ij.macro.MacroRunner.run(MacroRunner.java:146)
at java.lang.Thread.run(Thread.java:750)</p>
<p>You can find one example file at this link 1.
Thanks for your help !Best,Laurent</p>
<p><a class="reference external" href="https://zenodo.org/records/11637422">https://zenodo.org/records/11637422</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11637422">https://doi.org/10.5281/zenodo.11637422</a></p>
</section>
<hr class="docutils" />
<section id="if-you-license-it-itll-be-harder-to-steal-it-why-we-should-license-our-work">
<h2>If you license it, it’ll be harder to steal it. Why we should license our work<a class="headerlink" href="#if-you-license-it-itll-be-harder-to-steal-it-why-we-should-license-our-work" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Licensed CC-BY-4.0</p>
<p>Blog post about why we should license our work and what is important when choosing a license.</p>
<p>Tags: Licensing, Research Data Management</p>
<p>Content type: Blog Post</p>
<p><a class="reference external" href="https://focalplane.biologists.com/2023/05/06/if-you-license-it-itll-be-harder-to-steal-it-why-we-should-license-our-work/">https://focalplane.biologists.com/2023/05/06/if-you-license-it-itll-be-harder-to-steal-it-why-we-should-license-our-work/</a></p>
</section>
<hr class="docutils" />
<section id="image-analysis-training-resources">
<h2>Image Analysis Training Resources<a class="headerlink" href="#image-analysis-training-resources" title="Link to this heading">#</a></h2>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Neubias, Bioimage Analysis</p>
<p>Content type: Book</p>
<p><a class="reference external" href="https://neubias.github.io/training-resources/">https://neubias.github.io/training-resources/</a></p>
</section>
<hr class="docutils" />
<section id="image-processing-with-python">
<h2>Image Processing with Python<a class="headerlink" href="#image-processing-with-python" title="Link to this heading">#</a></h2>
<p>Mark Meysenburg, Toby Hodges, Dominik Kutra, Erin Becker, David Palmquist, et al.</p>
<p>Licensed CC-BY-4.0</p>
<p>This lesson shows how to use Python and scikit-image to do basic image processing.</p>
<p>Tags: Bioimage Analysis, Python</p>
<p>Content type: Tutorial, Workflow</p>
<p><a class="reference external" href="https://datacarpentry.org/image-processing/key-points.html">https://datacarpentry.org/image-processing/key-points.html</a></p>
</section>
<hr class="docutils" />
<section id="image-repository-decision-tree-where-do-i-deposit-my-imaging-data">
<h2>Image Repository Decision Tree - Where do I deposit my imaging data<a class="headerlink" href="#image-repository-decision-tree-where-do-i-deposit-my-imaging-data" title="Link to this heading">#</a></h2>
<p>Isabel Kemmer, Feriel Romdhane, Euro-BioImaging ERIC</p>
<p>Published 2024-10-22</p>
<p>Licensed CC-BY-4.0</p>
<p>Depositing data in quality data repositories is one crucial step towards FAIR (Findable, Accessible, Interoperable, and Reusable) data. Accordingly, Euro-BioImaging strongly encourages sharing scientific imaging data in established, thematic repositories. 
To guide you in the selection of appropriate repositories, we have created an overview of available repositories for different types of image data, including their scope and requirements. This decision tree guides you through questions about your data and directs you to the correct repository, and/or provides instructions for further processing to meet the critera of the repositories. 
Three seperate trees are provided for different classes of imaging data: open bioimage data, preclinical data, and human imaging data. </p>
<p><a class="reference external" href="https://zenodo.org/records/13945179">https://zenodo.org/records/13945179</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13945179">https://doi.org/10.5281/zenodo.13945179</a></p>
</section>
<hr class="docutils" />
<section id="imagej-tool-for-percentage-estimation-of-pneumonia-in-lungs">
<h2>ImageJ tool for percentage estimation of pneumonia in lungs<a class="headerlink" href="#imagej-tool-for-percentage-estimation-of-pneumonia-in-lungs" title="Link to this heading">#</a></h2>
<p>Martin Schätz, Olga Rubešová, Jan Mareš, Alan Spark</p>
<p>Published 2023-05-02</p>
<p>Licensed CC-BY-4.0</p>
<p>The software tool is developed on demand of Radiological Department of Faculty Hospital of Královské Vinohrady, with the aim to provide a tool to estimate the percentage of pneumonia (or COVID-19 presence) in lungs. Paper Estimation of Covid-19 lungs damage based on computer tomography images analysis presenting the tool is available on F1000reserach DOI: 10.12688/f1000research.109020.1. The underlying dataset is published in Zenodo (DOI:10.5281/zenodo.5805939). One of the challenges was to design a tool that would be available without complicated install procedures and would process data in a reasonable time even on office computers. For this reason, 8-bit and 16-bit version of the tool exists. The FIJI software (or ImageJ with Bio-Formats plugin installed) was selected as the best candidate. Examples of use and tutorials are available at GitHub. </p>
<p>Underlying data:
DOI:10.5281/zenodo.5805939
The first five datasets are analyzed using this tool, with results and parameters to repeat the analysis in results_csv.csv or results.xlsx.</p>
<p>Contributions:
Martin SCHÄTZ:       Coding, tool testing, data curation, data set analysis
Olga RUBEŠOVÁ:    Code review, tutorial preparation, tool testing, data set analysis
Jan MAREŠ:             Tool testing, data set analysis
Alan SPARK:             Tool testing</p>
<p>The work was funded by the Ministry of Education, Youth and Sports by grant ‘Development of Advanced Computational Algorithms for evaluating post-surgery rehabilitation’ number LTAIN19007. The work was also supported from the grant of Specific university research – grant No FCHI 2022-001.</p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/7885379">https://zenodo.org/records/7885379</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7885379">https://doi.org/10.5281/zenodo.7885379</a></p>
</section>
<hr class="docutils" />
<section id="incell-datasets-with-mix-of-2d-and-3d-failed-to-be-read">
<h2>InCell datasets with mix of 2D and 3D failed to be read<a class="headerlink" href="#incell-datasets-with-mix-of-2d-and-3d-failed-to-be-read" title="Link to this heading">#</a></h2>
<p>Fabien Kuttler, Rémy Dornier</p>
<p>Published 2025-01-31</p>
<p>Licensed CC-BY-4.0</p>
<p>The provided dataset contains 2 wells, 4 fields of view, 4 channels, no T but different number of Z according to the channel</p>
<p>Cy3 : 1 Z
DAPI : 16 Z
FITC : 1 Z
Brightfield : 1 Z</p>
<p>The mix 2D/3D is not correctly supported and the .xcde file cannot be read.
A discussion thread is already open on that topic.
Bio-Formats version : 8.0.1
 </p>
<p><a class="reference external" href="https://zenodo.org/records/14777242">https://zenodo.org/records/14777242</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14777242">https://doi.org/10.5281/zenodo.14777242</a></p>
</section>
<hr class="docutils" />
<section id="insights-and-impact-from-five-cycles-of-essential-open-source-software-for-science">
<h2>Insights and Impact From Five Cycles of Essential Open Source Software for Science<a class="headerlink" href="#insights-and-impact-from-five-cycles-of-essential-open-source-software-for-science" title="Link to this heading">#</a></h2>
<p>Kate Hertweck, Carly Strasser, Dario Taraborelli</p>
<p>Licensed CC-BY-4.0</p>
<p>Open source software (OSS) is essential for advancing scientific discovery, particularly in biomedical research, yet funding to support these vital tools has been limited. The Chan Zuckerberg Initiative’s Essential Open Source Software for Science (EOSS) program has significantly contributed to this field by providing $51.8 million in funding over five years to support the maintenance, growth, and community engagement of critical OSS tools. The program has impacted scientific OSS projects by improving their technical outputs, community building, and sustainability practices, and fostering collaborations within the OSS community. Additionally, EOSS funding has enhanced diversity, equity, and inclusion within the OSS community, although changes in principal investigator demographics were not observed. The funded projects have had a substantial impact on biomedical research by improving the usability and accessibility of scientific software, which has led to increased adoption and advancements in various biomedical fields.</p>
<p>Tags: Open Source Software, Funding, Sustainability</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://zenodo.org/records/11201216">https://zenodo.org/records/11201216</a></p>
</section>
<hr class="docutils" />
<section id="insights-from-acquiring-open-medical-imaging-datasets-for-foundation-model-development">
<h2>Insights from Acquiring Open Medical Imaging  Datasets for Foundation Model Development<a class="headerlink" href="#insights-from-acquiring-open-medical-imaging-datasets-for-foundation-model-development" title="Link to this heading">#</a></h2>
<p>Stefan Dvoretskii</p>
<p>Published 2024-04-10</p>
<p>Licensed CC-BY-4.0</p>
<p><a class="reference external" href="https://zenodo.org/records/11503289">https://zenodo.org/records/11503289</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11503289">https://doi.org/10.5281/zenodo.11503289</a></p>
</section>
<hr class="docutils" />
<section id="id1">
<h2>Insights from Acquiring Open Medical Imaging Datasets for Foundation Model Development<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>Stefan Dvoretskii</p>
<p>Published 2024-04-10</p>
<p>Licensed CC-BY-4.0</p>
<p><a class="reference external" href="https://zenodo.org/records/13380289">https://zenodo.org/records/13380289</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13380289">https://doi.org/10.5281/zenodo.13380289</a></p>
</section>
<hr class="docutils" />
<section id="institutionalization-and-collaboration-as-a-way-of-addressing-the-challenges-open-science-presents-to-libraries-the-university-of-konstanz-as-a-national-pioneer">
<h2>Institutionalization and Collaboration as a Way of Addressing the Challenges Open Science Presents to Libraries: The University of Konstanz as a National Pioneer<a class="headerlink" href="#institutionalization-and-collaboration-as-a-way-of-addressing-the-challenges-open-science-presents-to-libraries-the-university-of-konstanz-as-a-national-pioneer" title="Link to this heading">#</a></h2>
<p>Sophie Habinger, Maximilian Heber, Sonja Kralj, Emilia Mikautsch</p>
<p>Published 2024-07-09</p>
<p>Licensed CC-BY-4.0</p>
<p>The rise of Open Science (OS) and the academic community’s needs that come with it bring about a range of challenges for academic libraries. To face these challenges, the University of Konstanz has created a competence unit called Team Open Science in the Communication, Information, Media Center (KIM) - a joint unit of library and IT infrastructure. The Team creates synergies within itself and across the library. In December 2023, it involved 12 staff members specialising in open access (OA), research data management (RDM), open educational resources (OER) and virtual research environments (VRE). It collaborates closely with other KIM departments. This submission shall serve as a best practice example for the impact of OS on research libraries and, beyond that, the impact of research libraries on universities.
To enhance and foster OS, the Team provides individual consultations, services and office hours for researchers. Here, it collaborates closely with other librarians like subject specialists and the Team University Publications. Along similar lines, the KIM offers institutional repositories for publications (KOPS) and research data (KonDATA). Beyond that, the Team provides solutions to host OA journals and analyses researchers’ VRE needs to decide on implementation options. In sum, the Team is the central OS contact point for the entire university, underlining the major role the library holds in making institutional impact.
Furthermore, the Team had the leading role in creating the University of Konstanz’ OS Policy, one of the first ones passed by a German university. This policy stands out because it encompasses various OS domains. It demands, among other things, that text publications be made OA and that research data be managed according to relevant subject-specific standards. If permissible and reasonable, it demands that research data should be made publicly available at the earliest possible time. Along these lines, the policy has a large impact on how the library handles closed access books and subscription-based journals. As a consequence, OA is pursued wherever possible, leading to the highest OA quota of all German universities. In that sense, the Team is a crucial driving force of OS in the University of Konstanz, which ties in with the library’s major role of open research transformation.
Beyond the University of Konstanz, the Team is involved in a range of national and international projects collaborating with other libraries. On a national level, they lead the project open.access-network which provides an information platform for researchers and librarians and connects the German-speaking OA community through events like bar camps. The project KOALA-AV supports libraries in establishing consortial solutions for financing Diamond OA publications. Moreover, the Team is involved in the federal state initiative for RDM in Baden-Württemberg (bwFDM). Here, the Team is in charge of <a class="reference external" href="http://forschungsdaten.info">forschungsdaten.info</a>, the German-speaking countries’ leading RDM information platform, which will be offered in English within the next years. Internationally, the Team cooperates with librarians and other OS professionals from the European Reform University Alliance (ERUA) and the European University for Well-Being (EUniWell), establishing formats for best practice exchange, such as monthly OS Meet-Ups.</p>
<p><a class="reference external" href="https://zenodo.org/records/12699637">https://zenodo.org/records/12699637</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12699637">https://doi.org/10.5281/zenodo.12699637</a></p>
</section>
<hr class="docutils" />
<section id="interactive-image-data-flow-graphs">
<h2>Interactive Image Data Flow Graphs<a class="headerlink" href="#interactive-image-data-flow-graphs" title="Link to this heading">#</a></h2>
<p>Martin Schätz</p>
<p>Published 2022-10-17</p>
<p>Licensed CC-BY-4.0</p>
<p>The slides were presented during the Macro programming with ImageJ workshop (<a class="reference external" href="https://www.16mcm.cz/programme/#workshops">https://www.16mcm.cz/programme/#workshops</a>) which was part of the 16th Multinational Congress on Microscopy. It is a collection and “reshuffle” of slides originally made by Robert Haase on topics from Image Analysis in general up to User-friendly GPU-accelerated bio-image analysis and CLIJ2.</p>
<p><a class="reference external" href="https://zenodo.org/records/7215114">https://zenodo.org/records/7215114</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7215114">https://doi.org/10.5281/zenodo.7215114</a></p>
</section>
<hr class="docutils" />
<section id="intravital-microscopy-contrasting-agents-for-application-database">
<h2>Intravital microscopy contrasting agents for application - Database<a class="headerlink" href="#intravital-microscopy-contrasting-agents-for-application-database" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-06-19</p>
<p>Licensed CC-BY-4.0</p>
<p>This is a set of databases containing published use of substances which can be applied to rodents in order to contrast specific structures for optical intravital microscopy.
The first dataset contains applied final dosages, calculated for 25g-mice, as well as the orignally published amounts, concentrations and application routes of agents directly applied into the target organism.
The second dataset contains dosages and cell numbers for the external contrastation and subsequent application of cells into the target organism.
Filtering possible for organ system and contrasted structure/cell type in both datasets, substance class and fluorescent detection windows can be filtered in the dataset for direct agent application.
Source publications are listed by DOI.
 </p>
<p><a class="reference external" href="https://zenodo.org/records/12166710">https://zenodo.org/records/12166710</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12166710">https://doi.org/10.5281/zenodo.12166710</a></p>
</section>
<hr class="docutils" />
<section id="introducing-omero-vitessce-an-omero-web-plugin-for-multi-modal-data">
<h2>Introducing OMERO-vitessce: an <a class="reference external" href="http://OMERO.web">OMERO.web</a> plugin for multi-modal data<a class="headerlink" href="#introducing-omero-vitessce-an-omero-web-plugin-for-multi-modal-data" title="Link to this heading">#</a></h2>
<p>Michele Bortolomeazzi, Christian Schmidt, Jan-Philipp Mallm</p>
<p>Published 2025-02-07</p>
<p>Licensed CC-BY-4.0</p>
<p>omero-vitessce: an <a class="reference external" href="http://OMERO.web">OMERO.web</a> plugin for multi-modal data viewing.
OMERO is the most used research data management system (RDM) in the bioimaging domain, and has been adopted as a centralized RDM solution by several academic and research institutions. A main reason for this is the ability to directly view and annotate images from a web-based interface. However, this feature of OMERO is currently underpowered for the visualization of very large or multimodal datasets. These datasets, are becoming a more and more common foundation for biological and biomedical studies, due to the recent developments in imaging, and sequencing technologies which enabled their application to spatial-omics. In order to begin to provide this multimodal-data capability to OMERO, we developed omero-vitessce (<a class="github reference external" href="https://github.com/NFDI4BIOIMAGE/omero-vitessce/tree/main">NFDI4BIOIMAGE/omero-vitessce</a>), a new <a class="reference external" href="http://OMERO.web">OMERO.web</a> plugin for viewing data stored in OMERO with the Vitessce (<a class="reference external" href="http://vitessce.io/">http://vitessce.io/</a>) multimodal data viewer. omero-vitessce can be installed as an <a class="reference external" href="http://OMERO.web">OMERO.web</a> plugin with PiPy (<a class="reference external" href="https://pypi.org/project/omero-vitessce/">https://pypi.org/project/omero-vitessce/</a>), and allows users to set up interactive visualizations of their images of cells and tissues through interactive plots which are directly linked to the image. This enables the visual exploration of bioimage-analysis results and of multimodal data such as those generated through spatial-omics experiments. The data visualization is highly customizable and can be configured not only through custom configuration files, but also with the graphical interface provided by the plugin, thus making omero-vitessce a highly user-friendly solution for multimodal data viewing. most biological datasets. We plan to extend the interoperability of omero-vitessce with the OME-NGFF and SpatialData file formats to leverage the efficiency of these cloud optimized formats.
The three files in this Zenodo Record are all the same poster saved in different format all with high resolution images.</p>
<p><a class="reference external" href="https://zenodo.org/records/14832855">https://zenodo.org/records/14832855</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14832855">https://doi.org/10.5281/zenodo.14832855</a></p>
</section>
<hr class="docutils" />
<section id="introduction-to-bioimage-analysis">
<h2>Introduction to Bioimage Analysis<a class="headerlink" href="#introduction-to-bioimage-analysis" title="Link to this heading">#</a></h2>
<p>Pete Bankhead</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Python, Imagej, Bioimage Analysis</p>
<p>Content type: Book, Notebook</p>
<p><a class="reference external" href="https://bioimagebook.github.io/index.html">https://bioimagebook.github.io/index.html</a></p>
</section>
<hr class="docutils" />
<section id="introduction-to-research-data-management-and-open-research">
<h2>Introduction to Research Data Management and Open Research<a class="headerlink" href="#introduction-to-research-data-management-and-open-research" title="Link to this heading">#</a></h2>
<p>Shanmugasundaram</p>
<p>Published 2024-05-17</p>
<p>Licensed CC-BY-4.0</p>
<p>Introduction to RDM primarily for researchers. Can be seen as primer to all other materials in this catalogue.</p>
<p>Tags: Research Data Management, Open Science</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/4778265">https://zenodo.org/records/4778265</a></p>
</section>
<hr class="docutils" />
<section id="key-value-pair-template-for-annotation-in-omero-for-light-microscopy-data-acquired-with-axioscan7-core-facility-cellular-imaging-cfci">
<h2>Key-Value pair template for annotation in OMERO for light microscopy data acquired with AxioScan7 - Core Facility Cellular Imaging (CFCI)<a class="headerlink" href="#key-value-pair-template-for-annotation-in-omero-for-light-microscopy-data-acquired-with-axioscan7-core-facility-cellular-imaging-cfci" title="Link to this heading">#</a></h2>
<p>Silke Tulok, Anja Nobst, Anett Jannasch, Tom Boissonnet, Gunar Fabig</p>
<p>Published 2024-06-28</p>
<p>Licensed CC-BY-4.0</p>
<p>This Key-Value pair template is used for the data documentation during imaging experiments and the later data annotation in OMERO. It is tailored for the usage and image acquisition at the slide scanning system Zeiss AxioScan 7 in the Core Facility Cellular Imaging (CFCI). It contains important metadata of the imaging experiment, which are not saved in the corresponding imaging files. All users of the Core Facility Cellular Imaging are trained to use that file to document their imaging parameters directly during the data acquisition with the possibility for a later upload to OMERO. Furthermore, there is a corresponding public example image used in the publication “Setting up an institutional OMERO environment for bioimage data: perspectives from both facility staff and users” and is available here:
<a class="reference external" href="https://omero.med.tu-dresden.de/webclient/?show=image-33248">https://omero.med.tu-dresden.de/webclient/?show=image-33248</a>
This template was developed by the CFCI staff during the setup and usage of the AxioScan 7 and is based on the REMBI recommendations (<a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015</a>).
With this template it is possible to create a csv-file, that can be used to annotate an image or dataset in OMERO using the annotation script (<a class="github reference external" href="https://github.com/ome/omero-scripts/blob/develop/omero/annotation_scripts/">ome/omero-scripts</a>).
How to use:</p>
<p>fill the template sheet  with your metadata
select and copy the data range containing the Keys and Values
open a new excel sheet and paste transpose in cell A1 
Important: cell A1 contains always the name ‘dataset’ and cell A2 contains the exact name of the image/dataset, which should be annotated in OMERO
save the new excel sheet in csv-file (comma separated values) format</p>
<p>An example can be seen in sheet 3 ‘csv_AxioScan’.
Important note: The code has to be 8-Bit UCS transformation format (UTF-8) otherwise several characters (for example µ, %,°) might be not able to decode by the annotation script. We encountered this issue with old Microsoft-Office versions (MS Office 2016). 
Note: By filling the values in the excel sheet, avoid the usage of comma as decimal delimiter.
See cross reference:
10.5281/zenodo.12547566 Key-Value pair template for annotation of datasets in OMERO for light- and electron microscopy data within the research group of Prof. Mueller-Reichert
10.5281/zenodo.12546808 Key-Value pair template for annotation of datasets in OMERO (PERIKLES study)</p>
<p>Tags: Nfdi4Bioimage, Research Data Management</p>
<p><a class="reference external" href="https://zenodo.org/records/12578084">https://zenodo.org/records/12578084</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12578084">https://doi.org/10.5281/zenodo.12578084</a></p>
</section>
<hr class="docutils" />
<section id="key-value-pair-template-for-annotation-of-datasets-in-omero-perikles-study">
<h2>Key-Value pair template for annotation of datasets in OMERO (PERIKLES study)<a class="headerlink" href="#key-value-pair-template-for-annotation-of-datasets-in-omero-perikles-study" title="Link to this heading">#</a></h2>
<p>Anett Jannasch, Silke Tulok, Vanessa Aphaia Fiona Fuchs, Tom Boissonnet, Christian Schmidt, Michele Bortolomeazzi, Gunar Fabig, Chukwuebuka Okafornta</p>
<p>Published 2024-06-26</p>
<p>Licensed CC-BY-4.0</p>
<p>This is a Key-Value pair template used for the annotation of datasets in OMERO. It is tailored for a research study (PERIKLES project) on the biocompatibility of newly designed biomaterials out of pericardial tissue for cardiovascular substitutes (<a class="reference external" href="https://doi.org/10.1063/5.0182672">https://doi.org/10.1063/5.0182672</a>) conducted in the research department of Cardiac Surgery at the Faculty of Medicine Carl Gustav Carus at the Technische Universität Dresden . A corresponding public example dataset is used in the publication “Setting up an institutional OMERO environment for bioimage data: perspectives from both facility staff and users” and is available here
(<a class="reference external" href="https://omero.med.tu-dresden.de/webclient/?show=dataset-1557">https://omero.med.tu-dresden.de/webclient/?show=dataset-1557</a>).
The template is based on the REMBI recommendations (<a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015</a>) and it was developed during the PoL-Bio-Image Analysis Symposium in Dresden Aug 28th- Sept 1th 2023. 
With this template it is possible to create a csv-file, that can be used to annotate a dataset in OMERO using the annotation script (<a class="github reference external" href="https://github.com/ome/omero-scripts/blob/develop/omero/annotation_scripts/">ome/omero-scripts</a>).
How to use:
select and copy the data range containing Keys and Values
open a new excel sheet and paste transpose in column B1
type in A1 ‘dataset’
insert in A2 the exact name of the dataset, which should be annotated in OMERO
save the new excel sheet in csv- (comma seperated values) file format</p>
<p>Example can be seen in sheet 1 ‘csv import’. Important note; the code has to be 8-Bit UCS transformation format (UTF-8) otherwise several characters (for example µ, %,°) might not be able to decode by the annotation script. We encountered this issue with old Microsoft Office versions (e.g. MS Office 2016). 
Note: By filling the values in the excel sheet, avoid the usage of decimal delimiter.
 
See cross reference:
10.5281/zenodo.12547566 Key-Value pair template for annotation of datasets in OMERO (light- and electron microscopy data within the research group of Prof. Mueller-Reichert)
10.5281/zenodo.12578084 Key-Value pair template for annotation in OMERO for light microscopy data acquired with AxioScan7 - Core Facility Cellular Imaging (CFCI)</p>
<p>Tags: Nfdi4Bioimage, Research Data Management</p>
<p><a class="reference external" href="https://zenodo.org/records/12546808">https://zenodo.org/records/12546808</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12546808">https://doi.org/10.5281/zenodo.12546808</a></p>
</section>
<hr class="docutils" />
<section id="key-value-pair-template-for-annotation-of-datasets-in-omero-for-light-and-electron-microscopy-data-within-the-research-group-of-prof-muller-reichert">
<h2>Key-Value pair template for annotation of datasets in OMERO for light- and electron microscopy data within the research group of Prof. Müller-Reichert<a class="headerlink" href="#key-value-pair-template-for-annotation-of-datasets-in-omero-for-light-and-electron-microscopy-data-within-the-research-group-of-prof-muller-reichert" title="Link to this heading">#</a></h2>
<p>Gunar Fabig, Anett Jannasch, Chukwuebuka Okafornta, Tom Boissonnet, Christian Schmidt, Michele Bortolomeazzi, Vanessa Aphaia Fiona Fuchs, Maria Koeckert, Aayush Poddar, Martin Vogel, Hanna-Margareta Schwarzbach, Andy Vogelsang, Michael Gerlach, Anja Nobst, Thomas Müller-Reichert, Silke Tulok</p>
<p>Published 2024-06-26</p>
<p>Licensed CC-BY-4.0</p>
<p>This are a two Key-Value pair templates used for the annotation of datasets in OMERO. They are tailored for light- and electron microcopy data for all research projects of the research group of Prof. T. Mueller-Reichert.  All members of the Core Facility Cellular Imaging agreed for using these templates to annotate data in OMERO. Furthermore, there are a corresponding public example datasets used in the publication “Setting up an institutional OMERO environment for bioimage data: perspectives from both facility staff and users” and are available here:
<a class="reference external" href="https://omero.med.tu-dresden.de/webclient/?show=dataset-1552">https://omero.med.tu-dresden.de/webclient/?show=dataset-1552</a> –&gt; for lattice-light sheet microscopy
<a class="reference external" href="https://omero.med.tu-dresden.de/webclient/?show=dataset-1555--&amp;amp;gt">https://omero.med.tu-dresden.de/webclient/?show=dataset-1555–&amp;gt</a>; for electron microscopy data
That templates are based on the REMBI recommendations (<a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015</a>) and were developed during the PoL-Bio-Image Analysis Symposium in Dresden Aug 28th- Sept 1st in 2023 and further adapeted during the usage of OMERO. 
With every template it is possible to create a csv-file, that can be used to annotate a dataset in OMERO using the annotation script (<a class="github reference external" href="https://github.com/ome/omero-scripts/blob/develop/omero/annotation_scripts/">ome/omero-scripts</a>).
How to use:</p>
<p>fill the template with metadata
select and copy the data range containing the Keys and Values
open a new excel sheet and paste transpose in cell A1
Important: cell A1 contains always the name ‘dataset’ and cell A2 contains the exact name of the dataset, which should be annotated in OMERO
save the new excel sheet in csv-file (comma separated values) format</p>
<p>Examples can be seen in sheet 3 ‘csv_TOMO’ and sheet 5 csv_TEM’.
Important note: The code has to be 8-Bit UCS transformation format (UTF-8) otherwise several characters (for example µ, %,°) might be not able to decode by the annotation script. We encountered this issue with old Microsoft-Office versions (MS Office 2016). 
Note: By filling the values in the excel sheet, avoid the usage of comma as decimal delimiter.
See cross reference:
10.5281/zenodo.12546808 Key-Value pair template for annotation of datasets in OMERO (PERIKLES study)
10.5281/zenodo.12578084 Key-Value pair template for annotation in OMERO for light microscopy data acquired with AxioScan7 - Core Facility Cellular Imaging (CFCI)
 </p>
<p><a class="reference external" href="https://zenodo.org/records/12547566">https://zenodo.org/records/12547566</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12547566">https://doi.org/10.5281/zenodo.12547566</a></p>
</section>
<hr class="docutils" />
<section id="kollaboratives-arbeiten-und-versionskontrolle-mit-git">
<h2>Kollaboratives Arbeiten und Versionskontrolle mit Git<a class="headerlink" href="#kollaboratives-arbeiten-und-versionskontrolle-mit-git" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-04-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Gemeinsames Arbeiten im Internet stellt uns vor neue Herausforderungen: Wer hat eine Datei wann hochgeladen? Wer hat zum Inhalt beigetragen? Wie kann man Inhalte zusammenfuehren, wenn mehrere Mitarbeiter gleichzeitig Aenderungen gemacht haben? Das Versionskontrollwerkzeug git stellt eine umfassende Loesung fuer solche Fragen bereit. Die Onlineplatform <a class="reference external" href="http://github.com">github.com</a> stellt nicht nur Softwareentwicklern weltweit eine git-getriebene Platform zur Verfuegung und erlaubt ihnen effektiv zusammen zu arbeiten. In diesem Workshop lernen wir:</p>
<p>Infuerung in FAIR-Prinzipien im Softwarecontext
Arbeiten mit git: Pull-requests
Aufloesen von Merge-Konflikten
Automatisiertes Archivieren von Inhalten nach <a class="reference external" href="http://Zenodo.org">Zenodo.org</a>
Eigene Webseiten auf <a class="reference external" href="http://github.io">github.io</a> publizieren</p>
<p>Tags: Research Data Management, FAIR-Principles, Git, Zenodo</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/10972692">https://zenodo.org/records/10972692</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10972692">https://doi.org/10.5281/zenodo.10972692</a></p>
</section>
<hr class="docutils" />
<section id="kriterienkatalog-fur-materialien-aus-dem-themenbereich-forschungsdatenmanagement">
<h2>Kriterienkatalog für Materialien aus dem Themenbereich Forschungsdatenmanagement<a class="headerlink" href="#kriterienkatalog-fur-materialien-aus-dem-themenbereich-forschungsdatenmanagement" title="Link to this heading">#</a></h2>
<p>Linda Zollitsch, Swantje Piotrowski</p>
<p>Published 2025-01-24</p>
<p>Licensed CC-BY-4.0</p>
<p>Im Rahmen von FDM-SH Kontor – einem Projekt, das im Kontext der AG Kompetenzentwicklung von der Landesinitiative FDM-SH durchgeführt wurde - haben wir zum Ziel, eine kuratierte Materialbasis für Fortbildungen und Schulungen zu schaffen. Dies stellte uns vor die Herausforderung, festzulegen, wie die Materialien ausgewählt werden sollen.
Dieser Kriterienkatalog ist ein Versuch, erste Qualitätskriterien (insbesondere hinsichtlich der Nachnutzbarkeit und den FAIR-Prinzipien) für Materialien auf Basis von Metadaten zu erstellen. Dabei wurde das Vorgehen des Open Science Learning Gates (<a class="reference external" href="https://zenodo.org/records/12772135">https://zenodo.org/records/12772135</a>), als Vorbild genommen. Neben dem Metadatenschema der RDA (<a class="reference external" href="https://zenodo.org/records/6769695#.YrrP9-xBybQ">https://zenodo.org/records/6769695#.YrrP9-xBybQ</a>) haben wir auf das Metadatenschema der DINI/nestor UAG Schulungen/Fortbildungen (<a class="reference external" href="https://zenodo.org/records/3760398">https://zenodo.org/records/3760398</a>) sowie das DALIA Interchange Format (<a class="reference external" href="https://zenodo.org/records/11521029">https://zenodo.org/records/11521029</a>) zurückgegriffen.</p>
<p><a class="reference external" href="https://zenodo.org/records/14729452">https://zenodo.org/records/14729452</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14729452">https://doi.org/10.5281/zenodo.14729452</a></p>
</section>
<hr class="docutils" />
<section id="leo-linking-eln-with-omero">
<h2>LEO: Linking ELN with OMERO<a class="headerlink" href="#leo-linking-eln-with-omero" title="Link to this heading">#</a></h2>
<p>Escobar Diaz Guerrero, Rodrigo</p>
<p>Published 2024-05-08</p>
<p>Licensed CC-BY-4.0</p>
<p>First updates of LEO (Linking ELN with OMERO)</p>
<p><a class="reference external" href="https://zenodo.org/records/11146807">https://zenodo.org/records/11146807</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11146807">https://doi.org/10.5281/zenodo.11146807</a></p>
</section>
<hr class="docutils" />
<section id="lsm-example-j-dubrulle">
<h2>LSM example J. Dubrulle<a class="headerlink" href="#lsm-example-j-dubrulle" title="Link to this heading">#</a></h2>
<p>Salama Lab Fred Hutchinson Cancer Center</p>
<p>Published 2024-12-17</p>
<p>Licensed CC-BY-4.0</p>
<p><a class="reference external" href="https://zenodo.org/records/14510432">https://zenodo.org/records/14510432</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14510432">https://doi.org/10.5281/zenodo.14510432</a></p>
</section>
<hr class="docutils" />
<section id="lz4-compressed-imaris-ims-example-datasets">
<h2>LZ4-compressed Imaris ims example datasets.<a class="headerlink" href="#lz4-compressed-imaris-ims-example-datasets" title="Link to this heading">#</a></h2>
<p>Marco Stucchi</p>
<p>Published 2024-11-21</p>
<p>Licensed CC-BY-4.0</p>
<p>The files contained in this repository are cropped versions of Imaris demo images compressed with LZ4.</p>
<p><a class="reference external" href="https://zenodo.org/records/14197622">https://zenodo.org/records/14197622</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14197622">https://doi.org/10.5281/zenodo.14197622</a></p>
</section>
<hr class="docutils" />
<section id="large-language-models-an-introduction-for-life-scientists">
<h2>Large Language Models: An Introduction for Life Scientists<a class="headerlink" href="#large-language-models-an-introduction-for-life-scientists" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-12-12</p>
<p>Licensed CC-BY-4.0</p>
<p>This slide deck introduces Large Language Models to an audience of life-scientists. We first dive into terminology: Different kinds of Language Models and what they can be used for. The remaining slides are optional slides to allow us to dive deeper into topics such as tools for using LLMs in Science, Quality Assurance, Techniques such as Retrieval Augmented Generation and Prompt Engineering.</p>
<p>Tags: Globias, Artificial Intelligence</p>
<p><a class="reference external" href="https://zenodo.org/records/14418209">https://zenodo.org/records/14418209</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14418209">https://doi.org/10.5281/zenodo.14418209</a></p>
</section>
<hr class="docutils" />
<section id="large-tiling-confocal-acquisition-rat-brain">
<h2>Large tiling confocal acquisition (rat brain)<a class="headerlink" href="#large-tiling-confocal-acquisition-rat-brain" title="Link to this heading">#</a></h2>
<p>Julie Meystre</p>
<p>Published 2022-06-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: Large tiling confocal acquisition (rat brain)</p>
<p>Microscope: Zeiss LSM700</p>
<p>Microscopy data type: 108 tiles, each with 62 z-slices and 2 channels :
Channel 1: DAPI
Channel 2: cck staining</p>
<p>File format: .lsm (16-bit)</p>
<p>Image size: 1024x1024x62 (Pixel size: 0.152 x 0.152 x 1 micron), 2 channels.</p>
<p> </p>
<p>NOTE : Some tiles were annotated and used to train a StarDist3D model (<a class="reference external" href="https://doi.org/10.5281/zenodo.6645978">https://doi.org/10.5281/zenodo.6645978</a>   )</p>
<p><a class="reference external" href="https://zenodo.org/records/6646128">https://zenodo.org/records/6646128</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6646128">https://doi.org/10.5281/zenodo.6646128</a></p>
</section>
<hr class="docutils" />
<section id="leitfaden-zur-digitalen-datensparsamkeit-mit-praxisbeispielen">
<h2>Leitfaden zur digitalen Datensparsamkeit (mit Praxisbeispielen)<a class="headerlink" href="#leitfaden-zur-digitalen-datensparsamkeit-mit-praxisbeispielen" title="Link to this heading">#</a></h2>
<p>Maximilian Heber, Moritz Jakob, Matthias Landwehr, Jan Leendertse, Maximilian Müller, Gabriel Schneider, Dirk von Suchodoletz, Robert Ulrich</p>
<p>Published 2024-06-03</p>
<p>Licensed CC-BY-4.0</p>
<p>Im Zuge der stetig wachsenden Brisanz des Forschungsdatenmanagements fallen immer größere Mengen an Forschungsdaten an. Diese an sich begrüßenswerte Entwicklung führt zu technischen und organisatorischen Herausforderungen nicht nur im Bereich der Speicherung von Forschungsdaten, sondern in allen Phasen des Forschungsdatenlebenszyklus. Der vorliegende Beitrag erläutert vor diesem Hintergrund mögliche Motivationen hinter digitaler Datensparsamkeit mit Blick auf organisatorische, technische und ethische Kriterien, Datenschutz und Nachhaltigkeit. Anschließend werden vor dem Hintergrund zentraler Herausforderungen Umsetzungsvorschläge für das Vorfeld sowie den Verlauf eines Forschungsvorhabens gemacht. Zudem werden grundlegende Empfehlungen zur digitalen Datensparsamkeit ausgesprochen.
Eine kürzere Ausgabe des Leitfadens ist im Mai 2024 in der Zeitschrift o | bib erschienen: <a class="reference external" href="https://doi.org/10.5282/o-bib/6036">https://doi.org/10.5282/o-bib/6036</a>
Diese Ausgabe enthält ein zusätzliches Kapitel (4.2) mit konkreten Praxisbeispielen.
Dieser Artikel wurde ins Englische übersetzt:
Heber, M., Jakob, M., Landwehr, M., Leendertse, J., Müller, M., Schneider, G., von Suchodoletz, D., &amp; Ulrich, R. (2024). A Users’ Guide to Economical Digital Data Usage. Zenodo. <a class="reference external" href="https://doi.org/10.5281/zenodo.13752220">https://doi.org/10.5281/zenodo.13752220</a></p>
<p><a class="reference external" href="https://zenodo.org/records/11445843">https://zenodo.org/records/11445843</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11445843">https://doi.org/10.5281/zenodo.11445843</a></p>
</section>
<hr class="docutils" />
<section id="leitlinie-grundsatze-policy-richtlinie-forschungsdaten-policies-an-deutschen-universitaten">
<h2>Leitlinie? Grundsätze? Policy? Richtlinie? – Forschungsdaten-Policies an deutschen Universitäten<a class="headerlink" href="#leitlinie-grundsatze-policy-richtlinie-forschungsdaten-policies-an-deutschen-universitaten" title="Link to this heading">#</a></h2>
<p>Bea Hiemenz, Monika Kuberek</p>
<p>Published 2018-07-13</p>
<p>Licensed CC-BY-4.0</p>
<p>As a methodological approach, research data policies of German universities are collected and evaluated, and compared to international recommendations on research data policies.</p>
<p>Tags: Research Data Management, FAIR-Principles</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.o-bib.de/bib/article/view/2018H2S1-13">https://www.o-bib.de/bib/article/view/2018H2S1-13</a></p>
</section>
<hr class="docutils" />
<section id="limeseg-test-datasets">
<h2>LimeSeg Test Datasets<a class="headerlink" href="#limeseg-test-datasets" title="Link to this heading">#</a></h2>
<p>Sarah Machado, Vincent Mercier, Nicolas Chiaruttini</p>
<p>Published 2018-10-27</p>
<p>Licensed CC-BY-4.0</p>
<p>Image datasets from the publication : LimeSeg: A coarse-grained lipid membrane simulation for 3D image segmentation</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Vesicles.tif: spinning-disc confocal images of giant unilamellar vesicles
HelaCell-FIBSEM.tif:&amp;nbsp;a 3D Electron&amp;nbsp;Microscopy (EM)&amp;nbsp;dataset of nearly isotropic sections of a Hela cell, acquired with a focused ion beam scanning electron microscope (FIB-SEM). Sections are aligned with TrackEm2 (doi: ), without additional preprocessing.
DrosophilaEggChamber.tif: point scanning confocal images of a Drosophila egg chamber. Channel&amp;nbsp;1: cell nuclei &amp;nbsp;stained with DAPI. Channel 2:&amp;nbsp;cell membranes visualized with fused membrane proteins Nrg::GFP and Bsg::GFP.&amp;nbsp;
</pre></div>
</div>
<p>Image metadata contains extra information including voxel sizes.</p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/1472859">https://zenodo.org/records/1472859</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.1472859">https://doi.org/10.5281/zenodo.1472859</a></p>
</section>
<hr class="docutils" />
<section id="linked-open-data-for-microbial-population-biology">
<h2>Linked (Open) Data for Microbial Population Biology<a class="headerlink" href="#linked-open-data-for-microbial-population-biology" title="Link to this heading">#</a></h2>
<p>Carsten Fortmann-Grote</p>
<p>Published 2024-03-12</p>
<p>Licensed CC-BY-4.0</p>
<p><a class="reference external" href="https://zenodo.org/records/10808486">https://zenodo.org/records/10808486</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10808486">https://doi.org/10.5281/zenodo.10808486</a></p>
</section>
<hr class="docutils" />
<section id="liver-micrometastases-area-quantification-using-qupath-and-pixel-classifier">
<h2>Liver Micrometastases area quantification using QuPath and pixel classifier<a class="headerlink" href="#liver-micrometastases-area-quantification-using-qupath-and-pixel-classifier" title="Link to this heading">#</a></h2>
<p>Laia Simó-Riudalbas, Romain Guiet, Olivier Burri, Julien Duc, Didier Trono</p>
<p>Published 2022-05-06</p>
<p>Licensed CC-BY-4.0</p>
<p>Sample: Mouse (NSG) liver slices with human colorectal cancer cells metastases, stained with Hematoxylin &amp; Eosin. </p>
<p>Image Acquisition: Images were acquired on an Olympus VS120 Whole Slide Scanner, using a 20x objective (UPLSAPO, N.A. 0.75) and a color camera (Pike F505 Color) with an image pixel size of 0.345 microns.</p>
<p>Image Processing and Analysis: Obtained images were analyzed using the software QuPath [1] (version 0.3.2) using groovy scripts, making use of a pixel classifier to segment and measure cancer cell clusters.</p>
<p>Files :</p>
<p>Detailed_worflow.pdf : contains a detailed description of how pixel classifier was created</p>
<p>images_for_classifier_training.zip : contains all the vsi file obtained from the microscope and used for the training</p>
<p>project_for_classifier_training.zip : contains the QuPath project, with Training Image, annotations, classifiers and scripts for analysis</p>
<p>PythonCode.txt : code ran to transform output results from QuPath to final results</p>
<p> </p>
<p>[1] Bankhead, P. et al. QuPath: Open source software for digital pathology image analysis. Scientific Reports (2017). <a class="reference external" href="https://doi.org/10.1038/s41598-017-17204-5">https://doi.org/10.1038/s41598-017-17204-5</a></p>
<p><a class="reference external" href="https://zenodo.org/records/6523649">https://zenodo.org/records/6523649</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6523649">https://doi.org/10.5281/zenodo.6523649</a></p>
</section>
<hr class="docutils" />
<section id="making-the-most-of-bioimaging-data-through-interdisciplinary-interactions">
<h2>Making the most of bioimaging data through interdisciplinary interactions<a class="headerlink" href="#making-the-most-of-bioimaging-data-through-interdisciplinary-interactions" title="Link to this heading">#</a></h2>
<p>Virginie Uhlmann, Matthew Hartley, Josh Moore, Erin Weisbart, Assaf Zaritsky</p>
<p>Published 2024-10-23</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Bioimage Analysis, Open Science, Microscopy</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://journals.biologists.com/jcs/article/137/20/jcs262139/362478/Making-the-most-of-bioimaging-data-through">https://journals.biologists.com/jcs/article/137/20/jcs262139/362478/Making-the-most-of-bioimaging-data-through</a></p>
</section>
<hr class="docutils" />
<section id="making-your-package-available-on-conda-forge">
<h2>Making your package available on conda-forge<a class="headerlink" href="#making-your-package-available-on-conda-forge" title="Link to this heading">#</a></h2>
<p>Kevin Yamauchi</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Deployment, Python</p>
<p>Content type: Documentation</p>
<p><a class="reference external" href="https://kevinyamauchi.github.io/open-image-data/how_tos/conda_forge_packaging.html">https://kevinyamauchi.github.io/open-image-data/how_tos/conda_forge_packaging.html</a></p>
</section>
<hr class="docutils" />
<section id="managing-scientific-python-environments-using-conda-mamba-and-friends">
<h2>Managing Scientific Python environments using Conda, Mamba and friends<a class="headerlink" href="#managing-scientific-python-environments-using-conda-mamba-and-friends" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Python, Conda, Mamba</p>
<p>Content type: Blog Post</p>
<p><a class="reference external" href="https://focalplane.biologists.com/2022/12/08/managing-scientific-python-environments-using-conda-mamba-and-friends/">https://focalplane.biologists.com/2022/12/08/managing-scientific-python-environments-using-conda-mamba-and-friends/</a></p>
</section>
<hr class="docutils" />
<section id="measuring-reporter-activity-domain-in-epi-aggregates-and-gastruloids-ijm">
<h2>Measuring reporter activity domain in EPI aggregates and Gastruloids.ijm<a class="headerlink" href="#measuring-reporter-activity-domain-in-epi-aggregates-and-gastruloids-ijm" title="Link to this heading">#</a></h2>
<p>Romain Guiet, Olivier Burri, Mehmet Girgin, Matthias Lutolf</p>
<p>Published 2022-12-07</p>
<p>Licensed CC-BY-4.0</p>
<p>This imagej macro analyses the reporter intensity activity and expression domain in EPI aggregates and Gastruloids.</p>
<p><a class="reference external" href="https://zenodo.org/records/7409423">https://zenodo.org/records/7409423</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7409423">https://doi.org/10.5281/zenodo.7409423</a></p>
</section>
<hr class="docutils" />
<section id="meeting-in-the-middle-towards-successful-multidisciplinary-bioimage-analysis-collaboration">
<h2>Meeting in the Middle: Towards Successful Multidisciplinary Bioimage Analysis Collaboration<a class="headerlink" href="#meeting-in-the-middle-towards-successful-multidisciplinary-bioimage-analysis-collaboration" title="Link to this heading">#</a></h2>
<p>Anjalie Schlaeppi, Wilson Adams, Robert Haase, Jan Huisken, Ryan B. MacDonald, Kevin W. Eliceiri, Elisabeth C. Kugler</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Bioimage Analysis</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.frontiersin.org/articles/10.3389/fbinf.2022.889755/full">https://www.frontiersin.org/articles/10.3389/fbinf.2022.889755/full</a></p>
</section>
<hr class="docutils" />
<section id="metadata-annotation-workflow-for-omero-with-tabbles">
<h2>Metadata Annotation Workflow for OMERO with Tabbles<a class="headerlink" href="#metadata-annotation-workflow-for-omero-with-tabbles" title="Link to this heading">#</a></h2>
<p>Wendt Jens</p>
<p>Published 2023-09-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Short presentation given at at PoL BioImage Analysis Symposium Dresden 2023</p>
<p><a class="reference external" href="https://zenodo.org/records/8314968">https://zenodo.org/records/8314968</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8314968">https://doi.org/10.5281/zenodo.8314968</a></p>
</section>
<hr class="docutils" />
<section id="methods-in-bioimage-analysis">
<h2>Methods in bioimage analysis<a class="headerlink" href="#methods-in-bioimage-analysis" title="Link to this heading">#</a></h2>
<p>Christian Tischer</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Bioimage Analysis</p>
<p>Content type: Online Tutorial, Video, Slides</p>
<p><a class="reference external" href="https://www.ebi.ac.uk/training/events/methods-bioimage-analysis/">https://www.ebi.ac.uk/training/events/methods-bioimage-analysis/</a></p>
<p><a class="reference external" href="https://doi.org/10.6019/TOL.BioImageAnalysis22-w.2022.00001.1">https://doi.org/10.6019/TOL.BioImageAnalysis22-w.2022.00001.1</a></p>
<p><a class="reference external" href="https://drive.google.com/file/d/1MhuqfKhZcYu3bchWMqogIybKjamU5Msg/view">https://drive.google.com/file/d/1MhuqfKhZcYu3bchWMqogIybKjamU5Msg/view</a></p>
</section>
<hr class="docutils" />
<section id="microsam-talks">
<h2>MicroSam-Talks<a class="headerlink" href="#microsam-talks" title="Link to this heading">#</a></h2>
<p>Constantin Pape</p>
<p>Published 2024-05-23</p>
<p>Licensed CC-BY-4.0</p>
<p>Talks about Segment Anything for Microscopy: <a class="github reference external" href="https://github.com/computational-cell-analytics/micro-sam">computational-cell-analytics/micro-sam</a>.
Currently contains slides for two talks:</p>
<p>Overview of Segment Anythign for Microscopy given at the SWISSBIAS online meeting in April 2024
Talk about vision foundation models and Segment Anything for Microscopy given at Human Technopole as part of the EMBO Deep Learning Course in May 2024</p>
<p>Tags: Bioimage Analysis, Artificial Intelligence</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/11265038">https://zenodo.org/records/11265038</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11265038">https://doi.org/10.5281/zenodo.11265038</a></p>
</section>
<hr class="docutils" />
<section id="microscopy-data-analysis-machine-learning-and-the-bioimage-archive">
<h2>Microscopy data analysis: machine learning and the BioImage Archive<a class="headerlink" href="#microscopy-data-analysis-machine-learning-and-the-bioimage-archive" title="Link to this heading">#</a></h2>
<p>Andrii Iudin, Anna Foix-Romero, Anna Kreshuk, Awais Athar, Beth Cimini, Dominik Kutra, Estibalis Gomez de Mariscal, Frances Wong, Guillaume Jacquemet, Kedar Narayan, Martin Weigert, Nodar Gogoberidze, Osman Salih, Petr Walczysko, Ryan Conrad, Simone Weyend, Sriram Sundar Somasundharam, Suganya Sivagurunathan, Ugis Sarkans</p>
<p>Licensed CC-BY-4.0</p>
<p>The Microscopy data analysis: machine learning and the BioImage Archive course, which focused on introducing programmatic approaches used in the analysis of bioimage data via the BioImage Archive, ran in May 2023.</p>
<p>Tags: Bioimage Analysis, Python, Artificial Intelligence</p>
<p>Content type: Video, Slides</p>
<p><a class="reference external" href="https://www.ebi.ac.uk/training/materials/microscopy-data-analysis-machine-learning-and-the-bioimage-archive-materials/">https://www.ebi.ac.uk/training/materials/microscopy-data-analysis-machine-learning-and-the-bioimage-archive-materials/</a></p>
</section>
<hr class="docutils" />
<section id="microscopy-bids-an-extension-to-the-brain-imaging-data-structure-for-microscopy-data">
<h2>Microscopy-BIDS - An Extension to the Brain Imaging Data Structure for Microscopy Data<a class="headerlink" href="#microscopy-bids-an-extension-to-the-brain-imaging-data-structure-for-microscopy-data" title="Link to this heading">#</a></h2>
<p>Marie-Hélène Bourget, Lee Kamentsky, Satrajit S. Ghosh, Giacomo Mazzamuto, Alberto Lazari, et al.</p>
<p>Published 2022-04-19</p>
<p>Licensed CC-BY-4.0</p>
<p>The Brain Imaging Data Structure (BIDS) is a specification for organizing, sharing, and archiving neuroimaging data and metadata in a reusable way.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2022.871228/full">https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2022.871228/full</a></p>
</section>
<hr class="docutils" />
<section id="modeling-community-standards-for-metadata-as-templates-makes-data-fair">
<h2>Modeling community standards for metadata as templates makes data FAIR<a class="headerlink" href="#modeling-community-standards-for-metadata-as-templates-makes-data-fair" title="Link to this heading">#</a></h2>
<p>Mark A Musen, Martin J O’Connor, Erik Schultes, Marcos Martínez-Romero, Josef Hardi, John Graybeal</p>
<p>Published 2022-11-12</p>
<p>Licensed CC-BY-4.0</p>
<p>The authors have developed a model for scientific metadata, and they have made that model usable by both CEDAR and FAIRware. The approach shows that a formal metadata model can standardize reporting guidelines and that it can enable separate software systems to assist (1) in the authoring of standards-adherent metadata and (2) in the evaluation of existing metadata.</p>
<p>Tags: Data Stewardship, FAIR-Principles, Metadata</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/36371407/">https://pubmed.ncbi.nlm.nih.gov/36371407/</a></p>
<p><a class="reference external" href="https://www.nature.com/articles/s41597-022-01815-3">https://www.nature.com/articles/s41597-022-01815-3</a></p>
</section>
<hr class="docutils" />
<section id="modular-training-resources-for-bioimage-analysis">
<h2>Modular training resources for bioimage analysis<a class="headerlink" href="#modular-training-resources-for-bioimage-analysis" title="Link to this heading">#</a></h2>
<p>Christian Tischer, Antonio Politi, Tim-Oliver Buchholz, Elnaz Fazeli, Nicola Gritti, Aliaksandr Halavatyi, Sebastian Gonzalez Tirado, Julian Hennies, Toby Hodges, Arif Khan, Dominik Kutra, Stefania Marcotti, Bugra Oezdemir, Felix Schneider, Martin Schorb, Anniek Stokkermans, Yi Sun, Nima Vakili</p>
<p>Published 2024-12-03</p>
<p>Licensed CC-BY-4.0</p>
<p>Resources for teaching/preparing to teach bioimage analysis</p>
<p>Tags: Neubias, Bioimage Analysis</p>
<p><a class="reference external" href="https://zenodo.org/records/14264885">https://zenodo.org/records/14264885</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14264885">https://doi.org/10.5281/zenodo.14264885</a></p>
</section>
<hr class="docutils" />
<section id="morphological-analysis-of-neural-cells-with-weka-and-snt-fiji-plugins">
<h2>Morphological analysis of neural cells with WEKA and SNT Fiji plugins<a class="headerlink" href="#morphological-analysis-of-neural-cells-with-weka-and-snt-fiji-plugins" title="Link to this heading">#</a></h2>
<p>Daniel Waiger</p>
<p>Published 2022-07-14</p>
<p>Licensed CC-BY-4.0</p>
<p>A simple workflow to detect Soma and neurite paths, from light microscopy datasets.</p>
<p>Using open-source tools for beginners.</p>
<p><a class="reference external" href="https://zenodo.org/records/6834214">https://zenodo.org/records/6834214</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6834214">https://doi.org/10.5281/zenodo.6834214</a></p>
</section>
<hr class="docutils" />
<section id="multi-template-matching-for-object-detection-slides">
<h2>Multi-Template-Matching for object-detection (slides)<a class="headerlink" href="#multi-template-matching-for-object-detection-slides" title="Link to this heading">#</a></h2>
<p>Laurent Thomas</p>
<p>Published 2022-05-16</p>
<p>Licensed CC-BY-4.0</p>
<p>This presentations describes Multi-Template-Matching, a novel method extending on template-matching for object-detection in images.</p>
<p>The project was part of the PhD project of Laurent Thomas between 2017 and 2020, under supervision of Jochen Gehrig. The project was hosted at ACQUIFER Imaging with collaboration of the medical university of Heidelberg, and part of the ImageInLife Horizon2020 ITN (PhD program). </p>
<p><a class="reference external" href="https://zenodo.org/records/6554166">https://zenodo.org/records/6554166</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6554166">https://doi.org/10.5281/zenodo.6554166</a></p>
</section>
<hr class="docutils" />
<section id="multiplexed-histology-of-covid-19-post-mortem-lung-samples-control-case-1-fov1">
<h2>Multiplexed histology of COVID-19 post-mortem lung samples - CONTROL CASE 1 FOV1<a class="headerlink" href="#multiplexed-histology-of-covid-19-post-mortem-lung-samples-control-case-1-fov1" title="Link to this heading">#</a></h2>
<p>Anna Pascual Reguant, Ronja Mothes, Helena Radbruch, Anja E. Hauser</p>
<p>Published 2022-12-16</p>
<p>Licensed CC-BY-4.0</p>
<p>Image-based data set of a post-mortem lung sample from a non-COVID-related pneumonia donor (CONTROL CASE 1, FOV1)</p>
<p>Each image shows the same field of view (FOV), sequentially stained with the depicted fluorescence-labelled antibodies, including surface proteins, intracellular proteins and transcription factors. Images contain 2024 x 2024 pixels and are generated using an inverted wide-field fluorescence microscope with a 20x objective, a lateral resolution of 325 nm and an axial resolution above 5 µm. Images have been normalized and intensities adjusted.</p>
<p><a class="reference external" href="https://zenodo.org/records/7447491">https://zenodo.org/records/7447491</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7447491">https://doi.org/10.5281/zenodo.7447491</a></p>
</section>
<hr class="docutils" />
<section id="multiplexed-tissue-imaging-tools-and-approaches">
<h2>Multiplexed tissue imaging - tools and approaches<a class="headerlink" href="#multiplexed-tissue-imaging-tools-and-approaches" title="Link to this heading">#</a></h2>
<p>Agustín Andrés Corbat, OmFrederic, Jonas Windhager, Kristína Lidayová</p>
<p>Licensed CC-BY-4.0</p>
<p>Material for the I2K 2024 “Multiplexed tissue imaging - tools and approaches” workshop</p>
<p>Tags: Bioimage Analysis</p>
<p>Content type: Github Repository, Slides, Workshop</p>
<p><a class="github reference external" href="https://github.com/BIIFSweden/I2K2024-MTIWorkshop">BIIFSweden/I2K2024-MTIWorkshop</a></p>
<p><a class="reference external" href="https://docs.google.com/presentation/d/1R9-4lXAmTYuyFZpTMDR85SjnLsPZhVZ8/edit#slide=id.p1">https://docs.google.com/presentation/d/1R9-4lXAmTYuyFZpTMDR85SjnLsPZhVZ8/edit#slide=id.p1</a></p>
</section>
<hr class="docutils" />
<section id="my-journey-through-bioimage-analysis-teaching-methods-from-classroom-to-cloud">
<h2>My Journey Through Bioimage Analysis Teaching Methods From Classroom to Cloud<a class="headerlink" href="#my-journey-through-bioimage-analysis-teaching-methods-from-classroom-to-cloud" title="Link to this heading">#</a></h2>
<p>Elnaz Fazeli</p>
<p>Published 2024-02-19</p>
<p>Licensed CC-BY-4.0</p>
<p>In these slides I introducemy journey through teaching bioimage analysis courses in different formats, from in person courses to online material. I have an overview of different training formats and comparing these for different audiences. </p>
<p>Tags: Teaching</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/10679054">https://zenodo.org/records/10679054</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10679054">https://doi.org/10.5281/zenodo.10679054</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage">
<h2>NFDI4BIOIMAGE<a class="headerlink" href="#nfdi4bioimage" title="Link to this heading">#</a></h2>
<p>Carsten Fortmann-Grote</p>
<p>Published 2024-04-22</p>
<p>Licensed CC-BY-4.0</p>
<p>This presentation was given at the 2nd MPG-NFDI Workshop on April 18th.</p>
<p><a class="reference external" href="https://zenodo.org/records/11031747">https://zenodo.org/records/11031747</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11031747">https://doi.org/10.5281/zenodo.11031747</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis-online-kick-off-2023">
<h2>NFDI4BIOIMAGE - National Research Data Infrastructure for Microscopy and BioImage Analysis - Online Kick-Off 2023<a class="headerlink" href="#nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis-online-kick-off-2023" title="Link to this heading">#</a></h2>
<p>Stefanie Weidtkamp-Peters</p>
<p>Licensed CC-BY-4.0</p>
<p>NFDI4BIOIMAGE core mission, bioimage data challenge, task areas, FAIR bioimage workflows.</p>
<p>Tags: Research Data Management, FAIR-Principles, Bioimage Analysis, Nfdi4Bioimage</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8070038">https://doi.org/10.5281/zenodo.8070038</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis-conference-talk-the-pelagic-imaging-consortium-meets-helmholtz-imaging-5-10-2023-hamburg">
<h2>NFDI4BIOIMAGE - National Research Data Infrastructure for Microscopy and BioImage Analysis [conference talk: The Pelagic Imaging Consortium meets Helmholtz Imaging, 5.10.2023, Hamburg]<a class="headerlink" href="#nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis-conference-talk-the-pelagic-imaging-consortium-meets-helmholtz-imaging-5-10-2023-hamburg" title="Link to this heading">#</a></h2>
<p>Riccardo Massei</p>
<p>Licensed CC-BY-4.0</p>
<p>NFDI4BIOIMAGE is a consortium within the framework of the National Research Data Infrastructure (NFDI) in Germany. In this talk, the consortium and the contribution to the work programme by the Helmholtz Centre for Environmental Research (UFZ) in Leipzig are outlined.</p>
<p>Tags: Research Data Management, Bioimage Analysis, Nfdi4Bioimage</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.8414318">https://zenodo.org/doi/10.5281/zenodo.8414318</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis">
<h2>NFDI4BIOIMAGE - National Research Data Infrastructure for Microscopy and Bioimage Analysis<a class="headerlink" href="#nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis" title="Link to this heading">#</a></h2>
<p>NFDI4BIOIMAGE Consortium</p>
<p>Published 2024-08-07</p>
<p>Licensed CC-BY-4.0</p>
<p>Bioimaging refers to a collection of methods to visualize the internal structures and mechanisms of living organisms. The fundamental tool, the microscope, has enabled seminal discoveries like that of the cell as the smallest unit of life, and continues to expand our understanding of biological processes. Today, we can follow the interaction of single molecules within nanoseconds in a living cell, and the development of complete small organisms like fish and flies over several days starting from the fertilized egg. Each image pixel encodes multiple spatiotemporal and spectral dimensions, compounding the massive volume and complexity of bioimage data. Proper handling of this data is indispensable for analysis and its lack has become a growing hindrance for the many disciplines of the life and biomedical sciences relying on bioimaging. No single domain has the expertise to tackle this bottleneck alone.
As a method-specific consortium, NFDI4BIOMAGE seeks to address these issues, enabling bioimaging data to be shared and re-used like they are acquired, i.e., independently of disciplinary boundaries. We will provide solutions for exploiting the full information content of bioimage data and enable new discoveries through sharing and re-analysis. Our RDM strategy is based on a robust needs analysis that derives not only from a community survey but also from over a decade of experience in German BioImaging, the German Society for Microscopy and Image Analysis. It considers the entire lifecycle of bioimaging data, from acquisition to archiving, including analysis and enabling re-use. A foundational element of this strategy is the definition of a common, cloud-compatible, and interoperable digital object that bundles binary images with their descriptive and provenance metadata. With members from plant biology to neuroscience, NFDI4BIOIMAGE will champion the standardization of bioimage data to create a framework that answers discipline-specific needs while ensuring communication and interoperability with data types and RDM systems across domains. Integration of bioimage data with, e.g., omics data as the basis for spatial omics, holds great promise for fields such as cancer medicine. Unlocking the full potential of bioimage data will rely on the development and broad availability of exceptional analysis tools and training sets. NFDI4BIOIMAGE will make these accessible and usable including cutting-edge AI-based methods in scalable cloud environments. NFDI4BIOIMAGE intersects with multiple NFDI consortia, most prominently with GHGA for linking image and genomics data and with DataPLANT on the definition of FAIR data objects. Last but not least, NFDI4BIOIMAGE is internationally well connected and represents the opportunity for German scientists to keep path with and have a voice in several international initiatives focusing on the FAIRification of bioimage data as one of the main challenges for the advancement of knowledge in the life and biomedical sciences.</p>
<p><a class="reference external" href="https://zenodo.org/records/13168693">https://zenodo.org/records/13168693</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13168693">https://doi.org/10.5281/zenodo.13168693</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-data-management-illustrations-by-henning-falk">
<h2>NFDI4BIOIMAGE data management illustrations by Henning Falk<a class="headerlink" href="#nfdi4bioimage-data-management-illustrations-by-henning-falk" title="Link to this heading">#</a></h2>
<p>NFDI4BIOIMAGE Consortium</p>
<p>Published 2024-11-29</p>
<p>Licensed CC-BY-4.0</p>
<p>These illustrations were contracted by the Heinrich Heine University Düsseldorf in the frame of the consortium NFDI4BIOIMAGE from Henning Falk for the purpose of education and public outreach. The illustrations are free to use under a CC-BY 4.0 license.AttributionPlease include an attribution similar to: “Data annoation matters”, NFDI4BIOIMAGE Consortium (2024): NFDI4BIOIMAGE data management illustrations by Henning Falk, Zenodo, <a class="reference external" href="https://doi.org/10.5281/zenodo.14186100">https://doi.org/10.5281/zenodo.14186100</a>, is used under a CC-BY 4.0 license. Modifications to this illustration include cropping.
 </p>
<p>Tags: Nfdi4Bioimage, Research Data Management</p>
<p><a class="reference external" href="https://zenodo.org/records/14186101">https://zenodo.org/records/14186101</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14186101">https://doi.org/10.5281/zenodo.14186101</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-perspective-for-a-national-bioimaging-standard">
<h2>NFDI4BIOIMAGE: Perspective for a national bioimaging standard<a class="headerlink" href="#nfdi4bioimage-perspective-for-a-national-bioimaging-standard" title="Link to this heading">#</a></h2>
<p>Josh Moore, Susanne Kunis</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Nfdi4Bioimage</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://ceur-ws.org/Vol-3415/paper-27.pdf">https://ceur-ws.org/Vol-3415/paper-27.pdf</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon">
<h2>NFDI4Bioimage - TA3-Hackathon - UoC-2023 (Cologne Hackathon)<a class="headerlink" href="#nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon" title="Link to this heading">#</a></h2>
<p>Mohamed M. Abdrabbou, Mehrnaz Babaki, Tom Boissonnet, Michele Bortolomeazzi, Eik Dahms, Vanessa A. F. Fuchs, Moritz Hoevels, Niraj Kandpal, Christoph Möhl, Joshua A. Moore, Astrid Schauss, Andrea Schrader, Torsten Stöter, Julia Thönnißen, Monica Valencia-S., H. Lukas Weil, Jens Wendt and Peter Zentis</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Arc, Dataplant, Hackathon, Nfdi4Bioimage, OMERO, Python, Research Data Management</p>
<p>Content type: Event, Publication, Documentation</p>
<p><a class="github reference external" href="https://github.com/NFDI4BIOIMAGE/Cologne-Hackathon-2023">NFDI4BIOIMAGE/Cologne-Hackathon-2023</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10609770">https://doi.org/10.5281/zenodo.10609770</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon-2023-github-repository">
<h2>NFDI4Bioimage - TA3-Hackathon - UoC-2023 (Cologne-Hackathon-2023, GitHub repository)<a class="headerlink" href="#nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon-2023-github-repository" title="Link to this heading">#</a></h2>
<p>Mohamed Abdrabbou, Mehrnaz Babaki, Tom Boissonnet, Michele Bortolomeazzi, Eik Dahms, Vanessa Fuchs, A. F. Moritz Hoevels, Niraj Kandpal, Christoph Möhl, Joshua A. Moore, Astrid Schauss, Andrea Schrader, Torsten Stöter, Julia Thönnißen, Monica Valencia-S., H. Lukas Weil, Jens Wendt, Peter Zentis</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository documents the first NFDI4Bioimage - TA3-Hackathon - UoC-2023 (Cologne Hackathon), where topics like ‘Interoperability’, ‘REMBI / Mapping’, and ‘Neuroglancer (OMERO / zarr)’ were explored through collaborative discussions and workflow sessions, culminating in reports that bridge NFDI4Bioimage to DataPLANT. Funded by various DFG initiatives, this event emphasized documentation and use cases, contributing preparatory work for future interoperability projects at the 2nd de.NBI BioHackathon in Bielefeld.</p>
<p>Tags: Research Data Management, FAIR-Principles, Bioimage Analysis, Nfdi4Bioimage</p>
<p>Content type: Github Repository</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.10609770">https://zenodo.org/doi/10.5281/zenodo.10609770</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-calendar-2024-october-original-image">
<h2>NFDI4Bioimage Calendar 2024 October; original image<a class="headerlink" href="#nfdi4bioimage-calendar-2024-october-original-image" title="Link to this heading">#</a></h2>
<p>Christian Jüngst, Peter Zentis</p>
<p>Published 2024-09-25</p>
<p>Licensed CC-BY-4.0</p>
<p>Raw microscopy image from the NFDI4Bioimage calendar October 2024</p>
<p>Tags: Nfdi4Bioimage, Research Data Management</p>
<p><a class="reference external" href="https://zenodo.org/records/13837146">https://zenodo.org/records/13837146</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13837146">https://doi.org/10.5281/zenodo.13837146</a></p>
</section>
<hr class="docutils" />
<section id="new-kid-on-the-nfdi-block-nfdi4bioimage-a-national-initiative-for-fair-data-management-in-bioimaging-and-bioimage-analysis">
<h2>New Kid on the (NFDI) Block: NFDI4BIOIMAGE  - A National Initiative for FAIR Data Management in Bioimaging and Bioimage Analysis<a class="headerlink" href="#new-kid-on-the-nfdi-block-nfdi4bioimage-a-national-initiative-for-fair-data-management-in-bioimaging-and-bioimage-analysis" title="Link to this heading">#</a></h2>
<p>Cornelia Wetzker</p>
<p>Published 2024-10-29</p>
<p>Licensed CC-BY-4.0</p>
<p>The poster introduces the consortium NFDI4BIOIMAGE with its central objectives, provides an overview of challenges in bioimage data handling, sharing and analysis and lists support options by the consortium through its data stewardship team.
It is part of the work of the German consortium NFDI4BIOIMAGE funded by the Deutsche Forschungsgemeinschaft (DFG grant number NFDI 46/1, project number 501864659) and has been presented at the conference FDM&#64;Campus held in Göttingen September 23-25, 2024.</p>
<p><a class="reference external" href="https://zenodo.org/records/14006558">https://zenodo.org/records/14006558</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14006558">https://doi.org/10.5281/zenodo.14006558</a></p>
</section>
<hr class="docutils" />
<section id="nextflow-scalable-and-reproducible-scientific-workflows">
<h2>Nextflow: Scalable and reproducible scientific workflows<a class="headerlink" href="#nextflow-scalable-and-reproducible-scientific-workflows" title="Link to this heading">#</a></h2>
<p>Floden Evan, Di Tommaso Paolo</p>
<p>Published 2020-12-17</p>
<p>Licensed CC-BY-4.0</p>
<p>Nextflow is an open-source workflow management system that prioritizes portability and reproducibility. It enables users to develop and seamlessly scale genomics workflows locally, on HPC clusters, or in major cloud providers’ infrastructures. Developed since 2014 and backed by a fast-growing community, the Nextflow ecosystem is made up of users and developers across academia, government and industry. It counts over 1M downloads and over 10K users worldwide.</p>
<p>Tags: Workflow Engine</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/4334697">https://zenodo.org/records/4334697</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4334697">https://doi.org/10.5281/zenodo.4334697</a></p>
</section>
<hr class="docutils" />
<section id="ome-documentation">
<h2>OME Documentation<a class="headerlink" href="#ome-documentation" title="Link to this heading">#</a></h2>
<p>Licensed CC-BY-4.0</p>
<p>Tags: OMERO</p>
<p>Content type: Documentation</p>
<p><a class="reference external" href="https://www.openmicroscopy.org/docs/">https://www.openmicroscopy.org/docs/</a></p>
</section>
<hr class="docutils" />
<section id="ome-ngff-a-next-generation-file-format-for-expanding-bioimaging-data-access-strategies">
<h2>OME-NGFF: a next-generation file format for expanding bioimaging data-access strategies<a class="headerlink" href="#ome-ngff-a-next-generation-file-format-for-expanding-bioimaging-data-access-strategies" title="Link to this heading">#</a></h2>
<p>Josh Moore, Chris Allan, Sébastien Besson, jean-marie burel, Erin Diel, David Gault, Kevin Kozlowski, Dominik Lindner, Melissa Linkert, Trevor Manz, Will Moore, Constantin Pape, Christian Tischer, Jason R. Swedlow</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Nfdi4Bioimage, Research Data Management</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.nature.com/articles/s41592-021-01326-w">https://www.nature.com/articles/s41592-021-01326-w</a></p>
</section>
<hr class="docutils" />
<section id="ome2024-ngff-challenge-results">
<h2>OME2024 NGFF Challenge Results<a class="headerlink" href="#ome2024-ngff-challenge-results" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Published 2024-11-01</p>
<p>Licensed CC-BY-4.0</p>
<p>Presented at the 2024 FoundingGIDE event in Okazaki, Japan: <a class="reference external" href="https://founding-gide.eurobioimaging.eu/event/foundinggide-community-event-2024/">https://founding-gide.eurobioimaging.eu/event/foundinggide-community-event-2024/</a>
Note: much of the presentation was a demonstration of the OME2024-NGFF-Challenge – <a class="reference external" href="https://ome.github.io/ome2024-ngff-challenge/">https://ome.github.io/ome2024-ngff-challenge/</a> especially of querying an extraction of the metadata (<a class="github reference external" href="https://github.com/ome/ome2024-ngff-challenge-metadata">ome/ome2024-ngff-challenge-metadata</a>)
 </p>
<p>Tags: Nfdi4Bioimage, Research Data Management</p>
<p><a class="reference external" href="https://zenodo.org/records/14234608">https://zenodo.org/records/14234608</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14234608">https://doi.org/10.5281/zenodo.14234608</a></p>
</section>
<hr class="docutils" />
<section id="omero-tools">
<h2>Omero-tools<a class="headerlink" href="#omero-tools" title="Link to this heading">#</a></h2>
<p>Johannes Soltwedel</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository contains a collection of tools for working with OMERO. Such tools can be working with the OMERO command line interface to transfer datasets between repositories, etc.</p>
<p>Tags: OMERO, Bioimage Analysis</p>
<p>Content type: Github Repository</p>
<p><a class="reference external" href="https://biapol.github.io/omero-tools/">https://biapol.github.io/omero-tools/</a></p>
</section>
<hr class="docutils" />
<section id="open-image-data-handbook">
<h2>Open Image Data Handbook<a class="headerlink" href="#open-image-data-handbook" title="Link to this heading">#</a></h2>
<p>Kevin Yamauchi</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Neubias, Research Data Management, Napari, Python, Bioimage Analysis</p>
<p>Content type: Book, Notebook</p>
<p><a class="reference external" href="https://kevinyamauchi.github.io/open-image-data/intro.html">https://kevinyamauchi.github.io/open-image-data/intro.html</a></p>
</section>
<hr class="docutils" />
<section id="open-micoscropy-environment-ome-youtube-channel">
<h2>Open Micoscropy Environment (OME) Youtube Channel<a class="headerlink" href="#open-micoscropy-environment-ome-youtube-channel" title="Link to this heading">#</a></h2>
<p>Published None</p>
<p>Licensed CC-BY-4.0</p>
<p>OME develops open-source software and data format standards for the storage and manipulation of biological microscopy data</p>
<p>Tags: Open Source Software</p>
<p>Content type: Video, Collection</p>
<p><a class="reference external" href="https://www.youtube.com/&#64;OpenMicroscopyEnvironment">https://www.youtube.com/&#64;OpenMicroscopyEnvironment</a></p>
</section>
<hr class="docutils" />
<section id="open-science-sharing-licensing">
<h2>Open Science, Sharing &amp; Licensing<a class="headerlink" href="#open-science-sharing-licensing" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-04-18</p>
<p>Licensed CC-BY-4.0</p>
<p>Wir tauchen ein in die Welt der Open Science und definieren Begriffe wie Open Source, Open Access und die FAIR-Prinzipien (Findable, Accessible, Interoperable and Reuasable). Wir diskutieren, wie diese Methoden der [wissenschaftlichen] Kommunikation und des Datenmanagements die Welt verändern und wie wir sie praktisch in unsere Arbeit integrieren können. Dabei spielen Aspekte wie Copyright und Lizenzierung eine wichtige Rolle.</p>
<p>Tags: Research Data Management, Open Access, FAIR-Principles, Licensing</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/10990107">https://zenodo.org/records/10990107</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10990107">https://doi.org/10.5281/zenodo.10990107</a></p>
</section>
<hr class="docutils" />
<section id="optimisation-and-validation-of-a-swarm-intelligence-based-segmentation-algorithm-for-low-contrast-positron-emission-tomography">
<h2>Optimisation and Validation of a Swarm Intelligence based Segmentation Algorithm for low Contrast Positron Emission Tomography<a class="headerlink" href="#optimisation-and-validation-of-a-swarm-intelligence-based-segmentation-algorithm-for-low-contrast-positron-emission-tomography" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2014-04-01</p>
<p>Licensed CC-BY-4.0</p>
<p>In the field of radiooncological research, individualised therapy is one of the hot topics at the moment. As a key aspect biologically-adapted therapy is discussed. Therapy adaption based on biological parameters may include tomographic imaging to determine biological properties of the tumour. One often invoked imaging modality is positron emission tomography (PET) using the tracer [18F]-fluoromisonidazole (FMISO) for hypoxia imaging. Hypoxia imaging is of interest, because hypoxic tumours are known to be radiorestistant. Even further, patients with hypoxic tumours have worse prognosis compared to patients with normoxic tumours. Thus, hypoxia imaging appears promising for radiotherapy treatment adaption. For example, volumetric analysis of FMISO PET could deliver additional hypoxia target volumes, which may be irradiated with higher radiation doses to improve the therapeutic effect. However, limited contrast between target volume and background in FMISO PET images interferes image analysis.Established methods for target volume delineation in PET do not allow determination of reliable contours in FMISO PET. To tackle this aspect, this thesis focusses on an earlier developed swarm intelligence based segmentation algorithm for FMISO PET and rather, its optimisation and validation in a clinically relevant setting. In this setting, clinical FMISO PET images were used which were acquired as part of a clinical trial performed at the Clinic and Policlinic for Radiation Therapy and Radiooncology of the University Hospital Carl Gustav Carus Dresden. The segmentation algorithm was applied to these imaging data sets and optimised using a cross-validation approach incorporating reference contours from experienced observers who outlined FMISO PET positive volumes manually. Afterwards, the performance of the algorithm and the properties of the resulting contours were studied in more detail. The algorithm was shown to deliver contours which were similar to manually-created contours to a degree like manually-created contours were similar to each other. Thus, the application of the algorithm in clinical research is recommended to eliminate inter-observer-variabilities. Finally, it was shown that repeated FMISO PET imaging before and shortly after the beginning of combined radiochemotherapy lead to manually-created contours with significantly higher variations than the variations of automatically-created contours using the proposed algorithm. Increased contour similarity in subsequently acquired imaging data highlights the observer-independence of the algorithm. While several observers outline different volumes, in identical data sets as well as in subsequent imaging data sets, the algorithm outlines more stable volumes in both cases. Thus, increased contour reproducibility is reached by automation of the delineation process by the proposed algorithm. </p>
<p><a class="reference external" href="https://zenodo.org/records/7209862">https://zenodo.org/records/7209862</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7209862">https://doi.org/10.5281/zenodo.7209862</a></p>
</section>
<hr class="docutils" />
<section id="optimized-cranial-window-implantation-for-subcellular-and-functional-imaging-in-vivo">
<h2>Optimized cranial window implantation for subcellular and functional imaging in vivo<a class="headerlink" href="#optimized-cranial-window-implantation-for-subcellular-and-functional-imaging-in-vivo" title="Link to this heading">#</a></h2>
<p>Ben Vermaercke</p>
<p>Published 2025-01-13</p>
<p>Licensed CC-BY-4.0</p>
<p>Intravital workshop 15/11/2024</p>
<p><a class="reference external" href="https://zenodo.org/records/14641777">https://zenodo.org/records/14641777</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14641777">https://doi.org/10.5281/zenodo.14641777</a></p>
</section>
<hr class="docutils" />
<section id="overview-of-the-galaxy-omero-suite-upload-images-and-metadata-in-omero-using-galaxy">
<h2>Overview of the Galaxy OMERO-suite - Upload images and metadata in OMERO using Galaxy<a class="headerlink" href="#overview-of-the-galaxy-omero-suite-upload-images-and-metadata-in-omero-using-galaxy" title="Link to this heading">#</a></h2>
<p>Riccardo Massei, Björn Grüning</p>
<p>Published 2024-12-02</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: OMERO, Galaxy, Metadata, Nfdi4Bioimage</p>
<p>Content type: Tutorial, Framework, Workflow</p>
<p><a class="reference external" href="https://training.galaxyproject.org/training-material/topics/imaging/tutorials/omero-suite/tutorial.html">https://training.galaxyproject.org/training-material/topics/imaging/tutorials/omero-suite/tutorial.html</a></p>
</section>
<hr class="docutils" />
<section id="parallelization-and-heterogeneous-computing-from-pure-cpu-to-gpu-accelerated-image-processing">
<h2>Parallelization and heterogeneous computing: from pure CPU to GPU-accelerated image processing<a class="headerlink" href="#parallelization-and-heterogeneous-computing-from-pure-cpu-to-gpu-accelerated-image-processing" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Licensed CC-BY-4.0</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://f1000research.com/slides/11-1171">https://f1000research.com/slides/11-1171</a></p>
<p><a class="reference external" href="https://doi.org/10.7490/f1000research.1119154.1">https://doi.org/10.7490/f1000research.1119154.1</a></p>
</section>
<hr class="docutils" />
<section id="photonic-data-analysis-in-2050">
<h2>Photonic data analysis in 2050<a class="headerlink" href="#photonic-data-analysis-in-2050" title="Link to this heading">#</a></h2>
<p>Oleg Ryabchykov, Shuxia Guo, Thomas Bocklitz</p>
<p>Licensed CC-BY-4.0</p>
<p>Photonic data analysis, combining imaging, spectroscopy, machine learning, and computer science, requires flexible methods and interdisciplinary collaborations to advance. Essential developments include standardizing data infrastructure for comparability, optimizing data-driven models for complex investigations, and creating techniques to handle limited or unbalanced data and device variations.</p>
<p>Tags: FAIR-Principles, Machine Learning, Research Data Management</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://doi.org/10.1016/j.vibspec.2024.103685">https://doi.org/10.1016/j.vibspec.2024.103685</a></p>
</section>
<hr class="docutils" />
<section id="pol-bio-image-analysis-training-school-on-gpu-accelerated-image-analysis">
<h2>PoL Bio-Image Analysis Training School on GPU-Accelerated Image Analysis<a class="headerlink" href="#pol-bio-image-analysis-training-school-on-gpu-accelerated-image-analysis" title="Link to this heading">#</a></h2>
<p>Stephane Rigaud, Brian Northan, Till Korten, Neringa Jurenaite, Apurv Deepak Kulkarni, Peter Steinbach, Sebastian Starke, Johannes Soltwedel, Marvin Albert, Robert Haase</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository hosts notebooks, information and data for the GPU-Accelerated Image Analysis Track of the PoL Bio-Image Analysis Symposium.</p>
<p>Tags: Gpu, Clesperanto, Dask, Python</p>
<p>Content type: Notebook</p>
<p><a class="github reference external" href="https://github.com/BiAPoL/PoL-BioImage-Analysis-TS-GPU-Accelerated-Image-Analysis/">BiAPoL/PoL-BioImage-Analysis-TS-GPU-Accelerated-Image-Analysis</a></p>
</section>
<hr class="docutils" />
<section id="practical-guide-to-the-international-alignment-of-research-data-management-extended-edition">
<h2>Practical Guide to the International Alignment of Research Data Management - Extended Edition<a class="headerlink" href="#practical-guide-to-the-international-alignment-of-research-data-management-extended-edition" title="Link to this heading">#</a></h2>
<p>Licensed CC-BY-4.0</p>
<p>Content type: Book</p>
<p><a class="reference external" href="https://www.scienceeurope.org/our-resources/practical-guide-to-the-international-alignment-of-research-data-management/">https://www.scienceeurope.org/our-resources/practical-guide-to-the-international-alignment-of-research-data-management/</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4915861">https://doi.org/10.5281/zenodo.4915861</a></p>
</section>
<hr class="docutils" />
<section id="preprint-be-sustainable-recommendations-for-fair-resources-in-life-sciences-research-eosc-life-s-lessons">
<h2>Preprint: “Be Sustainable”, Recommendations for FAIR Resources in Life Sciences research: EOSC-Life’s Lessons<a class="headerlink" href="#preprint-be-sustainable-recommendations-for-fair-resources-in-life-sciences-research-eosc-life-s-lessons" title="Link to this heading">#</a></h2>
<p>Romain David, Arina Rybina, jean-marie burel, Jean-Karim Heriche, Pauline Audergon, Jan-Willem Boiten, Frederik Coppens, Sara Crockett, Exter Katrina, Sven Fahrener, Maddalena Fratelli, Carole Goble, Philipp Gormanns, Tobias Grantner, Bjorn Gruning, Kim Tamara Gurwitz, John Hancock, Henriette Harmse, Petr Holub, Nick Juty, Geoffrey Karnbach, Emma Karoune, Antje Keppler, Jessica Klemeier, Carla Lancelotti, Jean-Luc Legras, L. Allyson Lister, Dario Livio Longo, Rebecca Ludwig, Benedicte Madon, Marzia Massimi, Vera Matser, Rafaele Matteoni, Mayrhofer Michaela Th., Christian Ohmann, Maria Panagiotopoulou, Helen Parkinson, Isabelle Perseil, Claudia Pfander, Roland Pieruschka, Michael Raess, Andreas Rauber, Audrey S. Richard, Paolo Romano, Antonio Rosato, Alex Sanchez-Pla, Susanna-Assunta Sansone, Ugis Sarkans, Beatriz Serrano-Solano, Jing Tang, Ziaurrehman Tanoli, Jonathan Tedds, Harald Wagener, Martin Weise, Hans V. Westerhoff, Rudolf Wittner, Jonathan Ewbank, Niklas Blomberg, Philip Gribbon</p>
<p>Published 2023-09-12</p>
<p>Licensed CC-BY-4.0</p>
<p>“Be SURE - Be SUstainable REcommendations”The main goals and challenges for the Life Science (LS) communities in the Open Science framework are to increase reuse and sustainability of data resources, software tools, and workflows, especially in large-scale data-driven research and computational analyses. Here, we present key findings, procedures, effective measures and recommendations for generating and establishing sustainable LS resources based on the collaborative, cross-disciplinary work done within the EOSC-Life (European Open Science Cloud for Life Sciences) consortium. Bringing together 13 European LS Research Infrastructures (RIs), it has laid the foundation for an open, digital space to support biological and medical research. Using lessons learned from 27 selected projects, we describe the organisational, technical, financial and legal/ethical challenges that represent the main barriers to sustainability in the life sciences. We show how EOSC-Life provides a model for sustainable FAIR data management, including solutions for sensitive- and industry-related resources, by means of cross-disciplinary training and best practices sharing. Finally, we illustrate how data harmonisation and collaborative work facilitate interoperability of tools, data, solutions and lead to a better understanding of concepts, semantics and functionalities in the life <a class="reference external" href="http://sciences.IN">sciences.IN</a> PRESS EMBO Journal: <a class="reference external" href="https://www.embopress.org/journal/14602075&amp;amp;nbsp;AVAILABLE">https://www.embopress.org/journal/14602075&amp;nbsp;AVAILABLE</a> SOON at : <a class="reference external" href="https://doi.org/10.15252/embj.2023115008">https://doi.org/10.15252/embj.2023115008</a> </p>
<p><a class="reference external" href="https://zenodo.org/records/8338931">https://zenodo.org/records/8338931</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8338931">https://doi.org/10.5281/zenodo.8338931</a></p>
</section>
<hr class="docutils" />
<section id="prompt-engineering-agentic-workflows-and-multi-modal-large-language-models">
<h2>Prompt Engineering, Agentic Workflows and Multi-modal Large Language Models<a class="headerlink" href="#prompt-engineering-agentic-workflows-and-multi-modal-large-language-models" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2025-01-19</p>
<p>Licensed CC-BY-4.0</p>
<p>In these two slide-decks we explore applications of large language models. In the first slide deck we dive into prompt engineering, function calling and how to build agentic workflows. In the second slide-deck we explore multi-modal large language models focusing on vision language models and image generation models. </p>
<p><a class="reference external" href="https://zenodo.org/records/14692037">https://zenodo.org/records/14692037</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14692037">https://doi.org/10.5281/zenodo.14692037</a></p>
</section>
<hr class="docutils" />
<section id="qi-2024-analysis-lab-manual">
<h2>QI 2024 Analysis Lab Manual<a class="headerlink" href="#qi-2024-analysis-lab-manual" title="Link to this heading">#</a></h2>
<p>Beth Cimini, Florian Jug, QI 2024</p>
<p>Licensed CC-BY-4.0</p>
<p>This book contains the quantitative analysis labs for the QI CSHL course, 2024</p>
<p>Tags: Python</p>
<p>Content type: Notebook</p>
<p><a class="reference external" href="https://bethac07.github.io/qi_2024_analysis_lab_manual/intro.html">https://bethac07.github.io/qi_2024_analysis_lab_manual/intro.html</a></p>
</section>
<hr class="docutils" />
<section id="qm-course-lectures-on-bio-image-analysis-with-napari-2024">
<h2>QM Course Lectures on Bio-Image Analysis with napari 2024<a class="headerlink" href="#qm-course-lectures-on-bio-image-analysis-with-napari-2024" title="Link to this heading">#</a></h2>
<p>Marcelo Leomil Zoccoler</p>
<p>Licensed CC-BY-4.0</p>
<p>In these lectures, we will explore ways to analyze microscopy images with Python and visualize them with napari, an nD viewer open-source software. The analysis will be done in Python mostly using the scikit-image, pyclesperanto and apoc libraries, via Jupyter notebooks. We will also explore some napari plugins as an interactive and convenient alternative way of performing these analysis, especially the napari-assistant, napari-apoc and napari-flim-phasor-plotter plugins.</p>
<p>Tags: Napari, Python</p>
<p>Content type: Notebook</p>
<p><a class="reference external" href="https://zoccoler.github.io/QM_Course_Bio_Image_Analysis_with_napari_2024">https://zoccoler.github.io/QM_Course_Bio_Image_Analysis_with_napari_2024</a></p>
</section>
<hr class="docutils" />
<section id="quarep-limi-a-community-driven-initiative-to-establish-guidelines-for-quality-assessment-and-reproducibility-for-instruments-and-images-in-light-microscopy">
<h2>QUAREP-LiMi: A community-driven initiative to establish guidelines for quality assessment and reproducibility for instruments and images in light microscopy<a class="headerlink" href="#quarep-limi-a-community-driven-initiative-to-establish-guidelines-for-quality-assessment-and-reproducibility-for-instruments-and-images-in-light-microscopy" title="Link to this heading">#</a></h2>
<p>Glyn Nelson, Ulrike Boehme, et al.</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Quareo-Limi</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://onlinelibrary.wiley.com/doi/10.1111/jmi.13041">https://onlinelibrary.wiley.com/doi/10.1111/jmi.13041</a></p>
</section>
<hr class="docutils" />
<section id="qupath-open-source-software-for-analysing-awkward-images">
<h2>QuPath: Open source software for analysing (awkward) images<a class="headerlink" href="#qupath-open-source-software-for-analysing-awkward-images" title="Link to this heading">#</a></h2>
<p>Peter Bankhead</p>
<p>Published 2020-12-16</p>
<p>Licensed CC-BY-4.0</p>
<p>Slides from the CZI/EOSS online meeting in December 2020.</p>
<p>Tags: Bioimage Analysis</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/4328911">https://zenodo.org/records/4328911</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4328911">https://doi.org/10.5281/zenodo.4328911</a></p>
</section>
<hr class="docutils" />
<section id="rdf-as-a-bridge-to-domain-platforms-like-omero-or-there-and-back-again">
<h2>RDF as a bridge to domain-platforms like OMERO, or There and back again.<a class="headerlink" href="#rdf-as-a-bridge-to-domain-platforms-like-omero-or-there-and-back-again" title="Link to this heading">#</a></h2>
<p>Josh Moore, Andra Waagmeester, Kristina Hettne, Katherine Wolstencroft, Susanne Kunis</p>
<p>Licensed CC-BY-4.0</p>
<p>In 2005, the first version of OMERO stored RDF natively. However, just a year after the 1.0 release of RDF, performance considerations led to the development of a more traditional SQL approach for OMERO. A binary protocol makes it possible to query and retrieve metadata but the resulting information cannot immediately be combined with other sources. This is the adventure of rediscovering the benefit of RDF triples as a – if not the – common exchange mechanism.</p>
<p>Tags: Research Data Management, FAIR-Principles, Bioimage Analysis</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.10687658">https://zenodo.org/doi/10.5281/zenodo.10687658</a></p>
</section>
<hr class="docutils" />
<section id="rdm-starter-kit">
<h2>RDM Starter Kit<a class="headerlink" href="#rdm-starter-kit" title="Link to this heading">#</a></h2>
<p>GO FAIR</p>
<p>Licensed CC-BY-4.0</p>
<p>This page is supposed to serve as a Starter Kit for research data management (RDM). It lists resources designed to help researchers get started to organize their data.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Website</p>
<p><a class="reference external" href="https://www.go-fair.org/resources/rdm-starter-kit/">https://www.go-fair.org/resources/rdm-starter-kit/</a></p>
</section>
<hr class="docutils" />
<section id="rdm4mic-presentations">
<h2>RDM4Mic Presentations<a class="headerlink" href="#rdm4mic-presentations" title="Link to this heading">#</a></h2>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Research Data Management</p>
<p>Content type: Collection</p>
<p><a class="github reference external" href="https://github.com/German-BioImaging/RDM4mic/tree/master/presentations">German-BioImaging/RDM4mic</a></p>
</section>
<hr class="docutils" />
<section id="rdmkit-training-resources">
<h2>RDMKit Training Resources<a class="headerlink" href="#rdmkit-training-resources" title="Link to this heading">#</a></h2>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Research Data Management</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://rdmkit.elixir-europe.org/all_training_resources">https://rdmkit.elixir-europe.org/all_training_resources</a></p>
</section>
<hr class="docutils" />
<section id="research-data-management-on-campus-and-in-nfdi4bioimage">
<h2>RESEARCH DATA MANAGEMENT on Campus and in NFDI4BIOIMAGE<a class="headerlink" href="#research-data-management-on-campus-and-in-nfdi4bioimage" title="Link to this heading">#</a></h2>
<p>Cornelia Wetzker, Michael Schlierf</p>
<p>Published 2024-08-29</p>
<p>Licensed CC-BY-4.0</p>
<p>The poster is part of the work of the German consortium NFDI4BIOIMAGE funded by the Deutsche Forschungsgemeinschaft (DFG grant number NFDI 46/1, project number 501864659).</p>
<p><a class="reference external" href="https://zenodo.org/records/13684187">https://zenodo.org/records/13684187</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13684187">https://doi.org/10.5281/zenodo.13684187</a></p>
</section>
<hr class="docutils" />
<section id="rechtsfragen-bei-open-science-ein-leitfaden">
<h2>Rechtsfragen bei Open Science - Ein Leitfaden<a class="headerlink" href="#rechtsfragen-bei-open-science-ein-leitfaden" title="Link to this heading">#</a></h2>
<p>Till Kreutzer, Henning Lahmann</p>
<p>Published 2021-05-25</p>
<p>Licensed CC-BY-4.0</p>
<p>Die Digitalisierung ermöglicht eine offene Wissenschaft (Open Science). Diese hat viele Aspekte, insbesondere den freien Zugang zu wissenschaftlichen Veröffentlichungen und Materialien (Open Access), transparente Begutachtungsverfahren (Open Peer Review) oder quelloffene Technologien (Open Source). Das Programm Hamburg Open Science (Laufzeit 2018–2020) unterstützt unter anderem den Kulturwandel in der Wissenschaft. In diesem Kontext entstand der nun vorliegende Leitfaden, der das rechtliche Umfeld greifbar machen soll. Der Leitfaden erarbeitet die betroffenen Rechtsgebiete zunächst systematisch. Im zweiten Teil werden rechtliche Fragen zu Open Science beantwortet, die direkt aus den Universitäten und Bibliotheken kommen.</p>
<p>Tags: Open Science, Open Access, Copyright</p>
<p>Content type: Book</p>
<p><a class="reference external" href="https://hup.sub.uni-hamburg.de/oa-pub/catalog/book/205">https://hup.sub.uni-hamburg.de/oa-pub/catalog/book/205</a></p>
</section>
<hr class="docutils" />
<section id="reconstructed-images-of-a-2dsim-multiposition-acquisition">
<h2>Reconstructed images of a 2DSIM multiposition acquisition.<a class="headerlink" href="#reconstructed-images-of-a-2dsim-multiposition-acquisition" title="Link to this heading">#</a></h2>
<p>Louis Romette</p>
<p>Published 2025-02-19</p>
<p>Licensed CC-BY-4.0</p>
<p>Acquired with an Nikon SIM, in 2D-SIM mode at 488nm of excitation with 30% laser power and 200ms of exposition.  Fluorescence is a knocked-in mStayGold-β2Spectrin. Cells are rat hippocampal neurons à DIV 3. The file is a reconstructed multiposition acquisition (10 positions). Uploaded to show a probable issue with Bio-Formats in Fiji, where SIM reconstrcuted multipositions files open like static noise. </p>
<p><a class="reference external" href="https://zenodo.org/records/14893791">https://zenodo.org/records/14893791</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14893791">https://doi.org/10.5281/zenodo.14893791</a></p>
</section>
<hr class="docutils" />
<section id="report-on-a-pilot-study-implementation-of-omero-for-microscopy-data-management">
<h2>Report on a pilot study:  Implementation of OMERO for  microscopy data management<a class="headerlink" href="#report-on-a-pilot-study-implementation-of-omero-for-microscopy-data-management" title="Link to this heading">#</a></h2>
<p>Silke Tulok, Gunar Fabig, Andy Vogelsang, Thomas Kugel, Thomas Müller-Reichert</p>
<p>Published 2023-11-10</p>
<p>Licensed CC-BY-4.0</p>
<p>The Core Facility Cellular Imaging (CFCI) at the Faculty of Medicine Carl Gustav Carus (TU Dresden) is currently running a pilot project for testing the use and handling of the OMERO software. This is done together with interested users of the imaging facility and a research group. Currently, we are pushing forward this pilot study on a small scale without any data steward. Our experiences argue so far for giving data management issues into the hands of dedicated personnel not fully involved in research projects. As funding agencies will ask for higher and higher standards for implementing FAIRdata principles in the future, this will be a releva</p>
<p><a class="reference external" href="https://zenodo.org/records/10103316">https://zenodo.org/records/10103316</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10103316">https://doi.org/10.5281/zenodo.10103316</a></p>
</section>
<hr class="docutils" />
<section id="research-data-management-seminar-slides">
<h2>Research Data Management Seminar - Slides<a class="headerlink" href="#research-data-management-seminar-slides" title="Link to this heading">#</a></h2>
<p>Stefano Della Chiesa</p>
<p>Published 2022-05-18</p>
<p>Licensed CC-BY-4.0</p>
<p>This Research Data Management (RDM) Slides introduce to the multidisciplinary knowledge and competencies required to address policy compliance and research data management best practices throughout a project lifecycle, and beyond it.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Module 1 - Introduces the RDM giving its context in the Research Data Governance
Module 2 - Illustrates the most important RDM policies and principles
Module 3 - Provides the most relevant RDM knowledge bricks
Module 4 - Discuss the Data Management Plans (DMPs), examples, templates and guidance
</pre></div>
</div>
<p> </p>
<p>Tags: Research Data Management</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/record/6602101">https://zenodo.org/record/6602101</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6602101">https://doi.org/10.5281/zenodo.6602101</a></p>
</section>
<hr class="docutils" />
<section id="research-data-managemet-and-how-not-to-get-overwhelmed-with-data">
<h2>Research Data Managemet and how not to get overwhelmed with data<a class="headerlink" href="#research-data-managemet-and-how-not-to-get-overwhelmed-with-data" title="Link to this heading">#</a></h2>
<p>Martin Schätz</p>
<p>Published 2023-09-23</p>
<p>Licensed CC-BY-4.0</p>
<p>Research data management and how not to get overwhelmed with data presentation is an overview of bioimage analysis with a focus on the basics for data management planning, FAIR principles, and how to practically organize folders and prepares naming convention. The presentation includes an overview of metadata, Creative Common licenses, and a sum up of electronic laboratory notebooks. The last two slides go through how all of that works in practice in open access core microscopy facility.</p>
<p><a class="reference external" href="https://zenodo.org/records/8372703">https://zenodo.org/records/8372703</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8372703">https://doi.org/10.5281/zenodo.8372703</a></p>
</section>
<hr class="docutils" />
<section id="research-data-reusability-conceptual-foundations-barriers-and-enabling-technologies">
<h2>Research Data Reusability - Conceptual Foundations, Barriers and Enabling Technologies<a class="headerlink" href="#research-data-reusability-conceptual-foundations-barriers-and-enabling-technologies" title="Link to this heading">#</a></h2>
<p>Costantino Thanos</p>
<p>Published 2017-01-09</p>
<p>Licensed CC-BY-4.0</p>
<p>This article discusses various aspects of data reusability in the context of scientific research, including technological, legal, and policy frameworks.</p>
<p>Tags: Research Data Management, Open Science, Data Protection</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.mdpi.com/2304-6775/5/1/2">https://www.mdpi.com/2304-6775/5/1/2</a></p>
</section>
<hr class="docutils" />
<section id="research-data-management-for-bioimaging-the-2021-nfdi4bioimage-community-survey">
<h2>Research data management for bioimaging - the 2021 NFDI4BIOIMAGE community survey<a class="headerlink" href="#research-data-management-for-bioimaging-the-2021-nfdi4bioimage-community-survey" title="Link to this heading">#</a></h2>
<p>Christian Schmidt, Janina Hanne, Josh Moore, Christian Meesters, Elisa Ferrando-May, et al.</p>
<p>Published 2022-09-20</p>
<p>Licensed CC-BY-4.0</p>
<p>As an initiative within Germany’s National Research Data Infrastructure, the authors conducted this community survey in summer 2021 to assess the state of the art of bioimaging RDM and the community needs.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://f1000research.com/articles/11-638/v2">https://f1000research.com/articles/11-638/v2</a></p>
</section>
<hr class="docutils" />
<section id="id2">
<h2>Research data management for bioimaging: the 2021 NFDI4BIOIMAGE community survey<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p>Christian Schmidt, Janina Hanne, Josh Moore, Christian Meesters, Elisa Ferrando-May, Stefanie Weidtkamp-Peters, members of the NFDI4BIOIMAGE initiative</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Nfdi4Bioimage, Research Data Management</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://f1000research.com/articles/11-638">https://f1000research.com/articles/11-638</a></p>
</section>
<hr class="docutils" />
<section id="round-table-workshop-1-sample-stabilization-in-intravital-imaging">
<h2>Round Table Workshop 1 - Sample Stabilization in intravital Imaging<a class="headerlink" href="#round-table-workshop-1-sample-stabilization-in-intravital-imaging" title="Link to this heading">#</a></h2>
<p>Michael Gerlach, Hans-Ulrich Fried, Christiane Peuckert</p>
<p>Published 2024-11-14</p>
<p>Licensed CC-BY-4.0</p>
<p>Notes from a round table workshop on the 4th Day of Intravital Microscopy in Leuven, Belgium.
Contains hands-on tips, tricks and schemes to improve sample stability during various models of Intravital Miroscopy.</p>
<p><a class="reference external" href="https://zenodo.org/records/14161289">https://zenodo.org/records/14161289</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14161289">https://doi.org/10.5281/zenodo.14161289</a></p>
</section>
<hr class="docutils" />
<section id="round-table-workshop-2-correction-of-drift-and-movement">
<h2>Round Table Workshop 2 - Correction of Drift and Movement<a class="headerlink" href="#round-table-workshop-2-correction-of-drift-and-movement" title="Link to this heading">#</a></h2>
<p>Dr. Hellen Ishikawa-Ankerhold, Max Nobis</p>
<p>Published 2024-11-14</p>
<p>Licensed CC-BY-4.0</p>
<p>Session 2 of a round table workshop. Features description of image processing methods useful in intravital imaging to compensate for the motion of living tissue.</p>
<p><a class="reference external" href="https://zenodo.org/records/14161633">https://zenodo.org/records/14161633</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14161633">https://doi.org/10.5281/zenodo.14161633</a></p>
</section>
<hr class="docutils" />
<section id="running-deep-learning-scripts-in-the-bia-pol-omero-server">
<h2>Running Deep-Learning Scripts in the BiA-PoL Omero Server<a class="headerlink" href="#running-deep-learning-scripts-in-the-bia-pol-omero-server" title="Link to this heading">#</a></h2>
<p>Marcelo Zoccoler</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Python, Artificial Intelligence, Bioimage Analysis</p>
<p>Content type: Blog Post</p>
<p><a class="reference external" href="https://biapol.github.io/blog/marcelo_zoccoler/omero_scripts/readme.html">https://biapol.github.io/blog/marcelo_zoccoler/omero_scripts/readme.html</a></p>
</section>
<hr class="docutils" />
<section id="swc-gcnu-software-skills">
<h2>SWC/GCNU Software Skills<a class="headerlink" href="#swc-gcnu-software-skills" title="Link to this heading">#</a></h2>
<p>Licensed CC-BY-4.0</p>
<p>Computational skills training at the UCL Sainsbury Wellcome Centre and Gatsby Computational Neuroscience Unit, delivered by members of the Neuroinformatics Unit.</p>
<p>Content type: Collection, Online Course, Video, Tutorial</p>
<p><a class="reference external" href="https://software-skills.neuroinformatics.dev/index.html">https://software-skills.neuroinformatics.dev/index.html</a></p>
</section>
<hr class="docutils" />
<section id="sharing-and-licensing-material">
<h2>Sharing and licensing material<a class="headerlink" href="#sharing-and-licensing-material" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Licensed CC-BY-4.0</p>
<p>Introduction to sharing resources online and licensing</p>
<p>Tags: Sharing, Research Data Management</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://f1000research.com/slides/10-519">https://f1000research.com/slides/10-519</a></p>
</section>
<hr class="docutils" />
<section id="sharing-research-data-with-zenodo">
<h2>Sharing research data with Zenodo<a class="headerlink" href="#sharing-research-data-with-zenodo" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Licensed CC-BY-4.0</p>
<p>Blog post about how to share data using <a class="reference external" href="http://zenodo.org">zenodo.org</a></p>
<p>Tags: Sharing, Research Data Management</p>
<p>Content type: Blog Post</p>
<p><a class="reference external" href="https://focalplane.biologists.com/2023/02/15/sharing-research-data-with-zenodo/">https://focalplane.biologists.com/2023/02/15/sharing-research-data-with-zenodo/</a></p>
</section>
<hr class="docutils" />
<section id="slides-about-flute-a-python-gui-for-interactive-phasor-analysis-of-flim-data">
<h2>Slides about FLUTE: a Python GUI for interactive phasor analysis of FLIM data<a class="headerlink" href="#slides-about-flute-a-python-gui-for-interactive-phasor-analysis-of-flim-data" title="Link to this heading">#</a></h2>
<p>Chiara Stringari</p>
<p>Published 2024-03-19</p>
<p>Licensed CC-BY-4.0</p>
<p>This presentation introduces the open source software to analyze FLIM data:
FLUTE – (F)luorescence (L)ifetime (U)ltima(T)e (E)xplorer:
a Python GUI for interactive phasor analysis of FLIM data
 
The software is available on GitHub: <a class="github reference external" href="https://github.com/LaboratoryOpticsBiosciences/FLUTE">LaboratoryOpticsBiosciences/FLUTE</a>
and it is published on Biological imaging Journal: Gottlieb, D., Asadipour, B., Kostina, P., Ung, T., &amp; Stringari, C. (2023). FLUTE: A Python GUI for interactive phasor analysis of FLIM data. Biological Imaging, 1-22. doi:10.1017/S2633903X23000211
The lecture was part of the short talks on community developed FLIM-software at the German BioImaging workshop on FLIM in Munich.</p>
<p><a class="reference external" href="https://zenodo.org/records/10839310">https://zenodo.org/records/10839310</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10839310">https://doi.org/10.5281/zenodo.10839310</a></p>
</section>
<hr class="docutils" />
<section id="so-geschlossen-wie-notig-so-offen-wie-moglich-datenschutz-beim-umgang-mit-forschungsdaten">
<h2>So geschlossen wie nötig, so offen wie möglich - Datenschutz beim Umgang mit Forschungsdaten<a class="headerlink" href="#so-geschlossen-wie-notig-so-offen-wie-moglich-datenschutz-beim-umgang-mit-forschungsdaten" title="Link to this heading">#</a></h2>
<p>Pia Voigt</p>
<p>Published 2024-05-30</p>
<p>Licensed CC-BY-4.0</p>
<p>Der Umgang mit personenbezogenen Daten stellt Forschende oft vor rechtliche Herausforderungen: Unter welchen Bedingungen dürfen personenbezogene Daten verarbeitet werden? Welche Voraussetzungen müssen erfüllt sein und welche Strategien können angewendet werden, um Daten sicher speichern, verarbeiten, teilen und aufbewahren zu können? Mit Hilfe dieses Foliensatzes erhalten Sie Einblicke in datenschutzrechtliche Aspekte beim Umgang mit Ihren Forschungsdaten. </p>
<p>Tags: Research Data Management, Data Protection, FAIR-Principles</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/11396199">https://zenodo.org/records/11396199</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11396199">https://doi.org/10.5281/zenodo.11396199</a></p>
</section>
<hr class="docutils" />
<section id="spatialdata-an-open-and-universal-data-framework-for-spatial-omics">
<h2>SpatialData: an open and universal data framework for spatial omics<a class="headerlink" href="#spatialdata-an-open-and-universal-data-framework-for-spatial-omics" title="Link to this heading">#</a></h2>
<p>Luca Marconato, Giovanni Palla, Kevin A Yamauchi, Isaac Virshup, Elyas Heidari, Tim Treis, Marcella Toth, Rahul Shrestha, Harald Vöhringer, Wolfgang Huber, Moritz Gerstung, Josh Moore, Fabian J Theis, Oliver Stegle</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Python</p>
<p>Content type: Publication, Preprint</p>
<p><a class="reference external" href="https://www.biorxiv.org/content/10.1101/2023.05.05.539647v1.abstract">https://www.biorxiv.org/content/10.1101/2023.05.05.539647v1.abstract</a></p>
</section>
<hr class="docutils" />
<section id="stackview-sliceplot-example-data">
<h2>Stackview sliceplot example data<a class="headerlink" href="#stackview-sliceplot-example-data" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-11-03</p>
<p>Licensed CC-BY-4.0</p>
<p>This is a dataset of PNG images of <a class="reference external" href="https://zenodo.org/records/12623730">Bio-Image Data Science teaching slides</a>. The png_umap.yml file contains a list of all images and a dimensionality reduced embedding (Uniform Manifold Approximation Projection, UMAP) made using OpenAI’s text-embedding-ada-002 model.
A notebook for visualizing this data is published here: <a class="github reference external" href="https://github.com/haesleinhuepf/stackview/blob/main/docs/sliceplot.ipynb">haesleinhuepf/stackview</a></p>
<p><a class="reference external" href="https://zenodo.org/records/14030307">https://zenodo.org/records/14030307</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14030307">https://doi.org/10.5281/zenodo.14030307</a></p>
</section>
<hr class="docutils" />
<section id="structuring-of-data-and-metadata-in-bioimaging-concepts-and-technical-solutions-in-the-context-of-linked-data">
<h2>Structuring of Data and Metadata in Bioimaging: Concepts and technical Solutions in the Context of Linked Data<a class="headerlink" href="#structuring-of-data-and-metadata-in-bioimaging-concepts-and-technical-solutions-in-the-context-of-linked-data" title="Link to this heading">#</a></h2>
<p>Sarah Weischer, Jens Wendt, Thomas Zobel</p>
<p>Published 2022-07-12</p>
<p>Licensed CC-BY-4.0</p>
<p>Provides an overview of contexts, frameworks, and models from the world of bioimage data as well as metadata. Visualizes the techniques for structuring this data as Linked Data. (Walkthrough Video: <a class="reference external" href="https://doi.org/10.5281/zenodo.7018928">https://doi.org/10.5281/zenodo.7018928</a> )</p>
<p>Content:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Types of metadata
Data formats
Data Models Microscopy Data
Tools to edit/gather metadata
ISA Framework
FDO Framework
Ontology
RDF
JSON-LD
SPARQL
Knowledge Graph
Linked Data
Smart Data
...
</pre></div>
</div>
<p>Tags: Nfdi4Bioimage, Research Data Management</p>
<p><a class="reference external" href="https://zenodo.org/records/7018750">https://zenodo.org/records/7018750</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7018750">https://doi.org/10.5281/zenodo.7018750</a></p>
</section>
<hr class="docutils" />
<section id="sustainable-data-stewardship">
<h2>Sustainable Data Stewardship<a class="headerlink" href="#sustainable-data-stewardship" title="Link to this heading">#</a></h2>
<p>Stefano Della Chiesa</p>
<p>Published 2024-03-25</p>
<p>Licensed CC-BY-4.0</p>
<p>These slides were presented at the 2. SaxFDM-Beratungsstammtisch and delve into the strategic integration of Research Data Management (RDM) within research organizations. The Leibniz IOER presented an insightful overview of RDM activities and approaches, emphasizing the criticality of embedding RDM strategically within research institutions. The presentation showcases some best practices in RDM implementation through practical examples, offering valuable insights for optimizing data stewardship processes.</p>
<p>Tags: Research Data Management, Data Stewardship</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/10942559">https://zenodo.org/records/10942559</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10942559">https://doi.org/10.5281/zenodo.10942559</a></p>
</section>
<hr class="docutils" />
<section id="ten-simple-rules-for-making-training-materials-fair">
<h2>Ten simple rules for making training materials FAIR<a class="headerlink" href="#ten-simple-rules-for-making-training-materials-fair" title="Link to this heading">#</a></h2>
<p>Leyla Garcia, Bérénice Batut, Melissa L. Burke, Mateusz Kuzak, Fotis Psomopoulos, et al.</p>
<p>Published 2020-05-21</p>
<p>Licensed CC-BY-4.0</p>
<p>The authors offer trainers some simple rules, to help make their training materials FAIR, enabling others to find, (re)use, and adapt them.</p>
<p>Tags: Metadata, Bioinformatics, FAIR-Principles</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007854">https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007854</a></p>
</section>
<hr class="docutils" />
<section id="terminology-service-for-research-data-management-and-knowledge-discovery-in-low-temperature-plasma-physics">
<h2>Terminology service for research data management and knowledge discovery in low-temperature plasma physics<a class="headerlink" href="#terminology-service-for-research-data-management-and-knowledge-discovery-in-low-temperature-plasma-physics" title="Link to this heading">#</a></h2>
<p>Markus M. Becker, Ihda Chaerony Siffa, Roman Baum</p>
<p>Published 2024-12-11</p>
<p>Licensed CC-BY-4.0</p>
<p>Abstract:
Terminology services (TS) [1,2] play a pivotal role in achieving structured metadata by providing controlled vocabularies and ontologies that standardize the description of data. This is a crucial aspect of research data management (RDM) in all scientific disciplines. In addition, TS facilitate the use of a common vocabulary within a scientific community also in a more general context, e.g. to annotate scientific papers, patents or other content for better discoverability, as envisaged by the Open Research Knowledge Graph (ORKG) [3] or the Patents4Science project [4]. 
To make use of these opportunities, terminologies, ontologies and knowledge graphs must be developed and made available as TS where they do not yet exist. This step is currently being taken by the research community in low-temperature plasma (LTP) physics. LTP physics explores partially ionized gases and its technological applications. This vibrant field offers innovative solutions for societal challenges, ranging from developing efficient lighting and solar cells to revolutionizing healthcare through plasma medicine. Various activities and projects have been started in the past years to support the RDM in LTP research and development and to facilitate the application of data-driven research methods. These activities are supported in parts by the NFDI4BIOIMAGE consortium, active work in the NFDI section “(Meta)data, Terminologies, Provenance”, and the basic service Terminology Services 4 NFDI (TS4NFDI) funded by Base4NFDI. 
Recently, the ontology Plasma-O [5–7] for LTP physics has been developed at INP in collaboration with FIZ Karlsruhe – Leibniz Institute for Information Infrastructure, providing a framework for structuring metadata and building a knowledge graph for scientific information within the field. The present contribution will show how a TS utilizing this resource can support different aspects of RDM and knowledge discovery using concrete examples. The application cases include (i) standardizing data annotation: By providing researchers with a controlled vocabulary of LTP-specific terms and their relationships, ensuring consistent and unambiguous data descriptions; (ii) enabling semantic search: Moving beyond keyword-based searches, TS allow for complex queries based on the relationships between concepts, significantly improving data discoverability; (iii) facilitating data integration: By mapping data from different sources to a common ontology, TS enable seamless integration and analysis of heterogeneous datasets, which is crucial for data-driven research and development. The TS Suite of TS4NFDI with the provided widgets [8] fits perfectly to the requirements of these three application cases and will support the harmonization of metadata in LTP physics. The implementation of a public TS is required to provide the domain-specific metadata in a standardized format and will be instrumental in unlocking the full potential of the TS widgets for RDM and knowledge discovery by LTP researchers. Furthermore, the results can provide insights to other domains on how to apply TS to their specific needs.
 The work was supported in parts by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under the National Research Data Infrastructure – [NFDI46/1] – 501864659 and project number 496963457 as well as by the Federal Ministry of Education and Research (BMBF), project number 16KOA013A.
References:</p>
<p>[1]</p>
<p>S. Jupp, T. Burdett, C. Leroy, H. Parkinson, “A new Ontology Lookup Service at EMBL-EBI”, Workshop on Semantic Web Applications and Tools for Life Sciences (2015), <a class="reference external" href="https://ceur-ws.org/Vol-1546/paper_29.pdf">https://ceur-ws.org/Vol-1546/paper_29.pdf</a> (accessed: 2024-09-20).</p>
<p>[2]</p>
<p>P. L. Whetzel, N. F. Noy, N. H. Shah, P. R. Alexander, C. Nyulas, T. Tudorache, M. A. Musen, “BioPortal: enhanced functionality via new Web services from the National Center for Biomedical Ontology to access and use ontologies in software applications”, Nucleic Acids Res. 39 (2011) W541–W545, <a class="reference external" href="https://doi.org/10.1093/nar/gkr469">https://doi.org/10.1093/nar/gkr469</a>.</p>
<p>[3]</p>
<p>Open Research Knowledge Graph, <a class="reference external" href="https://orkg.org/">https://orkg.org/</a> (accessed: 2024-09-20).</p>
<p>[4]</p>
<p>Patents4Science – Establishing an Information Infrastructure for the Use of Patent Knowledge in Science, <a class="reference external" href="https://www.patents4science.org/">https://www.patents4science.org/</a> (accessed: 2024-09-20).</p>
<p>[5]</p>
<p>H. Sack, F. Hoppe, “Verbundprojekt: Qualitätssicherung und Vernetzung von Forschungsdaten in der Plasmatechnologie - QPTDat; Teilvorhaben: Wissensgraph und Ontologieentwicklung zur Vernetzung von Metadaten : Schlussbericht des Teilvorhabens”, 2023, <a class="reference external" href="https://doi.org/10.2314/KXP:1883436974">https://doi.org/10.2314/KXP:1883436974</a>.</p>
<p>[6]</p>
<p>I. Chaerony Siffa, R. Wagner, L. Vilardell Scholten, M. M. Becker, “Semantic Information Management in Low-Temperature Plasma Science and Technology with VIVO”, 2024, preprint, <a class="reference external" href="https://doi.org/10.48550/arXiv.2409.11065">https://doi.org/10.48550/arXiv.2409.11065</a>.</p>
<p>[7]</p>
<p>I. Chaerony Siffa, R. Wagner, L. Vilardell Scholten, M. M. Becker, “Plasma Ontology and Knowledge Graph Initial Release v0.5.0”, 2024, Zenodo, <a class="reference external" href="https://doi.org/10.5281/zenodo.13325226">https://doi.org/10.5281/zenodo.13325226</a>.</p>
<p>[8]</p>
<p>J. Sasse, V. Kneip, R. Baum, P. Zimmermann, J. Darms, J. Schneider, V. Clemens, P. Oladazimi, L. Kühnel, “ts4nfdi/terminology-service-suite: v2.6.0”, 2024, Zenodo, <a class="reference external" href="https://doi.org/10.5281/zenodo.13692297">https://doi.org/10.5281/zenodo.13692297</a>.</p>
<p><a class="reference external" href="https://zenodo.org/records/14381522">https://zenodo.org/records/14381522</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14381522">https://doi.org/10.5281/zenodo.14381522</a></p>
</section>
<hr class="docutils" />
<section id="test-dataset-for-whole-slide-image-registration">
<h2>Test Dataset for Whole Slide Image Registration<a class="headerlink" href="#test-dataset-for-whole-slide-image-registration" title="Link to this heading">#</a></h2>
<p>Romain Guiet, Nicolas Chiaruttini</p>
<p>Published 2021-04-12</p>
<p>Licensed CC-BY-4.0</p>
<p>Mouse duodenum fixed in 4% PFA overnight at 4°C, processed for paraffin infiltration using a standard histology procedure and cut at 4 microns were dewaxed, rehydrated, permeabilized with 0.5% Triton X-100 in PBS 1x and stained with Azide - Alexa Fluor 555 (Thermo Fisher) to detect EdU and DAPI for nuclei. The images were taken using a Leica DM5500 microscope with a 40X N.A.1 objective (black&amp;white camera: DFC350FXR2, pixel dimension: 0.161 microns). Next, the slide was unmounted and stained using the fully automated Ventana Discovery xT autostainer (Roche Diagnostics, Rotkreuz, Switzerland). All steps were performed on automate with Ventana solutions. Sections were pretreated with heat using the CC1 solution under mild conditions. The primary rat anti BrDU (clone: BU1/75 (ICR1), Serotec, diluted 1:300) was incubated 1 hour at 37°C. After incubation with a donkey anti rat biotin diluted 1:200 (Jackson ImmunoResearch Laboratories), chromogenic revelation was performed with DabMap kit. The section was counterstained with Harris hematoxylin (J.T. Baker) before a second round of imaging on DM5500 PL Fluotar 40X N.A.1.0 oil (color camera: DFC 320 R2, pixel dimension: 0.1725 microns). Before acquisition, a white-balance as well as a shading correction is performed according to Leica LAS software wizard. The fluorescence and DAB images were converted in ome.tiff multiresolution file with the kheops Fiji Plugin.</p>
<p>Sampled prepared in the EPFL histology core facility by Nathalie Müller and Gian-Filippo Mancini.</p>
<p>Associated documents:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>https://c4science.ch/w/bioimaging_and_optics_platform_biop/teaching/dab-intensity/
https://imagej.net/plugins/bdv/warpy/warpy
</pre></div>
</div>
<p>This document contains a full QuPath project with an example of registered image.</p>
<p> </p>
<p><a class="reference external" href="https://zenodo.org/records/5675686">https://zenodo.org/records/5675686</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5675686">https://doi.org/10.5281/zenodo.5675686</a></p>
</section>
<hr class="docutils" />
<section id="the-fair-guiding-principles-for-scientific-data-management-and-stewardship">
<h2>The FAIR Guiding Principles for scientific data management and stewardship<a class="headerlink" href="#the-fair-guiding-principles-for-scientific-data-management-and-stewardship" title="Link to this heading">#</a></h2>
<p>Mark D. Wilkinson, Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, et. al</p>
<p>Published 2016-03-15</p>
<p>Licensed CC-BY-4.0</p>
<p>This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.</p>
<p>Tags: FAIR-Principles, Research Data Management</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.nature.com/articles/sdata201618">https://www.nature.com/articles/sdata201618</a></p>
<p><a class="reference external" href="https://doi.org/10.1038/sdata.2016.18">https://doi.org/10.1038/sdata.2016.18</a></p>
</section>
<hr class="docutils" />
<section id="the-fair-guiding-principles-for-data-stewardship-fair-enough">
<h2>The FAIR guiding principles for data stewardship - fair enough?<a class="headerlink" href="#the-fair-guiding-principles-for-data-stewardship-fair-enough" title="Link to this heading">#</a></h2>
<p>Martin Boeckhout, Gerhard A. Zielhuis, Annelien L. Bredenoord</p>
<p>Published 2018-05-17</p>
<p>Licensed CC-BY-4.0</p>
<p>The FAIR guiding principles for research data stewardship (findability, accessibility, interoperability, and reusability) look set to become a cornerstone of research in the life sciences. A critical appraisal of these principles in light of ongoing discussions and developments about data sharing is in order.</p>
<p>Tags: FAIR-Principles, Data Stewardship, Sharing</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.nature.com/articles/s41431-018-0160-0">https://www.nature.com/articles/s41431-018-0160-0</a></p>
</section>
<hr class="docutils" />
<section id="the-information-infrastructure-for-bioimage-data-i3d-bio-project-to-advance-fair-microscopy-data-management-for-the-community">
<h2>The Information Infrastructure for BioImage Data (I3D:bio) project to advance FAIR microscopy data management for the community<a class="headerlink" href="#the-information-infrastructure-for-bioimage-data-i3d-bio-project-to-advance-fair-microscopy-data-management-for-the-community" title="Link to this heading">#</a></h2>
<p>Christian Schmidt, Michele Bortolomeazzi, Tom Boissonnet, Julia Dohle, Tobias Wernet, Janina Hanne, Roland Nitschke, Susanne Kunis, Karen Bernhardt, Stefanie Weidtkamp-Peters, Elisa Ferrando-May</p>
<p>Published 2024-03-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Research data management (RDM) in microscopy and image analysis is a challenging task. Large files in proprietary formats, complex N-dimensional array structures, and various metadata models and formats can make image data handling inconvenient and difficult. For data organization, annotation, and sharing, researchers need solutions that fit everyday practice and comply with the FAIR (Findable, Accessible, Interoperable, Reusable) principles. International community-based efforts have begun creating open data models (OME), an open file format and translation library (OME-TIFF, Bio-Formats), data management software platforms, and microscopy metadata recommendations and annotation tools. Bringing these developments into practice requires support and training. Iterative feedback and tool improvement is needed to foster practical adoption by the scientific community. The Information Infrastructure for BioImage Data (I3D:bio) project works on guidelines, training resources, and practical assistance for FAIR microscopy RDM adoption with a focus on the management platform OMERO and metadata annotations.</p>
<p>Tags: Nfdi4Bioimage, Research Data Management</p>
<p><a class="reference external" href="https://zenodo.org/records/10805204">https://zenodo.org/records/10805204</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10805204">https://doi.org/10.5281/zenodo.10805204</a></p>
</section>
<hr class="docutils" />
<section id="the-open-microscopy-environment-ome-data-model-and-xml-file-open-tools-for-informatics-and-quantitative-analysis-in-biological-imaging">
<h2>The Open Microscopy Environment (OME) Data Model and XML file - open tools for informatics and quantitative analysis in biological imaging<a class="headerlink" href="#the-open-microscopy-environment-ome-data-model-and-xml-file-open-tools-for-informatics-and-quantitative-analysis-in-biological-imaging" title="Link to this heading">#</a></h2>
<p>Ilya G. Goldberg, Chris Allan, jean-marie burel, Doug Creager, Andrea Falconi, et. al</p>
<p>Published 2005-05-03</p>
<p>Licensed CC-BY-4.0</p>
<p>The Open Microscopy Environment (OME) defines a data model and a software implementation to serve as an informatics framework for imaging in biological microscopy experiments, including representation of acquisition parameters, annotations and image analysis results.</p>
<p>Tags: Bioimage Analysis</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://genomebiology.biomedcentral.com/articles/10.1186/gb-2005-6-5-r47">https://genomebiology.biomedcentral.com/articles/10.1186/gb-2005-6-5-r47</a></p>
<p><a class="reference external" href="https://doi.org/10.1186/gb-2005-6-5-r47">https://doi.org/10.1186/gb-2005-6-5-r47</a></p>
</section>
<hr class="docutils" />
<section id="the-turing-way-guide-for-reproducible-research">
<h2>The Turing Way: Guide for reproducible research<a class="headerlink" href="#the-turing-way-guide-for-reproducible-research" title="Link to this heading">#</a></h2>
<p>Licensed [‘CC-BY-4.0’, ‘MIT’]</p>
<p>A guide which covers topics related to skills, tools and best practices for research reproducibility.</p>
<p>Content type: Book</p>
<p><a class="reference external" href="https://the-turing-way.netlify.app/reproducible-research/reproducible-research">https://the-turing-way.netlify.app/reproducible-research/reproducible-research</a></p>
</section>
<hr class="docutils" />
<section id="the-role-of-helmholtz-centers-in-nfdi4bioimage-a-national-consortium-enhancing-fair-data-management-for-microscopy-and-bioimage-analysis">
<h2>The role of Helmholtz Centers in NFDI4BIOIMAGE - A national consortium enhancing FAIR data management for microscopy and bioimage analysis<a class="headerlink" href="#the-role-of-helmholtz-centers-in-nfdi4bioimage-a-national-consortium-enhancing-fair-data-management-for-microscopy-and-bioimage-analysis" title="Link to this heading">#</a></h2>
<p>Riccardo Massei, Christian Schmidt, Michele Bortolomeazzi, Julia Thoennissen, Jan Bumberger, Timo Dickscheid, Jan-Philipp Mallm, Elisa Ferrando-May</p>
<p>Published 2024-06-06</p>
<p>Licensed CC-BY-4.0</p>
<p>Germany’s National Research Data Infrastructure (NFDI) aims to establish a sustained, cross-disciplinary research data management (RDM) infrastructure that enables researchers to handle FAIR (findable, accessible, interoperable, reusable) data. While FAIR principles have been adopted by funders, policymakers, and publishers, their practical implementation remains an ongoing effort. In the field of bio-imaging, harmonization of data formats, metadata ontologies, and open data repositories is necessary to achieve FAIR data. The NFDI4BIOIMAGE was established to address these issues and develop tools and best practices to facilitate FAIR microscopy and image analysis data in alignment with international community activities. The consortium operates through its Data Stewards team to provide expertise and direct support to help overcome RDM challenges. The three Helmholtz Centers in NFDI4BIOIMAGE aim to collaborate closely with other centers and initiatives, such as HMC, Helmholtz AI, and HIP. Here we present NFDI4BIOIMAGE’s work and its significance for research in Helmholtz and beyond</p>
<p>Tags: Nfdi4Bioimage, Research Data Management</p>
<p><a class="reference external" href="https://zenodo.org/records/11501662">https://zenodo.org/records/11501662</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11501662">https://doi.org/10.5281/zenodo.11501662</a></p>
</section>
<hr class="docutils" />
<section id="thinking-data-management-on-different-scales">
<h2>Thinking data management on different scales<a class="headerlink" href="#thinking-data-management-on-different-scales" title="Link to this heading">#</a></h2>
<p>Susanne Kunis</p>
<p>Licensed CC-BY-4.0</p>
<p>Presentation given at PoL BioImage Analysis Symposium Dresden 2023</p>
<p>Tags: Research Data Management, Nfdi4Bioimage</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.8329305">https://zenodo.org/doi/10.5281/zenodo.8329305</a></p>
</section>
<hr class="docutils" />
<section id="towards-preservation-of-life-science-data-with-nfdi4bioimage">
<h2>Towards Preservation of Life Science Data with NFDI4BIOIMAGE<a class="headerlink" href="#towards-preservation-of-life-science-data-with-nfdi4bioimage" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-09-03</p>
<p>Licensed CC-BY-4.0</p>
<p>This talk will present the initiatives of the NFDI4BioImage consortium aimed at the long-term preservation of life science data. We will discuss our efforts to establish metadata standards, which are crucial for ensuring data reusability and integrity. The development of sustainable infrastructure is another key focus, enabling seamless data integration and analysis in the cloud. We will take a look at how we manage training materials and communicate with our community. Through these actions, NFDI4BioImage seeks to enable FAIR bioimage data management for German researchers, across disciplines and embedded in the international framework.</p>
<p>Tags: Nfdi4Bioimage, Research Data Management</p>
<p><a class="reference external" href="https://zenodo.org/records/13640979">https://zenodo.org/records/13640979</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13640979">https://doi.org/10.5281/zenodo.13640979</a></p>
</section>
<hr class="docutils" />
<section id="towards-transparency-and-knowledge-exchange-in-ai-assisted-data-analysis-code-generation">
<h2>Towards Transparency and Knowledge Exchange in AI-assisted Data Analysis Code Generation<a class="headerlink" href="#towards-transparency-and-knowledge-exchange-in-ai-assisted-data-analysis-code-generation" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-10-14</p>
<p>Licensed CC-BY-4.0</p>
<p>The integration of Large Language Models (LLMs) in scientific research presents both opportunities and challenges for life scientists. Key challenges include ensuring transparency in AI-generated content and facilitating efficient knowledge exchange among researchers. These issues arise from the in-transparent nature of AI-driven code generation and the informal sharing of AI insights, which may hinder reproducibility and collaboration. This paper introduces git-bob, an innovative AI-assistant designed to address these challenges by fostering an interactive and transparent collaboration platform within GitHub. By enabling seamless dialogue between humans and AI, git-bob ensures that AI contributions are transparent and reproducible. Moreover, it supports collaborative knowledge exchange, enhancing the interdisciplinary dialogue necessary for cutting-edge life sciences research. The open-source nature of git-bob further promotes accessibility and customization, positioning it as a vital tool in employing LLMs responsibly and effectively within scientific communities.</p>
<p><a class="reference external" href="https://zenodo.org/records/13928832">https://zenodo.org/records/13928832</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13928832">https://doi.org/10.5281/zenodo.13928832</a></p>
</section>
<hr class="docutils" />
<section id="tracking-of-mitochondria-and-capturing-mitoflashes">
<h2>Tracking of mitochondria and capturing mitoflashes<a class="headerlink" href="#tracking-of-mitochondria-and-capturing-mitoflashes" title="Link to this heading">#</a></h2>
<p>Leonid Kostrykin, Diana Chiang Jurado</p>
<p>Published 2024-11-20</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Bioinformatics, Bioimage Analysis</p>
<p>Content type: Workflow, Tutorial</p>
<p><a class="reference external" href="https://training.galaxyproject.org/training-material/topics/imaging/tutorials/detection-of-mitoflashes/tutorial.html#tracking-of-mitochondria-and-capturing-mitoflashes">https://training.galaxyproject.org/training-material/topics/imaging/tutorials/detection-of-mitoflashes/tutorial.html#tracking-of-mitochondria-and-capturing-mitoflashes</a></p>
</section>
<hr class="docutils" />
<section id="train-the-trainer-concept-on-research-data-management">
<h2>Train-the-Trainer Concept on Research Data Management<a class="headerlink" href="#train-the-trainer-concept-on-research-data-management" title="Link to this heading">#</a></h2>
<p>Katarzyna Biernacka, Maik Bierwirth, Petra Buchholz, Dominika Dolzycka, Kerstin Helbig, Janna Neumann, Carolin Odebrecht, Cord Wiljes, Ulrike Wuttke</p>
<p>Published 2020-11-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Within the project FDMentor, a German Train-the-Trainer Programme on Research Data Management (RDM) was developed and piloted in a series of workshops. The topics cover many aspects of research data management, such as data management plans and the publication of research data, as well as didactic units on learning concepts, workshop design and a range of didactic methods.</p>
<p>After the end of the project, the concept was supplemented and updated by members of the Sub-Working Group Training/Further Education (UAG Schulungen/Fortbildungen) of the DINI/nestor Working Group Research Data (DINI/nestor-AG Forschungsdaten). The newly published English version of the Train-the-Trainer Concept contains the translated concept, the materials and all methods of the Train-the-Trainer Programme. Furthermore, additional English references and materials complement this version.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Book</p>
<p><a class="reference external" href="https://zenodo.org/record/4071471">https://zenodo.org/record/4071471</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4071471">https://doi.org/10.5281/zenodo.4071471</a></p>
</section>
<hr class="docutils" />
<section id="training-computational-skills-in-the-age-of-ai">
<h2>Training Computational Skills in the Age of AI<a class="headerlink" href="#training-computational-skills-in-the-age-of-ai" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-11-06</p>
<p>Licensed CC-BY-4.0</p>
<p>Artificial intelligence (AI) and large language models (LLMs) are changing the way we use computers in science. This slide deck introduces ways for using AI and LLMs for making training materials and for exchanging knowledge about how to use AI in joint discussions between humans and LLM-based AI-systems.</p>
<p><a class="reference external" href="https://zenodo.org/records/14043615">https://zenodo.org/records/14043615</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14043615">https://doi.org/10.5281/zenodo.14043615</a></p>
</section>
<hr class="docutils" />
<section id="using-glittr-org-to-find-compare-and-re-use-online-training-materials">
<h2>Using <a class="reference external" href="http://Glittr.org">Glittr.org</a> to find, compare and re-use online training materials<a class="headerlink" href="#using-glittr-org-to-find-compare-and-re-use-online-training-materials" title="Link to this heading">#</a></h2>
<p>Geert van Geest, Yann Haefliger, Monique Zahn-Zabal, Patricia M. Palagi</p>
<p>Licensed CC-BY-4.0</p>
<p><a class="reference external" href="http://Glittr.org">Glittr.org</a> is a platform that aggregates and indexes training materials on computational life sciences from public git repositories, making it easier for users to find, compare, and analyze these resources based on various metrics. By providing insights into the availability of materials, collaboration patterns, and licensing practices, <a class="reference external" href="http://Glittr.org">Glittr.org</a> supports adherence to the FAIR principles, benefiting the broader life sciences community.</p>
<p>Tags: Bioimage Analysis, Research Data Management</p>
<p>Content type: Publication, Preprint</p>
<p><a class="reference external" href="https://www.biorxiv.org/content/10.1101/2024.08.20.608021v1">https://www.biorxiv.org/content/10.1101/2024.08.20.608021v1</a></p>
</section>
<hr class="docutils" />
<section id="welcome-to-bioimage-town">
<h2>Welcome to BioImage Town<a class="headerlink" href="#welcome-to-bioimage-town" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Licensed CC-BY-4.0</p>
<p>Welcome at NFDI4BIOIMAGE All-Hands Meeting in Düsseldorf, Germany, October 16, 2023</p>
<p>Tags: OMERO, Bioimage Analysis, Nfdi4Bioimage</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.10008464">https://zenodo.org/doi/10.5281/zenodo.10008464</a></p>
</section>
<hr class="docutils" />
<section id="what-is-open-data">
<h2>What is Open Data?<a class="headerlink" href="#what-is-open-data" title="Link to this heading">#</a></h2>
<p>Daniel Dietrich, Jonathan Gray, Tim McNamara, Antti Poikola, Rufus Pollock, et al.</p>
<p>Licensed CC-BY-4.0</p>
<p>This handbook is about open data but what exactly is it? In particular what makes open data open, and what sorts of data are we talking about?</p>
<p>Tags: Open Science</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="http://opendatahandbook.org/guide/en/what-is-open-data/">http://opendatahandbook.org/guide/en/what-is-open-data/</a></p>
</section>
<hr class="docutils" />
<section id="who-you-gonna-call-data-stewards-to-the-rescue">
<h2>Who you gonna call? - Data Stewards to the rescue<a class="headerlink" href="#who-you-gonna-call-data-stewards-to-the-rescue" title="Link to this heading">#</a></h2>
<p>Vanessa Aphaia Fiona Fuchs, Jens Wendt, Maximilian Müller, Mohsen Ahmadi, Riccardo Massei, Cornelia Wetzker</p>
<p>Published 2024-03-01</p>
<p>Licensed CC-BY-4.0</p>
<p>The Data Steward Team of the NFDI4BIOIMAGE consortium presents themselves and the services (including the Helpdesk) that we offer.</p>
<p><a class="reference external" href="https://zenodo.org/records/10730424">https://zenodo.org/records/10730424</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10730424">https://doi.org/10.5281/zenodo.10730424</a></p>
</section>
<hr class="docutils" />
<section id="working-group-charter-rdm-helpdesk-network">
<h2>Working Group Charter. RDM Helpdesk Network<a class="headerlink" href="#working-group-charter-rdm-helpdesk-network" title="Link to this heading">#</a></h2>
<p>Judith Engel, Patrick Helling, Robert Herrenbrück, MarinaLemaire, Hela Mehrtens, Marcus Schmidt, Martha Stellmacher, Lukas Weimer, Cord Wiljes, Wolf Zinke</p>
<p>Published 2024-11-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Support is an essential component of an efficient infrastructure for research data management (RDM). Helpdesks guide researchers through this complex landscape and provide reliable support about all questions regarding research data management, including support for technical services, best practices, requirements of funding organizations and legal topics. In NFDI, most consortia have already established or are planning to establish helpdesks to support their specific communities. On a local level, many institutions have set up RDM helpdesks that provide support for the researchers of their own institution. Additional RDM support services are offered by RDM federal state initiatives, by research data centers, by specialist libraries, by the EOSC, and by providers of RDM-relevant tools. Helpdesks cover a wide range of institutions, disciplines, topics, methodologies and target audiences. However, the individual helpdesks are not yet interconnected and therefore cannot complement one another in an efficient way: Given the wide and constantly increasing complexity of RDM, no single helpdesk can provide the expertise for all potential support requests. Therefore, we see great potential in combining the efforts and resources of the existing RDM helpdesks into an efficient and comprehensive national RDM support network in order to provide optimal and tailored RDM support to all researchers and research-related institutions in Germany and in an international context.</p>
<p><a class="reference external" href="https://zenodo.org/records/14035822">https://zenodo.org/records/14035822</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14035822">https://doi.org/10.5281/zenodo.14035822</a></p>
</section>
<hr class="docutils" />
<section id="zeiss-axiozoom-stage-adapter">
<h2>Zeiss AxioZoom Stage Adapter<a class="headerlink" href="#zeiss-axiozoom-stage-adapter" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-06-20</p>
<p>Licensed CC-BY-4.0</p>
<p>A 3D- printable microscope stage adapter for the reproducible accomodation of samples at a Zeiss AxioZoom stereomicroscope.
4 cylindrical anchors are fixed to the glass plate of the stage. The stage adapter is reversibly placed on these anchors.
 </p>
<p><a class="reference external" href="https://zenodo.org/records/7963020">https://zenodo.org/records/7963020</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7963020">https://doi.org/10.5281/zenodo.7963020</a></p>
</section>
<hr class="docutils" />
<section id="zeiss-axiozoom-stage-adapter-12-6well-plate">
<h2>Zeiss AxioZoom Stage Adapter - 12/6Well Plate<a class="headerlink" href="#zeiss-axiozoom-stage-adapter-12-6well-plate" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-06-20</p>
<p>Licensed CC-BY-4.0</p>
<p>A 3D- printable microscope stage adapter for the reproducible accomodation of 6 or 12-well plates at a Zeiss AxioZoom microscope.
4 cylindrical anchors are fixed to the glass plate of the stage. The stage adapter is reversibly placed on these anchors and acommodates a standard Greiner 6- or 12-well plate.</p>
<p><a class="reference external" href="https://zenodo.org/records/7944877">https://zenodo.org/records/7944877</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7944877">https://doi.org/10.5281/zenodo.7944877</a></p>
</section>
<hr class="docutils" />
<section id="zeiss-axiozoom-stage-adapter-em-block-holder">
<h2>Zeiss AxioZoom Stage Adapter - EM block holder<a class="headerlink" href="#zeiss-axiozoom-stage-adapter-em-block-holder" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-06-20</p>
<p>Licensed CC-BY-4.0</p>
<p>A 3D- printable microscope stage adapter for the reproducible accomodation of EM Blocks at a Zeiss AxioZoom microscope.</p>
<p>4 cylindrical anchors are fixed to the glass plate of the stage. The stage adapter is reversibly placed on these anchors and acommodates 70 standard resin EM blocks.</p>
<p><a class="reference external" href="https://zenodo.org/records/7963006">https://zenodo.org/records/7963006</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7963006">https://doi.org/10.5281/zenodo.7963006</a></p>
</section>
<hr class="docutils" />
<section id="zeiss-axiozoom-stage-adapter-microscope-slides">
<h2>Zeiss AxioZoom Stage Adapter - Microscope slides<a class="headerlink" href="#zeiss-axiozoom-stage-adapter-microscope-slides" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-06-21</p>
<p>Licensed CC-BY-4.0</p>
<p>A 3D- printable microscope stage adapter for the reproducible accomodation of microscopic slides at a Zeiss AxioZoom microscope.
4 cylindrical anchors are fixed to the glass plate of the stage. The stage adapter is reversibly placed on these anchors and acommodates 4 standard glass slides.</p>
<p><a class="reference external" href="https://zenodo.org/records/7945018">https://zenodo.org/records/7945018</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7945018">https://doi.org/10.5281/zenodo.7945018</a></p>
</section>
<hr class="docutils" />
<section id="bina-cc-scalable-strategies-for-a-next-generation-of-fair-bioimaging">
<h2>[BINA CC] Scalable strategies for a next-generation of FAIR bioimaging<a class="headerlink" href="#bina-cc-scalable-strategies-for-a-next-generation-of-fair-bioimaging" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Published 2024-09-24</p>
<p>Licensed CC-BY-4.0</p>
<p>Presented at <a class="reference external" href="https://www.bioimagingnorthamerica.org/events/bina-2024-community-congress/">https://www.bioimagingnorthamerica.org/events/bina-2024-community-congress/</a></p>
<p><a class="reference external" href="https://zenodo.org/records/13831274">https://zenodo.org/records/13831274</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13831274">https://doi.org/10.5281/zenodo.13831274</a></p>
</section>
<hr class="docutils" />
<section id="cidas-scalable-strategies-for-a-next-generation-of-fair-bioimaging">
<h2>[CIDAS] Scalable strategies for a next-generation of FAIR bioimaging<a class="headerlink" href="#cidas-scalable-strategies-for-a-next-generation-of-fair-bioimaging" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Published 2025-01-23</p>
<p>Licensed CC-BY-4.0</p>
<p>Talk given at Georg-August-Universität Göttingen Campus Institute Data Science23rd January 2025
<a class="reference external" href="https://www.uni-goettingen.de/en/653203.html">https://www.uni-goettingen.de/en/653203.html</a></p>
<p><a class="reference external" href="https://zenodo.org/records/14845059">https://zenodo.org/records/14845059</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14845059">https://doi.org/10.5281/zenodo.14845059</a></p>
</section>
<hr class="docutils" />
<section id="cmcb-scalable-strategies-for-a-next-generation-of-fair-bioimaging">
<h2>[CMCB] Scalable strategies for a next-generation of FAIR bioimaging<a class="headerlink" href="#cmcb-scalable-strategies-for-a-next-generation-of-fair-bioimaging" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Published 2025-01-16</p>
<p>Licensed CC-BY-4.0</p>
<p>CMCB LIFE SCIENCES SEMINARSTechnische Universität Dresden16th January 2025
<a class="reference external" href="https://tu-dresden.de/cmcb/crtd/news-termine/termine/cmcb-life-sciences-seminar-josh-moore-german-bioimaging-e-v-society-for-microscopy-and-image-analysis-constance">https://tu-dresden.de/cmcb/crtd/news-termine/termine/cmcb-life-sciences-seminar-josh-moore-german-bioimaging-e-v-society-for-microscopy-and-image-analysis-constance</a>
 </p>
<p>Tags: Nfdi4Bioimage</p>
<p><a class="reference external" href="https://zenodo.org/records/14650434">https://zenodo.org/records/14650434</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14650434">https://doi.org/10.5281/zenodo.14650434</a></p>
</section>
<hr class="docutils" />
<section id="cordi-2023-zarr-a-cloud-optimized-storage-for-interactive-access-of-large-arrays">
<h2>[CORDI 2023] Zarr: A Cloud-Optimized Storage for Interactive Access of Large Arrays<a class="headerlink" href="#cordi-2023-zarr-a-cloud-optimized-storage-for-interactive-access-of-large-arrays" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Licensed CC-BY-4.0</p>
<p>For decades, the sharing of large N-dimensional datasets has posed issues across multiple domains. Interactively accessing terabyte-scale data has previously required significant server resources to properly prepare cropped or down-sampled representations on the fly. Now, a cloud-native chunked format easing this burden has been adopted in the bioimaging domain for standardization. The format — Zarr — is potentially of interest for other consortia and sections of NFDI.</p>
<p>Tags: Research Data Management, Bioimage Analysis, Data Science</p>
<p>Content type: Poster</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.8340247">https://zenodo.org/doi/10.5281/zenodo.8340247</a></p>
</section>
<hr class="docutils" />
<section id="community-meeting-2024-overview-team-image-data-analysis-and-management">
<h2>[Community Meeting 2024] Overview Team Image Data Analysis and Management<a class="headerlink" href="#community-meeting-2024-overview-team-image-data-analysis-and-management" title="Link to this heading">#</a></h2>
<p>Susanne Kunis, Thomas Zobel</p>
<p>Published 2024-03-08</p>
<p>Licensed CC-BY-4.0</p>
<p>Overview of Activities of the Team Image Data Analysis and Management of German BioImaging e.V.
 </p>
<p>Tags: Nfdi4Bioimage, Research Data Management</p>
<p><a class="reference external" href="https://zenodo.org/records/10796364">https://zenodo.org/records/10796364</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10796364">https://doi.org/10.5281/zenodo.10796364</a></p>
</section>
<hr class="docutils" />
<section id="community-meeting-2024-supporting-and-financing-rdm-projects-within-gerbi">
<h2>[Community Meeting 2024] Supporting and financing RDM projects within GerBI<a class="headerlink" href="#community-meeting-2024-supporting-and-financing-rdm-projects-within-gerbi" title="Link to this heading">#</a></h2>
<p>Stefanie Weidtkamp-Peters, Josh Moore, Christian Schmidt, Roland Nitschke, Susanne Kunis, Thomas Zobel</p>
<p>Published 2024-03-28</p>
<p>Licensed CC-BY-4.0</p>
<p>Overview of GerBI RDM projects: why and how?</p>
<p><a class="reference external" href="https://zenodo.org/records/10889694">https://zenodo.org/records/10889694</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10889694">https://doi.org/10.5281/zenodo.10889694</a></p>
</section>
<hr class="docutils" />
<section id="elmi-2024-ai-s-dirty-little-secret-without">
<h2>[ELMI 2024]  AI’s Dirty Little Secret: Without<a class="headerlink" href="#elmi-2024-ai-s-dirty-little-secret-without" title="Link to this heading">#</a></h2>
<p>FAIR Data, It’s Just Fancy Math</p>
<p>Josh Moore, Susanne Kunis</p>
<p>Published 2024-05-21</p>
<p>Licensed CC-BY-4.0</p>
<p>Poster presented at the European Light Microscopy Initiative meeting in Liverpool (<a class="reference external" href="https://www.elmi2024.org/">https://www.elmi2024.org/</a>)</p>
<p>Tags: Nfdi4Bioimage, Research Data Management</p>
<p><a class="reference external" href="https://zenodo.org/records/11235513">https://zenodo.org/records/11235513</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11235513">https://doi.org/10.5281/zenodo.11235513</a></p>
</section>
<hr class="docutils" />
<section id="elmi-2024-ai-s-dirty-little-secret-without-fair-data-it-s-just-fancy-math">
<h2>[ELMI 2024] AI’s Dirty Little Secret: Without FAIR Data, It’s Just Fancy Math<a class="headerlink" href="#elmi-2024-ai-s-dirty-little-secret-without-fair-data-it-s-just-fancy-math" title="Link to this heading">#</a></h2>
<p>Josh Moore, Susanne Kunis</p>
<p>Licensed CC-BY-4.0</p>
<p>Poster presented at the European Light Microscopy Initiative meeting in Liverpool (<a class="reference external" href="https://www.elmi2024.org/">https://www.elmi2024.org/</a>)</p>
<p>Tags: Research Data Management, FAIR-Principles, Bioimage Analysis, Nfdi4Bioimage</p>
<p>Content type: Poster</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.11235512">https://zenodo.org/doi/10.5281/zenodo.11235512</a></p>
</section>
<hr class="docutils" />
<section id="gbi-eoe-vii-five-or-ten-must-have-items-for-making-it-infrastructure-for-managing-bioimage-data">
<h2>[GBI EOE VII] Five (or ten) must-have items for making IT infrastructure for managing bioimage data<a class="headerlink" href="#gbi-eoe-vii-five-or-ten-must-have-items-for-making-it-infrastructure-for-managing-bioimage-data" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Published 2024-05-26</p>
<p>Licensed CC-BY-4.0</p>
<p>Presentation made to the GBI Image Data Management Working Group during the 7th Exchange of Experience in Uruguay.</p>
<p><a class="reference external" href="https://zenodo.org/records/11318151">https://zenodo.org/records/11318151</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11318151">https://doi.org/10.5281/zenodo.11318151</a></p>
</section>
<hr class="docutils" />
<section id="gbi-eoe-ix-nfdi4bioimage">
<h2>[GBI EoE IX] NFDI4BIOIMAGE<a class="headerlink" href="#gbi-eoe-ix-nfdi4bioimage" title="Link to this heading">#</a></h2>
<p>National Research Data Infrastructure
for Microscopy and BioImage Analysis</p>
<p>Josh Moore</p>
<p>Published 2024-10-29</p>
<p>Licensed CC-BY-4.0</p>
<p>Presented at <a class="reference external" href="https://globalbioimaging.org/exchange-of-experience/exchange-of-experience-ix">https://globalbioimaging.org/exchange-of-experience/exchange-of-experience-ix</a> in Okazaki, Japan.</p>
<p><a class="reference external" href="https://zenodo.org/records/14001388">https://zenodo.org/records/14001388</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14001388">https://doi.org/10.5281/zenodo.14001388</a></p>
</section>
<hr class="docutils" />
<section id="i2k-scalable-strategies-for-a-next-generation-of-fair-bioimaging">
<h2>[I2K] Scalable strategies for a next-generation of FAIR bioimaging<a class="headerlink" href="#i2k-scalable-strategies-for-a-next-generation-of-fair-bioimaging" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Published 2024-10-25</p>
<p>Licensed CC-BY-4.0</p>
<p>or, “OME-Zarr: ‘even a talk on formats [can be] interesting’”
Presented at <a class="reference external" href="https://events.humantechnopole.it/event/1/">https://events.humantechnopole.it/event/1/</a></p>
<p><a class="reference external" href="https://zenodo.org/records/13991322">https://zenodo.org/records/13991322</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13991322">https://doi.org/10.5281/zenodo.13991322</a></p>
</section>
<hr class="docutils" />
<section id="n4bi-ahm-welcome-to-bioimage-town">
<h2>[N4BI AHM] Welcome to BioImage Town<a class="headerlink" href="#n4bi-ahm-welcome-to-bioimage-town" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Published 2023-10-16</p>
<p>Licensed CC-BY-4.0</p>
<p>Keynote at the NFDI4BIOIMAGE All-Hands Meeting in Düsseldorf, Germany, October 16, 2023.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/10008465">https://zenodo.org/records/10008465</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10008465">https://doi.org/10.5281/zenodo.10008465</a></p>
</section>
<hr class="docutils" />
<section id="swat4hcls-2023-nfdi4bioimage-perspective-for-a-national-bioimage-standard">
<h2>[SWAT4HCLS 2023] NFDI4BIOIMAGE: Perspective for a national bioimage standard<a class="headerlink" href="#swat4hcls-2023-nfdi4bioimage-perspective-for-a-national-bioimage-standard" title="Link to this heading">#</a></h2>
<p>Josh Moore, Susanne Kunis</p>
<p>Licensed CC-BY-4.0</p>
<p>Poster presented at Semantic Web Applications and Tools for Health Care and Life Sciences (SWAT4HCLS 2023), Feb 13–16, 2023, Basel, Switzerland. NFDI4BIOIMAGE is a newly established German consortium dedicated to the FAIR representation of biological imaging data. A key deliverable is the definition of a semantically-compatible FAIR image object integrating RDF metadata with web-compatible storage of large n-dimensional binary data in OME-Zarr. We invite feedback from and collaboration with other endeavors during the soon-to-begin 5 year funding period.</p>
<p>Tags: Research Data Management, FAIR-Principles, Nfdi4Bioimage</p>
<p>Content type: Poster</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.7928332">https://zenodo.org/doi/10.5281/zenodo.7928332</a></p>
</section>
<hr class="docutils" />
<section id="short-talk-nfdi4bioimage-a-consortium-in-the-national-research-data-infrastructure">
<h2>[Short Talk] NFDI4BIOIMAGE - A consortium in the National Research Data Infrastructure<a class="headerlink" href="#short-talk-nfdi4bioimage-a-consortium-in-the-national-research-data-infrastructure" title="Link to this heading">#</a></h2>
<p>Christian Schmidt</p>
<p>Published 2024-04-10</p>
<p>Licensed CC-BY-4.0</p>
<p>Short Talk about the NFDI4BIOIMAGE consortium presented at the RDM in (Bio-)Medicine Information Event on April 10th, 2024, organized C³RDM &amp; ZB MED.</p>
<p><a class="reference external" href="https://zenodo.org/records/10939520">https://zenodo.org/records/10939520</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10939520">https://doi.org/10.5281/zenodo.10939520</a></p>
</section>
<hr class="docutils" />
<section id="workshop-material-fit-for-omero-how-imaging-facilities-and-it-departments-work-together-to-enable-rdm-for-bioimaging-october-16-17-2024-heidelberg">
<h2>[Workshop Material] Fit for OMERO - How imaging facilities and IT departments work together to enable RDM for bioimaging, October 16-17, 2024, Heidelberg<a class="headerlink" href="#workshop-material-fit-for-omero-how-imaging-facilities-and-it-departments-work-together-to-enable-rdm-for-bioimaging-october-16-17-2024-heidelberg" title="Link to this heading">#</a></h2>
<p>Tom Boissonnet, Bettina Hagen, Susanne Kunis, Christian Schmidt, Stefanie Weidtkamp-Peters</p>
<p>Published 2024-11-18</p>
<p>Licensed CC-BY-4.0</p>
<p>Fit for OMERO: How imaging facilities and IT departments work together to enable RDM for bioimaging
Description:
Research data management (RDM) in bioimaging is challenging because of large file sizes, heterogeneous file formats and the variability of imaging methods. The image data management system OMERO (OME Remote Objects) allows for centralized and secure storage, organization, annotation, and interrogation of microscopy data by researchers. It is an internationally well-supported open-source software tool that has become one of the best-known image data management tools among bioimaging scientists. Nevertheless, the de novo setup of OMERO at an institute is a multi-stakeholder process that demands time, funds, organization and iterative implementation. In this workshop, participants learn how to begin setting up OMERO-based image data management at their institution. The topics include:</p>
<p>Stakeholder identification at the university / research institute
Process management, time line expectations, and resources planning
Learning about each other‘s perspectives on chances and challenges for RDM
Funding opportunities and strategies for IT and imaging core facilities
Hands-on: Setting up an OMERO server in a virtual machine environment</p>
<p>Target audience:
This workshop was directed at universities and research institutions who consider or plan to implement OMERO, or are in an early phase of implementation. This workshop was intended for teams from IT departments and imaging facilities to participate together with one person from the IT department, and one person from the imaging core facility at the same institution.
The trainers:</p>
<p>Prof. Dr. Stefanie Weidtkamp-Peters (Imaging Core Facility Head, Center for Advanced Imaging, Heinrich Heine University of Düsseldorf)
Dr. Susanne Kunis (Software architect, OMERO administrator, metadata specialist, University of Osnabrück)
Dr. Tom Boissonnet (OMERO admin and image metadata specialist, Center for Advanced Imaging, Heinrich Heine University of Düsseldorf)
Dr. Bettina Hagen (IT Administration and service specialist, Max Planck Institute for the Biology of Ageing, Cologne) 
Dr. Christian Schmidt (Science Manager for Research Data Management in Bioimaging, German Cancer Research Center (DKFZ), Heidelberg)</p>
<p>Time and place
The format was a two-day, in-person workshop (October 16-17, 2024). Location: Heidelberg, Germany
Workshop learning goals</p>
<p>Learn the steps to establish a local RDM environment fit for bioimaging data
Create a network of IT experts and bioimaging specialists for bioimage RDM across institutions
Establish a stakeholder process management for installing OMERO-based RDM
Learn from each other, leverage different expertise
Learn how to train users, establish sustainability strategies, and foster FAIR RDM for bioimaging at your institution</p>
<p>Tags: Nfdi4Bioimage, Research Data Management</p>
<p><a class="reference external" href="https://zenodo.org/records/14178789">https://zenodo.org/records/14178789</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14178789">https://doi.org/10.5281/zenodo.14178789</a></p>
</section>
<hr class="docutils" />
<section id="workshop-bioimage-data-management-and-analysis-with-omero">
<h2>[Workshop] Bioimage data management and analysis with OMERO<a class="headerlink" href="#workshop-bioimage-data-management-and-analysis-with-omero" title="Link to this heading">#</a></h2>
<p>Riccardo Massei, Michele Bortolomeazzi, Christian Schmidt</p>
<p>Published 2024-05-13</p>
<p>Licensed CC-BY-4.0</p>
<p>Here we share the material used in a workshop held on May 13th, 2024, at the German Cancer Research Center in Heidelberg (on-premise)
Description:Microscopy experiments generate information-rich, multi-dimensional data, allowing us to investigate biological processes at high spatial and temporal resolution. Image processing and analysis is a standard procedure to retrieve quantitative information from biological imaging. Due to the complex nature of bioimaging files that often come in proprietary formats, it can be challenging to organize, structure, and annotate bioimaging data throughout a project. Data often needs to be moved between collaboration partners, transformed into open formats, processed with a variety of software tools, and exported to smaller-sized images for presentation. The path from image acquisition to final publication figures with quantitative results must be documented and reproducible.
In this workshop, participants learn how to use OMERO to organize their data and enrich the bioimage data with structured metadata annotations.We also focus on image analysis workflows in combination with OMERO based on the Fiji/ImageJ software and using Jupyter Notebooks. In the last part, we explore how OMERO can be used to create publication figures and prepare bioimage data for publication in a suitable repository such as the Bioimage Archive.
Module 1 (9 am - 10.15 am): Basics of OMERO, data structuring and annotation
Module 2 (10.45 am - 12.45 pm): OMERO and Fiji
Module 3 (1.45 pm - 3.45 pm): OMERO and Jupyter Notebooks
Module 4 (4.15 pm - 6. pm): Publication-ready figures and data with OMERO
The target group for this workshopThis workshop is directed at researchers at all career levels who plan to or have started to use OMERO for their microscopy research data management. We encourage the workshop participants to bring example data from their research to discuss suitable metadata annotation for their everyday practice.
Prerequisites:Users should bring their laptops and have access to the internet through one of the following options:- eduroam- institutional WiFi- VPN connection to their institutional networks to access OMERO
Who are the trainers?
Dr. Riccardo Massei (Helmholtz-Center for Environmental Research, UFZ, Leipzig) - Data Steward for Bioimaging Data in NFDI4BIOIMAGE
Dr. Michele Bortolomeazzi (DKFZ, Single cell Open Lab, bioimage data specialist, bioinformatician, staff scientist in the NFDI4BIOIMAGE project)
Dr. Christian Schmidt (Science Manager for Research Data Management in Bioimaging, German Cancer Research Center, Heidelberg, Project Coordinator of the NFDI4BIOIMAGE project)</p>
<p>Tags: Nfdi4Bioimage, Research Data Management</p>
<p><a class="reference external" href="https://zenodo.org/records/11350689">https://zenodo.org/records/11350689</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11350689">https://doi.org/10.5281/zenodo.11350689</a></p>
</section>
<hr class="docutils" />
<section id="workshop-fair-data-handling-for-microscopy-structured-metadata-annotation-in-omero">
<h2>[Workshop] FAIR data handling for microscopy: Structured metadata annotation in OMERO<a class="headerlink" href="#workshop-fair-data-handling-for-microscopy-structured-metadata-annotation-in-omero" title="Link to this heading">#</a></h2>
<p>Vanessa Fiona Aphaia Fuchs, Christian Schmidt, Tom Boissonnet</p>
<p>Published 2024-05-06</p>
<p>Licensed CC-BY-4.0</p>
<p>Description
Microscopy experiments generate information-rich, multi-dimensional data, allowing us to investigate biological processes at high spatial and temporal resolution. Image processing and analysis is a standard procedure to retrieve quantitative information from biological imaging. Due to the complex nature of bioimaging files that often come in proprietary formats, it can be challenging to organize, structure, and annotate bioimaging data throughout a project. Data often needs to be moved between collaboration partners, transformed into open formats, processed with a variety of software tools, and exported to smaller-sized images for presentation. The path from image acquisition to final publication figures with quantitative results must be documented and reproducible.
In this workshop, participants learn how to use structured metadata annotations in the image data management platform OMERO (OME Remote Objects) to optimize their data handling. This strategy helps both with organizing data for easier processing and analysis and for the preparation of data publication in journal manuscripts and in public repositories such as the BioImage Archive. Participants learn the principles of leveraging object-oriented data organization in OMERO to enhance findability and usability of their data, also in collaborative settings. The integration of OMERO with image analysis tools, in particular ImageJ/Fiji, will be trained. Moreover, users learn about community-accepted metadata checklists (REMBI) to enrich the value of their data toward reproducibility and reusability. In this workshop, we will provide hands-on training and recommendations on:</p>
<p>Structured metadata annotation features in OMERO and how to use them
Types of metadata in bioimaging: Technical metadata, sample metadata, analysis metadata
The use of ontologies and terminologies for metadata annotation
REMBI, the recommended metadata for biological images
Metadata-assisted image analysis streamlining
Tools for metadata annotation in OMERO</p>
<p>The target group for this workshop
This workshop is directed at researchers at all career levels who have started using OMERO for their microscopy research data management. We encourage the workshop participants to bring example data from their research to discuss suitable metadata annotation for their everyday practice.
Who are the trainers (see trainer description below for more details)</p>
<p>Dr. Vanessa Fuchs (NFDI4BIOIMAGE Data Steward, Center for Advanced Imaging, Heinrich-Heine University of Düsseldorf)
Dr. Tom Boissonnet (OMERO admin and image metadata specialist, Center for Advanced Imaging, Heinrich-Heine University of Düsseldorf)
Dr. Christian Schmidt (Science Manager for Research Data Management in Bioimaging, German Cancer Research Center, Heidelberg)</p>
<p>Material Description
Published here are the presentation slides that were used for input from the trainers during the different sessions of the programme. Additionally, a Fiji Macro is published that depends on the OMERO Extensions Plugin by Pouchin et al, 2022, F100Research, <a class="reference external" href="https://doi.org/10.12688/f1000research.110385.2">https://doi.org/10.12688/f1000research.110385.2</a> 
Programme Overview
Day 1 - April 29th, 2024 09.00 a.m. to 10.00 a.m.: Session 1 - Welcome and Introduction
10.00 a.m. to 10.30 a.m.:  Session 2 - Introduction to the FAIR principles &amp; data annotation
10:30 a.m. to 10:45 a.m.: Coffee break
10.45 a.m. to 12.00 a.m.: Session 3 - Data structure (datasets in OMERO) and organization with Tags 
12.00 a.m. to 1.00 p.m.:  Lunch Break
1.00 p.m. to 2.00 p.m.:  Session 4 - REMBI, Key-Value pair annotations in bioimaging
2:00 p.m. to 2.30 p.m.:  Session 5 - Ontologies for Key-Value Pairs in OMERO
2:30 p.m. to 2:45 p.m. Coffee break
2.45 p.m. to 3.45 p.m.:  Wrap-up, discussion, outlook on day 2
Day 2 - April 30th, 2024
09.00 a.m. to 09.30 a.m.:  Arrival and Start into day 2
09.30 a.m. to 11.30 a.m.:  Session 6 - Hands-on : REMBI-based Key-Value Pair annotation in OMERO
11.30 a.m. to 12.30 a.m.:  Lunch Break
12.30 a.m. to 1.15 p.m.: Session 7 - OMERO and OMERO.plugins
1.15 p.m. to 2.00 p.m.: Session 8 - Loading OMERO-hosted data into Fiji
2.00 p.m. to 2.15 p.m.: Coffee break 
2.15 p.m. to 3.00 p.m.: Discussion, Outlook</p>
<p><a class="reference external" href="https://zenodo.org/records/11109616">https://zenodo.org/records/11109616</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11109616">https://doi.org/10.5281/zenodo.11109616</a></p>
</section>
<hr class="docutils" />
<section id="workshop-research-data-management-for-microscopy-and-bioimage-analysis">
<h2>[Workshop] Research Data Management for Microscopy and BioImage Analysis<a class="headerlink" href="#workshop-research-data-management-for-microscopy-and-bioimage-analysis" title="Link to this heading">#</a></h2>
<p>Christian Schmidt, Tom Boissonnet, Michele Bortolomeazzi, Ksenia Krooß</p>
<p>Published 2024-09-30</p>
<p>Licensed CC-BY-4.0</p>
<p>Research Data Management for Microscopy and BioImage Analysis</p>
<p>Introduction to BioImaging Research Data Management, NFDI4BIOIMAGE and I3D:bioChristian Schmidt /DKFZ Heidelberg
OMERO as a tool for bioimaging data managementTom Boissonnet /Heinrich-Heine Universität Düsseldorf
Reproducible image analysis workflows with OMERO software APIsMichele Bortolomeazzi /DKFZ Heidelberg
Publishing datasets in public archives for bioimage dataKsenia Krooß /Heinrich-Heine Universität Düsseldorf</p>
<p>Date &amp; Venue:Thursday, Sept. 26, 5.30 p.m.Haus 22 / Paul Ehrlich Lecture Hall (H22-1)University Hospital Frankfurt</p>
<p>Tags: Nfdi4Bioimage, Research Data Management</p>
<p><a class="reference external" href="https://zenodo.org/records/13861026">https://zenodo.org/records/13861026</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13861026">https://doi.org/10.5281/zenodo.13861026</a></p>
</section>
<hr class="docutils" />
<section id="ilastik-interactive-machine-learning-for-bio-image-analysis">
<h2>ilastik: interactive machine learning for (bio)image analysis<a class="headerlink" href="#ilastik-interactive-machine-learning-for-bio-image-analysis" title="Link to this heading">#</a></h2>
<p>Anna Kreshuk, Dominik Kutra</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Artificial Intelligence, Bioimage Analysis</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.4330625">https://zenodo.org/doi/10.5281/zenodo.4330625</a></p>
</section>
<hr class="docutils" />
<section id="introduction-to-generative-ai">
<h2>introduction-to-generative-ai<a class="headerlink" href="#introduction-to-generative-ai" title="Link to this heading">#</a></h2>
<p>Bruna Piereck, Alexander Botzki</p>
<p>Published 2024-09-27T14:38:51+00:00</p>
<p>Licensed CC-BY-4.0</p>
<p>Course repository for Strategic Use of Generative AI</p>
<p>Tags: Artificial Intelligence</p>
<p>Content type: Github Repository, Tutorial</p>
<p><a class="github reference external" href="https://github.com/vibbits/introduction-to-generative-ai">vibbits/introduction-to-generative-ai</a></p>
<p><a class="reference external" href="https://liascript.github.io/course/?https://raw.githubusercontent.com/vibbits/introduction-to-generative-ai/refs/heads/main/README.md">https://liascript.github.io/course/?https://raw.githubusercontent.com/vibbits/introduction-to-generative-ai/refs/heads/main/README.md</a></p>
</section>
<hr class="docutils" />
<section id="nextflow-workshop">
<h2>nextflow-workshop<a class="headerlink" href="#nextflow-workshop" title="Link to this heading">#</a></h2>
<p>Tuur Muyldermans, Kris Davie, Alexander, Nicolas Vannieuwkerke, Kobe Lavaerts, Marcel Ribeiro-Dantas, Bruna Piereck, Steff Taelman</p>
<p>Published 2023-03-29T10:40:04+00:00</p>
<p>Licensed CC-BY-4.0</p>
<p>Nextflow workshop materials March 2023</p>
<p>Tags: Workflow, Nextflow</p>
<p>Content type: Github Repository, Tutorial</p>
<p><a class="github reference external" href="https://github.com/vibbits/nextflow-workshop">vibbits/nextflow-workshop</a></p>
<p><a class="reference external" href="https://liascript.github.io/course/?https://raw.githubusercontent.com/vibbits/nextflow-workshop/main/README.md#1">https://liascript.github.io/course/?https://raw.githubusercontent.com/vibbits/nextflow-workshop/main/README.md#1</a></p>
</section>
<hr class="docutils" />
<section id="re3data-org-registry-of-research-data-repositories">
<h2><a class="reference external" href="http://re3data.org">re3data.org</a> - registry of Research Data Repositories<a class="headerlink" href="#re3data-org-registry-of-research-data-repositories" title="Link to this heading">#</a></h2>
<p>Licensed CC-BY-4.0</p>
<p>Re3data is a global registry of research data repositories that covers research data repositories from different academic disciplines. It includes repositories that enable permanent storage of and access to data sets to researchers, funding bodies, publishers, and scholarly institutions.</p>
<p>Tags: Research Data Management</p>
<p>Content type: Website</p>
<p><a class="reference external" href="https://www.re3data.org/">https://www.re3data.org/</a></p>
</section>
<hr class="docutils" />
<section id="scikit-learn-mooc">
<h2>scikit-learn MOOC<a class="headerlink" href="#scikit-learn-mooc" title="Link to this heading">#</a></h2>
<p>Loïc Estève et al.</p>
<p>Licensed CC-BY-4.0</p>
<p>Machine learning in Python with scikit-learn MOOC</p>
<p>Tags: Bioimage Analysis, Machine Learning</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/INRIA/scikit-learn-mooc">INRIA/scikit-learn-mooc</a></p>
</section>
<hr class="docutils" />
<section id="training-resources">
<h2>training-resources<a class="headerlink" href="#training-resources" title="Link to this heading">#</a></h2>
<p>Christian Tischer, Antonio Politi, Toby Hodges, maulakhan, grinic, bugraoezdemir, Tim-Oliver Buchholz, Elnaz Fazeli, Aliaksandr Halavatyi, Dominik Kutra, Stefania Marcotti, AnniekStok, Felix, jhennies, Severina Klaus, Martin Schorb, Nima Vakili, Sebastian Gonzalez Tirado, Stefan Helfrich, Yi Sun, Ziqiang Huang, Jan Eglinger, Constantin Pape, Joel Lüthi, Matt McCormick, Oane Gros</p>
<p>Published 2020-04-23T07:51:38+00:00</p>
<p>Licensed CC-BY-4.0</p>
<p>Resources for teaching/preparing to teach bioimage analysis</p>
<p>Tags: Bioimageanalysis, Neurobias</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/NEUBIAS/training-resources">NEUBIAS/training-resources</a></p>
<hr class="docutils" />
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./licenses"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="bsd-3-clause.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Bsd-3-clause (27)</p>
      </div>
    </a>
    <a class="right-next"
       href="cc-by-sa-4.0.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Cc-by-sa-4.0 (5)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zenodo-und-co-was-bringt-und-wer-braucht-ein-repositorium">“ZENODO und Co.” Was bringt und wer braucht ein Repositorium?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#frames-of-fluorescent-particles">10 frames of fluorescent particles</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#d-nuclei-annotations-and-stardist-3d-model-s-rat-brain">3D Nuclei annotations and StarDist 3D model(s) (rat brain)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#steps-towards-reproducible-research">6 Steps Towards Reproducible Research</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-cloud-optimized-storage-for-interactive-access-of-large-arrays">A Cloud-Optimized Storage for Interactive Access of Large Arrays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-glimpse-of-the-open-source-flim-analysis-software-tools-flimfit-flute-and-napari-flim-phasor-plotter">A Glimpse of the Open-Source FLIM Analysis Software Tools FLIMfit, FLUTE and napari-flim-phasor-plotter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-hitchhiker-s-guide-through-the-bio-image-analysis-software-universe">A Hitchhiker’s guide through the bio-image analysis software universe</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-journey-to-fair-microscopy-data">A journey to FAIR microscopy data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abdominal-imaging-window-aiw-for-intravital-imaging">Abdominal Imaging Window (AIW) for Intravital Imaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aberrated-bead-stack">Aberrated Bead Stack</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abstract-nfdi-basic-service-for-data-management-plans">Abstract - NFDI Basic Service for Data Management Plans</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#alles-meins-oder-urheberrechte-klaren-fur-forschungsdaten">Alles meins – oder!? Urheberrechte klären für Forschungsdaten</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#angebote-der-nfdi-fur-die-forschung-im-bereich-zoologie">Angebote der NFDI für die Forschung im Bereich Zoologie</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#artificial-blobs-and-labels-image">Artificial Blobs and Labels image</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#astigmatic-4pi-bead-stack">Astigmatic 4Pi bead stack</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bids-lecture-2024">BIDS-lecture-2024</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#biomero-a-scalable-and-extensible-image-analysis-framework">BIOMERO - A scalable and extensible image analysis framework</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bigdataprocessor2-a-free-and-open-source-fiji-plugin-for-inspection-and-processing-of-tb-sized-image-data">BigDataProcessor2: A free and open-source Fiji plugin for inspection and processing of TB sized image data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-data-strudel-for-workshop-on-research-data-management-in-tu-dresden-core-facilities">Bio-Image Data Strudel for Workshop on Research Data Management in TU Dresden Core Facilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis-code-generation">Bio-image Analysis Code Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis-code-generation-using-bia-bob">Bio-image Analysis Code Generation using bia-bob</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis-with-the-help-of-large-language-models">Bio-image Analysis with the Help of Large Language Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-data-science">Bio-image Data Science</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-data-science-lectures-uni-leipzig-scads-ai">Bio-image Data Science Lectures @ Uni Leipzig / ScaDS.AI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis-biostatistics-programming-and-machine-learning-for-computational-biology">Bio-image analysis, biostatistics, programming and machine learning for computational biology</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-tools-database">Bio.tools database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioformats-command-line-cli-tools">BioFormats Command line (CLI) tools</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimage-analysis-notebooks">BioImage Analysis Notebooks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimage-io-chatbot-globias-seminar">BioImage.IO Chatbot, GloBIAS Seminar</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#browsing-the-open-microscopy-image-data-resource-with-python">Browsing the Open Microscopy Image Data Resource with Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-fair-image-analysis-pipelines-for-high-content-screening-hcs-data-using-galaxy">Building FAIR image analysis pipelines for high-content-screening (HCS) data using Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-a-fair-image-data-ecosystem-for-microscopy-communities">Building a FAIR image data ecosystem for microscopy communities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#czi-carl-zeiss-image-dataset-with-artificial-test-camera-images-with-various-dimension-for-testing-libraries-reading">CZI (Carl Zeiss Image) dataset with artificial test camera images with various dimension for testing libraries reading</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#czi-file-examples">CZI file examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellpose-model-for-digital-phase-contrast-images">Cellpose model for Digital Phase Contrast images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellpose-models-for-label-prediction-from-brightfield-and-digital-phase-contrast-images">Cellpose models for Label Prediction from Brightfield and Digital Phase Contrast images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges-and-opportunities-for-bio-image-analysis-core-facilities">Challenges and opportunities for bio-image analysis core-facilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#challenges-and-opportunities-for-bioimage-analysis-core-facilities">Challenges and opportunities for bioimage analysis core-facilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chatgpt-for-image-analysis">ChatGPT for Image Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#collaborative-working-and-version-control-with-git-hub">Collaborative Working and Version Control with git[hub]</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#collaborative-bio-image-analysis-script-editing-with-git">Collaborative bio-image analysis script editing with git</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#combining-the-bids-and-arc-directory-structures-for-multimodal-research-data-organization">Combining the BIDS and ARC Directory Structures for Multimodal Research Data Organization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conference-slides-4th-day-of-intravital-microscopy">Conference Slides - 4th Day of Intravital Microscopy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#crashkurs-forschungsdatenmanagement">Crashkurs Forschungsdatenmanagement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-workflows-and-advanced-workflow-options">Creating Workflows and Advanced Workflow Options</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-a-research-data-management-plan-using-chatgpt">Creating a Research Data Management Plan using chatGPT</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-open-computational-curricula">Creating open computational curricula</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cultivating-open-training">Cultivating Open Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cultivating-open-training-to-advance-bio-image-analysis">Cultivating Open Training to advance Bio-image Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dl4miceverywhere">DL4MicEverywhere</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-carpentry-for-biologists">Data Carpentry for Biologists</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-life-cycle">Data life cycle</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-stewardship-and-research-data-management-tools-for-multimodal-linking-of-imaging-data-in-plasma-medicine">Data stewardship and research data management tools for multimodal linking of imaging data in plasma medicine</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataplant-knowledge-base">DataPLANT knowledge base</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-from-incell-2200-microscope-misread-as-a-plate">Dataset from InCell 2200 microscope misread as a plate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datenmanagement">Datenmanagement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datenmanagement-im-fokus-organisation-speicherstrategien-und-datenschutz">Datenmanagement im Fokus: Organisation, Speicherstrategien und Datenschutz</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datenmanagementplane-erstellen-teil-1">Datenmanagementpläne erstellen - Teil 1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datenmanagementplane-erstellen-teil-2">Datenmanagementpläne erstellen - Teil 2</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deconvolution-test-dataset">Deconvolution Test Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#developing-semi-automatic-analysis-pipelines-and-technological-solutions-for-metadata-annotation-and-management-in-high-content-screening-hcs-bioimaging">Developing (semi)automatic analysis pipelines and technological solutions for metadata annotation and management in high-content screening (HCS) bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#developing-a-training-strategy">Developing a Training Strategy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#developing-open-source-software-for-bioimage-analysis-opportunities-and-challenges">Developing open-source software for bioimage analysis: opportunities and challenges</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#development-of-a-platform-for-advanced-optics-education-training-and-prototyping">Development of a platform for advanced optics education, training and prototyping</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#digital-phase-contrast-on-primary-dermal-human-fibroblasts-cells">Digital Phase Contrast on Primary Dermal Human Fibroblasts cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#edam-bioimaging-the-ontology-of-bioimage-informatics-operations-topics-data-and-formats">EDAM-bioimaging - The ontology of bioimage informatics operations, topics, data, and formats</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#edam-bioimaging-the-ontology-of-bioimage-informatics-operations-topics-data-and-formats-update-2020">EDAM-bioimaging: The ontology of bioimage informatics operations, topics, data, and formats (update 2020)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#efficiently-starting-institutional-research-data-management">Efficiently starting institutional research data management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#einblicke-ins-forschungsdatenmanagement-darf-ich-das-veroffentlichen-rechtsfragen-im-umgang-mit-forschungsdaten">Einblicke ins Forschungsdatenmanagement - Darf ich das veröffentlichen? Rechtsfragen im Umgang mit Forschungsdaten</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#erstellung-und-realisierung-einer-institutionellen-forschungsdaten-policy">Erstellung und Realisierung einer institutionellen Forschungsdaten-Policy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-scientific-ambassadors-program">Euro-BioImaging  Scientific Ambassadors Program</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-eric-annual-report-2022">Euro-BioImaging ERIC Annual Report 2022</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-s-guide-to-fair-bioimage-data-practical-tasks">Euro-BioImaging’s Guide to FAIR BioImage Data - Practical Tasks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-s-template-for-research-data-management-plans">Euro-BioImaging’s Template for Research Data Management Plans</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-batchconvert-v0-0-4">Euro-BioImaging/BatchConvert: v0.0.4</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evident-oir-sample-files-tiles-stitched-image-fv-4000">Evident OIR sample files tiles + stitched image - FV 4000</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evident-oir-sample-files-with-lambda-scan-fv-4000">Evident OIR sample files with lambda scan - FV 4000</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-imaris-ims-datasets">Example Imaris ims datasets.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-microscopy-metadata-json-files-produced-using-micro-meta-app-to-document-example-microscopy-experiments-performed-at-individual-core-facilities">Example Microscopy Metadata JSON files produced using Micro-Meta App to document example microscopy experiments performed at individual core facilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-operetta-dataset">Example Operetta Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#excel-template-for-adding-key-value-pairs-to-images">Excel template for adding Key-Value Pairs to images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fair-bioimage-data">FAIR BioImage Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fair-high-content-screening-in-bioimaging">FAIR High Content Screening in Bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fair-priciples">FAIR Priciples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fairy-deep-learning-for-bioimage-analysis">FAIRy deep-learning for bioImage analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#finding-and-using-publicly-available-data">Finding and using publicly available data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forschungsdaten-org">Forschungsdaten.org</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forschungsdatenmanagement-zukunftsfest-gestalten-impulse-fur-die-strukturevaluation-der-nationalen-forschungsdateninfrastruktur-nfdi">Forschungsdatenmanagement zukunftsfest gestalten – Impulse für die   Strukturevaluation der Nationalen Forschungsdateninfrastruktur (NFDI)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-cells-to-pixels-bridging-biologists-and-image-analysts-through-a-common-language">From Cells to Pixels: Bridging Biologists and  Image Analysts Through a Common Language</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-paper-to-pixels-navigation-through-your-research-data-presentations-of-speakers">From Paper to Pixels: Navigation through your Research Data - presentations of speakers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#galaxy-training">Galaxy Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-artificial-intelligence-for-bio-image-analysis">Generative artificial intelligence for bio-image analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gerbi-chat-teil-1-vom-bedarf-bis-zum-groszgerateantrag-schreiben">GerBI-Chat: Teil 1 - Vom Bedarf bis zum Großgeräteantrag-Schreiben</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gerbi-chat-teil-2-wie-schreibe-ich-am-besten-einen-groszegrateantrag">GerBI-Chat: Teil 2 - Wie schreibe ich am besten einen Großegräteantrag</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-started-with-mambaforge-and-python">Getting started with Mambaforge and Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-started-with-python-intro-and-set-up-a-conda-environment">Getting started with Python: intro and set-up a conda environment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#guidance-for-developing-a-research-data-management-rdm-policy">Guidance for Developing a Research Data Management (RDM) Policy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gut-analysis-toolbox">Gut Analysis Toolbox</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gut-analysis-toolbox-training-data-and-2d-models-for-segmenting-enteric-neurons-neuronal-subtypes-and-ganglia">Gut Analysis Toolbox: Training data and 2D models for segmenting enteric neurons, neuronal subtypes and ganglia</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hackaton-results-conversion-of-knime-image-analysis-workflows-to-galaxy">Hackaton Results - Conversion of KNIME image analysis workflows to Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hela-kyoto-cells-under-the-scope">HeLa “Kyoto” cells under the scope</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#high-throughput-automated-data-analysis-and-data-management-workflow-with-cellprofiler-and-omero">High throughput &amp; automated data analysis and data management workflow with Cellprofiler and OMERO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#highlights-from-the-2016-2020-neubias-training-schools-for-bioimage-analysts-a-success-story-and-key-asset-for-analysts-and-life-scientists">Highlights from the 2016-2020 NEUBIAS training schools for Bioimage Analysts: a success story and key asset for analysts and life scientists</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hitchhiking-through-a-diverse-bio-image-analysis-software-universe">Hitchhiking through a diverse Bio-image Analysis Software Universe</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#human-dab-staining-axioscan-bf-20x">Human DAB staining Axioscan BF 20x</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#i3d-bio-s-omero-training-material-re-usable-adjustable-multi-purpose-slides-for-local-user-training">I3D:bio’s OMERO training material: Re-usable, adjustable, multi-purpose slides for local user training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ics-ids-stitched-file">ICS/IDS stitched file</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#if-you-license-it-itll-be-harder-to-steal-it-why-we-should-license-our-work">If you license it, it’ll be harder to steal it. Why we should license our work</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-analysis-training-resources">Image Analysis Training Resources</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-processing-with-python">Image Processing with Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-repository-decision-tree-where-do-i-deposit-my-imaging-data">Image Repository Decision Tree - Where do I deposit my imaging data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imagej-tool-for-percentage-estimation-of-pneumonia-in-lungs">ImageJ tool for percentage estimation of pneumonia in lungs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#incell-datasets-with-mix-of-2d-and-3d-failed-to-be-read">InCell datasets with mix of 2D and 3D failed to be read</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#insights-and-impact-from-five-cycles-of-essential-open-source-software-for-science">Insights and Impact From Five Cycles of Essential Open Source Software for Science</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#insights-from-acquiring-open-medical-imaging-datasets-for-foundation-model-development">Insights from Acquiring Open Medical Imaging  Datasets for Foundation Model Development</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Insights from Acquiring Open Medical Imaging Datasets for Foundation Model Development</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#institutionalization-and-collaboration-as-a-way-of-addressing-the-challenges-open-science-presents-to-libraries-the-university-of-konstanz-as-a-national-pioneer">Institutionalization and Collaboration as a Way of Addressing the Challenges Open Science Presents to Libraries: The University of Konstanz as a National Pioneer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interactive-image-data-flow-graphs">Interactive Image Data Flow Graphs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#intravital-microscopy-contrasting-agents-for-application-database">Intravital microscopy contrasting agents for application - Database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introducing-omero-vitessce-an-omero-web-plugin-for-multi-modal-data">Introducing OMERO-vitessce: an OMERO.web plugin for multi-modal data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-bioimage-analysis">Introduction to Bioimage Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-research-data-management-and-open-research">Introduction to Research Data Management and Open Research</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pair-template-for-annotation-in-omero-for-light-microscopy-data-acquired-with-axioscan7-core-facility-cellular-imaging-cfci">Key-Value pair template for annotation in OMERO for light microscopy data acquired with AxioScan7 - Core Facility Cellular Imaging (CFCI)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pair-template-for-annotation-of-datasets-in-omero-perikles-study">Key-Value pair template for annotation of datasets in OMERO (PERIKLES study)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pair-template-for-annotation-of-datasets-in-omero-for-light-and-electron-microscopy-data-within-the-research-group-of-prof-muller-reichert">Key-Value pair template for annotation of datasets in OMERO for light- and electron microscopy data within the research group of Prof. Müller-Reichert</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kollaboratives-arbeiten-und-versionskontrolle-mit-git">Kollaboratives Arbeiten und Versionskontrolle mit Git</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kriterienkatalog-fur-materialien-aus-dem-themenbereich-forschungsdatenmanagement">Kriterienkatalog für Materialien aus dem Themenbereich Forschungsdatenmanagement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#leo-linking-eln-with-omero">LEO: Linking ELN with OMERO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lsm-example-j-dubrulle">LSM example J. Dubrulle</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lz4-compressed-imaris-ims-example-datasets">LZ4-compressed Imaris ims example datasets.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#large-language-models-an-introduction-for-life-scientists">Large Language Models: An Introduction for Life Scientists</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#large-tiling-confocal-acquisition-rat-brain">Large tiling confocal acquisition (rat brain)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#leitfaden-zur-digitalen-datensparsamkeit-mit-praxisbeispielen">Leitfaden zur digitalen Datensparsamkeit (mit Praxisbeispielen)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#leitlinie-grundsatze-policy-richtlinie-forschungsdaten-policies-an-deutschen-universitaten">Leitlinie? Grundsätze? Policy? Richtlinie? – Forschungsdaten-Policies an deutschen Universitäten</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limeseg-test-datasets">LimeSeg Test Datasets</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linked-open-data-for-microbial-population-biology">Linked (Open) Data for Microbial Population Biology</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#liver-micrometastases-area-quantification-using-qupath-and-pixel-classifier">Liver Micrometastases area quantification using QuPath and pixel classifier</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#making-the-most-of-bioimaging-data-through-interdisciplinary-interactions">Making the most of bioimaging data through interdisciplinary interactions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#making-your-package-available-on-conda-forge">Making your package available on conda-forge</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#managing-scientific-python-environments-using-conda-mamba-and-friends">Managing Scientific Python environments using Conda, Mamba and friends</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#measuring-reporter-activity-domain-in-epi-aggregates-and-gastruloids-ijm">Measuring reporter activity domain in EPI aggregates and Gastruloids.ijm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#meeting-in-the-middle-towards-successful-multidisciplinary-bioimage-analysis-collaboration">Meeting in the Middle: Towards Successful Multidisciplinary Bioimage Analysis Collaboration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metadata-annotation-workflow-for-omero-with-tabbles">Metadata Annotation Workflow for OMERO with Tabbles</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#methods-in-bioimage-analysis">Methods in bioimage analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microsam-talks">MicroSam-Talks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microscopy-data-analysis-machine-learning-and-the-bioimage-archive">Microscopy data analysis: machine learning and the BioImage Archive</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microscopy-bids-an-extension-to-the-brain-imaging-data-structure-for-microscopy-data">Microscopy-BIDS - An Extension to the Brain Imaging Data Structure for Microscopy Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling-community-standards-for-metadata-as-templates-makes-data-fair">Modeling community standards for metadata as templates makes data FAIR</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modular-training-resources-for-bioimage-analysis">Modular training resources for bioimage analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#morphological-analysis-of-neural-cells-with-weka-and-snt-fiji-plugins">Morphological analysis of neural cells with WEKA and SNT Fiji plugins</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-template-matching-for-object-detection-slides">Multi-Template-Matching for object-detection (slides)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiplexed-histology-of-covid-19-post-mortem-lung-samples-control-case-1-fov1">Multiplexed histology of COVID-19 post-mortem lung samples - CONTROL CASE 1 FOV1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiplexed-tissue-imaging-tools-and-approaches">Multiplexed tissue imaging - tools and approaches</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#my-journey-through-bioimage-analysis-teaching-methods-from-classroom-to-cloud">My Journey Through Bioimage Analysis Teaching Methods From Classroom to Cloud</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage">NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis-online-kick-off-2023">NFDI4BIOIMAGE - National Research Data Infrastructure for Microscopy and BioImage Analysis - Online Kick-Off 2023</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis-conference-talk-the-pelagic-imaging-consortium-meets-helmholtz-imaging-5-10-2023-hamburg">NFDI4BIOIMAGE - National Research Data Infrastructure for Microscopy and BioImage Analysis [conference talk: The Pelagic Imaging Consortium meets Helmholtz Imaging, 5.10.2023, Hamburg]</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis">NFDI4BIOIMAGE - National Research Data Infrastructure for Microscopy and Bioimage Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-data-management-illustrations-by-henning-falk">NFDI4BIOIMAGE data management illustrations by Henning Falk</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-perspective-for-a-national-bioimaging-standard">NFDI4BIOIMAGE: Perspective for a national bioimaging standard</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon">NFDI4Bioimage - TA3-Hackathon - UoC-2023 (Cologne Hackathon)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon-2023-github-repository">NFDI4Bioimage - TA3-Hackathon - UoC-2023 (Cologne-Hackathon-2023, GitHub repository)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-2024-october-original-image">NFDI4Bioimage Calendar 2024 October; original image</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#new-kid-on-the-nfdi-block-nfdi4bioimage-a-national-initiative-for-fair-data-management-in-bioimaging-and-bioimage-analysis">New Kid on the (NFDI) Block: NFDI4BIOIMAGE  - A National Initiative for FAIR Data Management in Bioimaging and Bioimage Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nextflow-scalable-and-reproducible-scientific-workflows">Nextflow: Scalable and reproducible scientific workflows</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome-documentation">OME Documentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome-ngff-a-next-generation-file-format-for-expanding-bioimaging-data-access-strategies">OME-NGFF: a next-generation file format for expanding bioimaging data-access strategies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome2024-ngff-challenge-results">OME2024 NGFF Challenge Results</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omero-tools">Omero-tools</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-image-data-handbook">Open Image Data Handbook</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-micoscropy-environment-ome-youtube-channel">Open Micoscropy Environment (OME) Youtube Channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-science-sharing-licensing">Open Science, Sharing &amp; Licensing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimisation-and-validation-of-a-swarm-intelligence-based-segmentation-algorithm-for-low-contrast-positron-emission-tomography">Optimisation and Validation of a Swarm Intelligence based Segmentation Algorithm for low Contrast Positron Emission Tomography</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimized-cranial-window-implantation-for-subcellular-and-functional-imaging-in-vivo">Optimized cranial window implantation for subcellular and functional imaging in vivo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview-of-the-galaxy-omero-suite-upload-images-and-metadata-in-omero-using-galaxy">Overview of the Galaxy OMERO-suite - Upload images and metadata in OMERO using Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parallelization-and-heterogeneous-computing-from-pure-cpu-to-gpu-accelerated-image-processing">Parallelization and heterogeneous computing: from pure CPU to GPU-accelerated image processing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#photonic-data-analysis-in-2050">Photonic data analysis in 2050</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pol-bio-image-analysis-training-school-on-gpu-accelerated-image-analysis">PoL Bio-Image Analysis Training School on GPU-Accelerated Image Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#practical-guide-to-the-international-alignment-of-research-data-management-extended-edition">Practical Guide to the International Alignment of Research Data Management - Extended Edition</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprint-be-sustainable-recommendations-for-fair-resources-in-life-sciences-research-eosc-life-s-lessons">Preprint: “Be Sustainable”, Recommendations for FAIR Resources in Life Sciences research: EOSC-Life’s Lessons</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-engineering-agentic-workflows-and-multi-modal-large-language-models">Prompt Engineering, Agentic Workflows and Multi-modal Large Language Models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qi-2024-analysis-lab-manual">QI 2024 Analysis Lab Manual</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qm-course-lectures-on-bio-image-analysis-with-napari-2024">QM Course Lectures on Bio-Image Analysis with napari 2024</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quarep-limi-a-community-driven-initiative-to-establish-guidelines-for-quality-assessment-and-reproducibility-for-instruments-and-images-in-light-microscopy">QUAREP-LiMi: A community-driven initiative to establish guidelines for quality assessment and reproducibility for instruments and images in light microscopy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qupath-open-source-software-for-analysing-awkward-images">QuPath: Open source software for analysing (awkward) images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdf-as-a-bridge-to-domain-platforms-like-omero-or-there-and-back-again">RDF as a bridge to domain-platforms like OMERO, or There and back again.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdm-starter-kit">RDM Starter Kit</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdm4mic-presentations">RDM4Mic Presentations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdmkit-training-resources">RDMKit Training Resources</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-management-on-campus-and-in-nfdi4bioimage">RESEARCH DATA MANAGEMENT on Campus and in NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rechtsfragen-bei-open-science-ein-leitfaden">Rechtsfragen bei Open Science - Ein Leitfaden</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reconstructed-images-of-a-2dsim-multiposition-acquisition">Reconstructed images of a 2DSIM multiposition acquisition.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#report-on-a-pilot-study-implementation-of-omero-for-microscopy-data-management">Report on a pilot study:  Implementation of OMERO for  microscopy data management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-management-seminar-slides">Research Data Management Seminar - Slides</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-managemet-and-how-not-to-get-overwhelmed-with-data">Research Data Managemet and how not to get overwhelmed with data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-reusability-conceptual-foundations-barriers-and-enabling-technologies">Research Data Reusability - Conceptual Foundations, Barriers and Enabling Technologies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-management-for-bioimaging-the-2021-nfdi4bioimage-community-survey">Research data management for bioimaging - the 2021 NFDI4BIOIMAGE community survey</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Research data management for bioimaging: the 2021 NFDI4BIOIMAGE community survey</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#round-table-workshop-1-sample-stabilization-in-intravital-imaging">Round Table Workshop 1 - Sample Stabilization in intravital Imaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#round-table-workshop-2-correction-of-drift-and-movement">Round Table Workshop 2 - Correction of Drift and Movement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#running-deep-learning-scripts-in-the-bia-pol-omero-server">Running Deep-Learning Scripts in the BiA-PoL Omero Server</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#swc-gcnu-software-skills">SWC/GCNU Software Skills</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sharing-and-licensing-material">Sharing and licensing material</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sharing-research-data-with-zenodo">Sharing research data with Zenodo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#slides-about-flute-a-python-gui-for-interactive-phasor-analysis-of-flim-data">Slides about FLUTE: a Python GUI for interactive phasor analysis of FLIM data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#so-geschlossen-wie-notig-so-offen-wie-moglich-datenschutz-beim-umgang-mit-forschungsdaten">So geschlossen wie nötig, so offen wie möglich - Datenschutz beim Umgang mit Forschungsdaten</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spatialdata-an-open-and-universal-data-framework-for-spatial-omics">SpatialData: an open and universal data framework for spatial omics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stackview-sliceplot-example-data">Stackview sliceplot example data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#structuring-of-data-and-metadata-in-bioimaging-concepts-and-technical-solutions-in-the-context-of-linked-data">Structuring of Data and Metadata in Bioimaging: Concepts and technical Solutions in the Context of Linked Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sustainable-data-stewardship">Sustainable Data Stewardship</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ten-simple-rules-for-making-training-materials-fair">Ten simple rules for making training materials FAIR</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#terminology-service-for-research-data-management-and-knowledge-discovery-in-low-temperature-plasma-physics">Terminology service for research data management and knowledge discovery in low-temperature plasma physics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-dataset-for-whole-slide-image-registration">Test Dataset for Whole Slide Image Registration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-fair-guiding-principles-for-scientific-data-management-and-stewardship">The FAIR Guiding Principles for scientific data management and stewardship</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-fair-guiding-principles-for-data-stewardship-fair-enough">The FAIR guiding principles for data stewardship - fair enough?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-information-infrastructure-for-bioimage-data-i3d-bio-project-to-advance-fair-microscopy-data-management-for-the-community">The Information Infrastructure for BioImage Data (I3D:bio) project to advance FAIR microscopy data management for the community</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-open-microscopy-environment-ome-data-model-and-xml-file-open-tools-for-informatics-and-quantitative-analysis-in-biological-imaging">The Open Microscopy Environment (OME) Data Model and XML file - open tools for informatics and quantitative analysis in biological imaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-turing-way-guide-for-reproducible-research">The Turing Way: Guide for reproducible research</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-role-of-helmholtz-centers-in-nfdi4bioimage-a-national-consortium-enhancing-fair-data-management-for-microscopy-and-bioimage-analysis">The role of Helmholtz Centers in NFDI4BIOIMAGE - A national consortium enhancing FAIR data management for microscopy and bioimage analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#thinking-data-management-on-different-scales">Thinking data management on different scales</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#towards-preservation-of-life-science-data-with-nfdi4bioimage">Towards Preservation of Life Science Data with NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#towards-transparency-and-knowledge-exchange-in-ai-assisted-data-analysis-code-generation">Towards Transparency and Knowledge Exchange in AI-assisted Data Analysis Code Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tracking-of-mitochondria-and-capturing-mitoflashes">Tracking of mitochondria and capturing mitoflashes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-the-trainer-concept-on-research-data-management">Train-the-Trainer Concept on Research Data Management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-computational-skills-in-the-age-of-ai">Training Computational Skills in the Age of AI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-glittr-org-to-find-compare-and-re-use-online-training-materials">Using Glittr.org to find, compare and re-use online training materials</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#welcome-to-bioimage-town">Welcome to BioImage Town</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-open-data">What is Open Data?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#who-you-gonna-call-data-stewards-to-the-rescue">Who you gonna call? - Data Stewards to the rescue</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#working-group-charter-rdm-helpdesk-network">Working Group Charter. RDM Helpdesk Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter">Zeiss AxioZoom Stage Adapter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter-12-6well-plate">Zeiss AxioZoom Stage Adapter - 12/6Well Plate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter-em-block-holder">Zeiss AxioZoom Stage Adapter - EM block holder</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter-microscope-slides">Zeiss AxioZoom Stage Adapter - Microscope slides</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bina-cc-scalable-strategies-for-a-next-generation-of-fair-bioimaging">[BINA CC] Scalable strategies for a next-generation of FAIR bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cidas-scalable-strategies-for-a-next-generation-of-fair-bioimaging">[CIDAS] Scalable strategies for a next-generation of FAIR bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cmcb-scalable-strategies-for-a-next-generation-of-fair-bioimaging">[CMCB] Scalable strategies for a next-generation of FAIR bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cordi-2023-zarr-a-cloud-optimized-storage-for-interactive-access-of-large-arrays">[CORDI 2023] Zarr: A Cloud-Optimized Storage for Interactive Access of Large Arrays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#community-meeting-2024-overview-team-image-data-analysis-and-management">[Community Meeting 2024] Overview Team Image Data Analysis and Management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#community-meeting-2024-supporting-and-financing-rdm-projects-within-gerbi">[Community Meeting 2024] Supporting and financing RDM projects within GerBI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#elmi-2024-ai-s-dirty-little-secret-without">[ELMI 2024]  AI’s Dirty Little Secret: Without</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#elmi-2024-ai-s-dirty-little-secret-without-fair-data-it-s-just-fancy-math">[ELMI 2024] AI’s Dirty Little Secret: Without FAIR Data, It’s Just Fancy Math</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gbi-eoe-vii-five-or-ten-must-have-items-for-making-it-infrastructure-for-managing-bioimage-data">[GBI EOE VII] Five (or ten) must-have items for making IT infrastructure for managing bioimage data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gbi-eoe-ix-nfdi4bioimage">[GBI EoE IX] NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#i2k-scalable-strategies-for-a-next-generation-of-fair-bioimaging">[I2K] Scalable strategies for a next-generation of FAIR bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#n4bi-ahm-welcome-to-bioimage-town">[N4BI AHM] Welcome to BioImage Town</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#swat4hcls-2023-nfdi4bioimage-perspective-for-a-national-bioimage-standard">[SWAT4HCLS 2023] NFDI4BIOIMAGE: Perspective for a national bioimage standard</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#short-talk-nfdi4bioimage-a-consortium-in-the-national-research-data-infrastructure">[Short Talk] NFDI4BIOIMAGE - A consortium in the National Research Data Infrastructure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workshop-material-fit-for-omero-how-imaging-facilities-and-it-departments-work-together-to-enable-rdm-for-bioimaging-october-16-17-2024-heidelberg">[Workshop Material] Fit for OMERO - How imaging facilities and IT departments work together to enable RDM for bioimaging, October 16-17, 2024, Heidelberg</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workshop-bioimage-data-management-and-analysis-with-omero">[Workshop] Bioimage data management and analysis with OMERO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workshop-fair-data-handling-for-microscopy-structured-metadata-annotation-in-omero">[Workshop] FAIR data handling for microscopy: Structured metadata annotation in OMERO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workshop-research-data-management-for-microscopy-and-bioimage-analysis">[Workshop] Research Data Management for Microscopy and BioImage Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ilastik-interactive-machine-learning-for-bio-image-analysis">ilastik: interactive machine learning for (bio)image analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-generative-ai">introduction-to-generative-ai</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nextflow-workshop">nextflow-workshop</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#re3data-org-registry-of-research-data-repositories">re3data.org - registry of Research Data Repositories</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scikit-learn-mooc">scikit-learn MOOC</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-resources">training-resources</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Robert Haase, Clément Caporal,... and the NFDI4BioImage Initiative
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on 2025-03-03.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <p>
Copyright: Licensed <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">CC-BY 4.0</a> unless mentioned otherwise. 
Contributions and feedback are welcome.
</p>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>