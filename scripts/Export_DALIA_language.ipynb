{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2640d79f-4397-4cec-8b56-ad2f4e6867f0",
   "metadata": {},
   "source": [
    "## Extension of the [Export_to_DALIA](scripts/Export_to_DALIA.ipynb) Notebook. \n",
    "To speed up the process of converting the [nfdi4bioimage.yml](resources/nfdi4bioimage.yml) file to the DALIA format, the language detection part is separated from the main workflow.\n",
    "This notebook should be run regularly, to ensure proper documentation of the language in our Training Material entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8091aca8-8ced-4159-8047-af41c04fc1c1",
   "metadata": {},
   "source": [
    "#### Extract the Language of each Entry\n",
    "This is done using the [xlm-roberta-base-language-detection](https://huggingface.co/papluca/xlm-roberta-base-language-detection) model via the transformers package pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "947afccc-a37c-483f-b8a9-3433e281d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from generate_link_lists import load_dataframe\n",
    "\n",
    "destination = '../docs/export/DALIA_training_materials.csv'\n",
    "df = pd.read_csv(destination)\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b7e1270-7f5d-451a-8f0d-d5db1eda6ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = \"papluca/xlm-roberta-base-language-detection\"\n",
    "pipe = pipeline(\"text-classification\", model=model_ckpt)\n",
    "\n",
    "def detect_language(text):\n",
    "    lang = pipe([text], top_k=1, truncation=True)[0][0][\"label\"]\n",
    "    return lang if lang in [\"en\", \"de\"] else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aaba39c-fbd8-4f3f-9cde-2e7c857a94a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if "Language" not in df.columns:\n",
    "    df["Language"] = None\n",
    "mask = df[\"Language\"].isna() | df[\"Language\"].eq('')\n",
    "\n",
    "# Process the DataFrame only where no entry is available at the language column\n",
    "df.loc[mask, \"Language\"] = df.loc[mask, \"Title\"].apply(detect_language)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec32e7e6-7479-4c4f-bc0c-c6f902a25b9b",
   "metadata": {},
   "source": [
    "### 8. Introduce the **FileFormat** Column by comparing the MediaType to a FileFormat list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0032674f-2a3c-44fa-9783-77fa69eeaec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import time\n",
    "\n",
    "# Function to extract record ID from a Zenodo link\n",
    "def extract_zenodo_record_id(url):\n",
    "    # Regex to match Zenodo record links and extract the record ID\n",
    "    match = re.search(r\"https://zenodo.org/records/(\\d+)\", url)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Function to fetch file formats from Zenodo using the record ID\n",
    "def fetch_file_formats(record_id):\n",
    "    if not record_id:\n",
    "        return None\n",
    "    api_url = f\"https://zenodo.org/api/records/{record_id}\"\n",
    "    try:\n",
    "        time.sleep(1)  # Add a 1-second delay between requests\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()  # Raise an error for non-2xx responses\n",
    "        data = response.json()\n",
    "        file_types = {\n",
    "            file[\"key\"].split(\".\")[-1].lower()\n",
    "            for file in data.get(\"files\", [])\n",
    "            if \".\" in file[\"key\"]\n",
    "        }\n",
    "        return \" * \".join(sorted(file_types)) if file_types else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching file formats for record ID {record_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to process a single URL or a list of URLs\n",
    "def process_links(link_input):\n",
    "    if isinstance(link_input, str):\n",
    "        # Single URL case\n",
    "        record_id = extract_zenodo_record_id(link_input)\n",
    "        if record_id:\n",
    "            return fetch_file_formats(record_id)\n",
    "    elif isinstance(link_input, list):\n",
    "        # List of URLs case\n",
    "        for link in link_input:\n",
    "            record_id = extract_zenodo_record_id(link.strip())\n",
    "            if record_id:\n",
    "                file_format = fetch_file_formats(record_id)\n",
    "                if file_format:  # Return on first valid result\n",
    "                    return file_format\n",
    "    return None  # Return None if no valid formats are found\n",
    "\n",
    "# Change the FileFormat Column where it is NA or empty\n",
    "mask = df[\"FileFormat\"].isna() | df[\"FileFormat\"].eq('')\n",
    "df.loc[mask, \"FileFormat\"] = df.loc[mask, \"Link\"].apply(process_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b3326a-7dfa-401b-8840-ac47c518c5fc",
   "metadata": {},
   "source": [
    "Additionally map the Type Column to certain File Formats, if it is not already filled from the previous step. (only works for certain MediaTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "decf831b-cf6d-4965-8f68-8340635785be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_file_format(media_type, file_format):\n",
    "    # If FileFormat already has a valid entry, return it as is\n",
    "    if file_format is not None and file_format.strip() != \"\":\n",
    "        return file_format\n",
    "    # Map media types to specific file formats\n",
    "    if media_type == \"audio\":\n",
    "        return \".mp3\"\n",
    "    elif media_type == \"video\":\n",
    "        return \".mp4\"\n",
    "    else:\n",
    "        return \"\"  # Return empty string if no mapping is needed\n",
    "\n",
    "# Apply the mapping function\n",
    "df[\"FileFormat\"] = df.apply(\n",
    "    lambda row: map_file_format(row[\"MediaType\"], row[\"FileFormat\"]),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0c7adc-ade4-43dd-a015-2ce27ad111e8",
   "metadata": {},
   "source": [
    "### Save the updated DALIA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5178f6b5-5aa1-4db1-974c-7254259894a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 453 rows.\n"
     ]
    }
   ],
   "source": [
    "# Save\n",
    "df.to_csv(destination, index=False)\n",
    "\n",
    "num_rows = df.shape[0]\n",
    "print(f\"Exported {num_rows} rows.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
