
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Exclude from dalia (460) &#8212; NFDI4BioImage Training Materials</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/css/searchbox.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/0.6.0/lunr.min.js"></script>
    <script src="../_static/js/searchbox.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tags/exclude_from_dalia';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Fair-principles (29)" href="fair-principles.html" />
    <link rel="prev" title="Data stewardship (6)" href="data_stewardship.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="2025-10-21"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../readme.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="NFDI4BioImage Training Materials - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="NFDI4BioImage Training Materials - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../readme.html">
                    NFDI4BioImage Training Materials
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">What's new</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../whats_new.html">Recently added (9)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Contributing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../contributing/index.html">How to contribute</a></li>

<li class="toctree-l1"><a class="reference internal" href="../contributing/submit_app.html">Using the Training Materials Submission App</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing/format.html">YML format</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">By tag</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ai-ready.html">Ai-ready (86)</a></li>
<li class="toctree-l1"><a class="reference internal" href="artificial_intelligence.html">Artificial intelligence (52)</a></li>
<li class="toctree-l1"><a class="reference internal" href="bioimage_analysis.html">Bioimage analysis (214)</a></li>
<li class="toctree-l1"><a class="reference internal" href="bioinformatics.html">Bioinformatics (20)</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_stewardship.html">Data stewardship (6)</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Exclude from dalia (460)</a></li>
<li class="toctree-l1"><a class="reference internal" href="fair-principles.html">Fair-principles (29)</a></li>
<li class="toctree-l1"><a class="reference internal" href="fiji.html">Fiji (6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="galaxy.html">Galaxy (6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="imagej.html">Imagej (20)</a></li>
<li class="toctree-l1"><a class="reference internal" href="include_in_dalia.html">Include in dalia (338)</a></li>
<li class="toctree-l1"><a class="reference internal" href="licensing.html">Licensing (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="metadata.html">Metadata (15)</a></li>
<li class="toctree-l1"><a class="reference internal" href="napari.html">Napari (14)</a></li>
<li class="toctree-l1"><a class="reference internal" href="neubias.html">Neubias (27)</a></li>
<li class="toctree-l1"><a class="reference internal" href="nfdi4bioimage.html">Nfdi4bioimage (80)</a></li>
<li class="toctree-l1"><a class="reference internal" href="omero.html">Omero (42)</a></li>
<li class="toctree-l1"><a class="reference internal" href="open_science.html">Open science (9)</a></li>
<li class="toctree-l1"><a class="reference internal" href="open_source_software.html">Open source software (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="python.html">Python (71)</a></li>
<li class="toctree-l1"><a class="reference internal" href="reproducibility.html">Reproducibility (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="research_data_management.html">Research data management (148)</a></li>
<li class="toctree-l1"><a class="reference internal" href="sharing.html">Sharing (12)</a></li>
<li class="toctree-l1"><a class="reference internal" href="workflow.html">Workflow (9)</a></li>
<li class="toctree-l1"><a class="reference internal" href="workflow_engine.html">Workflow engine (13)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">By content type</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../content_types/blog%20post.html">Blog post (28)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/book.html">Book (21)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/code.html">Code (10)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/collection.html">Collection (86)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/data.html">Data (94)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/document.html">Document (8)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/documentation.html">Documentation (19)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/event.html">Event (8)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/github%20repository.html">Github repository (70)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/notebook.html">Notebook (57)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/online%20tutorial.html">Online tutorial (10)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/poster.html">Poster (10)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/preprint.html">Preprint (6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/publication.html">Publication (74)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/slides.html">Slides (85)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/tutorial.html">Tutorial (48)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/video.html">Video (40)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/website.html">Website (12)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../content_types/workshop.html">Workshop (14)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">By license</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../licenses/all_rights_reserved.html">All rights reserved (14)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../licenses/apache-2.0.html">Apache-2.0 (6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../licenses/bsd-2-clause.html">Bsd-2-clause (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../licenses/bsd-3-clause.html">Bsd-3-clause (37)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../licenses/cc-by-3.0.html">Cc-by-3.0 (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../licenses/cc-by-4.0.html">Cc-by-4.0 (418)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../licenses/cc-by-nc-sa-4.0.html">Cc-by-nc-sa-4.0 (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../licenses/cc-by-sa-4.0.html">Cc-by-sa-4.0 (6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../licenses/cc0-1.0.html">Cc0-1.0 (25)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../licenses/gpl-2.0.html">Gpl-2.0 (8)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../licenses/gpl-3.0.html">Gpl-3.0 (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../licenses/mit.html">Mit (32)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../licenses/unknown.html">Unknown (111)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">By domain</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../domain/bbbc.broadinstitute.org.html">Bbbc.broadinstitute.org (12)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/biapol.github.io.html">Biapol.github.io (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/docs.google.com.html">Docs.google.com (6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/doi.org.html">Doi.org (353)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/f1000research.com.html">F1000research.com (11)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/focalplane.biologists.com.html">Focalplane.biologists.com (14)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/git.mpi-cbg.de.html">Git.mpi-cbg.de (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/github.com.html">Github.com (151)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/training.galaxyproject.org.html">Training.galaxyproject.org (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/www.biorxiv.org.html">Www.biorxiv.org (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/www.ebi.ac.uk.html">Www.ebi.ac.uk (18)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/www.nature.com.html">Www.nature.com (21)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/www.youtube.com.html">Www.youtube.com (29)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../domain/zenodo.org.html">Zenodo.org (334)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../statistics/readme.html">Statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../export/readme.html">Open data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gdpr_compliance.html">GDPR Compliance Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../imprint.html">Imprint</a></li>

</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/NFDI4BIOIMAGE/training" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/NFDI4BIOIMAGE/training/issues/new?title=Issue%20on%20page%20%2Ftags/exclude_from_dalia.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/tags/exclude_from_dalia.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Exclude from dalia (460)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lif-files-misbehaving-in-fiji-but-fine-in-lasx">.lif files misbehaving in fiji but fine in LASX</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#frames-of-fluorescent-particles">10 frames of fluorescent particles</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-science-bowl">2018 Data Science Bowl</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimage-analysis-survey-community-experiences-and-needs-for-the-future">2020 BioImage Analysis Survey: Community experiences and needs for the future</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#d-ground-truth-annotations-of-nuclei-in-3d-microscopy-volumes">3D Ground Truth Annotations of Nuclei in 3D Microscopy Volumes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#d-hl60-cell-line-synthetic-data">3D HL60 Cell line (synthetic data)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#d-nuclei-annotations-and-stardist-3d-model-s-rat-brain">3D Nuclei annotations and StarDist 3D model(s) (rat brain)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#d-cell-shape-of-drosophila-wing-disc">3D cell shape of Drosophila Wing Disc</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#d-light-sheet-microscopy-data-for-selma3d-2024-challenge-training-subset-with-annotations">3D light-sheet microscopy data for SELMA3D 2024 challenge - Training subset with annotations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#d-nuclei-instance-segmentation-dataset-of-fluorescence-microscopy-volumes-of-c-elegans">3D nuclei instance segmentation dataset of fluorescence microscopy volumes of C. elegans</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-cloud-optimized-storage-for-interactive-access-of-large-arrays">A Cloud-Optimized Storage for Interactive Access of Large Arrays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-glimpse-of-the-open-source-flim-analysis-software-tools-flimfit-flute-and-napari-flim-phasor-plotter">A Glimpse of the Open-Source FLIM Analysis Software Tools FLIMfit, FLUTE and napari-flim-phasor-plotter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-call-for-public-archives-for-biological-image-data">A call for public archives for biological image data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-checklist-for-designing-and-improving-the-visualization-of-scientific-data">A checklist for designing and improving the visualization of scientific data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-deep-learning-approach-to-quantify-auditory-hair-cells">A deep learning approach to quantify auditory hair cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-mihc-mrxs-example">A mihc mrxs example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-study-on-long-term-reproducibility-of-image-analysis-results-on-imagej-and-fiji">A study on long-term reproducibility of image analysis results on ImageJ and Fiji</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abic-intermediate-fiji-image-analysis-course-2024">ABIC - Intermediate Fiji Image Analysis Course 2024</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ai4life-teams-up-with-galaxy-training-network-gtn-to-enhance-training-resources">AI4Life teams up with Galaxy Training Network (GTN) to enhance training resources</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abdominal-imaging-window-aiw-for-intravital-imaging">Abdominal Imaging Window (AIW) for Intravital Imaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aberrated-bead-stack">Aberrated Bead Stack</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abstract-nfdi-basic-service-for-data-management-plans">Abstract - NFDI Basic Service for Data Management Plans</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-a-workflow-to-biaflows">Adding a Workflow to BIAFLOWS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#an-annotated-fluorescence-image-dataset-for-training-nuclear-segmentation-methods">An annotated fluorescence image dataset for training nuclear segmentation methods</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#an-annotated-high-content-fluorescence-microscopy-dataset-with-hoechst-33342-stained-nuclei-and-manually-labelled-outlines">An annotated high-content fluorescence microscopy dataset with Hoechst 33342-stained nuclei and manually labelled outlines</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#an-image-based-data-driven-analysis-of-cellular-architecture-in-a-developing-tissue">An image-based data-driven analysis of cellular architecture in a developing tissue</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#andor-dragonfly-confocal-image-of-bpae-cells-stained-for-actin-ims-file-format">Andor Dragonfly confocal image of BPAE cells stained for actin, IMS file format</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#angebote-der-nfdi-fur-die-forschung-im-bereich-zoologie">Angebote der NFDI für die Forschung im Bereich Zoologie</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#annotated-research-context-arc">Annotated Research Context (ARC</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#annotated-high-throughput-microscopy-image-sets-for-validation">Annotated high-throughput microscopy image sets for validation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#artificial-blobs-and-labels-image">Artificial Blobs and Labels image</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assessment-of-residual-breast-cancer-cellularity-after-neoadjuvant-chemotherapy-using-digital-pathology">Assessment of Residual Breast Cancer Cellularity after Neoadjuvant Chemotherapy using Digital Pathology</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#astigmatic-4pi-bead-stack">Astigmatic 4Pi bead stack</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-labelling-of-hela-kyoto-cells-using-deep-learning-tools">Automatic labelling of HeLa “Kyoto” cells using Deep Learning tools</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#axioscan-7-fluorescent-channels-not-displaying-in-qupath">Axioscan 7 fluorescent channels not displaying in QuPath</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bccd-dataset">BCCD Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bhg2023-omero-arc">BHG2023-OMERO-ARC</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bia-seminar-series">BIA Seminar Series</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bids-lecture-2024">BIDS-lecture-2024</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#biomero-a-scalable-and-extensible-image-analysis-framework">BIOMERO - A scalable and extensible image analysis framework</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#beads-imaged-over-time">Beads imaged over time</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#biapy-bioimage-analysis-pipelines-in-python">BiaPy: Bioimage analysis pipelines in Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bigdataprocessor2-a-free-and-open-source-fiji-plugin-for-inspection-and-processing-of-tb-sized-image-data">BigDataProcessor2: A free and open-source Fiji plugin for inspection and processing of TB sized image data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis">Bio Image Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis-lecture-2020">Bio Image Analysis Lecture 2020</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis-icob-2023">Bio-image Analysis ICOB 2023</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-data-science-lectures-2025-uni-leipzig-scads-ai">Bio-image Data Science Lectures 2025 @ Uni Leipzig / ScaDS.AI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-data-science-lectures-uni-leipzig-scads-ai">Bio-image Data Science Lectures @ Uni Leipzig / ScaDS.AI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-tools-database">Bio.tools database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioengine">BioEngine</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioengine-documentation">BioEngine Documentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioformats-command-line-cli-tools">BioFormats Command line (CLI) tools</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimage-archive-ai-gallery">BioImage Archive AI Gallery</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimage-archive-visual-gallery">BioImage Archive Visual Gallery</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimage-archive-volume-em-gallery">BioImage Archive Volume EM Gallery</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimage-informatics-index-training-materials">BioImage Informatics Index Training Materials</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimage-archive">Bioimage Archive</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimage-model-zoo">Bioimage Model Zoo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimaging-workflow-based-on-omero-elabftw-and-adamant-for-integrating-images-with-multimodal-metadata">Bioimaging workflow based on OMERO, eLabFTW, and Adamant for integrating images with multimodal metadata</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#biologists-stop-putting-umap-plots-in-your-papers">Biologists, stop putting UMAP plots in your papers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#biomero">Biomero</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#breast-cancer-nuclei-images-for-dl-training-zerocostdl4mic-stardist-model">Breast Cancer Nuclei images for DL Training + ZeroCostDL4Mic StarDist Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#breast-cancer-semantic-segmentation-bcss-dataset">Breast Cancer Semantic Segmentation (BCSS) dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bridging-imaging-users-to-imaging-analysis-a-community-survey">Bridging Imaging Users to Imaging Analysis - A community survey</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bring-your-own-data-workshops">Bring your own data workshops</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-fair-image-analysis-pipelines-for-high-content-screening-hcs-data-using-galaxy">Building FAIR image analysis pipelines for high-content-screening (HCS) data using Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-a-fair-image-data-ecosystem-for-microscopy-communities">Building a FAIR image data ecosystem for microscopy communities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clij-gpu-accelerated-image-processing-for-everyone">CLIJ: GPU-accelerated image processing for everyone</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coba-nih-2024-bridging-imaging-users-to-imaging-analysis-survey-survey-data-with-preliminary-exploration">COBA-NIH/2024_Bridging_Imaging_Users_to_Imaging_Analysis_Survey: Survey data with preliminary exploration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coba-center-for-open-bioimage-analysis-youtube-channel">COBA: Center for Open Bioimage Analysis YouTube Channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ct-physics">CT Physics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#czi-carl-zeiss-image-dataset-with-artificial-test-camera-images-with-various-dimension-for-testing-libraries-reading">CZI (Carl Zeiss Image) dataset with artificial test camera images with various dimension for testing libraries reading</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#czi-file-examples">CZI file examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#czi-open-science-program-collection">CZI: Open Science Program Collection</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-tracking-challenge-2d-datasets">Cell Tracking Challenge - 2D Datasets</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-tracking-challenge-3d-datasets">Cell Tracking Challenge - 3D Datasets</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellbindb-a-large-scale-multimodal-annotated-dataset">CellBinDB: A Large-Scale Multimodal Annotated Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#celltrackcolab">CellTrackColab</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellpose-model-for-digital-phase-contrast-images">Cellpose model for Digital Phase Contrast images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellpose-models-for-label-prediction-from-brightfield-and-digital-phase-contrast-images">Cellpose models for Label Prediction from Brightfield and Digital Phase Contrast images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellpose-training-data-and-scripts-from-inhibition-of-cers1-in-aging-skeletal-muscle-exacerbates-age-related-muscle-impairments">Cellpose training data and scripts from “Inhibition of CERS1 in aging skeletal muscle exacerbates age-related muscle impairments”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellpose-training-data-and-scripts-from-machine-learning-for-histological-annotation-and-quantification-of-cortical-layers">Cellpose training data and scripts from “Machine learning for histological annotation and quantification of cortical layers”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#checklists-for-publishing-images-and-image-analysis">Checklists for publishing images and image analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chinese-hamster-ovary-cells">Chinese Hamster Ovary Cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#choose-an-open-source-license">Choose an open source license</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chris-halvin-youtube-channel">Chris Halvin YouTube channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cloud-based-virtual-desktops-for-reproducible-research">Cloud-Based Virtual Desktops for Reproducible Research</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#collaborative-working-and-version-control-with-git-hub">Collaborative working and  Version Control with Git[Hub]</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#combining-stardist-and-trackmate-example-1-breast-cancer-cell-dataset">Combining StarDist and TrackMate example 1 -  Breast cancer cell dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#combining-stardist-and-trackmate-example-2-t-cell-dataset">Combining StarDist and TrackMate example 2 -  T cell dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#combining-stardist-and-trackmate-example-3-flow-chamber-dataset">Combining StarDist and TrackMate example 3 -  Flow chamber dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#combining-the-bids-and-arc-directory-structures-for-multimodal-research-data-organization">Combining the BIDS and ARC Directory Structures for Multimodal Research Data Organization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conference-slides-4th-day-of-intravital-microscopy">Conference Slides - 4th Day of Intravital Microscopy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cryonuseg">CryoNuSeg</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dcimg-dense-beads-taken-in-chunks-over-time">DCIMG dense beads taken in chunks over time</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-napari-napari-as-a-tool-for-deep-learning-project-management">DEEP NAPARI : Napari as a tool for deep learning project management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dl4miceverywhere">DL4MicEverywhere</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dl4proteins-notebooks">DL4Proteins-notebooks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dl-mbl-2021-exercises">DL@MBL 2021 Exercises</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dng-in-bioformat-opens-in-wrong-resolution">DNG in BioFormat opens in wrong resolution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dask-course">Dask Course</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-stewardship-wizard">Data Stewardship Wizard</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-life-cycle">Data life cycle</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-from-incell-2200-microscope-misread-as-a-plate">Dataset from InCell 2200 microscope misread as a plate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deconvolution-test-dataset">Deconvolution Test Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-learning-segmentation-projects-of-fib-sem-dataset-of-u2-os-cell">Deep learning segmentation projects of FIB-SEM dataset of U2-OS cell</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-learning-training-data-jove">Deep learning training data (JOVE)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deepbacs-bacillus-subtilis-fluorescence-segmentation-dataset">DeepBacs – Bacillus subtilis fluorescence segmentation dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deepbacs-escherichia-coli-bright-field-segmentation-dataset">DeepBacs – Escherichia coli bright field segmentation dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deepbacs-mixed-segmentation-dataset-and-stardist-model">DeepBacs – Mixed segmentation dataset and StarDist model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deepbacs-staphylococcus-aureus-widefield-segmentation-dataset">DeepBacs – Staphylococcus aureus widefield segmentation dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#democratizing-knowledge-representation-with-biocypher">Democratizing knowledge representation with BioCypher</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#detection-and-segmentation-of-cell-nuclei-in-virtual-microscopy-images-a-minimum-model-approach">Detection and Segmentation of Cell Nuclei in Virtual Microscopy Images A Minimum-Model Approach</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#developing-semi-automatic-analysis-pipelines-and-technological-solutions-for-metadata-annotation-and-management-in-high-content-screening-hcs-bioimaging">Developing (semi)automatic analysis pipelines and technological solutions for metadata annotation and management in high-content screening (HCS) bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#development-fair-image-analysis-workflows-and-rdm-pipelines-in-galaxy">Development FAIR image analysis workflows and RDM pipelines in Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diffusion-models-for-image-restoration-an-introduction">Diffusion Models for Image Restoration - An Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#digital-phase-contrast-on-primary-dermal-human-fibroblasts-cells">Digital Phase Contrast on Primary Dermal Human Fibroblasts cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#digitalsreeni-youtube-channel">DigitalSreeni YouTube Channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dokumentation-und-anleitung-zum-elektronischen-laborbuch-elabftw">Dokumentation und Anleitung zum elektronischen Laborbuch (eLabFTW)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#drosophila-kc167-cells">Drosophila Kc167 cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#edam-bioimaging-the-ontology-of-bioimage-informatics-operations-topics-data-and-formats">EDAM-bioimaging - The ontology of bioimage informatics operations, topics, data, and formats</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embl-ebi-material-collection">EMBL-EBI material collection</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embo-practical-course-advanced-methods-in-bioimage-analysis">EMBO Practical Course Advanced methods in bioimage analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#epflx-image-processing-and-analysis-for-life-scientists">EPFLx: Image Processing and Analysis for Life Scientists</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#effect-of-local-topography-on-cell-division-of-staphylococci-sp">Effect of local topography on cell division of Staphylococci sp.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embedseg-repository">EmbedSeg Repository</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embryonic-mice-ultrasound-volumes-with-body-and-brain-volume-segmentation-masks">Embryonic mice ultrasound volumes with body and brain volume segmentation masks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#enabling-global-image-data-sharing-in-the-life-sciences">Enabling Global Image Data Sharing in the Life Sciences</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#erick-martins-ratamero-expanding-the-ome-ecosystem-for-imaging-data-management-scipy-2024">Erick Martins Ratamero - Expanding the OME ecosystem for imaging data management | SciPy 2024</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-scientific-ambassadors-program">Euro-BioImaging  Scientific Ambassadors Program</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-annual-report-2020">Euro-BioImaging Annual Report 2020</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-annual-report-2021">Euro-BioImaging Annual Report 2021</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-annual-report-2023">Euro-BioImaging Annual Report 2023</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-annual-report-2024">Euro-BioImaging Annual Report 2024</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-communication-youtube-channel">Euro-BioImaging Communication YouTube Channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-eric-annual-report-2022">Euro-BioImaging ERIC Annual Report 2022</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-s-template-for-research-data-management-plans">Euro-BioImaging’s Template for Research Data Management Plans</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-batchconvert-v0-0-4">Euro-BioImaging/BatchConvert: v0.0.4</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evident-oir-sample-files-tiles-stitched-image-fv-4000">Evident OIR sample files tiles + stitched image - FV 4000</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evident-oir-sample-files-with-lambda-scan-fv-4000">Evident OIR sample files with lambda scan - FV 4000</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-imaris-ims-datasets">Example Imaris ims datasets.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-microscopy-metadata-json-files-produced-using-micro-meta-app-to-document-example-microscopy-experiments-performed-at-individual-core-facilities">Example Microscopy Metadata JSON files produced using Micro-Meta App to document example microscopy experiments performed at individual core facilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-operetta-dataset">Example Operetta Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-pipeline-tutorial">Example Pipeline Tutorial</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#excel-template-for-adding-key-value-pairs-to-images">Excel template for adding Key-Value Pairs to images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fair-bioimage-data">FAIR BioImage Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fair-high-content-screening-in-bioimaging">FAIR High Content Screening in Bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fiber-and-vessel-dataset-for-segmentation-and-characterization">Fiber and vessel dataset for segmentation and characterization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fiji">Fiji</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fiji-is-just-imagej-tutorials">Fiji Is Just ImageJ Tutorials</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fit-for-omero-how-imaging-facilities-and-it-departments-work-together-to-enable-rdm-for-bioimaging">Fit for OMERO: How imaging facilities and IT departments work together to enable RDM for bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forschungsdatenmanagement-zukunftsfest-gestalten-impulse-fur-die-strukturevaluation-der-nationalen-forschungsdateninfrastruktur-nfdi">Forschungsdatenmanagement zukunftsfest gestalten – Impulse für die   Strukturevaluation der Nationalen Forschungsdateninfrastruktur (NFDI)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fractal-documentation">Fractal Documentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#galaxy-documentation">Galaxy Documentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#galaxy-imaging">Galaxy Imaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#galaxy-training">Galaxy Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#galaxy-training-material">Galaxy Training Material</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#galaxyproject-youtube-channel">GalaxyProject YouTube Channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gerbi-teaching-resources-link-list">GerBI Teaching Resources Link List</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gerbi-chat-teil-1-vom-bedarf-bis-zum-groszgerateantrag-schreiben">GerBI-Chat: Teil 1 - Vom Bedarf bis zum Großgeräteantrag-Schreiben</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gerbi-chat-teil-2-wie-schreibe-ich-am-besten-einen-groszegrateantrag">GerBI-Chat: Teil 2 - Wie schreibe ich am besten einen Großegräteantrag</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#get-started-accessing-the-de-nbi-cloud">Get started accessing the de.NBI cloud.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ghent-university-research-data-management-rdm-policy-and-support">Ghent University Research Data Management (RDM) - policy and support</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#glencoe-software-webinars">Glencoe Software Webinars</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#globias">GloBIAS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#globias-in-person-workshop-2024">GloBIAS in-person workshop 2024</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#global-bioimaging-training-database">Global BioImaging Training Database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#global-bioimaging-youtube-channel">Global BioImaging YouTube channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#go-nuclear-a-deep-learning-based-toolkit-for-3d-nuclei-segmentation-and-quantitative-analysis-in-cellular-and-tissue-context">Go-Nuclear. A deep learning-based toolkit for 3D nuclei segmentation and quantitative analysis in cellular and tissue context</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ground-truth-cell-body-segmentation-used-for-starfinity-training">Ground-truth cell body segmentation used for Starfinity training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gut-analysis-toolbox">Gut Analysis Toolbox</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gut-analysis-toolbox-training-data-and-2d-models-for-segmenting-enteric-neurons-neuronal-subtypes-and-ganglia">Gut Analysis Toolbox: Training data and 2D models for segmenting enteric neurons, neuronal subtypes and ganglia</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hpa-nucleus-segmentation-dpnunet">HPA Nucleus Segmentation (DPNUnet)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ht1080wt-cells-embedded-in-3d-collagen-type-i-matrices-manual-annotations-for-cell-instance-segmentation-and-tracking">HT1080WT cells embedded in 3D collagen type I matrices - manual annotations for cell instance segmentation and tracking</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hackaton-results-conversion-of-knime-image-analysis-workflows-to-galaxy">Hackaton Results - Conversion of KNIME image analysis workflows to Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#harmonizing-the-generation-and-pre-publication-stewardship-of-fair-image-data">Harmonizing the Generation and Pre-publication Stewardship of FAIR Image Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hela-kyoto-cells-under-the-scope">HeLa “Kyoto” cells under the scope</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hitchhiking-through-a-diverse-bio-image-analysis-software-universe">Hitchhiking through a diverse Bio-image Analysis Software Universe</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-open-source-software-could-finally-get-the-worlds-microscopes-speaking-the-same-language">How open-source software could finally get the world’s microscopes speaking the same language</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-get-started-with-jupyter-and-colab">How to get started with Jupyter and Colab</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-make-cartographic-projections-using-imsane">How to make cartographic projections using ImSAnE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#human-dab-staining-axioscan-bf-20x">Human DAB staining Axioscan BF 20x</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#human-ht29-colon-cancer-cells">Human HT29 colon-cancer cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#human-hepatocyte-and-murine-fibroblast-cells-co-culture-experiment">Human Hepatocyte and Murine Fibroblast cells Co-culture experiment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#human-lung-tissue-microscopy-dic-fluorescence-cell-and-nuclei-semantic-instance-annotations">Human Lung Tissue Microscopy (DIC, Fluorescence, Cell and Nuclei Semantic Instance Annotations)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#human-u2os-cells-out-of-focus">Human U2OS cells (out of focus)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#i3d-bio-information-infrastructure-for-bioimage-data-bioimage-metadata">I3D bio – Information Infrastructure for BioImage Data - Bioimage Metadata</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#i3d-bio-list-of-online-training-material">I3D:bio list of online training material</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ics-ids-stitched-file">ICS/IDS stitched file</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#itkelastix-examples">ITKElastix Examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ibiology-bioimage-analysis-course-the-life-cycle-of-an-image-data-set">Ibiology. Bioimage Analysis Course. The Life Cycle of an Image Data Set</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-data-resources">Image Data Resources</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-data-services-at-euro-bioimaging-community-efforts-towards-fair-image-data-and-analysis-services">Image Data Services at Euro-BioImaging: Community efforts towards FAIR Image Data and Analysis Services</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-analysis-in-galaxy">Image analysis in Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imagej-bioformats-8-3-0-importer-incorrectly-reading-nd2-metadata">ImageJ Bioformats 8.3.0 Importer Incorrectly Reading ND2 Metadata</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imagej-tool-for-percentage-estimation-of-pneumonia-in-lungs">ImageJ tool for percentage estimation of pneumonia in lungs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#images-acquired-with-zeiss-sigma-300-images-with-low-magnification-are-corrently-not-handeled-correctly">Images acquired with Zeiss Sigma 300 - Images with low magnification are corrently not handeled correctly</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imaris-tutorials">Imaris Tutorials</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-kidney">Implantation of abdominal imaging windows on the mouse kidney</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-kidney-short-version">Implantation of abdominal imaging windows on the mouse kidney - short version</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-liver">Implantation of abdominal imaging windows on the mouse liver</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-liver-short-version">Implantation of abdominal imaging windows on the mouse liver - short version</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#incell-datasets-with-mix-of-2d-and-3d-failed-to-be-read">InCell datasets with mix of 2D and 3D failed to be read</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ink-in-a-dish">Ink in a dish</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#insights-and-impact-from-five-cycles-of-essential-open-source-software-for-science">Insights and Impact From Five Cycles of Essential Open Source Software for Science</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#insights-from-acquiring-open-medical-imaging-datasets-for-foundation-model-development">Insights from Acquiring Open Medical Imaging  Datasets for Foundation Model Development</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Insights from Acquiring Open Medical Imaging Datasets for Foundation Model Development</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#institutionalization-and-collaboration-as-a-way-of-addressing-the-challenges-open-science-presents-to-libraries-the-university-of-konstanz-as-a-national-pioneer">Institutionalization and Collaboration as a Way of Addressing the Challenges Open Science Presents to Libraries: The University of Konstanz as a National Pioneer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#integration-of-bioimage-and-omics-data-resources">Integration of Bioimage and *Omics data resources</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#intravital-microscopy-contrasting-agents-for-application-database">Intravital microscopy contrasting agents for application - Database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introducing-omero-vitessce-an-omero-web-plugin-for-multi-modal-data">Introducing OMERO-vitessce: an OMERO.web plugin for multi-modal data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-light-microscopy-widefield-microscopy">Introduction to light-microscopy / Widefield microscopy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#jipipe-visual-batch-processing-for-imagej">JIPipe: visual batch processing for ImageJ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#jupyter-for-interactive-cloud-computing">Jupyter for interactive cloud computing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#knime-image-processing">KNIME Image Processing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pair-template-for-annotation-in-omero-for-light-microscopy-data-acquired-with-axioscan7-core-facility-cellular-imaging-cfci">Key-Value pair template for annotation in OMERO for light microscopy data acquired with AxioScan7 - Core Facility Cellular Imaging (CFCI)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pair-template-for-annotation-of-datasets-in-omero-perikles-study">Key-Value pair template for annotation of datasets in OMERO (PERIKLES study)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pair-template-for-annotation-of-datasets-in-omero-for-light-and-electron-microscopy-data-within-the-research-group-of-prof-muller-reichert">Key-Value pair template for annotation of datasets in OMERO for light- and electron microscopy data within the research group of Prof. Müller-Reichert</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pairs-scripts">Key-Value pairs scripts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#leo">LEO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#leo-linking-eln-with-omero">LEO: Linking ELN with OMERO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lmrg-image-analysis-study-fish-datasets">LMRG Image Analysis Study - FISH datasets</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lmrg-image-analysis-study-nuclei-datasets">LMRG Image Analysis Study - nuclei datasets</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lsm-example-j-dubrulle">LSM example J. Dubrulle</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lz4-compressed-imaris-ims-example-datasets">LZ4-compressed Imaris ims example datasets.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#large-tiling-confocal-acquisition-rat-brain">Large tiling confocal acquisition (rat brain)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laser-perturbation-imaging-data-for-patterned-invagination-prevents-mechanical-instability-during-gastrulation">Laser perturbation imaging data for: Patterned invagination prevents mechanical instability during gastrulation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laulauthom-maskfromrois-fiji-masks-from-rois-plugins-for-fiji-initial-release">LauLauThom/MaskFromRois-Fiji: Masks from ROIs plugins for Fiji - initial release</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laulauthom-maskfromrois-fiji-v1-0-1-better-handle-cancel">LauLauThom/MaskFromRois-Fiji: v1.0.1 - better handle “cancel”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-materials-of-the-deeplife-course">Lecture-materials of the DeepLife course</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#leica-lif-file-with-errors-in-channel-order-when-imported-with-bio-formats">Leica (.lif) file with errors in channel order when imported with Bio-formats</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#leitlinie-grundsatze-policy-richtlinie-forschungsdaten-policies-an-deutschen-universitaten">Leitlinie? Grundsätze? Policy? Richtlinie? – Forschungsdaten-Policies an deutschen Universitäten</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#life-science-competence-centres-open-by-design">Life Science Competence Centres: Open by Design</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lightsheet-and-in-situ-imaging-data-for-patterned-invagination-prevents-mechanical-instability-during-gastrulation">Lightsheet and in situ imaging data for: Patterned invagination prevents mechanical instability during gastrulation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limeseg-test-datasets">LimeSeg Test Datasets</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linked-open-data-for-microbial-population-biology">Linked (Open) Data for Microbial Population Biology</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linking-of-research-meta-data-in-omero-to-foster-fair-data-in-plasma-science">Linking of Research (Meta-)data in OMERO to Foster FAIR Data in Plasma Science</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lund-declaration-on-maximising-the-benefits-of-research-data">Lund Declaration on Maximising the Benefits of Research Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lynsec-lymphoma-nuclear-segmentation-and-classification">LyNSeC: Lymphoma Nuclear Segmentation and Classification</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mdemic-a-metadata-annotation-tool-to-facilitate-management-of-fair-image-data-in-the-bioimaging-community">MDEmic: a metadata annotation tool to facilitate management of FAIR image data in the bioimaging community</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#midog-2021">MIDOG 2021</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mri-physics">MRI Physics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-and-deep-learning-on-the-cloud-segmentation">Machine and Deep Learning on the cloud: Segmentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#masterclasses-from-the-euro-bioimaging-evolve-mentoring-programme-2025">Masterclasses from the Euro-Bioimaging EVOLVE Mentoring programme 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#materials-for-embl-coding-club-mini-tutorials">Materials for EMBL Coding Club Mini-Tutorials</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#measuring-reporter-activity-domain-in-epi-aggregates-and-gastruloids-ijm">Measuring reporter activity domain in EPI aggregates and Gastruloids.ijm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#melanoma-histopathology-dataset-with-tissue-and-nuclei-annotations">Melanoma Histopathology Dataset with Tissue and Nuclei Annotations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#melbourne-advanced-microscopy-facility">Melbourne Advanced Microscopy Facility</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#membrain-seg-training-data">MemBrain-seg training data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#memorandum-of-understanding-of-nfdi-consortia-from-earth-chemical-and-life-sciences-to-support-a-network-called-the-geo-chem-life-science-helpdesk-cluster">Memorandum of Understanding of NFDI consortia from Earth-, Chemical and Life Sciences to support a network called the Geo-Chem-Life Science Helpdesk Cluster</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metadata-annotation-workflow-for-omero-with-tabbles">Metadata Annotation Workflow for OMERO with Tabbles</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metadata-in-bioimaging">Metadata in Bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#methodsj2-a-software-tool-to-capture-metadata-and-generate-comprehensive-microscopy-methods-text">MethodsJ2: a software tool to capture metadata and generate comprehensive microscopy methods text</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metrics-reloaded-a-framework-for-trustworthy-image-analysis-validation">Metrics Reloaded - A framework for trustworthy image analysis validation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mitobo-a-toolbox-for-image-processing-and-analysis">MiToBo - A Toolbox for Image Processing and Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#micro-meta-app-an-interactive-tool-for-collecting-microscopy-metadata-based-on-community-specifications">Micro-Meta App: an interactive tool for collecting microscopy metadata based on community specifications</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microsam-talks">MicroSam-Talks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microscopy-bids-an-extension-to-the-brain-imaging-data-structure-for-microscopy-data">Microscopy-BIDS - An Extension to the Brain Imaging Data Structure for Microscopy Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microscopydb">MicroscopyDB</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monuseg-dataset">MoNuSeg Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-and-simulations-for-patterned-invagination-prevents-mechanical-instability-during-gastrulation">Model and simulations for: Patterned invagination prevents mechanical instability during gastrulation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling-community-standards-for-metadata-as-templates-makes-data-fair">Modeling community standards for metadata as templates makes data FAIR</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#models-and-applications-for-bioimage-io">Models and Applications for BioImage.IO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modular-training-resources-for-bioimage-analysis">Modular training resources for bioimage analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modularimageanalysis-mia-assembly-of-modularisedimage-and-object-analysis-workflows-in-imagej">ModularImageAnalysis (MIA): Assembly of modularisedimage and object analysis workflows in ImageJ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monusac-2020">MonuSAC 2020</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#morpholibj-documentation">MorphoLibJ documentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mouse-embryo-blastocyst-cells">Mouse embryo blastocyst cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multimodal-large-language-models-for-bioimage-analysis">Multimodal large language models for bioimage analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiplexed-histology-of-covid-19-post-mortem-lung-samples-control-case-1-fov1">Multiplexed histology of COVID-19 post-mortem lung samples - CONTROL CASE 1 FOV1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neubias-youtube-channel">NEUBIAS YouTube Channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi-daten-als-gemeinsames-gut-fur-exzellente-forschung-organisiert-durch-die-wissenschaft-in-deutschland">NFDI - Daten als gemeinsames Gut für exzellente Forschung, organisiert durch die Wissenschaft in Deutschland.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage">NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-an-initiative-for-a-national-research-data-infrastructure-for-microscopy-data">NFDI4BIOIMAGE - An Initiative for a National Research Data Infrastructure for Microscopy Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis-conference-talk-the-pelagic-imaging-consortium-meets-helmholtz-imaging-5-10-2023-hamburg">NFDI4BIOIMAGE - National Research Data Infrastructure for Microscopy and BioImage Analysis [conference talk: The Pelagic Imaging Consortium meets Helmholtz Imaging, 5.10.2023, Hamburg]</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-a-consortium-of-the-national-research-data-infrastructure">NFDI4BIOIMAGE - a consortium of the National Research Data Infrastructure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-april-2025">NFDI4BIOIMAGE Calendar April 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-august-2025">NFDI4BIOIMAGE Calendar August 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-cover-2025">NFDI4BIOIMAGE Calendar Cover 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-december-2025">NFDI4BIOIMAGE Calendar December 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-february-2025">NFDI4BIOIMAGE Calendar February 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-january-2025">NFDI4BIOIMAGE Calendar January 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-july-2025">NFDI4BIOIMAGE Calendar July 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-june-2025">NFDI4BIOIMAGE Calendar June 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-march-2025">NFDI4BIOIMAGE Calendar March 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-may-2025">NFDI4BIOIMAGE Calendar May 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-november-2025">NFDI4BIOIMAGE Calendar November 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-october-2025">NFDI4BIOIMAGE Calendar October 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-september-2025">NFDI4BIOIMAGE Calendar September 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-perspective-for-a-national-bioimaging-standard">NFDI4BIOIMAGE: Perspective for a national bioimaging standard</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon">NFDI4Bioimage - TA3-Hackathon - UoC-2023 (Cologne Hackathon)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon-2023-github-repository">NFDI4Bioimage - TA3-Hackathon - UoC-2023 (Cologne-Hackathon-2023, GitHub repository)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-2024-october-original-image">NFDI4Bioimage Calendar 2024 October; original image</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-2025-march-original-image">NFDI4Bioimage Calendar 2025 March; original image</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfditalk-cloud-based-image-data-science">NFDITalk Cloud based image data science</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ngff-converter">NGFF Converter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nd2-does-not-open-in-fiji-bio-formats-8-1-1">Nd2 does not open in Fiji Bio_formats 8.1.1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nd2-does-not-open-in-fiji-bio-formats-8-1-1-additional-files">Nd2 does not open in Fiji Bio_formats 8.1.1 (additional files)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nd2-does-not-open-in-fiji-bio-formats-8-1-1-on-windows">Nd2 does not open in Fiji Bio_formats 8.1.1 (on Windows)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neurips-2022-cell-segmentation-competition-dataset">NeurIPS 2022 Cell Segmentation Competition Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-networks-and-deep-learning">Neural Networks and Deep Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#new-kid-on-the-nfdi-block-nfdi4bioimage-a-national-initiative-for-fair-data-management-in-bioimaging-and-bioimage-analysis">New Kid on the (NFDI) Block: NFDI4BIOIMAGE  - A National Initiative for FAIR Data Management in Bioimaging and Bioimage Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#new-report-highlights-the-scientific-impact-of-open-source-software">New report highlights the scientific impact of open source software</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nextflow-core">NextFlow core</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nextflow-documentation">NextFlow documentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nextflow-scalable-and-reproducible-scientific-workflows">Nextflow: Scalable and reproducible scientific workflows</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nuinsseg">NuInsSeg</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nuclei-of-u2os-cells-in-a-chemical-screen">Nuclei of U2OS cells in a chemical screen</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nuclei-of-mouse-embryonic-cells">Nuclei of mouse embryonic cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ocelot-overlapped-cell-on-tissue-dataset-for-histopathology">OCELOT: Overlapped Cell on Tissue Dataset for Histopathology</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome-event-database">OME Event Database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome-ngff-a-next-generation-file-format-for-expanding-bioimaging-data-access-strategies">OME-NGFF: a next-generation file format for expanding bioimaging data-access strategies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome-zarr-course">OME-Zarr course</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome2024-ngff-challenge-results">OME2024 NGFF Challenge Results</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omero-qupath">OMERO - QuPath</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omero-for-microscopy-research-data-management">OMERO for microscopy research data management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omexcavator-a-tool-for-exporting-and-connecting-domain-specific-metadata-in-a-wider-knowledge-graph">OMExcavator: a tool for exporting and connecting domain-specific metadata in a wider knowledge graph</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omero-tools">Omero-tools</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-micoscropy-environment-ome-youtube-channel">Open Micoscropy Environment (OME) Youtube Channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-microscopy-environment-youtube-channel">Open Microscopy Environment YouTube channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-source-platform-for-scalable-multi-purpose-virtual-desktop-infrastructures">Open Source Platform for Scalable Multi-Purpose Virtual Desktop Infrastructures</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-microscopy-in-the-life-sciences-quo-vadis">Open microscopy in the life sciences: quo vadis?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimisation-and-validation-of-a-swarm-intelligence-based-segmentation-algorithm-for-low-contrast-positron-emission-tomography">Optimisation and Validation of a Swarm Intelligence based Segmentation Algorithm for low Contrast Positron Emission Tomography</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimized-cranial-window-implantation-for-subcellular-and-functional-imaging-in-vivo">Optimized cranial window implantation for subcellular and functional imaging in vivo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parallel-fiji-visualizer">Parallel_Fiji_Visualizer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parhyale-3d-segmentation-dataset">Parhyale 3D segmentation dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#platynereis-em-training-data">Platynereis EM training data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#platynereis-dumerilii-full-length-transcriptome-of-developmental-stages">Platynereis dumerilii full-length transcriptome of developmental stages</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pdum-workflow-zip-folder-3-40-gb">0-Pdum_workflow.zip (folder)
3.40 GB</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plugin-omero-batch-plugin">Plugin “omero-batch-plugin”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plugin-omero-cli-transfer">Plugin “omero-cli-transfer”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plugin-simple-omero-client">Plugin “simple-omero-client”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#predicting-axillary-lymph-node-metastasis-in-early-breast-cancer-using-deep-learning-on-primary-tumor-biopsy-slides">Predicting Axillary Lymph Node Metastasis in Early Breast Cancer Using Deep Learning on Primary Tumor Biopsy Slides</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprint-be-sustainable-recommendations-for-fair-resources-in-life-sciences-research-eosc-life-s-lessons">Preprint: “Be Sustainable”, Recommendations for FAIR Resources in Life Sciences research: EOSC-Life’s Lessons</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prodgerlab-stardist-hiv-target-cell-training-set">ProdgerLab-StarDist-HIV Target Cell Training Set</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdf-as-a-bridge-to-domain-platforms-like-omero-or-there-and-back-again">RDF as a bridge to domain-platforms like OMERO, or There and back again.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdm4mic-presentations">RDM4Mic Presentations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdm4mic">RDM4mic</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdmbites-bioimage-metadata">RDMBites BioImage metadata</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdmo-research-data-management-organiser">RDMO - Research Data Management Organiser</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdm-system-connector">RDM_system_connector</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rembi-recommended-metadata-for-biological-imagesenabling-reuse-of-microscopy-data-in-biology">REMBI - Recommended Metadata for Biological Images—enabling reuse of microscopy data in biology</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-management-on-campus-and-in-nfdi4bioimage">RESEARCH DATA MANAGEMENT on Campus and in NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reconstructed-images-of-a-2dsim-multiposition-acquisition">Reconstructed images of a 2DSIM multiposition acquisition.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reference-collection-to-push-back-against-common-statistical-myths">Reference Collection to push back against “Common Statistical Myths”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reporting-and-reproducibility-in-microscopy">Reporting and reproducibility in microscopy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#repository-for-combinatorial-wnt-signaling-landscape-during-brachiopod-anteroposterior-patterning">Repository for: Combinatorial Wnt signaling landscape during brachiopod anteroposterior patterning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-reusability-conceptual-foundations-barriers-and-enabling-technologies">Research Data Reusability - Conceptual Foundations, Barriers and Enabling Technologies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-what-are-the-key-issues-to-consider-when-publishing-this-kind-of-material">Research data - what are the key issues to consider when publishing this kind of material?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-management-for-bioimaging-the-2021-nfdi4bioimage-community-survey">Research data management for bioimaging - the 2021 NFDI4BIOIMAGE community survey</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Research data management for bioimaging: the 2021 NFDI4BIOIMAGE community survey</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#root-tissue-segmentation-dataset">Root tissue segmentation dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#round-table-workshop-1-sample-stabilization-in-intravital-imaging">Round Table Workshop 1 - Sample Stabilization in intravital Imaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#round-table-workshop-2-correction-of-drift-and-movement">Round Table Workshop 2 - Correction of Drift and Movement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stedycon-obf-dataset-with-simulated-intensity-and-complex-stacks-for-bioformats-mr-4362">STEDYCON OBF dataset with simulated intensity and complex stacks for bioformats MR #4362</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-data-for-pr-4284-https-github-com-ome-bioformats-pull-4284">Sample data for PR#4284 (https://github.com/ome/bioformats/pull/4284)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sciaugment">SciAugment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scientific-colour-maps">Scientific colour maps</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scripts-filopodyanr-a-case-study-for-the-neubias-ts7-in-szeged">Scripts_FilopodyanR - a case study for the NEUBIAS TS7 in Szeged</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#segmentation-of-nuclei-in-histopathology-images-by-deep-regression-of-the-distance-map">Segmentation of Nuclei in Histopathology Images by deep regression of the distance map</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#segmenting-cells-in-a-spheroid-in-3d-using-2d-stardist-within-trackmate">Segmenting cells in a spheroid in 3D using 2D StarDist within TrackMate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-up-an-institutional-omero-environment-for-bioimage-data-perspectives-from-both-facility-staff-and-users">Setting up an institutional OMERO environment for bioimage data: Perspectives from both facility staff and users</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulated-hl60-cells-from-the-cell-tracking-challenge">Simulated HL60 cells (from the Cell Tracking Challenge)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#single-cell-approach-dissecting-agr-quorum-sensing-dynamics-in-staphylococcus-aureus">Single-cell approach dissecting agr quorum sensing dynamics in Staphylococcus aureus</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#snakemake-documentation">Snakemake Documentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spatialdata-an-open-and-universal-data-framework-for-spatial-omics">SpatialData: an open and universal data framework for spatial omics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stackview-sliceplot-example-data">Stackview sliceplot example data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#standard-and-super-resolution-bioimaging-data-analysis-a-primer">Standard and Super-Resolution Bioimaging Data Analysis: A Primer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-adipocyte-segmentation-training-data-training-notebook-and-model">StarDist Adipocyte Segmentation Training data, Training Notebook and Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-model-and-data-for-the-segmentation-of-yersinia-enterocolitica-cells-in-widefield-images">StarDist model and data for the segmentation of Yersinia enterocolitica cells in widefield images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-aspc1-lifeact">StarDist_AsPC1_Lifeact</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-bf-monocytes-dataset">StarDist_BF_Monocytes_dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-bf-neutrophil-dataset">StarDist_BF_Neutrophil_dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-bf-cancer-cell-dataset-10x">StarDist_BF_cancer_cell_dataset_10x</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-bf-cancer-cell-dataset-20x">StarDist_BF_cancer_cell_dataset_20x</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-fluorescent-cells">StarDist_Fluorescent_cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-huvec-nuclei-dataset">StarDist_HUVEC_nuclei_dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-tumorcell-nuclei">StarDist_TumorCell_nuclei</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-model-and-training-dataset-for-automated-tracking-of-mda-mb-231-and-bt20-cells">Stardist model and training dataset for automated tracking of MDA-MB-231 and BT20 cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-miapaca2-from-cd44">Stardist_MiaPaCa2_from_CD44</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-rethinking">Statistical Rethinking</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#studentsourcing-aggregating-and-re-using-data-from-a-practical-cell-biology-course">Studentsourcing - aggregating and re-using data from a practical cell biology course</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#submitting-data-to-the-bioimage-archive">Submitting data to the BioImage Archive</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#synapsenet-training-data">SynapseNet Training Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#synthetic-cells">Synthetic cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#synthetic-images-and-segmentation-masks-simulating-hl-60-cell-nucleus-in-3d">Synthetic images and segmentation masks simulating HL-60 cell nucleus in 3D</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tess-event-database">TESS Event database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tess-training-materials">TESS training materials</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tnbc">TNBC</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#terminology-service-for-research-data-management-and-knowledge-discovery-in-low-temperature-plasma-physics">Terminology service for research data management and knowledge discovery in low-temperature plasma physics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tess-search-for-data-life-cycle">Tess Search for Data Life Cycle</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-dataset-for-whole-slide-image-registration">Test Dataset for Whole Slide Image Registration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-bioimage-archive-building-a-home-for-life-sciences-microscopy-data">The BioImage Archive – Building a Home for Life-Sciences Microscopy Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-fair-guiding-principles-for-scientific-data-management-and-stewardship">The FAIR Guiding Principles for scientific data management and stewardship</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-fair-guiding-principles-for-data-stewardship-fair-enough">The FAIR guiding principles for data stewardship - fair enough?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-fiji-updater">The Fiji Updater</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-information-infrastructure-for-bioimage-data-i3d-bio-project-to-advance-fair-microscopy-data-management-for-the-community">The Information Infrastructure for BioImage Data (I3D:bio) project to advance FAIR microscopy data management for the community</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-open-microscopy-environment-ome-data-model-and-xml-file-open-tools-for-informatics-and-quantitative-analysis-in-biological-imaging">The Open Microscopy Environment (OME) Data Model and XML file - open tools for informatics and quantitative analysis in biological imaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-role-of-helmholtz-centers-in-nfdi4bioimage-a-national-consortium-enhancing-fair-data-management-for-microscopy-and-bioimage-analysis">The role of Helmholtz Centers in NFDI4BIOIMAGE - A national consortium enhancing FAIR data management for microscopy and bioimage analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#towards-fair-data-workflows-for-multidisciplinary-science-ongoing-endeavors-and-future-perspectives-in-plasma-technology">Towards FAIR Data Workflows for Multidisciplinary Science: Ongoing Endeavors and Future Perspectives in Plasma Technology</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#towards-preservation-of-life-science-data-with-nfdi4bioimage">Towards Preservation of Life Science Data with NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#towards-transparency-and-knowledge-exchange-in-ai-assisted-data-analysis-code-generation">Towards Transparency and Knowledge Exchange in AI-assisted Data Analysis Code Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#towards-community-driven-metadata-standards-for-light-microscopy-tiered-specifications-extending-the-ome-model">Towards community-driven metadata standards for light microscopy - tiered specifications extending the OME model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-set-of-microscopy-images-for-dietler-et-al-nature-communications-2020">Training set of microscopy images for Dietler et al. Nature Communications 2020</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trendsinmicroscopy2025">TrendsInMicroscopy2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-metric-related-pitfalls-in-image-analysis-validation">Understanding metric-related pitfalls in image analysis validation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#upcoming-image-analysis-events">Upcoming Image Analysis Events</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-glittr-org-to-find-compare-and-re-use-online-training-materials">Using Glittr.org to find, compare and re-use online training materials</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#v4sdb-winter-school-2025">V4SDB_Winter_School_2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#volumetric-segmentation-of-biological-cells-and-subcellular-structures-for-optical-diffraction-tomography-images-dataset">Volumetric segmentation of biological cells and subcellular structures for optical diffraction tomography images - dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#webatlas-pipeline-for-integrated-single-cell-and-spatial-transcriptomic-data">WebAtlas pipeline for integrated single cell and spatial transcriptomic data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#welcome-to-bioimage-town">Welcome to BioImage Town</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-bioimage-analysis-an-introduction">What is Bioimage Analysis? An Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#who-you-gonna-call-data-stewards-to-the-rescue">Who you gonna call? - Data Stewards to the rescue</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workflowhub">WorkflowHub</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#working-group-charter-rdm-helpdesk-network">Working Group Charter. RDM Helpdesk Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workshop-june2024-madrid">Workshop-June2024-Madrid</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zarr-a-cloud-optimized-storage-for-interactive-access-of-large-arrays">Zarr - A Cloud-Optimized Storage for Interactive Access of Large Arrays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter">Zeiss AxioZoom Stage Adapter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter-12-6well-plate">Zeiss AxioZoom Stage Adapter - 12/6Well Plate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter-em-block-holder">Zeiss AxioZoom Stage Adapter - EM block holder</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter-microscope-slides">Zeiss AxioZoom Stage Adapter - Microscope slides</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zerocostdl4mic-stardist-2d-example-training-and-test-dataset-light">ZeroCostDL4Mic - Stardist 2D example training and test dataset (light)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zerocostdl4mic-stardist-example-training-and-test-dataset">ZeroCostDL4Mic - Stardist example training and test dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zerocostdl4mic-exploiting-google-colab-to-develop-a-free-and-open-source-toolbox-for-deep-learning-in-microscopy">ZeroCostDL4Mic: exploiting Google Colab to develop a free and open-source toolbox for Deep-Learning in microscopy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bina-cc-scalable-strategies-for-a-next-generation-of-fair-bioimaging">[BINA CC] Scalable strategies for a next-generation of FAIR bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cordi-2023-zarr-a-cloud-optimized-storage-for-interactive-access-of-large-arrays">[CORDI 2023] Zarr: A Cloud-Optimized Storage for Interactive Access of Large Arrays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#community-meeting-2024-overview-team-image-data-analysis-and-management">[Community Meeting 2024] Overview Team Image Data Analysis and Management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#community-meeting-2024-supporting-and-financing-rdm-projects-within-gerbi">[Community Meeting 2024] Supporting and financing RDM projects within GerBI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gbi-eoe-ix-nfdi4bioimage">[GBI EoE IX] NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#n4bi-ahm-welcome-to-bioimage-town">[N4BI AHM] Welcome to BioImage Town</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#short-talk-nfdi4bioimage-a-consortium-in-the-national-research-data-infrastructure">[Short Talk] NFDI4BIOIMAGE - A consortium in the National Research Data Infrastructure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solved-sample-fluorescence-qptiff-file-not-rendered-correctly-by-qupath-v-0-6-0-correctly-by-qupath-v-0-5-1">[Solved] Sample fluorescence .qptiff file not rendered correctly by QuPath v.0.6.0, correctly by Qupath v.0.5.1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workshop-material-fit-for-omero-how-imaging-facilities-and-it-departments-work-together-to-enable-rdm-for-bioimaging-october-16-17-2024-heidelberg">[Workshop Material] Fit for OMERO - How imaging facilities and IT departments work together to enable RDM for bioimaging, October 16-17, 2024, Heidelberg</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#arivis-vision4d-tutorials">arivis Vision4D Tutorials</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioformats2raw-converter">bioformats2raw Converter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimageio-chatbot">bioimageio-chatbot</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cba-support-template">cba-support-template</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellpose-training-data">cellpose training data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datenbiene">datenbiene</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#de-nbi-youtube-channel">de.NBI YouTube Channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#de-nbi-cloud-access-registration-guide">de.NBI cloud access registration guide</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#denbi-online-training-media-library">deNBI Online Training Media Library</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dmtxsamplecreator">dmtxSampleCreator</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embo-bia-2025">embo-bia-2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#i2k-2020-s3-zarr-workshop">i2k-2020-s3-zarr-workshop</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ilastik-interactive-machine-learning-for-bio-image-analysis">ilastik: interactive machine learning for (bio)image analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imaris-file-not-read-by-bfgetreader">imaris file not read by bfGetReader()</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#martinschatz-cz-scicount-v1-0-0-with-reusable-example-notebooks">martinschatz-cz/SciCount: v1.0.0 with reusable example notebooks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microlist">microlist</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome-ngff-validator">ome-ngff-validator</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome2024-ngff-challenge">ome2024-ngff-challenge</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omero-arc">omero-arc</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omero-ontop-mappings">omero-ontop-mappings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omero-quay">omero-quay</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omero-vitessce">omero-vitessce</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#patho-prompt-injection">patho_prompt_injection</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quantixed-thedigitalcell-first-complete-code-set">quantixed/TheDigitalCell: First complete code set</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#raw2ometiff-converter">raw2ometiff Converter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#re3data-org-registry-of-research-data-repositories">re3data.org - registry of Research Data Repositories</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training">training</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="exclude-from-dalia-460">
<h1>Exclude from dalia (460)<a class="headerlink" href="#exclude-from-dalia-460" title="Link to this heading">#</a></h1>
<section id="lif-files-misbehaving-in-fiji-but-fine-in-lasx">
<h2>.lif files misbehaving in fiji but fine in LASX<a class="headerlink" href="#lif-files-misbehaving-in-fiji-but-fine-in-lasx" title="Link to this heading">#</a></h2>
<p>Pamela Young</p>
<p>Published 2025-05-07</p>
<p>Licensed CC-BY-4.0</p>
<p>.lif files misbehaving in fiji but fine in LASX.  This data opens fine in LASX but FIJI only likes some of the files.  I think it was captured during a poweroutage so may have lived on a temp drive and been recovered when the power came back.  LASX uses the .lifext but I don’t think FIJI does.  I have included it however since it is part of the dataset output from the microscope.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15353569">https://zenodo.org/records/15353569</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15353569">https://doi.org/10.5281/zenodo.15353569</a></p>
</section>
<hr class="docutils" />
<section id="frames-of-fluorescent-particles">
<h2>10 frames of fluorescent particles<a class="headerlink" href="#frames-of-fluorescent-particles" title="Link to this heading">#</a></h2>
<p>Zach Marin, Maohan Su</p>
<p>Published 2024-12-05</p>
<p>Licensed CC-BY-4.0</p>
<p>10 frames of fluorescent particles. They don’t do much, but they are a DCIMG version 0x7 file example.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14281237">https://zenodo.org/records/14281237</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14281237">https://doi.org/10.5281/zenodo.14281237</a></p>
</section>
<hr class="docutils" />
<section id="data-science-bowl">
<h2>2018 Data Science Bowl<a class="headerlink" href="#data-science-bowl" title="Link to this heading">#</a></h2>
<p>Booz Allen Hamilton</p>
<p>Published 2018-01-16</p>
<p>Licensed RESTRICTIVE LICENSE</p>
<p>This dataset contains a large number of segmented nuclei images. The images were acquired under a variety of conditions and vary in the cell type, magnification, and imaging modality (brightfield vs. fluorescence). The dataset is designed to challenge an algorithms ability to generalize across these variations.</p>
<p>Tags: Nuclei Images, Restrictive License, Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://www.kaggle.com/c/data-science-bowl-2018/data">https://www.kaggle.com/c/data-science-bowl-2018/data</a></p>
</section>
<hr class="docutils" />
<section id="bioimage-analysis-survey-community-experiences-and-needs-for-the-future">
<h2>2020 BioImage Analysis Survey: Community experiences and needs for the future<a class="headerlink" href="#bioimage-analysis-survey-community-experiences-and-needs-for-the-future" title="Link to this heading">#</a></h2>
<p>Nasim Jamali, Ellen T. A. Dobson, Kevin W. Eliceiri, Anne E. Carpenter, Beth A. Cimini</p>
<p>Published 2021</p>
<p>Licensed BSD-3-CLAUSE</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://doi.org/10.1017/s2633903x21000039">https://doi.org/10.1017/s2633903x21000039</a></p>
<p><a class="github reference external" href="https://github.com/ciminilab/2021_Jamali_BiologicalImaging">ciminilab/2021_Jamali_BiologicalImaging</a></p>
</section>
<hr class="docutils" />
<section id="d-ground-truth-annotations-of-nuclei-in-3d-microscopy-volumes">
<h2>3D Ground Truth Annotations of Nuclei in 3D Microscopy Volumes<a class="headerlink" href="#d-ground-truth-annotations-of-nuclei-in-3d-microscopy-volumes" title="Link to this heading">#</a></h2>
<p>Alain Chen, Liming Wu, Seth Winfree, Kenneth Dunn, Paul Salama, Edward Delp, Teresa Zulueta-Coarasa</p>
<p>Published 2024-12-20</p>
<p>Licensed CC-BY-4.0</p>
<p>This submission contains a set of 3D microscopy volumes of cell nuclei from different species and tissues that have been manually segmented. We also provide synthetically generated 3D microscopy volumes that can be used for training segmentation methods.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://www.ebi.ac.uk/bioimage-archive/galleries/ai/analysed-dataset/S-BIAD1518/">https://www.ebi.ac.uk/bioimage-archive/galleries/ai/analysed-dataset/S-BIAD1518/</a></p>
</section>
<hr class="docutils" />
<section id="d-hl60-cell-line-synthetic-data">
<h2>3D HL60 Cell line (synthetic data)<a class="headerlink" href="#d-hl60-cell-line-synthetic-data" title="Link to this heading">#</a></h2>
<p>David Svoboda, Michal Kozubkek, Stanislav Stejskal</p>
<p>Published 2009-06-01</p>
<p>Licensed CC-BY-3.0</p>
<p>One of the principal challenges in counting or segmenting nuclei is dealing with clustered nuclei. To help assess algorithms performance in this regard, this synthetic image set consists of four subsets with increasing degree of clustering. Each subset is also provided in two diferent levels of quality: high SNR and low SNR.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://bbbc.broadinstitute.org/BBBC024">https://bbbc.broadinstitute.org/BBBC024</a></p>
</section>
<hr class="docutils" />
<section id="d-nuclei-annotations-and-stardist-3d-model-s-rat-brain">
<h2>3D Nuclei annotations and StarDist 3D model(s) (rat brain)<a class="headerlink" href="#d-nuclei-annotations-and-stardist-3d-model-s-rat-brain" title="Link to this heading">#</a></h2>
<p>Romain Guiet</p>
<p>Published 2022-06-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: 3D Nuclei annotations and StarDist3D model(s) (rat brain)</p>
<p>Images:  From a large tiling acquisition ( <a class="reference external" href="https://doi.org/10.5281/zenodo.6646128">https://doi.org/10.5281/zenodo.6646128</a> ) individual Tile (xyz : 1024x1024x62) were downsampled and cropped (128x128x62). Four crops, from different tiles (./annotations_BIOP/images/) were manually annotated with ITK-SNAP (./annotations_BIOP/masks/)</p>
<p>These four images, and their corresponding masks, were cropped into four quadrants (./crops_BIOP_v1/) in order to get 16 different images (64x64x62).</p>
<p>Conda environment: A conda environment was created using the yml file  stardist0.8_TF1.15.yml</p>
<p>Training : Training was performed using the jupyter notebook 1-Training_notebook.ipynb.
Three different trainings (with the same random seed, same anisotropy, patch size and grid) were performed and produced three different models (./models/)</p>
<p>Validation images (from the random seed used) were exported to ease the visual inspection of the results(./val_rdm42/).</p>
<p>Validation:  To save metrics in a csv file and compare predictions to the annotations the jupyter notebook 2-QC_notebook.ipynb can be used on the validation folder.</p>
<p>Large images: To test the model on larger images one can use Whole_ds441.tif (or Crop_ds441.tif )
These images were obtained using the plugin BigSticher on the raw data ( <a class="reference external" href="https://doi.org/10.5281/zenodo.6646128">https://doi.org/10.5281/zenodo.6646128</a> ), resaved as h5 and exported the downsample by 4 version.</p>
<p> </p>
<p> </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/6645978">https://zenodo.org/records/6645978</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6645978">https://doi.org/10.5281/zenodo.6645978</a></p>
</section>
<hr class="docutils" />
<section id="d-cell-shape-of-drosophila-wing-disc">
<h2>3D cell shape of Drosophila Wing Disc<a class="headerlink" href="#d-cell-shape-of-drosophila-wing-disc" title="Link to this heading">#</a></h2>
<p>Giulia Paci, Ines Fernandez Mosquera, Pablo Vicente Munuera, Yanlan Mao</p>
<p>Published 2023-08-14</p>
<p>Licensed CC0-1.0</p>
<p>Segmentation masks of individual cells in Drosophila wing discs</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://www.ebi.ac.uk/bioimage-archive/galleries/S-BIAD843-ai.html">https://www.ebi.ac.uk/bioimage-archive/galleries/S-BIAD843-ai.html</a></p>
</section>
<hr class="docutils" />
<section id="d-light-sheet-microscopy-data-for-selma3d-2024-challenge-training-subset-with-annotations">
<h2>3D light-sheet microscopy data for SELMA3D 2024 challenge - Training subset with annotations<a class="headerlink" href="#d-light-sheet-microscopy-data-for-selma3d-2024-challenge-training-subset-with-annotations" title="Link to this heading">#</a></h2>
<p>Ying Chen, Johannes C. Paetzold, Ali Erturk, Doris Kaltenecker, Mihail Todorov, Harsharan Singh Bhatia, Shan Zhao, Luciano Höher</p>
<p>Published 2024-06-05</p>
<p>Licensed CC-BY-4.0</p>
<p>This dataset is the training set with annotations for the SELMA3D challenge. The SELMA3D challenge focuses on self-supervised learning for 3D light-sheet microscopy image segmentation. Its objective is to encourage the development of self-supervised learning methods for general segmentation of various structures in 3D light-sheet microscopy images. The dataset comtains 3D image patches of different labeled biological structures in the brain, including blood vessels, c-Fos labeled brain cells involved in neural activity, cell nuclei, and Alzheimers disease plaques. Each patch includes corresponding pixel-wise annotations for the labeled structures.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://www.ebi.ac.uk/bioimage-archive/galleries/ai/analysed-dataset/S-BIAD1196/">https://www.ebi.ac.uk/bioimage-archive/galleries/ai/analysed-dataset/S-BIAD1196/</a></p>
</section>
<hr class="docutils" />
<section id="d-nuclei-instance-segmentation-dataset-of-fluorescence-microscopy-volumes-of-c-elegans">
<h2>3D nuclei instance segmentation dataset of fluorescence microscopy volumes of C. elegans<a class="headerlink" href="#d-nuclei-instance-segmentation-dataset-of-fluorescence-microscopy-volumes-of-c-elegans" title="Link to this heading">#</a></h2>
<p>Fuhui Long, Hanchuan Peng, Xiao Liu, Stuart K Kim, Eugene Myers, Dagmar Kainmüller, Martin Weigert</p>
<p>Published 2022-02-01</p>
<p>Licensed CC-BY-4.0</p>
<p>The dataset consists of 28 confocal microscopy volumes of C. elegans worms at the L1 stage and  corresponding stacks of densely annotated nuclei instance segmentation masks.</p>
<ul class="simple">
<li><p>28 raw images and corresponding masks of average dimension (xyz) 1050 x 140 x 140</p></li>
<li><p>Pixelsize (xyz): 0.116 x 0.116 x 0.122μm</p></li>
<li><p>Microscope: Leica confocal microscopy, 63x oil objective</p></li>
</ul>
<p>The original raw data and preliminary annotations were  part of the following publication (please cite if you use the dataset):
 
Long, F., Peng, H., Liu, X., Kim, S. K., &amp; Myers, E. (2009). A 3D digital atlas of C. elegans and its application to single-cell analyses. Nature methods, 6(9), 667-672.</p>
<p>The nuclei annotation masks were further manually curated by Dagmar Kainmueller (MDC Berlin) for the following publication:</p>
<p>Hirsch, P., &amp; Kainmueller, D. (2020). An auxiliary task for learning nuclei segmentation in 3d microscopy images. In Medical Imaging with Deep Learning (pp. 304-321). PMLR.</p>
<p>We provide the dataset already structured into the train/validation/test split as used by the above as well as the following publications: </p>
<p>Weigert, M., Schmidt, U., Haase, R., Sugawara, K., &amp; Myers, G. (2020). Star-convex polyhedra for 3d object detection and segmentation in microscopy. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (pp. 3666-3673).
 </p>
<p> </p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/5942575">https://zenodo.org/records/5942575</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5942575">https://doi.org/10.5281/zenodo.5942575</a></p>
</section>
<hr class="docutils" />
<section id="a-cloud-optimized-storage-for-interactive-access-of-large-arrays">
<h2>A Cloud-Optimized Storage for Interactive Access of Large Arrays<a class="headerlink" href="#a-cloud-optimized-storage-for-interactive-access-of-large-arrays" title="Link to this heading">#</a></h2>
<p>Josh Moore, Susanne Kunis</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Nfdi4Bioimage, Research Data Management, Exclude From Dalia</p>
<p>Content type: Publication, Conference Abstract</p>
<p><a class="reference external" href="https://doi.org/10.52825/cordi.v1i.285">https://doi.org/10.52825/cordi.v1i.285</a></p>
</section>
<hr class="docutils" />
<section id="a-glimpse-of-the-open-source-flim-analysis-software-tools-flimfit-flute-and-napari-flim-phasor-plotter">
<h2>A Glimpse of the Open-Source FLIM Analysis Software Tools FLIMfit, FLUTE and napari-flim-phasor-plotter<a class="headerlink" href="#a-glimpse-of-the-open-source-flim-analysis-software-tools-flimfit-flute-and-napari-flim-phasor-plotter" title="Link to this heading">#</a></h2>
<p>Anca Margineanu, Chiara Stringari, Marcelo Zoccoler, Cornelia Wetzker</p>
<p>Published 2024-03-27</p>
<p>Licensed CC-BY-4.0</p>
<p>The presentations introduce open-source software to read in, visualize and analyse fluorescence lifetime imaging microscopy (FLIM) raw data developed for life scientists. The slides were presented at German Bioimaging (GerBI) FLIM Workshop held February 26 to 29 2024 at the Biomedical Center of LMU München by Anca Margineanu, Chiara Stringari and Conni Wetzker. </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/10886750">https://zenodo.org/records/10886750</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10886750">https://doi.org/10.5281/zenodo.10886750</a></p>
</section>
<hr class="docutils" />
<section id="a-call-for-public-archives-for-biological-image-data">
<h2>A call for public archives for biological image data<a class="headerlink" href="#a-call-for-public-archives-for-biological-image-data" title="Link to this heading">#</a></h2>
<p>Jan Ellenberg, Jason R. Swedlow, Mary Barlow, Charles E. Cook, Ugis Sarkans, Ardan Patwardhan, Alvis Brazma, Ewan Birney</p>
<p>Tags: Research Data Management, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.nature.com/articles/s41592-018-0195-8">https://www.nature.com/articles/s41592-018-0195-8</a></p>
</section>
<hr class="docutils" />
<section id="a-checklist-for-designing-and-improving-the-visualization-of-scientific-data">
<h2>A checklist for designing and improving the visualization of scientific data<a class="headerlink" href="#a-checklist-for-designing-and-improving-the-visualization-of-scientific-data" title="Link to this heading">#</a></h2>
<p>Helena Klara Jambor</p>
<p>Published 2025-06-13</p>
<p>Licensed COPYRIGHT</p>
<p>Creating clear and engaging scientific figures is crucial to communicate complex data. In this Comment, I condense principles from design, visual perception and data visualization research in a checklist that can help researchers to improve their data visualization, by focusing on clarity, accessibility and design best practices.</p>
<p>Tags: Copyright, Research Data Management, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.nature.com/articles/s41556-025-01684-z.pdf">https://www.nature.com/articles/s41556-025-01684-z.pdf</a></p>
</section>
<hr class="docutils" />
<section id="a-deep-learning-approach-to-quantify-auditory-hair-cells">
<h2>A deep learning approach to quantify auditory hair cells<a class="headerlink" href="#a-deep-learning-approach-to-quantify-auditory-hair-cells" title="Link to this heading">#</a></h2>
<p>Maurizio Cortada, Loïc Sauteur, Michael Lanz, Soledad Levano, Daniel Bodmer</p>
<p>Published 2021-03-09</p>
<p>Licensed CC-BY-4.0</p>
<p>StarDist 2D deep learning model and training dataset.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/4590066">https://zenodo.org/records/4590066</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4590066">https://doi.org/10.5281/zenodo.4590066</a></p>
</section>
<hr class="docutils" />
<section id="a-mihc-mrxs-example">
<h2>A mihc mrxs example<a class="headerlink" href="#a-mihc-mrxs-example" title="Link to this heading">#</a></h2>
<p>Wang</p>
<p>Published 2025-08-27</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16962727">https://zenodo.org/records/16962727</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16962727">https://doi.org/10.5281/zenodo.16962727</a></p>
</section>
<hr class="docutils" />
<section id="a-study-on-long-term-reproducibility-of-image-analysis-results-on-imagej-and-fiji">
<h2>A study on long-term reproducibility of image analysis results on ImageJ and Fiji<a class="headerlink" href="#a-study-on-long-term-reproducibility-of-image-analysis-results-on-imagej-and-fiji" title="Link to this heading">#</a></h2>
<p>Robert Haase, Deborah Schmidt, Wayne Rasband, Curtis Rueden, Florian Jug, Pavel Tomancak, Eugene W. Myers</p>
<p>Tags: Imagej, Exclude From Dalia</p>
<p>Content type: Publication, Poster</p>
<p><a class="reference external" href="https://figshare.com/articles/poster/I2K_Poster_Haase_V6_ImageJ_repro_pdf/7409525">https://figshare.com/articles/poster/I2K_Poster_Haase_V6_ImageJ_repro_pdf/7409525</a></p>
</section>
<hr class="docutils" />
<section id="abic-intermediate-fiji-image-analysis-course-2024">
<h2>ABIC - Intermediate Fiji Image Analysis Course 2024<a class="headerlink" href="#abic-intermediate-fiji-image-analysis-course-2024" title="Link to this heading">#</a></h2>
<p>Rensu Petrus Theart</p>
<p>Licensed CC-BY-4.0</p>
<p>A structured beginner to intermediate-level course in image analysis using Fiji, developed for ABIC 2024.  It includes a video lecture playlist, course documentation, and participant image files.</p>
<p>Tags: Bioimage Analysis, Image Processing, Teaching Resource, Imagej, Exclude From Dalia</p>
<p>Content type: Workshop, Video, Document</p>
<p><a class="reference external" href="https://www.youtube.com/playlist?list=PL0RrV4sTNwh2S9Lb7d1TzJWPGgdw_YVnb">https://www.youtube.com/playlist?list=PL0RrV4sTNwh2S9Lb7d1TzJWPGgdw_YVnb</a></p>
<p><a class="reference external" href="https://docs.google.com/document/d/1h-3oJDR7gd_y3tfgN3clPwt2O4g34QRPp_FJ4v2Q7kA/edit?usp=sharing">https://docs.google.com/document/d/1h-3oJDR7gd_y3tfgN3clPwt2O4g34QRPp_FJ4v2Q7kA/edit?usp=sharing</a></p>
<p><a class="reference external" href="https://www.dropbox.com/scl/fi/7njq2wp680vubt6rwhn5f/ParticipantImages.zip?rlkey=pk3kttbsclk69ixxp1yv9j8p3&amp;amp;dl=0">https://www.dropbox.com/scl/fi/7njq2wp680vubt6rwhn5f/ParticipantImages.zip?rlkey=pk3kttbsclk69ixxp1yv9j8p3&amp;dl=0</a></p>
</section>
<hr class="docutils" />
<section id="ai4life-teams-up-with-galaxy-training-network-gtn-to-enhance-training-resources">
<h2>AI4Life teams up with Galaxy Training Network (GTN) to enhance training resources<a class="headerlink" href="#ai4life-teams-up-with-galaxy-training-network-gtn-to-enhance-training-resources" title="Link to this heading">#</a></h2>
<p>Caterina Fuster-Barceló</p>
<p>Licensed UNKNOWN</p>
<p>Tags: Artificial Intelligence, Workflow Engine, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Documentation</p>
<p><a class="reference external" href="https://ai4life.eurobioimaging.eu/ai4life-teams-up-with-galaxy-training-network-gtn-to-enhance-training-resources/">https://ai4life.eurobioimaging.eu/ai4life-teams-up-with-galaxy-training-network-gtn-to-enhance-training-resources/</a></p>
</section>
<hr class="docutils" />
<section id="abdominal-imaging-window-aiw-for-intravital-imaging">
<h2>Abdominal Imaging Window (AIW) for Intravital Imaging<a class="headerlink" href="#abdominal-imaging-window-aiw-for-intravital-imaging" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-11-15</p>
<p>Licensed CC-BY-4.0</p>
<p>This upload features a simple model for the creation (Manufacturing/Prototyping) of an abdominal imaging window (AIW) for use in mice intravital microscopy.
Manufacture in titanium for chronic implantation. Measures in mm.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14168603">https://zenodo.org/records/14168603</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14168603">https://doi.org/10.5281/zenodo.14168603</a></p>
</section>
<hr class="docutils" />
<section id="aberrated-bead-stack">
<h2>Aberrated Bead Stack<a class="headerlink" href="#aberrated-bead-stack" title="Link to this heading">#</a></h2>
<p>Zach Marin</p>
<p>Published 2024-12-03</p>
<p>Licensed CC-BY-4.0</p>
<p>Bead stack taken on lower path of a 4Pi without deformable mirror corrections. DCIMG examples, not for other purposes.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14268554">https://zenodo.org/records/14268554</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14268554">https://doi.org/10.5281/zenodo.14268554</a></p>
</section>
<hr class="docutils" />
<section id="abstract-nfdi-basic-service-for-data-management-plans">
<h2>Abstract - NFDI Basic Service for Data Management Plans<a class="headerlink" href="#abstract-nfdi-basic-service-for-data-management-plans" title="Link to this heading">#</a></h2>
<p>Licensed CC-BY-4.0</p>
<p>The NFDI Basic Service DMP4NFDI supports consortia in developing and providing data management plans (DMP) services for their community.</p>
<p>Tags: Research Data Management, Exclude From Dalia</p>
<p>Content type: Document</p>
<p><a class="reference external" href="https://base4nfdi.de/images/AbstractDMP4NFDI.pdf">https://base4nfdi.de/images/AbstractDMP4NFDI.pdf</a></p>
</section>
<hr class="docutils" />
<section id="adding-a-workflow-to-biaflows">
<h2>Adding a Workflow to BIAFLOWS<a class="headerlink" href="#adding-a-workflow-to-biaflows" title="Link to this heading">#</a></h2>
<p>Sébastien Tosi, Volker Baecker, Benjamin Pavie</p>
<p>Licensed BSD-2-CLAUSE</p>
<p>Tags: Neubias, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Slides</p>
<p><a class="github reference external" href="https://github.com/RoccoDAnt/Defragmentation_TrainingSchool_EOSC-Life_2022/blob/main/Slides/Adding_a_workflow_to_BIAFLOWS.pdf">RoccoDAnt/Defragmentation_TrainingSchool_EOSC-Life_2022</a></p>
</section>
<hr class="docutils" />
<section id="an-annotated-fluorescence-image-dataset-for-training-nuclear-segmentation-methods">
<h2>An annotated fluorescence image dataset for training nuclear segmentation methods<a class="headerlink" href="#an-annotated-fluorescence-image-dataset-for-training-nuclear-segmentation-methods" title="Link to this heading">#</a></h2>
<p>Sabine Taschner-Mandl, Inge M. Ambros, Peter F. Ambros, Klaus Beiske, Allan Hanbury, Wolfgang Doerr, Tamara Weiss, Maria Berneder, Magdalena Ambros, Eva Bozsaky, Florian Kromp, Teresa Zulueta-Coarasa</p>
<p>Published 2023-03-07</p>
<p>Licensed CC0-1.0</p>
<p>Ground-truth annotated fluorescence image dataset for training nuclear segmentation methods</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://www.ebi.ac.uk/bioimage-archive/galleries/S-BIAD634-ai.html">https://www.ebi.ac.uk/bioimage-archive/galleries/S-BIAD634-ai.html</a></p>
</section>
<hr class="docutils" />
<section id="an-annotated-high-content-fluorescence-microscopy-dataset-with-hoechst-33342-stained-nuclei-and-manually-labelled-outlines">
<h2>An annotated high-content fluorescence microscopy dataset with Hoechst 33342-stained nuclei and manually labelled outlines<a class="headerlink" href="#an-annotated-high-content-fluorescence-microscopy-dataset-with-hoechst-33342-stained-nuclei-and-manually-labelled-outlines" title="Link to this heading">#</a></h2>
<p>Malou Arvidsson, Salma Kazemi Rashed, Sonja Aits</p>
<p>Published 2022-06-17</p>
<p>Licensed CC-BY-4.0</p>
<p>Here we present a benchmarking dataset of fluorescence microscopy images with Hoechst 33342-stained nuclei together with annotations of nuclei, nuclear fragments and micronuclei. Images were randomly selected from an RNA interference screen with a modified U2OS osteosarcoma cell line, acquired on a Thermo Fischer CX7 high-content imaging system at 20x magnification. Labelling was performed by a single annotator and reviewed by a biomedical expert.</p>
<p>The dataset contains 50 images showing over 2000 labelled nuclear objects in total, which is sufficiently large to train well-performing neural networks for instance or semantic segmentation. It is pre-split into training, development and test set, each in a zip file. The dataset should be referred to as Aitslab_bioimaging1. A brief article describing the dataset is also available (Arvidsson M, Kazemi Rashed S, Aits S. 10.1016/j.dib.2022.108769 )</p>
<p>Dataset description:</p>
<p>Fluorescence microscopy images: original .C01 files and files converted to 8-bit .png format (Grayscale)</p>
<p>Annotations: 24-bit .png format (RGB)</p>
<p>Script used to convert C01 to png images: C01_to_png.py file with python code and <a class="reference external" href="http://readme.md">readme.md</a> file with instructions to run it</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/6657260">https://zenodo.org/records/6657260</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6657260">https://doi.org/10.5281/zenodo.6657260</a></p>
</section>
<hr class="docutils" />
<section id="an-image-based-data-driven-analysis-of-cellular-architecture-in-a-developing-tissue">
<h2>An image-based data-driven analysis of cellular architecture in a developing tissue<a class="headerlink" href="#an-image-based-data-driven-analysis-of-cellular-architecture-in-a-developing-tissue" title="Link to this heading">#</a></h2>
<p>Jonas Hartmann, Mie Wong, Elisa Gallo, Darren Gilmour</p>
<p>Published 2022-12-13</p>
<p>Licensed CC-BY-4.0</p>
<p>3D zebrafish embryo images with single-cell segmentation and point cloud-based morphometry</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://www.ebi.ac.uk/bioimage-archive/galleries/S-BIAD599-ai.html">https://www.ebi.ac.uk/bioimage-archive/galleries/S-BIAD599-ai.html</a></p>
</section>
<hr class="docutils" />
<section id="andor-dragonfly-confocal-image-of-bpae-cells-stained-for-actin-ims-file-format">
<h2>Andor Dragonfly confocal image of BPAE cells stained for actin, IMS file format<a class="headerlink" href="#andor-dragonfly-confocal-image-of-bpae-cells-stained-for-actin-ims-file-format" title="Link to this heading">#</a></h2>
<p>Hoku West-Foyle</p>
<p>Published 2025-01-16</p>
<p>Licensed CC0-1.0</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14675120">https://zenodo.org/records/14675120</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14675120">https://doi.org/10.5281/zenodo.14675120</a></p>
</section>
<hr class="docutils" />
<section id="angebote-der-nfdi-fur-die-forschung-im-bereich-zoologie">
<h2>Angebote der NFDI für die Forschung im Bereich Zoologie<a class="headerlink" href="#angebote-der-nfdi-fur-die-forschung-im-bereich-zoologie" title="Link to this heading">#</a></h2>
<p>Birgitta König-Ries, Robert Haase, Daniel Nüst, Konrad Förstner, Judith Sophie Engel</p>
<p>Published 2024-12-04</p>
<p>Licensed CC-BY-4.0</p>
<p>In diesem Slidedeck geben wir einen Einblick in Angebote und Dienste der Nationalen Forschungsdaten Infrastruktur (NFDI), die Relevant für die Zoologie und angrenzende Disziplinen relevant sein könnten.</p>
<p>Tags: Nfdi4Bioimage, Research Data Management, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14278058">https://zenodo.org/records/14278058</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14278058">https://doi.org/10.5281/zenodo.14278058</a></p>
</section>
<hr class="docutils" />
<section id="annotated-research-context-arc">
<h2>Annotated Research Context (ARC<a class="headerlink" href="#annotated-research-context-arc" title="Link to this heading">#</a></h2>
<p>Kevin Frey, Kevin Schneider, Lukas Weil, Dominik Brilhaus, Timo Mühlhaus, Manuel Feser, Hannah-Doerpholz</p>
<p>Licensed UNKNOWN</p>
<p>The ARC is a framework for organizing and documenting research data, as well as a container that continuously supports collaboration, data exchange, and adherence to FAIR principles among various researchers. The ARC can be checked for completeness and quality at any time and converted into a citable data publication without interrupting the research or documentation process. It is built on widely accepted research data standards such as RO-Crate, ISA, and abstract CWL.</p>
<p>Tags: Research Data Management, Fair, Exclude From Dalia</p>
<p>Content type: Framework</p>
<p><a class="reference external" href="https://arc-rdm.org/">https://arc-rdm.org/</a></p>
</section>
<hr class="docutils" />
<section id="annotated-high-throughput-microscopy-image-sets-for-validation">
<h2>Annotated high-throughput microscopy image sets for validation<a class="headerlink" href="#annotated-high-throughput-microscopy-image-sets-for-validation" title="Link to this heading">#</a></h2>
<p>Vebjorn Ljosa, Katherine L Sokolnicki, Anne E Carpenter</p>
<p>Broad Bioimage Benchmark Collection (BBBC)</p>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Collection, Data</p>
<p><a class="reference external" href="https://www.nature.com/articles/nmeth.2083">https://www.nature.com/articles/nmeth.2083</a></p>
<p><a class="reference external" href="https://bbbc.broadinstitute.org/">https://bbbc.broadinstitute.org/</a></p>
</section>
<hr class="docutils" />
<section id="artificial-blobs-and-labels-image">
<h2>Artificial Blobs and Labels image<a class="headerlink" href="#artificial-blobs-and-labels-image" title="Link to this heading">#</a></h2>
<p>Romain</p>
<p>Published 2023-05-10</p>
<p>Licensed CC-BY-4.0</p>
<p>A groovy script to use in Fiji to generate artificial images and labels, with example images.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/7919117">https://zenodo.org/records/7919117</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7919117">https://doi.org/10.5281/zenodo.7919117</a></p>
</section>
<hr class="docutils" />
<section id="assessment-of-residual-breast-cancer-cellularity-after-neoadjuvant-chemotherapy-using-digital-pathology">
<h2>Assessment of Residual Breast Cancer Cellularity after Neoadjuvant Chemotherapy using Digital Pathology<a class="headerlink" href="#assessment-of-residual-breast-cancer-cellularity-after-neoadjuvant-chemotherapy-using-digital-pathology" title="Link to this heading">#</a></h2>
<p>Mohammad Peikari, Sherine Salama, Sharon Nofech-Mozes, Anne L. Martel</p>
<p>Published 2017-10-04</p>
<p>Licensed CC-BY-3.0</p>
<p>Breast cancer (BC) is the second most commonly diagnosed cancer in the U.S. with more than 250,000 new cases of invasive breast cancers reported in 2017. The majority of women with locally advanced and a subset of patients with operable breast cancer will undergo systemic therapy prior to their surgery (neoadjuvant therapy/ NAT) to reduce the size of tumor(s) and possibly further undergo breast conserving surgery. The Post-NAT-BRCA dataset is a collection of representative sections from breast resections in patients with residual invasive BC following NAT. Histologic sections were prepared and digitized to produce high resolution, microscopic images of treated BC tumors. Also included, are clinical features and expert pathology annotations of tumor cellularity and cell types. The Residual Cancer Burden Index (RCBi), is a clinically validated tool for assessment of response to NAT associated with prognosis. Tumor cellularity is one of the parameters used for calculating the RCBi. In this dataset, tumor cellularity refers to a measure of residual disease after NAT, in the form of proportion of malignant tumor inside the tumor bed region; also annotated. (See MD Anderson RCB Calculator for a detailed description of tumor cellularity.) Malignant, healthy, lymphocyte and other labels were also provided for individual cells to aid development of cell segmentation algorithms.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://www.cancerimagingarchive.net/collection/post-nat-brca/">https://www.cancerimagingarchive.net/collection/post-nat-brca/</a></p>
</section>
<hr class="docutils" />
<section id="astigmatic-4pi-bead-stack">
<h2>Astigmatic 4Pi bead stack<a class="headerlink" href="#astigmatic-4pi-bead-stack" title="Link to this heading">#</a></h2>
<p>Zach Marin, Maohan Su</p>
<p>Published 2024-12-06</p>
<p>Licensed CC-BY-4.0</p>
<p>Bead stack taken on a 4Pi. DCIMG 0x1000000 file with a 4-pixel correction requirement.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14287640">https://zenodo.org/records/14287640</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14287640">https://doi.org/10.5281/zenodo.14287640</a></p>
</section>
<hr class="docutils" />
<section id="automatic-labelling-of-hela-kyoto-cells-using-deep-learning-tools">
<h2>Automatic labelling of HeLa “Kyoto” cells using Deep Learning tools<a class="headerlink" href="#automatic-labelling-of-hela-kyoto-cells-using-deep-learning-tools" title="Link to this heading">#</a></h2>
<p>Romain Guiet</p>
<p>Published 2022-02-25</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: Automatic labelling of HeLa “Kyoto” cells using Deep Learning tools</p>
<p>Data type: Microscopy images from the dataset “HeLa “Kyoto” cells under the scope”, Brightfield (BF), Digital Phase Contrast (DPC, either “raw” or “square-rooted”), Tubulin and H2B fluorescent channel, paired with their corresponding nuclei or cell/cyto label images.</p>
<p>Labels images: Labels images were generated using the script “prepare_trainingDataset_cellpose.ijm”.</p>
<p>Briefly, for 5 defined time-points (1,10,50,100,150), channels of interest were duplicated, resaved and :</p>
<p>-        nuclei label images were obtained using StarDist on H2B channel</p>
<p>-        cell label images were obtained using Cellpose on Tubulin and H2B channels</p>
<p>A quick visual inspection of the resulting label images concluded that they were satisfying enough, despite certainly not being perfect.</p>
<p>Notes :</p>
<p>-       This labelling strategy:</p>
<p>o   will not produce 100% accurate labels, but they might be more reproducible than labels generated by humans and are (definitely) much faster to obtain.</p>
<p>o   is NOT a recommended way of generating labels images, but for educational purposes.</p>
<p>-       The fluorescent channels are part of the dataset to ease the process of review of the labels and are NOT used for training. We generated the labels from the fluorescent channels to later predict labels from the BF or DPC channels only. As such, the fluorescent channels should not be “reused” with our labels during training.</p>
<p>File format: .tif (16-bit)</p>
<p>Image size: 540x540 (Pixel size: 0.299 nm)</p>
<p> </p>
<p>NOTE: This dataset uses the “HeLa “Kyoto” cells under the scope”  dataset (<a class="reference external" href="https://doi.org/10.5281/zenodo.6139958">https://doi.org/10.5281/zenodo.6139958</a>) to automatically generate annotations</p>
<p>NOTE: This dataset was used to train cellpose models in the following Zenodo entry <a class="reference external" href="https://doi.org/10.5281/zenodo.6140111">https://doi.org/10.5281/zenodo.6140111</a></p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/6140064">https://zenodo.org/records/6140064</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6140064">https://doi.org/10.5281/zenodo.6140064</a></p>
</section>
<hr class="docutils" />
<section id="axioscan-7-fluorescent-channels-not-displaying-in-qupath">
<h2>Axioscan 7 fluorescent channels not displaying in QuPath<a class="headerlink" href="#axioscan-7-fluorescent-channels-not-displaying-in-qupath" title="Link to this heading">#</a></h2>
<p>j</p>
<p>Published 2024-06-25</p>
<p>Hi &#64;ome team,Please find the .czi file attached. When loaded into QuPath using BioFormats, the fluorescence channels populate the brightness/contrast panel but do not show up in the viewer. Re-exporting as OME.Tiff from Zen and loading into QuPath does not help either - the channels do not populate the brightness/contrast panel in this case, and it shows as a RGB image.Please let me know if any further info is needed from me to troubleshoot!
Best,J</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/12533989">https://zenodo.org/records/12533989</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12533989">https://doi.org/10.5281/zenodo.12533989</a></p>
</section>
<hr class="docutils" />
<section id="bccd-dataset">
<h2>BCCD Dataset<a class="headerlink" href="#bccd-dataset" title="Link to this heading">#</a></h2>
<p>Shenggan Gan, Nicolas Chen</p>
<p>Published 2017-12-07</p>
<p>Licensed MIT</p>
<p>BCCD Dataset is a small-scale dataset for blood cells detection.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="github reference external" href="https://github.com/Shenggan/BCCD_Dataset">Shenggan/BCCD_Dataset</a></p>
</section>
<hr class="docutils" />
<section id="bhg2023-omero-arc">
<h2>BHG2023-OMERO-ARC<a class="headerlink" href="#bhg2023-omero-arc" title="Link to this heading">#</a></h2>
<p>Andrea Schrader, Michele Bortolomeazzi, Niraj Kandpal, Torsten Stöter, Kevin Schneider, Peter Zentis, Josh Moore, Jeam-Marie Burel, Tom Boissonnet</p>
<p>Licensed CC-BY-4.0</p>
<p>Repository for documentation during the 2nd de.NBI BioHackathon Germany - 11.-15.12.2023 - OMERO-ARC project (in short: BHG2023-OMERO-ARC)</p>
<p>Tags: Nfdi4Bioimage, Bioinformatics, OMERO, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/NFDI4BIOIMAGE/BHG2023-OMERO-ARC">NFDI4BIOIMAGE/BHG2023-OMERO-ARC</a></p>
</section>
<hr class="docutils" />
<section id="bia-seminar-series">
<h2>BIA Seminar Series<a class="headerlink" href="#bia-seminar-series" title="Link to this heading">#</a></h2>
<p>GloBIAS</p>
<p>Licensed UNKNOWN</p>
<p>The primary goal of this seminar series is to provide a dynamic platform for bioimage analysts, enabling the community to stay up to date with the latest developments in the field and foster community interactions. The seminars are designed to cater to intermediate and advanced analysts, focusing on practical, high-level content that extends beyond basic instruction.</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://www.globias.org/activities/bia-seminar-series">https://www.globias.org/activities/bia-seminar-series</a></p>
</section>
<hr class="docutils" />
<section id="bids-lecture-2024">
<h2>BIDS-lecture-2024<a class="headerlink" href="#bids-lecture-2024" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Licensed CC-BY-4.0</p>
<p>Training resources for Students at Uni Leipzig who want to dive into bio-image data science with Python. The material developed here between April and July 2024.</p>
<p>Tags: Bioimage Analysis, Artificial Intelligence, Python, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/ScaDS/BIDS-lecture-2024/">ScaDS/BIDS-lecture-2024</a></p>
</section>
<hr class="docutils" />
<section id="biomero-a-scalable-and-extensible-image-analysis-framework">
<h2>BIOMERO - A scalable and extensible image analysis framework<a class="headerlink" href="#biomero-a-scalable-and-extensible-image-analysis-framework" title="Link to this heading">#</a></h2>
<p>Torec T. Luik, Rodrigo Rosas-Bertolini, Eric A.J. Reits, Ron A. Hoebe, Przemek M. Krawczyk</p>
<p>Published None</p>
<p>Licensed CC-BY-4.0</p>
<p>The authors introduce BIOMERO (bioimage analysis in OMERO), a bridge connecting OMERO, a renowned bioimaging data management platform, FAIR workflows, and high-performance computing (HPC) environments.</p>
<p>Tags: OMERO, Workflow, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://doi.org/10.1016/j.patter.2024.101024">https://doi.org/10.1016/j.patter.2024.101024</a></p>
</section>
<hr class="docutils" />
<section id="beads-imaged-over-time">
<h2>Beads imaged over time<a class="headerlink" href="#beads-imaged-over-time" title="Link to this heading">#</a></h2>
<p>Zach Marin</p>
<p>Published 2025-04-04</p>
<p>Licensed CC-BY-4.0</p>
<p>DCIMG 0x1000000 images of beads over time (30 seconds, 0.03 s exposure). </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15150937">https://zenodo.org/records/15150937</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15150937">https://doi.org/10.5281/zenodo.15150937</a></p>
</section>
<hr class="docutils" />
<section id="biapy-bioimage-analysis-pipelines-in-python">
<h2>BiaPy: Bioimage analysis pipelines in Python<a class="headerlink" href="#biapy-bioimage-analysis-pipelines-in-python" title="Link to this heading">#</a></h2>
<p>Daniel Franco-Barranco, et al.</p>
<p>BiaPy is an open source Python library for building bioimage analysis pipelines, also called workflows.</p>
<p>Tags: Workflow Engine, Python, Exclude From Dalia</p>
<p>Content type: Documentation</p>
<p><a class="reference external" href="https://biapy.readthedocs.io/">https://biapy.readthedocs.io/</a></p>
</section>
<hr class="docutils" />
<section id="bigdataprocessor2-a-free-and-open-source-fiji-plugin-for-inspection-and-processing-of-tb-sized-image-data">
<h2>BigDataProcessor2: A free and open-source Fiji plugin for inspection and processing of TB sized image data<a class="headerlink" href="#bigdataprocessor2-a-free-and-open-source-fiji-plugin-for-inspection-and-processing-of-tb-sized-image-data" title="Link to this heading">#</a></h2>
<p>Christian Tischer, Ashis Ravindran, Sabine Reither, Nicolas Chiaruttini, Rainer Pepperkok, Nils Norlin</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Research Data Management, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://doi.org/10.1093/bioinformatics/btab106">https://doi.org/10.1093/bioinformatics/btab106</a></p>
</section>
<hr class="docutils" />
<section id="bio-image-analysis">
<h2>Bio Image Analysis<a class="headerlink" href="#bio-image-analysis" title="Link to this heading">#</a></h2>
<p>Christian Tischer</p>
<p>Licensed UNKNOWN</p>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Slides</p>
<p><a class="github reference external" href="https://github.com/tischi/presentation-image-analysis">tischi/presentation-image-analysis</a></p>
</section>
<hr class="docutils" />
<section id="bio-image-analysis-lecture-2020">
<h2>Bio Image Analysis Lecture 2020<a class="headerlink" href="#bio-image-analysis-lecture-2020" title="Link to this heading">#</a></h2>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Collection, Video</p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=e-2DbkUwKk4&amp;amp;list=PL5ESQNfM5lc7SAMstEu082ivW4BDMvd0U">https://www.youtube.com/watch?v=e-2DbkUwKk4&amp;list=PL5ESQNfM5lc7SAMstEu082ivW4BDMvd0U</a></p>
</section>
<hr class="docutils" />
<section id="bio-image-analysis-icob-2023">
<h2>Bio-image Analysis ICOB 2023<a class="headerlink" href="#bio-image-analysis-icob-2023" title="Link to this heading">#</a></h2>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Workshop, Collection</p>
<p><a class="github reference external" href="https://github.com/WeiChenChu/Bioimage_Analysis_ICOB_2023">WeiChenChu/Bioimage_Analysis_ICOB_2023</a></p>
</section>
<hr class="docutils" />
<section id="bio-image-data-science-lectures-2025-uni-leipzig-scads-ai">
<h2>Bio-image Data Science Lectures 2025 &#64; Uni Leipzig / <a class="reference external" href="http://ScaDS.AI">ScaDS.AI</a><a class="headerlink" href="#bio-image-data-science-lectures-2025-uni-leipzig-scads-ai" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2025-07-10</p>
<p>Licensed CC-BY-4.0</p>
<p>These are the PPTx training resources for Students at Uni Leipzig who want to dive into bio-image data science with Python. The material will develop here and in the corresponding github repository between April and July 2025.</p>
<p>Tags: Nfdi4Bioimage, Bioimage Analysis, Artificial Intelligence, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15858127">https://zenodo.org/records/15858127</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15858127">https://doi.org/10.5281/zenodo.15858127</a></p>
</section>
<hr class="docutils" />
<section id="bio-image-data-science-lectures-uni-leipzig-scads-ai">
<h2>Bio-image Data Science Lectures &#64; Uni Leipzig / <a class="reference external" href="http://ScaDS.AI">ScaDS.AI</a><a class="headerlink" href="#bio-image-data-science-lectures-uni-leipzig-scads-ai" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Licensed CC-BY-4.0</p>
<p>These are the PPTx training resources for Students at Uni Leipzig who want to dive into bio-image data science with Python. The material developed here between April and July 2024.</p>
<p>Tags: Bioimage Analysis, Artificial Intelligence, Python, Exclude From Dalia</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/12623730">https://zenodo.org/records/12623730</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12623730">https://doi.org/10.5281/zenodo.12623730</a></p>
</section>
<hr class="docutils" />
<section id="bio-tools-database">
<h2>Bio.tools database<a class="headerlink" href="#bio-tools-database" title="Link to this heading">#</a></h2>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Bioinformatics, Exclude From Dalia</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://bio.tools/">https://bio.tools/</a></p>
</section>
<hr class="docutils" />
<section id="bioengine">
<h2>BioEngine<a class="headerlink" href="#bioengine" title="Link to this heading">#</a></h2>
<p>Jeremy Metz, Beatriz Serrano-Solano, Wei Ouyang</p>
<p>Licensed UNKNOWN</p>
<p>BioEngine is a cloud infrastructure to run BioImage model zoo based workflows in the cloud.</p>
<p>Tags: Artificial Intelligence, Workflow Engine, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://ai4life.eurobioimaging.eu/announcing-bioengine/">https://ai4life.eurobioimaging.eu/announcing-bioengine/</a></p>
</section>
<hr class="docutils" />
<section id="bioengine-documentation">
<h2>BioEngine Documentation<a class="headerlink" href="#bioengine-documentation" title="Link to this heading">#</a></h2>
<p>Wei Ouyang, Nanguage, Jeremy Metz, Craig Russell</p>
<p>Licensed MIT</p>
<p>BioEngine, a Python package designed for flexible deployment and execution of bioimage analysis models and workflows using AI, accessible via HTTP API and RPC.</p>
<p>Tags: Workflow Engine, Artificial Intelligence, Python, Exclude From Dalia</p>
<p>Content type: Documentation</p>
<p><a class="reference external" href="https://bioimage-io.github.io/bioengine/#/">https://bioimage-io.github.io/bioengine/#/</a></p>
</section>
<hr class="docutils" />
<section id="bioformats-command-line-cli-tools">
<h2>BioFormats Command line (CLI) tools<a class="headerlink" href="#bioformats-command-line-cli-tools" title="Link to this heading">#</a></h2>
<p>Published 2024-10-24</p>
<p>Licensed CC-BY-4.0</p>
<p>Bio-Formats is a standalone Java library for reading and writing life sciences image file formats. There are several scripts for using Bio-Formats on the command line, which are listed here.</p>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Documentation</p>
<p><a class="reference external" href="https://bio-formats.readthedocs.io/en/v8.0.0/users/comlinetools/index.html">https://bio-formats.readthedocs.io/en/v8.0.0/users/comlinetools/index.html</a></p>
</section>
<hr class="docutils" />
<section id="bioimage-archive-ai-gallery">
<h2>BioImage Archive AI Gallery<a class="headerlink" href="#bioimage-archive-ai-gallery" title="Link to this heading">#</a></h2>
<p>Licensed CC0-1.0</p>
<p>Tags: Bioimage Analysis, Artificial Intelligence, Exclude From Dalia</p>
<p>Content type: Collection, Data</p>
<p><a class="reference external" href="https://www.ebi.ac.uk/bioimage-archive/galleries/AI.html">https://www.ebi.ac.uk/bioimage-archive/galleries/AI.html</a></p>
</section>
<hr class="docutils" />
<section id="bioimage-archive-visual-gallery">
<h2>BioImage Archive Visual Gallery<a class="headerlink" href="#bioimage-archive-visual-gallery" title="Link to this heading">#</a></h2>
<p>Licensed CC0-1.0</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Collection, Data</p>
<p><a class="reference external" href="https://www.ebi.ac.uk/bioimage-archive/galleries/visualisation.html">https://www.ebi.ac.uk/bioimage-archive/galleries/visualisation.html</a></p>
</section>
<hr class="docutils" />
<section id="bioimage-archive-volume-em-gallery">
<h2>BioImage Archive Volume EM Gallery<a class="headerlink" href="#bioimage-archive-volume-em-gallery" title="Link to this heading">#</a></h2>
<p>Licensed CC0-1.0</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Collection, Data</p>
<p><a class="reference external" href="https://www.ebi.ac.uk/bioimage-archive/galleries/vem.html">https://www.ebi.ac.uk/bioimage-archive/galleries/vem.html</a></p>
</section>
<hr class="docutils" />
<section id="bioimage-informatics-index-training-materials">
<h2>BioImage Informatics Index Training Materials<a class="headerlink" href="#bioimage-informatics-index-training-materials" title="Link to this heading">#</a></h2>
<p>Licensed ODC-BY-1.0</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://biii.eu/training-material">https://biii.eu/training-material</a></p>
</section>
<hr class="docutils" />
<section id="bioimage-archive">
<h2>Bioimage Archive<a class="headerlink" href="#bioimage-archive" title="Link to this heading">#</a></h2>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Collection, Data, Publication</p>
<p><a class="reference external" href="https://www.ebi.ac.uk/bioimage-archive/">https://www.ebi.ac.uk/bioimage-archive/</a></p>
<p><a class="reference external" href="https://www.sciencedirect.com/science/article/abs/pii/S0022283622000791">https://www.sciencedirect.com/science/article/abs/pii/S0022283622000791</a></p>
</section>
<hr class="docutils" />
<section id="bioimage-model-zoo">
<h2>Bioimage Model Zoo<a class="headerlink" href="#bioimage-model-zoo" title="Link to this heading">#</a></h2>
<p>Licensed UNKNOWN</p>
<p>Tags: Bioimage Analysis, Artificial Intelligence, Exclude From Dalia</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://bioimage.io/">https://bioimage.io/</a></p>
</section>
<hr class="docutils" />
<section id="bioimaging-workflow-based-on-omero-elabftw-and-adamant-for-integrating-images-with-multimodal-metadata">
<h2>Bioimaging workflow based on OMERO, eLabFTW, and Adamant for integrating images with multimodal metadata<a class="headerlink" href="#bioimaging-workflow-based-on-omero-elabftw-and-adamant-for-integrating-images-with-multimodal-metadata" title="Link to this heading">#</a></h2>
<p>Mohsen Ahmadi, Robert Wagner, Sander Bekeschus, Becker, Markus M.</p>
<p>Published 2025-07-29</p>
<p>Licensed CC-BY-4.0</p>
<p>This research data management workflow for bioimaging is designed to bridge the gap between image metadata and experimental / process metadata. By linking images and microscopy-related metadata with broader experimental records, the workflow particularly supports the adoption of the FAIR (Findable, Accessible, Interoperable, Reusable) data principles in interdisciplinary fields where bioimaging is used to analyse treated samples requiring multimodal metadata. A Jupyter Notebook guides the user through the metadata level, data handling level, and data processing level and connects various software components in a modular manner. On the metadata level, microscope-specific metadata are captured using the Micro-Meta App and stored as reusable digital assets. Adamant provides a user interface to collect and process schema-based metadata related to the experiment / treatment procedure. Structured imaging and process metadata are attached to the complete experiment description in eLabFTW. On the data handling level, OMERO serves as the central platform for storing and managing microscopy images together with their metadata retrieved from eLabFTW (workflow with ELN) or directly from JSON files (workflow without ELN). On the data processing level, OMERO supports both automated and manual image analysis either directly via the Jupyter Notebook or FIJI. Due to the modularity of the workflow, the integrated tools can be substituted with equivalent systems based on institutional / user requirements. Whether in teaching or research settings, this workflow supports high-throughput, reproducible imaging workflows, ensuring that data, metadata, and analysis steps remain transparent, interoperable, and reusable across diverse bioimage analysis platforms.</p>
<p>Tags: Nfdi4Bioimage, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16561545">https://zenodo.org/records/16561545</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16561545">https://doi.org/10.5281/zenodo.16561545</a></p>
</section>
<hr class="docutils" />
<section id="biologists-stop-putting-umap-plots-in-your-papers">
<h2>Biologists, stop putting UMAP plots in your papers<a class="headerlink" href="#biologists-stop-putting-umap-plots-in-your-papers" title="Link to this heading">#</a></h2>
<p>Rafael Irizarry</p>
<p>Published 2024-12-23</p>
<p>Licensed UNKNOWN</p>
<p>UMAP is a powerful tool for exploratory data analysis, but without a clear understanding of how it works, it can easily lead to confusion and misinterpretation.</p>
<p>Tags: Biology, Data Analysis, Umap, Exclude From Dalia</p>
<p>Content type: Blog Post</p>
<p><a class="reference external" href="https://simplystatistics.org/posts/2024-12-23-biologists-stop-including-umap-plots-in-your-papers/">https://simplystatistics.org/posts/2024-12-23-biologists-stop-including-umap-plots-in-your-papers/</a></p>
</section>
<hr class="docutils" />
<section id="biomero">
<h2>Biomero<a class="headerlink" href="#biomero" title="Link to this heading">#</a></h2>
<p>Torec Luik, Johannes Soltwedel</p>
<p>Published 2024-07-24</p>
<p>Licensed APACHE-2.0</p>
<p>The BIOMERO framework, for BioImage analysis in OMERO, allows you to run (FAIR) bioimage analysis workflows directly from OMERO on a high-performance compute (HPC) cluster, remotely through SSH.</p>
<p>Tags: OMERO, Github, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/NL-BioImaging/biomero">NL-BioImaging/biomero</a></p>
</section>
<hr class="docutils" />
<section id="breast-cancer-nuclei-images-for-dl-training-zerocostdl4mic-stardist-model">
<h2>Breast Cancer Nuclei images for DL Training + ZeroCostDL4Mic StarDist Model<a class="headerlink" href="#breast-cancer-nuclei-images-for-dl-training-zerocostdl4mic-stardist-model" title="Link to this heading">#</a></h2>
<p>Ofra Golani, Vishnu Mohan, Tamar Geiger</p>
<p>Published 2024-05-21</p>
<p>Licensed CC-BY-4.0</p>
<p>Training dataset:Paired microscopy images (fluorescence) and corresponding masks
Microscopy data type: Fluorescence microscopy and masks obtained via manual correction of automatic segmentation with pre-trained StarDist model (see <a class="github reference external" href="https://github.com/qupath/models/tree/main/stardist">qupath/models</a>) 
Cells were imaged using a 20x objective with a 1x camera adapter was used in conjunction with a pco.edge 4.2 4MP camera on Pannoramic SCAN 150 scanner.
Cell type: FFPE tissue sections were sliced from all cancer-containing paraffin blocks
File format: .tif (8-bit for fluorescence and 16-bit for the masks)
 
StarDist Model:The StarDist model was generated using the ZeroCostDL4Mic platform (Chamier et al., 2021). This custom StarDist model was trained for 100 epochs using 80 manually annotated paired images (image dimensions: (257, 257)) with a batch size of 2, an augmentation factor of 10 and a mae loss function. The StarDist “Versatile fluorescent nuclei” model was used as a training starting point. Key python packages used include TensorFlow (v 2.2.0), Keras (v 1.1.2), CSBdeep (v 0.7.2), NumPy (v 1.21.6), Cuda (v 11..1.105). The training was accelerated using a Tesla P100GPU.The model weights can be used in the ZeroCostDL4Mic StarDist 2D notebook or in the StarDist Fiji plugin. a QuPath-compatible model is also provided.
 
 </p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/11235393">https://zenodo.org/records/11235393</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11235393">https://doi.org/10.5281/zenodo.11235393</a></p>
</section>
<hr class="docutils" />
<section id="breast-cancer-semantic-segmentation-bcss-dataset">
<h2>Breast Cancer Semantic Segmentation (BCSS) dataset<a class="headerlink" href="#breast-cancer-semantic-segmentation-bcss-dataset" title="Link to this heading">#</a></h2>
<p>Mohamed Amgad, Habiba Elfandy, Hagar Hussein, Lamees A Atteya, Mai A T Elsebaie, Lamia S Abo Elnasr, Rokia A Sakr, Hazem S E Salem, Ahmed F Ismail, Anas M Saad, Joumana Ahmed, Maha A T Elsebaie, Mustafijur Rahman, Inas A Ruhban, Nada M Elgazar, Yahya Alagha, Mohamed H Osman, Ahmed M Alhusseiny, Mariam M Khalaf, Abo-Alela F Younes, Ali Abdulkarim, Duaa M Younes, Ahmed M Gadallah, Ahmad M Elkashash, Salma Y Fala, Basma M Zaki, Jonathan Beezley, Deepak R Chittajallu, David Manthey, David A Gutman, Lee A D Cooper</p>
<p>Published 2019-11-09</p>
<p>Licensed CC0-1.0</p>
<p>This repo contains the necessary information and download instructions to download the dataset associated with the paper: Amgad M, Elfandy H, …, Gutman DA, Cooper LAD. Structured crowdsourcing enables convolutional segmentation of histology images. Bioinformatics. 2019. doi: 10.1093/bioinformatics/btz083. This data can be visualized in a public instance of the Digital Slide Archive at this link. If you click the “eye” image icon in the Annotations panel on the right side of the screen, you will see the results of a collaborative annotation.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="github reference external" href="https://github.com/PathologyDataScience/BCSS">PathologyDataScience/BCSS</a></p>
</section>
<hr class="docutils" />
<section id="bridging-imaging-users-to-imaging-analysis-a-community-survey">
<h2>Bridging Imaging Users to Imaging Analysis - A community survey<a class="headerlink" href="#bridging-imaging-users-to-imaging-analysis-a-community-survey" title="Link to this heading">#</a></h2>
<p>Suganya Sivagurunathan, Stefania Marcotti, Carl J Nelson, Martin L Jones, David J Barry, Thomas J A Slater, Kevin W Eliceiri, Beth A Cimini</p>
<p>Published 2023</p>
<p>Licensed BSD-3-CLAUSE</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Publication, Preprint</p>
<p><a class="reference external" href="https://www.biorxiv.org/content/10.1101/2023.06.05.543701v1">https://www.biorxiv.org/content/10.1101/2023.06.05.543701v1</a></p>
<p><a class="github reference external" href="https://github.com/COBA-NIH/2023_ImageAnalysisSurvey">COBA-NIH/2023_ImageAnalysisSurvey</a></p>
</section>
<hr class="docutils" />
<section id="bring-your-own-data-workshops">
<h2>Bring your own data workshops<a class="headerlink" href="#bring-your-own-data-workshops" title="Link to this heading">#</a></h2>
<p>Tags: Bioimage Analysis, Research Data Management, Exclude From Dalia</p>
<p>Content type: Workshop</p>
<p><a class="reference external" href="https://www.dtls.nl/fair-data/byod/">https://www.dtls.nl/fair-data/byod/</a></p>
</section>
<hr class="docutils" />
<section id="building-fair-image-analysis-pipelines-for-high-content-screening-hcs-data-using-galaxy">
<h2>Building FAIR image analysis pipelines for high-content-screening (HCS) data using Galaxy<a class="headerlink" href="#building-fair-image-analysis-pipelines-for-high-content-screening-hcs-data-using-galaxy" title="Link to this heading">#</a></h2>
<p>Riccardo Massei, Matthias Berndt, Beatriz Serrano-Solano, Wibke Busch, Stefan Scholz, Hannes Bohring, Jo Nyffeler, Luise Reger, Jan Bumberger, Lucille Lopez-Delisle</p>
<p>Published 2024-11-06</p>
<p>Licensed CC-BY-4.0</p>
<p>Imaging is crucial across various scientific disciplines, particularly in life sciences, where it plays a key role in studies ranging from single molecules to whole organisms. However, the complexity and sheer volume of image data, especially from high-content screening (HCS) experiments involving cell lines or other organisms, present significant challenges. Managing and analysing this data efficiently requires well-defined image processing tools and analysis pipelines that align with the FAIR principles—ensuring they are findable, accessible, interoperable, and reusable across different domains.
In the frame of NFDI4BioImaging (the National Research Data Infrastructure focusing on bioimaging in Germany), we want to find viable solutions for storing, processing, analysing, and sharing HCS data. In particular, we want to develop solutions to make findable and machine-readable metadata using (semi)automatic analysis pipelines. In scientific research, such pipelines are crucial for maintaining data integrity, supporting reproducibility, and enabling interdisciplinary collaboration. These tools can be used by different users to retrieve images based on specific attributes as well as support quality control by identifying appropriate metadata.
Galaxy, an open-source, web-based platform for data-intensive research, offers a solution by enabling the construction of reproducible pipelines for image analysis. By integrating popular analysis software like CellProfiler and connecting with cloud services such as OMERO and IDR, Galaxy facilitates the seamless access and management of image data. This capability is particularly valuable in bioimaging, where automated pipelines can streamline the handling of complex metadata, ensuring data integrity and fostering interdisciplinary collaboration. This approach not only increases the efficiency of HCS bioimaging but also contributes to the broader scientific community’s efforts to embrace FAIR principles, ultimately advancing scientific discovery and innovation.
In the present study, we proposed an automated analysis pipeline for storing, processing, analysing, and sharing HCS bioimaging data. The (semi)automatic workflow was developed by taking as a case study a dataset of zebrafish larvae and cell lines images previously obtained from an automated imaging system generating data in an HCS fashion. In our workflows, images are automatically enriched with metadata (i.e. key-value pairs, tags, raw data, regions of interest) and uploaded to the UFZ-OME Remote Objects (OMERO) server using a novel OMERO tool suite developed with GALAXY. Workflows give the possibility to the user to intuitively fetch images from the local server and perform image analysis (i.e. annotation) or even more complex toxicological analyses (dose response modelling). Furthermore, we want to improve the FAIRness of the protocol by adding a direct upload link to the Image Data Resource (IDR) repository to automatically prepare the data for publication and sharing.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14044640">https://zenodo.org/records/14044640</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14044640">https://doi.org/10.5281/zenodo.14044640</a></p>
<p><a class="reference external" href="https://galaxyproject.org/news/2024-11-08-galaxy-imaging-fair-pipelines/">https://galaxyproject.org/news/2024-11-08-galaxy-imaging-fair-pipelines/</a></p>
</section>
<hr class="docutils" />
<section id="building-a-fair-image-data-ecosystem-for-microscopy-communities">
<h2>Building a FAIR image data ecosystem for microscopy communities<a class="headerlink" href="#building-a-fair-image-data-ecosystem-for-microscopy-communities" title="Link to this heading">#</a></h2>
<p>Isabel Kemmer, Antje Keppler, Beatriz Serrano-Solano, Arina Rybina, Buğra Özdemir, Johanna Bischof, Ayoub El Ghadraoui, John E. Eriksson, Aastha Mathur</p>
<p>Tags: Research Data Management, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://link.springer.com/article/10.1007/s00418-023-02203-7">https://link.springer.com/article/10.1007/s00418-023-02203-7</a></p>
</section>
<hr class="docutils" />
<section id="clij-gpu-accelerated-image-processing-for-everyone">
<h2>CLIJ: GPU-accelerated image processing for everyone<a class="headerlink" href="#clij-gpu-accelerated-image-processing-for-everyone" title="Link to this heading">#</a></h2>
<p>Robert Haase, Loic Royer, et al.</p>
<p>Published 2020</p>
<p>Licensed ALL RIGHTS RESERVED</p>
<p>CLIJ is a collection of image processing functions that use graphics processing units for accelerated processing.</p>
<p>Tags: Imagej, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://doi.org/10.1038/s41592-019-0650-1">https://doi.org/10.1038/s41592-019-0650-1</a></p>
</section>
<hr class="docutils" />
<section id="coba-nih-2024-bridging-imaging-users-to-imaging-analysis-survey-survey-data-with-preliminary-exploration">
<h2>COBA-NIH/2024_Bridging_Imaging_Users_to_Imaging_Analysis_Survey: Survey data with preliminary exploration<a class="headerlink" href="#coba-nih-2024-bridging-imaging-users-to-imaging-analysis-survey-survey-data-with-preliminary-exploration" title="Link to this heading">#</a></h2>
<p>Erin Weisbart</p>
<p>Published 2025-09-15</p>
<p>Licensed BSD-3-CLAUSE</p>
<p>Contains the survey data collected through the 2024 Bridging Imaging Users to Imaging Analysis Survey and figures/code from preliminary data exploration of the survey results.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/17127544">https://zenodo.org/records/17127544</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.17127544">https://doi.org/10.5281/zenodo.17127544</a></p>
</section>
<hr class="docutils" />
<section id="coba-center-for-open-bioimage-analysis-youtube-channel">
<h2>COBA: Center for Open Bioimage Analysis YouTube Channel<a class="headerlink" href="#coba-center-for-open-bioimage-analysis-youtube-channel" title="Link to this heading">#</a></h2>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Collection, Video</p>
<p><a class="reference external" href="https://www.youtube.com/&#64;cobacenterforopenbioimagea1864">https://www.youtube.com/&#64;cobacenterforopenbioimagea1864</a></p>
</section>
<hr class="docutils" />
<section id="ct-physics">
<h2>CT Physics<a class="headerlink" href="#ct-physics" title="Link to this heading">#</a></h2>
<p>Radiology Tutorials</p>
<p>Published 2025-01-01</p>
<p>Licensed UNKNOWN</p>
<p>This is a playlist of videos about how CT works</p>
<p>Tags: Imaging, Exclude From Dalia</p>
<p>Content type: Video</p>
<p><a class="reference external" href="https://youtube.com/playlist?list=PLWfaNqiSdtzW_muHrCkwJm9FyovAue-jN&amp;amp;si=-zIXh87DMkAEuJVd">https://youtube.com/playlist?list=PLWfaNqiSdtzW_muHrCkwJm9FyovAue-jN&amp;si=-zIXh87DMkAEuJVd</a></p>
</section>
<hr class="docutils" />
<section id="czi-carl-zeiss-image-dataset-with-artificial-test-camera-images-with-various-dimension-for-testing-libraries-reading">
<h2>CZI (Carl Zeiss Image) dataset with artificial test camera images with various dimension for testing libraries reading<a class="headerlink" href="#czi-carl-zeiss-image-dataset-with-artificial-test-camera-images-with-various-dimension-for-testing-libraries-reading" title="Link to this heading">#</a></h2>
<p>Sebastian Rhode</p>
<p>Published 2022-08-22</p>
<p>Licensed CC-BY-4.0</p>
<p>Set of CZI test images created by using a simulated microscope with a test grayscale camera (no LSM or AiryScan or RGB). The filename indicates the used dimension(s) for the acquisition experiment. The files can be used to test the basic functionality of libraries reading CZI files.</p>
<p>Examples:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>S=2_T=3_CH=1.czi = 2 Scenes, 3 TimePoints and 1 Channel

	Z-Stack was not activated inside acquisition experiment


S=2_T=3_Z=5_CH=2.czi = 2 Scenes, 3 TimePoints, 5-Z-Planes and 1 Channels

	Z-Stack was activated inside acquisition experiment
</pre></div>
</div>
<p>The test files (so far) contain not any data with more “advanced” dimensions like AiryScan rawdata, illumination angles etc. Also no CZI files with pixel type RGB are included yet.</p>
<p> </p>
<p> </p>
<p> </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/7015307">https://zenodo.org/records/7015307</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7015307">https://doi.org/10.5281/zenodo.7015307</a></p>
</section>
<hr class="docutils" />
<section id="czi-file-examples">
<h2>CZI file examples<a class="headerlink" href="#czi-file-examples" title="Link to this heading">#</a></h2>
<p>Nicolas Chiaruttini</p>
<p>Published 2023-08-18</p>
<p>Licensed CC-BY-4.0</p>
<p>A set of public CZI files. These can be used for testing CZI readers.</p>
<ul class="simple">
<li><p>Demo LISH 4x8 15pct 647.czi: A cleared mouse brain acquired with a Zeiss LightSheet Z1 with 32 tiles. Courtesy of the Carl Petersen lab LSENS (<a class="reference external" href="https://www.epfl.ch/labs/lsens">https://www.epfl.ch/labs/lsens</a>). Sampled prepared by Yanqi Liu an imaged by Olivier Burri.</p></li>
<li><p>test_gray.czi: a synthetically generated CZI file without metadata, made by Sebastian Rhode</p></li>
<li><p>Image_1_2023_08_18__14_32_31_964.czi: an example multi-part CZI file, containing only camera noise</p></li>
<li><p>a xt scan, xz scan, xzt scan</p></li>
<li><p>a set of multi angle, multi illumination, mutli tile acquisition, taken on the LightSheet Z1 microscope of the PTBIOP by Lorenzo Talà</p></li>
</ul>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/8305531">https://zenodo.org/records/8305531</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8305531">https://doi.org/10.5281/zenodo.8305531</a></p>
</section>
<hr class="docutils" />
<section id="czi-open-science-program-collection">
<h2>CZI: Open Science Program Collection<a class="headerlink" href="#czi-open-science-program-collection" title="Link to this heading">#</a></h2>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://zenodo.org/communities/eoss">https://zenodo.org/communities/eoss</a></p>
</section>
<hr class="docutils" />
<section id="cell-tracking-challenge-2d-datasets">
<h2>Cell Tracking Challenge - 2D Datasets<a class="headerlink" href="#cell-tracking-challenge-2d-datasets" title="Link to this heading">#</a></h2>
<p>Licensed UNKNOWN</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Collection, Data</p>
<p><a class="reference external" href="http://celltrackingchallenge.net/2d-datasets/">http://celltrackingchallenge.net/2d-datasets/</a></p>
</section>
<hr class="docutils" />
<section id="cell-tracking-challenge-3d-datasets">
<h2>Cell Tracking Challenge - 3D Datasets<a class="headerlink" href="#cell-tracking-challenge-3d-datasets" title="Link to this heading">#</a></h2>
<p>Licensed UNKNOWN</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Collection, Data</p>
<p><a class="reference external" href="http://celltrackingchallenge.net/3d-datasets/">http://celltrackingchallenge.net/3d-datasets/</a></p>
</section>
<hr class="docutils" />
<section id="cellbindb-a-large-scale-multimodal-annotated-dataset">
<h2>CellBinDB: A Large-Scale Multimodal Annotated Dataset<a class="headerlink" href="#cellbindb-a-large-scale-multimodal-annotated-dataset" title="Link to this heading">#</a></h2>
<p>Can Shi, Jinghong Fan, Zhonghan Deng, Huanlin Liu, Qiang Kang, Yumei Li, Jing Guo, Jingwen Wang, Jinjiang Gong, Sha Liao, Ao Chen, Ying Zhang, Mei Li</p>
<p>Published 2024-11-20</p>
<p>Licensed CC-ZERO</p>
<p>CellBinDB is a large-scale, multimodal annotated dataset for cell segmentation. It contains 1,044 annotated microscope images and 109,083 cell annotations, covering four staining types: DAPI, ssDNA, H&amp;E, and mIF. CellBinDB contains samples from two species, human and mouse, covering more than 30 histologically different tissue types, including disease-related tissues. The images in CellBinDB come from two sources: 844 mouse images from internal experiments and 200 human images from the open access platform 10x Genomics. We annotated all images in CellBinDB and provide two types of image annotations: semantic and instance masks. A xlsx file is attached to record the detailed information of each image.
In addition, we provide the images and annotations of nine other widely used publicly available cell segmentation datasets downloaded from their original sources, retaining their original formats for ease of use. 
The file ‘mixed_licenses.txt’ contains the original accessions of the public datasets used in our project and their associated licenses. Please refer to these links for more information about each dataset and its licensing terms, and use it according to the specifications.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/15370205">https://zenodo.org/records/15370205</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15370205">https://doi.org/10.5281/zenodo.15370205</a></p>
</section>
<hr class="docutils" />
<section id="celltrackcolab">
<h2>CellTrackColab<a class="headerlink" href="#celltrackcolab" title="Link to this heading">#</a></h2>
<p>Guillaume Jacquemet</p>
<p>Licensed MIT</p>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Notebook, Collection</p>
<p><a class="reference external" href="https://www.biorxiv.org/content/10.1101/2023.10.20.563252v2">https://www.biorxiv.org/content/10.1101/2023.10.20.563252v2</a></p>
<p><a class="github reference external" href="https://github.com/guijacquemet/CellTracksColab">guijacquemet/CellTracksColab</a></p>
</section>
<hr class="docutils" />
<section id="cellpose-model-for-digital-phase-contrast-images">
<h2>Cellpose model for Digital Phase Contrast images<a class="headerlink" href="#cellpose-model-for-digital-phase-contrast-images" title="Link to this heading">#</a></h2>
<p>Laura Capolupo, Olivier Burri, Romain Guiet</p>
<p>Published 2022-02-09</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: Cellpose model for Digital Phase Contrast images</p>
<p>Data type: Cellpose model, trained via transfer learning from ‘cyto’ model.</p>
<p>Training Dataset: Light microscopy (Digital Phase Contrast) and Manual annotations (10.5281/zenodo.5996883)</p>
<p>Training Procedure: Model was trained using a Cellpose version 0.6.5 with GPU support (NVIDIA GeForce RTX 2080) using default settings as per the Cellpose documentation </p>
<p>python -m cellpose –train –dir TRAINING/DATASET/PATH/train –test_dir TRAINING/DATASET/PATH/test –pretrained_model cyto –chan 0 –chan2 0</p>
<p>The model file (MODEL NAME) in this repository is the result of this training.</p>
<p>Prediction Procedure: Using this model, a label image can be obtained from new unseen images in a given folder with</p>
<p>python -m cellpose –dir NEW/DATASET/PATH –pretrained_model FULL_MODEL_PATH –chan 0 –chan2 0 –save_tif –no_npy</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/6023317">https://zenodo.org/records/6023317</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6023317">https://doi.org/10.5281/zenodo.6023317</a></p>
</section>
<hr class="docutils" />
<section id="cellpose-models-for-label-prediction-from-brightfield-and-digital-phase-contrast-images">
<h2>Cellpose models for Label Prediction from Brightfield and Digital Phase Contrast images<a class="headerlink" href="#cellpose-models-for-label-prediction-from-brightfield-and-digital-phase-contrast-images" title="Link to this heading">#</a></h2>
<p>Romain Guiet, Olivier Burri</p>
<p>Published 2022-02-25</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: Cellpose models for Brightfield and Digital Phase Contrast images</p>
<p>Data type: Cellpose models trained via transfer learning from the ‘nuclei’ and ‘cyto2’ pretrained model with additional Training Dataset . Includes corresponding csv files with ‘Quality Control’ metrics(§) (model.zip).</p>
<p>Training Dataset: Light microscopy (Digital Phase Contrast or Brightfield) and automatic annotations (nuclei or cyto) (<a class="reference external" href="https://doi.org/10.5281/zenodo.6140064">https://doi.org/10.5281/zenodo.6140064</a>)</p>
<p>Training Procedure: The cellpose models were trained using cellpose version 1.0.0 with GPU support (NVIDIA GeForce K40) using default settings as per the Cellpose documentation . Training was done using a Renku environment (renku template).</p>
<p> </p>
<p>Command Line Execution for the different trained models</p>
<p>nuclei_from_bf:</p>
<p>cellpose –train –dir ‘data/train/’ –test_dir ‘data/test/’ –pretrained_model nuclei  –img_filter _bf –mask_filter _nuclei –chan 0 –chan2 0 –use_gpu –verbose</p>
<p>cyto_from_bf:</p>
<p>cellpose –train –dir ‘data/train/’ –test_dir ‘data/test/’ –pretrained_model cyto2 –img_filter _bf –mask_filter _cyto –chan 0 –chan2 0 –use_gpu –verbose</p>
<p> </p>
<p>nuclei_from_dpc:</p>
<p>cellpose –train –dir ‘data/train/’ –test_dir ‘data/test/’ –pretrained_model nuclei  –img_filter _dpc –mask_filter _nuclei –chan 0 –chan2 0 –use_gpu –verbose</p>
<p>cyto_from_dpc:</p>
<p>cellpose –train –dir ‘data/train/’ –test_dir ‘data/test/’ –pretrained_model cyto2 –img_filter _dpc –mask_filter _cyto –chan 0 –chan2 0 –use_gpu –verbose</p>
<p> </p>
<p>nuclei_from_sqrdpc:</p>
<p>cellpose –train –dir ‘data/train/’ –test_dir ‘data/test/’ –pretrained_model nuclei –img_filter _sqrdpc –mask_filter _nuclei –chan 0 –chan2 0 –use_gpu –verbose</p>
<p>cyto_from_sqrdpc:</p>
<p>cellpose –train –dir ‘data/train/’ –test_dir ‘data/test/’ –pretrained_model cyto2 –img_filter _sqrdpc –mask_filter _cyto –chan 0 –chan2 0 –use_gpu –verbose</p>
<p> </p>
<p>NOTE (§): We provide a notebook for Quality Control, which is an adaptation of the “Cellpose (2D and 3D)” notebook from ZeroCostDL4Mic .</p>
<p>NOTE: This dataset used a training dataset from the Zenodo entry(<a class="reference external" href="https://doi.org/10.5281/zenodo.6140064">https://doi.org/10.5281/zenodo.6140064</a>) generated from the “HeLa “Kyoto” cells under the scope”  dataset Zenodo entry(<a class="reference external" href="https://doi.org/10.5281/zenodo.6139958">https://doi.org/10.5281/zenodo.6139958</a>) in order to automatically generate the label images.</p>
<p>NOTE: Make sure that you delete the “_flow” images that are auto-computed when running the training. If you do not, then the flows from previous runs will be used for the new training, which might yield confusing results.</p>
<p> </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/6140111">https://zenodo.org/records/6140111</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6140111">https://doi.org/10.5281/zenodo.6140111</a></p>
</section>
<hr class="docutils" />
<section id="cellpose-training-data-and-scripts-from-inhibition-of-cers1-in-aging-skeletal-muscle-exacerbates-age-related-muscle-impairments">
<h2>Cellpose training data and scripts from “Inhibition of CERS1 in aging skeletal muscle exacerbates age-related muscle impairments”<a class="headerlink" href="#cellpose-training-data-and-scripts-from-inhibition-of-cers1-in-aging-skeletal-muscle-exacerbates-age-related-muscle-impairments" title="Link to this heading">#</a></h2>
<p>Martin Wohlwend, Olivier Burri, Johan Auwerx</p>
<p>Published 2024-02-27</p>
<p>Licensed CC-BY-4.0</p>
<p>This Workflow contains all the material necessary to reproduce the results of the QuPath analysis performed in the paper
 “Inhibition of CERS1 in aging skeletal muscle exacerbates age-related muscle impairments”
Inside this workflow and dataset, you will find the following folders</p>
<p>QuPath Training Project: A QuPath 0.3.2 project containing all the manual annotations (ground truths) used to train the cellpose model, as well as the script to start the training
QuPath Demo Project: A QuPath 0.3.2 project containing an example image that can be segmented using cellpose, followed by the classification of the CD45 expressing fibers
Training Images and Demo Images: The raw whole slide scanner 20x images needed by the above QuPath projects
Model: The fodler contianing the trained cellpose model
Cellpose Training Folder: The exported raw and ground truth images that the above cellpose model was trained on
Scripts: The QuPath scripts, also located in their respective QuPath projects, that were created for this whole workflow
QC: A Jupyter notebook, based on ZeroCostDL4Mic that computes quality metrics in order to assess the performance of the trained cellpose model. The folder also contains the resulting metrics.</p>
<p>Installation and Use
If you are going to use the QuPath projects, you need a local QuPath Installation <a class="reference external" href="https://qupath.github.io/">https://qupath.github.io/</a> that is configured to run the QuPath Cellpose Extension <a class="github reference external" href="https://github.com/BIOP/qupath-extension-cellpose">BIOP/qupath-extension-cellpose</a> as well as a working Cellpose installation <a class="github reference external" href="https://github.com/MouseLand/cellpose">MouseLand/cellpose</a>
Instructions for installation are available from the links above.
After that, you should be able to open the QuPath project, navigate to the “Automate &gt; Project scripts” menu and locate the script you wish to run.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/7041137">https://zenodo.org/records/7041137</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7041137">https://doi.org/10.5281/zenodo.7041137</a></p>
</section>
<hr class="docutils" />
<section id="cellpose-training-data-and-scripts-from-machine-learning-for-histological-annotation-and-quantification-of-cortical-layers">
<h2>Cellpose training data and scripts from “Machine learning for histological annotation and quantification of cortical layers”<a class="headerlink" href="#cellpose-training-data-and-scripts-from-machine-learning-for-histological-annotation-and-quantification-of-cortical-layers" title="Link to this heading">#</a></h2>
<p>Jean Jacquemier, Julie Meystre, Olivier Burri</p>
<p>Published 2024-07-04</p>
<p>Licensed CC-BY-4.0</p>
<p>This Workflow contains all the material necessary to reproduce the cells detection, thanks to the QuPath performed in the paper
 “Machine learning for histological annotation and quantification of cortical layers”
Inside this workflow and dataset, you will find the following folders</p>
<p>QuPath Training Project: A QuPath 0.5.0 project containing all the manual annotations (ground truths) used to train the cellpose model, as well as the script to start the training
Training Images and Demo Images: The raw whole slide scanner images needed by the above QuPath project
Model: The fodler containing the trained cellpose model
cellpose-training Folder: The exported raw and ground truth images that the above cellpose model was trained on
Scripts: The QuPath scripts, also located in their respective QuPath projects, that were created for this whole workflow
QC: A Jupyter notebook, based on ZeroCostDL4Mic that computes quality metrics in order to assess the performance of the trained cellpose model. The folder also contains the resulting metrics.</p>
<p>Installation and Use
If you are going to use the QuPath projects, you need a local QuPath Installation <a class="reference external" href="https://qupath.github.io/">https://qupath.github.io/</a> that is configured to run the QuPath Cellpose Extension <a class="github reference external" href="https://github.com/BIOP/qupath-extension-cellpose">BIOP/qupath-extension-cellpose</a> as well as a working Cellpose installation <a class="github reference external" href="https://github.com/MouseLand/cellpose">MouseLand/cellpose</a>
Instructions for installation are available from the links above.
After that, you should be able to open the QuPath project, navigate to the “Automate &gt; Project scripts” menu and locate the script you wish to run.</p>
<ol class="arabic simple">
<li><p>train a cell segmentation algorithm in the context of the rat brain Layer Boundaries project </p></li>
<li><p>trigger cell segmentation from a QuPath project in a semi-automated pipeline</p></li>
</ol>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/12656468">https://zenodo.org/records/12656468</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12656468">https://doi.org/10.5281/zenodo.12656468</a></p>
</section>
<hr class="docutils" />
<section id="checklists-for-publishing-images-and-image-analysis">
<h2>Checklists for publishing images and image analysis<a class="headerlink" href="#checklists-for-publishing-images-and-image-analysis" title="Link to this heading">#</a></h2>
<p>Christopher Schmied</p>
<p>Published 2023-09-14</p>
<p>Licensed CC0-1.0</p>
<p>In this paper we introduce two sets of checklists. One is concerned with the publication of images. The other one gives instructions for the publication of image analysis.</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Forum Post</p>
<p><a class="reference external" href="https://forum.image.sc/t/checklists-for-publishing-images-and-image-analysis/86304">https://forum.image.sc/t/checklists-for-publishing-images-and-image-analysis/86304</a></p>
</section>
<hr class="docutils" />
<section id="chinese-hamster-ovary-cells">
<h2>Chinese Hamster Ovary Cells<a class="headerlink" href="#chinese-hamster-ovary-cells" title="Link to this heading">#</a></h2>
<p>Krisztian Koos, József Molnár, Lóránd Kelemen, Gábor Tamás, Peter Horvath</p>
<p>Published 2016-07-29</p>
<p>Licensed CC-BY-3.0</p>
<p>The image set consists of 60 Differential Interference Contrast (DIC) images of Chinese Hamster Ovary (CHO) cells. The images are taken on an Olympus Cell-R microscope with a 20x lens at the time when the cell initiated their attachment to the bottom of the dish.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://bbbc.broadinstitute.org/BBBC030">https://bbbc.broadinstitute.org/BBBC030</a></p>
</section>
<hr class="docutils" />
<section id="choose-an-open-source-license">
<h2>Choose an open source license<a class="headerlink" href="#choose-an-open-source-license" title="Link to this heading">#</a></h2>
<p>GitHub</p>
<p>Licensed CC-BY-3.0 UNPORTED</p>
<p>Ressource that helps to choose an open source license for your project.</p>
<p>Tags: Open Source, Licensing, Exclude From Dalia</p>
<p>Content type: Website</p>
<p><a class="reference external" href="https://choosealicense.com">https://choosealicense.com</a></p>
</section>
<hr class="docutils" />
<section id="chris-halvin-youtube-channel">
<h2>Chris Halvin YouTube channel<a class="headerlink" href="#chris-halvin-youtube-channel" title="Link to this heading">#</a></h2>
<p>Licensed UNKNOWN</p>
<p>Tags: Napari, Python, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Collection, Video</p>
<p><a class="reference external" href="https://www.youtube.com/&#64;chrishavlin">https://www.youtube.com/&#64;chrishavlin</a></p>
<p><a class="reference external" href="https://www.youtube.com/playlist?list=PLqbhAmYZU5KxuAcnNBIxyBkivUEiKswq1">https://www.youtube.com/playlist?list=PLqbhAmYZU5KxuAcnNBIxyBkivUEiKswq1</a></p>
</section>
<hr class="docutils" />
<section id="cloud-based-virtual-desktops-for-reproducible-research">
<h2>Cloud-Based Virtual Desktops for Reproducible Research<a class="headerlink" href="#cloud-based-virtual-desktops-for-reproducible-research" title="Link to this heading">#</a></h2>
<p>Yi Sun, Christian Tischer, Kelleher, Harry Alexander, Jean-Karim Heriche</p>
<p>Published 2025-09-10</p>
<p>Licensed CC-BY-4.0</p>
<p>Reproducing computing environments become increasingly challenging in research, especially when compute-intensive scientific workflows require specialised software stacks, specialized hardware (e.g. GPUs), and interactive analysis tools. While traditional high-performance computing (HPC) systems offer scalable resources for batch processing, they don’t easily support interactive workflows. On the other hand, workstations have fixed resources  and face workflow deployment challenges because conflicts can occur when multiple tools and dependencies are deployed into the same environment. To address these limitations, we present cloud-based virtual desktop platforms, built on the desktop-as-a-service (DaaS) model, using a containerised, cloud-native approach.  Our platforms offer on-demand, customized desktop environments accessible from any web browser, with dynamic allocation of CPU, memory, and GPU resources for efficient utilization of resources. We introduce two types of virtual desktops: BAND, built on top of a Slurm scheduler and BARD, using Kubernetes. In both cases, containerization ensures consistent and reproducible environments across sessions and pre-installed software improves accessibility for researchers. Deployment and system administration are also simplified through the use of orchestration and automation tools.  Our virtual desktop platforms are particularly valuable for bioimage analysis, which requires complex workflows involving high interactivity, multiple software and GPU acceleration. By combining containerization and cloud-native services, BAND and BARD offer a scalable and sustainable model for delivering interactive, reproducible research environments.</p>
<p>Tags: Nfdi4Bioimage, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/17092303">https://zenodo.org/records/17092303</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.17092303">https://doi.org/10.5281/zenodo.17092303</a></p>
</section>
<hr class="docutils" />
<section id="collaborative-working-and-version-control-with-git-hub">
<h2>Collaborative working and  Version Control with Git[Hub]<a class="headerlink" href="#collaborative-working-and-version-control-with-git-hub" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2025-05-10</p>
<p>Licensed CC-BY-4.0</p>
<p>Working together on the internet presents us with new challenges: Who uploaded a file and when? Who contributed to the project when and why? How can content be merged when multiple team members make changes at the same time? The version control tool Git offers a comprehensive solution to these questions. The online platform <a class="reference external" href="http://GitHub.com">GitHub.com</a> provides a Git-driven platform that enables effective collaboration. Attendees of this hands-on tutorial will learn:</p>
<p>Introduction to version control with Git[Hub]</p>
<p>Working with Git: Pull requests</p>
<p>Resolving merge conflicts</p>
<p>Artificial intelligence that can respond to GitHub issues</p>
<p>Tags: Nfdi4Bioimage, Research Data Management, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15379632">https://zenodo.org/records/15379632</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15379632">https://doi.org/10.5281/zenodo.15379632</a></p>
</section>
<hr class="docutils" />
<section id="combining-stardist-and-trackmate-example-1-breast-cancer-cell-dataset">
<h2>Combining StarDist and TrackMate example 1 -  Breast cancer cell dataset<a class="headerlink" href="#combining-stardist-and-trackmate-example-1-breast-cancer-cell-dataset" title="Link to this heading">#</a></h2>
<p>Guillaume Jacquemet</p>
<p>Published 2020-09-17</p>
<p>Licensed CC-BY-4.0</p>
<p>Description: Contains a StarDist example training dataset, a test dataset, and the StarDist model generated using ZeroCostDL4Mic (see <a class="github reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki/Stardist">HenriquesLab/ZeroCostDL4Mic</a>)</p>
<p>Training dataset: 72 Paired microscopy images (fluorescence) and corresponding masks</p>
<p>Microscopy data type: Fluorescence microscopy (SiR-DNA) and masks obtained via manual segmentation (see <a class="github reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki/Stardist">HenriquesLab/ZeroCostDL4Mic</a> for details about the segmentation)</p>
<p>Microscope: Spinning disk confocal microscope with a 20x 0.8 NA objective</p>
<p>Cell type: <a class="reference external" href="http://DCIS.COM">DCIS.COM</a> Lifeact-RFP cells</p>
<p>File format: .tif (16-bit for fluorescence and 8 and 16-bit for the masks)</p>
<p>Image size: 1024x1024 (Pixel size: 634 nm)</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/4034976">https://zenodo.org/records/4034976</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4034976">https://doi.org/10.5281/zenodo.4034976</a></p>
</section>
<hr class="docutils" />
<section id="combining-stardist-and-trackmate-example-2-t-cell-dataset">
<h2>Combining StarDist and TrackMate example 2 -  T cell dataset<a class="headerlink" href="#combining-stardist-and-trackmate-example-2-t-cell-dataset" title="Link to this heading">#</a></h2>
<p>Nathan H. Roy, Guillaume Jacquemet</p>
<p>Published 2020-09-17</p>
<p>Licensed CC-BY-4.0</p>
<p>Description: Contains a StarDist example training dataset, a test dataset, and the StarDist model generated using ZeroCostDL4Mic (see <a class="github reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki/Stardist">HenriquesLab/ZeroCostDL4Mic</a>)</p>
<p>Training dataset: 209 Paired microscopy images (brightfield) and corresponding masks</p>
<p>Microscopy data type: brightfield microscopy and masks obtained via manual segmentation (see <a class="github reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki/Stardist">HenriquesLab/ZeroCostDL4Mic</a> for details about the segmentation)</p>
<p>Microscope: Imaging was done using a 10x phase contrast objective at 37°C on a Zeiss Axiovert 200M microscope equipped with an automated X-Y stage and a Roper EMCCD camera. Time-lapse images were collected every 30 sec for 10 min using SlideBook 6 software (Intelligent Imaging Innovations).</p>
<p>File format: .tif (16-bit for brightfield images and 8 and 16-bit for the masks)</p>
<p>Image size: 1024x1024 (Pixel size: 645 nm)</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/4034929">https://zenodo.org/records/4034929</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4034929">https://doi.org/10.5281/zenodo.4034929</a></p>
</section>
<hr class="docutils" />
<section id="combining-stardist-and-trackmate-example-3-flow-chamber-dataset">
<h2>Combining StarDist and TrackMate example 3 -  Flow chamber dataset<a class="headerlink" href="#combining-stardist-and-trackmate-example-3-flow-chamber-dataset" title="Link to this heading">#</a></h2>
<p>Gautier Follain, Guillaume Jacquemet</p>
<p>Published 2020-09-17</p>
<p>Licensed CC-BY-4.0</p>
<p>Description: Contains a StarDist example training dataset, a test dataset, and the StarDist model generated using ZeroCostDL4Mic (see <a class="github reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki/Stardist">HenriquesLab/ZeroCostDL4Mic</a>)</p>
<p>Training dataset: Paired microscopy images (brightfield) and corresponding masks</p>
<p>Microscopy data type: brightfield microscopy and masks obtained via manual segmentation (see <a class="github reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki/Stardist">HenriquesLab/ZeroCostDL4Mic</a> for details about the segmentation)</p>
<p>Microscope: Images were acquired with a brightfield microscope (Zeiss Laser-TIRF 3 Imaging System, Carl Zeiss) and a 10X objective.</p>
<p>File format: .tif (8-bit for brightfield images and 8 and 16-bit for the masks)</p>
<p>Image size: 1024x1024 (Pixel size: 650 nm)</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/4034939">https://zenodo.org/records/4034939</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4034939">https://doi.org/10.5281/zenodo.4034939</a></p>
</section>
<hr class="docutils" />
<section id="combining-the-bids-and-arc-directory-structures-for-multimodal-research-data-organization">
<h2>Combining the BIDS and ARC Directory Structures for Multimodal Research Data Organization<a class="headerlink" href="#combining-the-bids-and-arc-directory-structures-for-multimodal-research-data-organization" title="Link to this heading">#</a></h2>
<p>Torsten Stöter, Tobias Gottschall, Andrea Schrader, Peter Zentis, Monica Valencia-Schneider, Niraj Kandpal, Werner Zuschratter, Astrid Schauss, Timo Dickscheid, Timo Mühlhaus, Dirk von Suchodoletz</p>
<p>Licensed CC-BY-4.0</p>
<p>Interdisciplinary collaboration and integrating large, diverse datasets are crucial for answering complex research questions, requiring multimodal data analysis and adherence to FAIR principles. To address challenges in capturing the full research cycle and contextualizing data, DataPLANT developed the Annotated Research Context (ARC), while the neuroimaging community extended the Brain Imaging Data Structure (BIDS) for microscopic image data, both providing standardized, file system-based storage structures for organizing and sharing data with metadata.</p>
<p>Tags: Research Data Management, FAIR-Principles, Exclude From Dalia</p>
<p>Content type: Poster</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.8349562">https://zenodo.org/doi/10.5281/zenodo.8349562</a></p>
</section>
<hr class="docutils" />
<section id="conference-slides-4th-day-of-intravital-microscopy">
<h2>Conference Slides - 4th Day of Intravital Microscopy<a class="headerlink" href="#conference-slides-4th-day-of-intravital-microscopy" title="Link to this heading">#</a></h2>
<p>Dr. Hellen Ishikawa-Ankerhold</p>
<p>Published 2024-11-13</p>
<p>Licensed CC-BY-4.0</p>
<p>Conference Slides for the presentation of GerBI e.V. at the 4th Day of Intravital Microscopy in Leuven, Belgium.
Features Structure, activities and Links to join GerBI e.V.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14113714">https://zenodo.org/records/14113714</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14113714">https://doi.org/10.5281/zenodo.14113714</a></p>
</section>
<hr class="docutils" />
<section id="cryonuseg">
<h2>CryoNuSeg<a class="headerlink" href="#cryonuseg" title="Link to this heading">#</a></h2>
<p>Amirreza Mahbod, Benjamin Bancher, Isabella Ellinger, Deyun Zhang, Syed Nauyan Rashid</p>
<p>Published 2019-12-31</p>
<p>Licensed CC-BY-NC-SA-4.0</p>
<p>A Dataset for Nuclei Segmentation of Cryosectioned H&amp;E-Stained Histologic Images</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://www.kaggle.com/datasets/ipateam/segmentation-of-nuclei-in-cryosectioned-he-images">https://www.kaggle.com/datasets/ipateam/segmentation-of-nuclei-in-cryosectioned-he-images</a></p>
</section>
<hr class="docutils" />
<section id="dcimg-dense-beads-taken-in-chunks-over-time">
<h2>DCIMG dense beads taken in chunks over time<a class="headerlink" href="#dcimg-dense-beads-taken-in-chunks-over-time" title="Link to this heading">#</a></h2>
<p>Zach Marin</p>
<p>Published 2025-08-14</p>
<p>Licensed CC-BY-4.0</p>
<p>Two 2000-frame chunks acquired at different times (~40 minutes apart) on a 4Pi widefield, showing some slow sample drift. </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16875377">https://zenodo.org/records/16875377</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16875377">https://doi.org/10.5281/zenodo.16875377</a></p>
</section>
<hr class="docutils" />
<section id="deep-napari-napari-as-a-tool-for-deep-learning-project-management">
<h2>DEEP NAPARI : Napari as a tool for deep learning project management<a class="headerlink" href="#deep-napari-napari-as-a-tool-for-deep-learning-project-management" title="Link to this heading">#</a></h2>
<p>Herearii Metuarea, David Rousseau, Pejman Rasti, Valentin Gilet</p>
<p>Licensed UNKNOWN</p>
<p>Tags: Artificial Intelligence, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Notebook</p>
<p><a class="github reference external" href="https://github.com/hereariim/DEEP-NAPARI">hereariim/DEEP-NAPARI</a></p>
</section>
<hr class="docutils" />
<section id="dl4miceverywhere">
<h2>DL4MicEverywhere<a class="headerlink" href="#dl4miceverywhere" title="Link to this heading">#</a></h2>
<p>Iván Hidalgo, et al.</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Notebook, Collection</p>
<p><a class="github reference external" href="https://github.com/HenriquesLab/DL4MicEverywhere">HenriquesLab/DL4MicEverywhere</a></p>
</section>
<hr class="docutils" />
<section id="dl4proteins-notebooks">
<h2>DL4Proteins-notebooks<a class="headerlink" href="#dl4proteins-notebooks" title="Link to this heading">#</a></h2>
<p>Michael Chungyoun, Courtney Thomas, Britnie Carpentier, GabeAu79, puv-sreev, Jeffrey Gray</p>
<p>Published 2024-09-04T12:24:24+00:00</p>
<p>Colab Notebooks covering deep learning tools for biomolecular structure prediction and design</p>
<p>Tags: Bioinformatics, Exclude From Dalia</p>
<p>Content type: Github Repository, Collection</p>
<p><a class="github reference external" href="https://github.com/Graylab/DL4Proteins-notebooks">Graylab/DL4Proteins-notebooks</a></p>
</section>
<hr class="docutils" />
<section id="dl-mbl-2021-exercises">
<h2>DL&#64;MBL 2021 Exercises<a class="headerlink" href="#dl-mbl-2021-exercises" title="Link to this heading">#</a></h2>
<p>Jan Funke, Constantin Pape, Morgan Schwartz, Xiaoyan</p>
<p>Licensed UNKNOWN</p>
<p>Tags: Artificial Intelligence, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Slides, Notebook</p>
<p><a class="github reference external" href="https://github.com/JLrumberger/DL-MBL-2021">JLrumberger/DL-MBL-2021</a></p>
</section>
<hr class="docutils" />
<section id="dng-in-bioformat-opens-in-wrong-resolution">
<h2>DNG in BioFormat opens in wrong resolution<a class="headerlink" href="#dng-in-bioformat-opens-in-wrong-resolution" title="Link to this heading">#</a></h2>
<p>Michael</p>
<p>Published 2025-07-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15933943">https://zenodo.org/records/15933943</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15933943">https://doi.org/10.5281/zenodo.15933943</a></p>
</section>
<hr class="docutils" />
<section id="dask-course">
<h2>Dask Course<a class="headerlink" href="#dask-course" title="Link to this heading">#</a></h2>
<p>Guillaume Witz</p>
<p>Licensed UNKNOWN</p>
<p>Tags: Python, Bioimage Analysis, Big Data, Exclude From Dalia</p>
<p>Content type: Notebook</p>
<p><a class="github reference external" href="https://github.com/guiwitz/DaskCourse">guiwitz/DaskCourse</a></p>
</section>
<hr class="docutils" />
<section id="data-stewardship-wizard">
<h2>Data Stewardship Wizard<a class="headerlink" href="#data-stewardship-wizard" title="Link to this heading">#</a></h2>
<p>Licensed UNKOWN</p>
<p>Leading open-source platform for collaborative and living data management plans.</p>
<p>Tags: Data Stewardship, Open Source, Research Data Management, FAIR-Principles, Exclude From Dalia</p>
<p>Content type: Website, Online Tutorial</p>
<p><a class="reference external" href="https://ds-wizard.org/">https://ds-wizard.org/</a></p>
</section>
<hr class="docutils" />
<section id="data-life-cycle">
<h2>Data life cycle<a class="headerlink" href="#data-life-cycle" title="Link to this heading">#</a></h2>
<p>ELIXIR (2021) Research Data Management Kit</p>
<p>Licensed CC-BY-4.0</p>
<p>In this section, information is organised according to the stages of the research data life cycle.</p>
<p>Tags: Data Life Cycle, Research Data Management, Exclude From Dalia</p>
<p>Content type: Collection, Website, Online Tutorial</p>
<p><a class="reference external" href="https://rdmkit.elixir-europe.org/data_life_cycle">https://rdmkit.elixir-europe.org/data_life_cycle</a></p>
</section>
<hr class="docutils" />
<section id="dataset-from-incell-2200-microscope-misread-as-a-plate">
<h2>Dataset from InCell 2200 microscope misread as a plate<a class="headerlink" href="#dataset-from-incell-2200-microscope-misread-as-a-plate" title="Link to this heading">#</a></h2>
<p>Fabien Kuttler, Rémy Dornier</p>
<p>Published 2025-01-30</p>
<p>Licensed CC-BY-4.0</p>
<p>Two dummy datasets are provided in this repository : </p>
<p>Dataset_Ok : 96 wells, 9 fields of view per well, 4 different channels (DAPI, Cy3, FITC, Brightfield), no Z, no T. The .xcde file of this dataset is correctly read by BioFormats, as the dataset is recognized as a plate, and can be imported on OMERO
Dataset_fail: 20 wells, 4 fields of view per well, 5 channels, with one duplicate (DAPI, FITC, Cy3, Cy5 wix 4 , Cy5 wix 5), no Z, no T. The .xcde file of this dataset is not correctly read by BioFormats and no images are imported on OMERO.</p>
<p>BioFormats version: 8.0.1
A discussion thread has been open on this topic.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14769820">https://zenodo.org/records/14769820</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14769820">https://doi.org/10.5281/zenodo.14769820</a></p>
</section>
<hr class="docutils" />
<section id="deconvolution-test-dataset">
<h2>Deconvolution Test Dataset<a class="headerlink" href="#deconvolution-test-dataset" title="Link to this heading">#</a></h2>
<p>Romain Guiet</p>
<p>Published 2021-07-14</p>
<p>Licensed CC-BY-4.0</p>
<p>This a test dataset, HeLa cells stained for action using Phalloidin-488 acquired on confocal Zeiss LSM710, which contains</p>
<ul class="simple">
<li><p>Ph488.czi (contains all raw metadata)</p></li>
<li><p>Raw_large.tif ( is the tif version of Ph488.czi, provided for conveninence as tif doesn’t need Bio-Formats to be open in Fiji )</p></li>
<li><p>Raw.tif , is a crop of the large image</p></li>
</ul>
<p>- PSFHuygens_confocal_Theopsf.tif , is a theoretical PSF generated with HuygensPro</p>
<p>- PSFgen_WF_WBpsf.tif  , is a theoretical PSF generated with PSF generator</p>
<ul class="simple">
<li><p>PSFgen_WFsquare_WBpsf.tif, is the result of the square operation on PSFgen_WF_WBpsf.tif , to approximate a confocal PSF</p></li>
</ul>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/5101351">https://zenodo.org/records/5101351</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5101351">https://doi.org/10.5281/zenodo.5101351</a></p>
</section>
<hr class="docutils" />
<section id="deep-learning-segmentation-projects-of-fib-sem-dataset-of-u2-os-cell">
<h2>Deep learning segmentation projects of FIB-SEM dataset of U2-OS cell<a class="headerlink" href="#deep-learning-segmentation-projects-of-fib-sem-dataset-of-u2-os-cell" title="Link to this heading">#</a></h2>
<p>Belevich Ilya, Eija Jokitalo</p>
<p>Published 2023-10-26</p>
<p>Licensed CC-BY-4.0</p>
<p>This submission includes ground truth datasets that were used to segment the nuclear envelope (NE), mitochondria, endoplasmic reticulum (ER) and Golgi from a human bone osteosarcoma epithelial cell (U2-OS) imaged using focused-ion beam scanning electron microscopy (FIB-SEM).The full FIB-SEM dataset is deposited to EMPIAR (<a class="reference external" href="https://www.ebi.ac.uk/empiar">https://www.ebi.ac.uk/empiar</a>, EMPIAR-11746). </p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/10043461">https://zenodo.org/records/10043461</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10043461">https://doi.org/10.5281/zenodo.10043461</a></p>
</section>
<hr class="docutils" />
<section id="deep-learning-training-data-jove">
<h2>Deep learning training data (JOVE)<a class="headerlink" href="#deep-learning-training-data-jove" title="Link to this heading">#</a></h2>
<p>Jessica Heebner, Carson Purnell, Ryan Hylton, Mike Marsh, Michael Grillo, Matt Swulius</p>
<p>Published 2022-11-18</p>
<p>Licensed CC-ZERO</p>
<p>Cryo-electron tomography (cryo-ET) allows researchers to image cells in their native, hydrated state at the highest resolution currently possible. However, the technique has several limitations that make analyzing the data it generates time-intensive and difficult. Hand-segmenting a single tomogram can take hours to days of human effort, but the microscope can easily generate 50 or more tomograms a day. Current deep learning segmentation programs for cryo-ET do exist but are limited to segmenting one structure at a time. Here multi-slice U-Net convolutional neural networks are trained and applied to automatically segment multiple structures simultaneously within cryo-tomograms. With proper preprocessing, these networks can be robustly inferred to many tomograms without the need for training individual networks for each tomogram. This workflow dramatically improves the speed with which cryo-electron tomograms can be analyzed by cutting segmentation time down to under 30 min in most cases. Further, segmentations can be used to improve the accuracy of filament tracing within a cellular context and to rapidly extract coordinates for subtomogram averaging.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/7335439">https://zenodo.org/records/7335439</a></p>
<p><a class="reference external" href="https://doi.org/10.5061/dryad.rxwdbrvct">https://doi.org/10.5061/dryad.rxwdbrvct</a></p>
</section>
<hr class="docutils" />
<section id="deepbacs-bacillus-subtilis-fluorescence-segmentation-dataset">
<h2>DeepBacs – Bacillus subtilis fluorescence segmentation dataset<a class="headerlink" href="#deepbacs-bacillus-subtilis-fluorescence-segmentation-dataset" title="Link to this heading">#</a></h2>
<p>Séamus Holden, Mia Conduit</p>
<p>Published 2021-10-05</p>
<p>Licensed CC-BY-4.0</p>
<p>Training and test images of live B. subtilis cells expressing FtsZ-GFP for the task of segmentation.</p>
<p>Additional information can be found on this github wiki.</p>
<p>The example shows the fluorescence widefield image of live B. subtilis cells expressing FtsZ-GFP and the manually annotated segmentation mask.</p>
<p> </p>
<p>Data type: Paired fluorescence and segmented mask images</p>
<p>Microscopy data type: 2D widefield images (fluorescence) </p>
<p>Microscope: Custom-built 100x inverted microscope bearing a 100x TIRF objective (Nikon CFI Apochromat TIRF 100XC Oil); images were captured on a Prime BSI sCMOS camera (Teledyne Photometrics)</p>
<p>Cell type: B. subtilis strain SH130 grown under agarose pads</p>
<p>File format: .tiff (8-bit) or .png (8-bit)</p>
<p>For segmented masks, binary masks are used for training of CARE/U-Net models, 8-bit .tif ROI maps for training of StarDist models and .png images for training of pix2pix models</p>
<p>Image size: 1024 x 1024 px² (Pixel size: 65 nm)</p>
<p>Image preprocessing: Images were denoised using PureDenoise and resulting 32-bit images were converted into 8-bit images after normalizing to 1% and 99.98% percentiles. Images were manually annotated using the Labkit Fiji plugin</p>
<p> </p>
<p>Author(s): Mia Conduit1,2, Séamus Holden1,3</p>
<p>Contact email: <a class="reference external" href="mailto:Seamus&#46;Holden&#37;&#52;&#48;newcastle&#46;ac&#46;uk">Seamus<span>&#46;</span>Holden<span>&#64;</span>newcastle<span>&#46;</span>ac<span>&#46;</span>uk</a></p>
<p> </p>
<p>Affiliation:</p>
<ol class="arabic simple">
<li><p>Centre for Bacterial Cell Biology, Biosciences Institute, Newcastle University, NE2 4AX UK</p></li>
<li><p>ORCID: 0000-0002-7169-907X</p></li>
</ol>
<p> </p>
<p> Associated publications: Whitley et al., 2021, Nature Communications, <a class="reference external" href="https://doi.org/10.15252/embj.201696235">https://doi.org/10.15252/embj.201696235</a></p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/5550968">https://zenodo.org/records/5550968</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5550968">https://doi.org/10.5281/zenodo.5550968</a></p>
</section>
<hr class="docutils" />
<section id="deepbacs-escherichia-coli-bright-field-segmentation-dataset">
<h2>DeepBacs – Escherichia coli bright field segmentation dataset<a class="headerlink" href="#deepbacs-escherichia-coli-bright-field-segmentation-dataset" title="Link to this heading">#</a></h2>
<p>Christoph Spahn, Mike Heilemann</p>
<p>Published 2021-10-05</p>
<p>Licensed CC-BY-4.0</p>
<p>Training and test images of live E. coli cells imaged under bright field for the task of segmentation.</p>
<p>Additional information can be found on this github wiki.</p>
<p>The example shows a bright field image of live E. coli cells and the manually annotated segmentation mask.</p>
<p> </p>
<p>Data type: Paired bright field and segmented mask images </p>
<p>Microscopy data type: 2D bright field images recorded at 1 min interval</p>
<p>Microscope: Nikon Eclipse Ti-E equipped with an Apo TIRF 1.49NA 100x oil immersion objective</p>
<p>Cell type: E. coli MG1655 wild type strain (CGSC #6300).</p>
<p>File format: .tif (8-bit)</p>
<p>Image size: 1024 x 1024 px² (79 nm / pixel), 19/15 individual frames (training/test dataset)</p>
<p>1024 x 1024 px² (79 nm / pixel), 9 regions of interest with 80 frames &#64; 1 min time interval (live-cell time series)</p>
<p>Image preprocessing: Raw images were recorded in 16-bit mode (image size 512 x 512 px² &#64; 158 nm/px). Images were upscaled with a factor of 2 (no interpolation) to enable generation of higher-quality segmentation masks. Two sets of mask images are provided: RoiMaps for instance segmentation using e.g. StarDist or binary images for CARE or U-Net.</p>
<p>Author(s): Christoph Spahn1,2, Mike Heilemann1,3</p>
<p>Contact email: <a class="reference external" href="mailto:christoph&#46;spahn&#37;&#52;&#48;mpi-marburg&#46;mpg&#46;de">christoph<span>&#46;</span>spahn<span>&#64;</span>mpi-marburg<span>&#46;</span>mpg<span>&#46;</span>de</a></p>
<p> </p>
<p>Affiliation(s): </p>
<ol class="arabic simple">
<li><p>Institute of Physical and Theoretical Chemistry, Max-von-Laue Str. 7, Goethe-University Frankfurt, 60439 Frankfurt, Germany</p></li>
<li><p>ORCID: 0000-0001-9886-2263 </p></li>
<li><p>ORCID: 0000-0002-9821-3578</p></li>
</ol>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/5550935">https://zenodo.org/records/5550935</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5550935">https://doi.org/10.5281/zenodo.5550935</a></p>
</section>
<hr class="docutils" />
<section id="deepbacs-mixed-segmentation-dataset-and-stardist-model">
<h2>DeepBacs – Mixed segmentation dataset and StarDist model<a class="headerlink" href="#deepbacs-mixed-segmentation-dataset-and-stardist-model" title="Link to this heading">#</a></h2>
<p>Christoph Spahn, Mike Heilemann, Séamus Holden, Mia Conduit, Pereira, Pedro Matos, Mariana Pinho</p>
<p>Published 2021-10-05</p>
<p>Licensed CC-BY-4.0</p>
<p>Mixed training and test images of S. aureus, E. coli and B. subtilis for cell segmentation using StarDist, as well as the trained StarDist model.</p>
<p>Additional information can be found on this github wiki.</p>
<p> </p>
<p>Data type: Paired bright field / fluorescence and segmented mask images</p>
<p>Microscopy data type: 2D widefield images; DIC and fluorescence for S. aureus, bright field images for E. coli, and fluorescence images for B. subtilis</p>
<p>Microscopes: </p>
<p>S. aureus: </p>
<p>GE HealthCare Deltavision OMX system (with temperature and humidity control, 37°C) equipped with an Olympus 60x 1.42NA Oil immersion objective and 2 PCO Edge 5.5 sCMOS cameras (one for DIC, one for fluorescence)</p>
<p>E.coli:</p>
<p>Nikon Eclipse Ti-E equipped with an Apo TIRF 1.49NA 100x oil immersion objective</p>
<p>B. subtilis:</p>
<p>Custom-built 100x inverted microscope bearing a 100x TIRF objective (Nikon CFI Apochromat TIRF 100XC Oil); images were captured on a Prime BSI sCMOS camera (Teledyne Photometrics)</p>
<p> </p>
<p>Cell types: S. aureus strain JE2, E. coli MG1655 (CGSC #6300) and B. subtilis strain SH130; all grown under agarose pads</p>
<p>File format: .tif (8-bit and 16-bit)</p>
<p>Image size: 512 x 512 px² &#64; 80 nm pixel size (S. aureus); 1024 x 1024 px² &#64; 79 nm pixel size (E. coli); 1024 x 1024 px² &#64; 65 nm pixel size (B. subtilis)</p>
<p>Image preprocessing: </p>
<p>S. aureus:</p>
<p>Raw images were manually annotated by drawing ellipses in the NR fluorescence image and segmented images were created using the LOCI plugin (“ROI Map”). For training, images and masks were quartered into four 256 x 256 px² patches.</p>
<p>E. coli:</p>
<p>Raw images were recorded in 16-bit mode (image size 512x512 px² &#64; 158 nm/px). Images were upscaled with a factor of 2 (no interpolation) to enable generation of higher-quality segmentation masks.</p>
<p>B. subtilis:</p>
<p>Images were denoised using PureDenoise and resulting 32-bit images were converted into 8-bit images after normalizing to 1% and 99.98% percentiles. Images were manually annotated using the Labkit Fiji plugin</p>
<p> </p>
<p>StarDist model:</p>
<p>The StarDist 2D model was generated using the ZeroCostDL4Mic platform (Chamier et al., 2021). It was trained from scratch for 200 epochs (120 steps/epoch) on 155 paired image patches (image dimensions: (1024, 1024), patch size: (256,256)) with a batch size of 4, 10% validation data, 64 rays on grid 2, a learning rate of 0.0003 and a mae loss function, using the StarDist 2D ZeroCostDL4Mic notebook (v 1.12.2). Key python packages used include tensorflow (v 0.1.12), Keras (v 2.3.1), csbdeep (v 0.6.1), numpy (v 1.19.5), cuda (v 11.0.221). The training was accelerated using a Tesla P100GPU. The dataset was augmented by a factor of 3.</p>
<p> </p>
<p>The model weights can be used in the ZeroCostDL4Mic StarDist 2D notebook, the StarDist Fiji plugin or the TrackMate Fiji plugin (v7+).</p>
<p> </p>
<p>Author(s): Christoph Spahn1,2, Mike Heilemann1,3, Mia Conduit4, Séamus Holden4,5, Pedro Matos Pereira6,7, Mariana Pinho6,8</p>
<p>Contact email: <a class="reference external" href="mailto:christoph&#46;spahn&#37;&#52;&#48;mpi-marburg&#46;mpg&#46;de">christoph<span>&#46;</span>spahn<span>&#64;</span>mpi-marburg<span>&#46;</span>mpg<span>&#46;</span>de</a>, <a class="reference external" href="mailto:Seamus&#46;Holden&#37;&#52;&#48;newcastle&#46;ac&#46;uk">Seamus<span>&#46;</span>Holden<span>&#64;</span>newcastle<span>&#46;</span>ac<span>&#46;</span>uk</a>, <a class="reference external" href="mailto:pmatos&#37;&#52;&#48;itqb&#46;unl&#46;pt">pmatos<span>&#64;</span>itqb<span>&#46;</span>unl<span>&#46;</span>pt</a> and <a class="reference external" href="mailto:mgpinho&#37;&#52;&#48;itqb&#46;unl&#46;pt">mgpinho<span>&#64;</span>itqb<span>&#46;</span>unl<span>&#46;</span>pt</a></p>
<p> </p>
<p>Affiliation(s): </p>
<ol class="arabic simple">
<li><p>Institute of Physical and Theoretical Chemistry, Max-von-Laue Str. 7, Goethe-University Frankfurt, 60439 Frankfurt, Germany</p></li>
<li><p>ORCID: 0000-0001-9886-2263 </p></li>
<li><p>ORCID: 0000-0002-9821-3578</p></li>
<li><p>Centre for Bacterial Cell Biology, Biosciences Institute, Newcastle University, NE2 4AX UK</p></li>
<li><p>ORCID: 0000-0002-7169-907X</p></li>
<li><p>Bacterial Cell Biology, Instituto de Tecnologia Química e Biológica António Xavier, Universidade Nova de Lisboa, Oeiras, Portugal</p></li>
<li><p>ORCID: 0000-0002-1426-9540</p></li>
<li><p>ORCID: 0000-0002-7132-8842</p></li>
</ol>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/5551009">https://zenodo.org/records/5551009</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5551009">https://doi.org/10.5281/zenodo.5551009</a></p>
</section>
<hr class="docutils" />
<section id="deepbacs-staphylococcus-aureus-widefield-segmentation-dataset">
<h2>DeepBacs – Staphylococcus aureus widefield segmentation dataset<a class="headerlink" href="#deepbacs-staphylococcus-aureus-widefield-segmentation-dataset" title="Link to this heading">#</a></h2>
<p>Pereira, Pedro Matos, Mariana Pinho</p>
<p>Published 2021-10-05</p>
<p>Licensed CC-BY-4.0</p>
<p>Training and test images of live S. aureus cells for the task of cell segmentation.</p>
<p>Additional information can be found in the github wiki.</p>
<p>The example shows the bright field and Nile Red fluorescence image of live S. aureus cells, as well as the manually annotated segmentation mask.</p>
<p> </p>
<p>Data type: Paired DIC/fluorescence and segmented mask images</p>
<p>Microscopy data type: 2D widefield images (DIC and fluorescence)</p>
<p>Microscope:  GE HealthCare Deltavision OMX system (with temperature and humidity control, 37°C) equipped with an Olympus 60x 1.42NA Oil immersion objective and 2 PCO Edge 5.5 sCMOS cameras (one for DIC, one for fluorescence)</p>
<p>Cell type: S. aureus strain JE2 grown under agarose pads</p>
<p>File format: .tif (16-bit)</p>
<p>Image size: 512 x 512 px² (80 nm/px)
Image preprocessing: Raw images were manually annotated by drawing ellipses in the NR fluorescence image and segmented images were created using the LOCI plugin (“ROI Map”). For training, images and masks were quartered into four 256 x 256 px² patches.</p>
<p> </p>
<p>Author(s): Pedro Matos Pereira1,2, Mariana Pinho1,3</p>
<p>Contact email: <a class="reference external" href="mailto:pmatos&#37;&#52;&#48;itqb&#46;unl&#46;pt">pmatos<span>&#64;</span>itqb<span>&#46;</span>unl<span>&#46;</span>pt</a> and <a class="reference external" href="mailto:mgpinho&#37;&#52;&#48;itqb&#46;unl&#46;pt">mgpinho<span>&#64;</span>itqb<span>&#46;</span>unl<span>&#46;</span>pt</a></p>
<p> </p>
<p>Affiliation: </p>
<ol class="arabic simple">
<li><p>Bacterial Cell Biology, Instituto de Tecnologia Química e Biológica António Xavier, Universidade Nova de Lisboa, Oeiras, Portugal</p></li>
<li><p>ORCID: <a class="reference external" href="https://orcid.org/0000-0002-1426-9540">https://orcid.org/0000-0002-1426-9540</a></p></li>
<li><p>ORCID: <a class="reference external" href="https://orcid.org/0000-0002-7132-8842">https://orcid.org/0000-0002-7132-8842</a></p></li>
</ol>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/5550933">https://zenodo.org/records/5550933</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5550933">https://doi.org/10.5281/zenodo.5550933</a></p>
</section>
<hr class="docutils" />
<section id="democratizing-knowledge-representation-with-biocypher">
<h2>Democratizing knowledge representation with BioCypher<a class="headerlink" href="#democratizing-knowledge-representation-with-biocypher" title="Link to this heading">#</a></h2>
<p>Sebastian Lobentanzer, Patrick Aloy, Jan Baumbach, Balazs Bohar, Vincent Carey, Pornpimol Charoentong, Katharina Danhauser, Tunca Doğan, Johann Dreo, Ian Dunham, Elias Farr, Adrià Fernandez-Torras, Benjamin Gyori, Michael Hartung, Charles Tapley Hoyt, Christoph Klein, Tamas Korcsmaros, Andreas Maier, Matthias Mann, David Ochoa, Elena Pareja-Lorente, Ferdinand Popp, Martin Preusse, Niklas Probul, Benno Schwikowski, Bünyamin Sen, Maximilian Strauss, Denes Turei, Erva Ulusoy, Dagmar Waltemath, Judith Wodke, Julio Saez-Rodriguez</p>
<p>Published 2023-06-19</p>
<p>Licensed UNKNOWN</p>
<p>BioCypher is a framework to support users in creating KGs</p>
<p>Tags: Knowledge Graph, Bioinformatics, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.nature.com/articles/s41587-023-01848-y">https://www.nature.com/articles/s41587-023-01848-y</a></p>
</section>
<hr class="docutils" />
<section id="detection-and-segmentation-of-cell-nuclei-in-virtual-microscopy-images-a-minimum-model-approach">
<h2>Detection and Segmentation of Cell Nuclei in Virtual Microscopy Images A Minimum-Model Approach<a class="headerlink" href="#detection-and-segmentation-of-cell-nuclei-in-virtual-microscopy-images-a-minimum-model-approach" title="Link to this heading">#</a></h2>
<p>Stephan Wienert, Daniel Heim, Kai Saeger, Albrecht Stenzinger, Michael Beil, Peter Hufnagl, Manfred Dietel, Carsten Denkert, Frederick Klauschen</p>
<p>Published 2012-07-11</p>
<p>Licensed CC-BY-NC-SA-3.0</p>
<p>A novel contour-based approach to cell detection and segmentation has been developed, which uses minimal prior information and detects contours independently of their shape, avoiding a segmentation bias. This approach has been shown to accurately segment a broad range of normal and disease-related morphological features, with high precision and recall rates.</p>
<p>Tags: Nuclei Images, Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://www.nature.com/articles/srep00503#Sec16">https://www.nature.com/articles/srep00503#Sec16</a></p>
</section>
<hr class="docutils" />
<section id="developing-semi-automatic-analysis-pipelines-and-technological-solutions-for-metadata-annotation-and-management-in-high-content-screening-hcs-bioimaging">
<h2>Developing (semi)automatic analysis pipelines and technological solutions for metadata annotation and management in high-content screening (HCS) bioimaging<a class="headerlink" href="#developing-semi-automatic-analysis-pipelines-and-technological-solutions-for-metadata-annotation-and-management-in-high-content-screening-hcs-bioimaging" title="Link to this heading">#</a></h2>
<p>Riccardo Massei, Stefan Scholz, Wibke Busch, Thomas Schnike, Hannes Bohring, Jan Bumberger</p>
<p>Licensed CC-BY-4.0</p>
<p>High-content screening (HCS) bioimaging automates the imaging and analysis of numerous biological samples, generating extensive metadata that is crucial for effective image management and interpretation. Efficiently handling this complex data is essential to implementing FAIR principles and realizing HCS’s full potential for scientific discoveries.</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Poster</p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8434325">https://doi.org/10.5281/zenodo.8434325</a></p>
</section>
<hr class="docutils" />
<section id="development-fair-image-analysis-workflows-and-rdm-pipelines-in-galaxy">
<h2>Development FAIR image analysis workflows and RDM pipelines in Galaxy<a class="headerlink" href="#development-fair-image-analysis-workflows-and-rdm-pipelines-in-galaxy" title="Link to this heading">#</a></h2>
<p>Riccardo Massei, Beatriz Serrano-Solano, Anne Fouilloux, Björg Gruening, Yi Sun, Diana Chiang, Matthias Bernt, Leonid Kostrykin</p>
<p>Published 2025-09-10</p>
<p>Licensed CC-BY-4.0</p>
<p>Imaging is crucial across various scientific disciplines, particularly in life sciences, where it plays a key role in studies ranging from single molecules to whole organisms. However, the complexity and sheer volume of image data present significant challenges. Managing and analyzing this data efficiently requires well-defined image processing tools and analysis pipelines that align with the FAIR principles—ensuring they are findable, accessible, interoperable, and reusable across different domains. In the frame of NFDI4BIOIMAGE1 (the National Research Data Infrastructure focusing on bioimaging in Germany), we want to find viable solutions for storing, processing, analyzing, and sharing bioimaging data. In particular, we want to develop solutions to make findable and machine-readable metadata developing analysis pipelines. In scientific research, such pipelines are crucial for maintaining data integrity, supporting reproducibility, and enabling interdisciplinary collaboration. These tools can be used by different users to retrieve images based on specific attributes as well as support quality control by identifying appropriate metadata. Galaxy, an open-source, web-based platform for data-intensive research, offers a solution by enabling the construction of reproducible pipelines for image analysis2. By integrating popular analysis software like CellProfiler and connecting with cloud services such as OMERO and IDR, Galaxy facilitates the seamless access and management of image data. This capability is particularly valuable in bioimaging, where automated pipelines can streamline the handling of complex metadata, ensuring data integrity and fostering interdisciplinary collaboration. This approach not only increases the efficiency of RDM processes in bioimaging but also contributes to the broader scientific community’s efforts to embrace FAIR principles, ultimately advancing scientific discovery and innovation. In the present poster, we showed how to integrate RDM processes and tools in Galaxy. We will showcase how Images can be enriched with metadata (i.e. key-value pairs, tags, raw data, regions of interest) and uploaded to a target OME Remote Objects (OMERO) server using a novel set of OMERO tools developed with Galaxy3. Workflows give the possibility to the user to intuitively fetch images from the local server and perform image analysis (i.e. annotation). Furthermore, we will show the potential integration of eletronic lab books such as eLabFTW4, cloud storage systems (i.e. OneData)5 and interactive norebooks (Jupyter Notebooks) 6 in the Galaxy pipeline.</p>
<p>Tags: Nfdi4Bioimage, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/17093454">https://zenodo.org/records/17093454</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.17093454">https://doi.org/10.5281/zenodo.17093454</a></p>
</section>
<hr class="docutils" />
<section id="diffusion-models-for-image-restoration-an-introduction">
<h2>Diffusion Models for Image Restoration - An Introduction<a class="headerlink" href="#diffusion-models-for-image-restoration-an-introduction" title="Link to this heading">#</a></h2>
<p>Anirban Ray</p>
<p>Licensed UNKNOWN</p>
<p>Presentation given at the EMBO-DL4MIA 2024, Advanced Topic Seminar, May-11-2024</p>
<p>Tags: Bioimage Analysis, Diffusion Models, Tu Dresden, Exclude From Dalia</p>
<p>Content type: Presentation</p>
<p><a class="reference external" href="https://drive.google.com/file/d/1pPVUUMi5w2Ojw_SaBzSQVaXUuIKtQ7Ma/view">https://drive.google.com/file/d/1pPVUUMi5w2Ojw_SaBzSQVaXUuIKtQ7Ma/view</a></p>
</section>
<hr class="docutils" />
<section id="digital-phase-contrast-on-primary-dermal-human-fibroblasts-cells">
<h2>Digital Phase Contrast on Primary Dermal Human Fibroblasts cells<a class="headerlink" href="#digital-phase-contrast-on-primary-dermal-human-fibroblasts-cells" title="Link to this heading">#</a></h2>
<p>Laura Capolupo</p>
<p>Published 2022-02-09</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: Digital Phase Contrast on Primary Dermal Human Fibroblasts cells </p>
<p>Data type: Paired microscopy images (Digital Phase Contrast, square rooted) and corresponding labels/masks used for cellpose training (the corresponding Brightfield images are also present), organized as recommended by cellpose documentation.</p>
<p>Microscopy data type: Light microscopy (Digital Phase Contrast and Brighfield )</p>
<p>Manual annotations: Labels/masks obtained via manual segmentation. For each region, all cells were annotated manually. Uncertain objects (Dust, fused cells) were left unannotated, so that the cellpose model (10.5281/zenodo.6023317) may mimic the same user bias during prediction. This was particularly necessary due to the accumulation of floating debris in the center of the well.</p>
<p>Microscope: Perkin Elmer Operetta microscope with a 10x 0.35 NA objective</p>
<p>Cell type: Primary Dermal Human Fibroblasts cells</p>
<p>File format: .tif (16-bit for DPC and 16-bit for the masks)</p>
<p>Image size: 1024x1024 (Pixel size: 634 nm)</p>
<p>NOTE : This dataset was used to train cellpose model ( 10.5281/zenodo.6023317 )</p>
<p> </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/5996883">https://zenodo.org/records/5996883</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5996883">https://doi.org/10.5281/zenodo.5996883</a></p>
</section>
<hr class="docutils" />
<section id="digitalsreeni-youtube-channel">
<h2>DigitalSreeni YouTube Channel<a class="headerlink" href="#digitalsreeni-youtube-channel" title="Link to this heading">#</a></h2>
<p>Sreeni Bhattiprolu</p>
<p>A collection tutorial videos for using Python in general and for processing images using Python, machine learning and deep learning</p>
<p>Tags: Python, Exclude From Dalia</p>
<p>Content type: Collection, Video</p>
<p><a class="reference external" href="https://www.youtube.com/digitalsreeni">https://www.youtube.com/digitalsreeni</a></p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=A4po9z61TME">https://www.youtube.com/watch?v=A4po9z61TME</a></p>
</section>
<hr class="docutils" />
<section id="dokumentation-und-anleitung-zum-elektronischen-laborbuch-elabftw">
<h2>Dokumentation und Anleitung zum elektronischen Laborbuch (eLabFTW)<a class="headerlink" href="#dokumentation-und-anleitung-zum-elektronischen-laborbuch-elabftw" title="Link to this heading">#</a></h2>
<p>Lienhard Wegewitz, F. Strauß</p>
<p>Published 2020-03-23</p>
<p>Licensed AGPL-3.0</p>
<p>Documentation for eLabFTW. With eLabFTW you get a secure, modern and compliant system to track your experiments efficiently but also manage your lab with a powerful and versatile database.</p>
<p>Tags: Research Data Management, Exclude From Dalia</p>
<p>Content type: Documentation, Document, Tutorial</p>
<p><a class="reference external" href="https://www.fdm.tu-clausthal.de/fileadmin/FDM/documents/Manual_eLab_v0.3_20200323.pdf">https://www.fdm.tu-clausthal.de/fileadmin/FDM/documents/Manual_eLab_v0.3_20200323.pdf</a></p>
<p><a class="reference external" href="https://www.elabftw.net/">https://www.elabftw.net/</a></p>
</section>
<hr class="docutils" />
<section id="drosophila-kc167-cells">
<h2>Drosophila Kc167 cells<a class="headerlink" href="#drosophila-kc167-cells" title="Link to this heading">#</a></h2>
<p>Vebjorn Ljosa, Katherine L. Sokolnicki, Anne E. Carpenter</p>
<p>Published 2012-06-28</p>
<p>Licensed CC0-1.0</p>
<p>Drosophila melanogaster Kc167 cells were stained for DNA (to label nuclei) and actin (a cytoskeletal protein, to show the cell body). Automatic cytometry requires that cells be segmented, i.e., that the pixels belonging to each cell be identified. Because segmenting nuclei and distinguishing foreground from background is comparatively easy for these images, the focus here is on finding the boundaries between adjacent cells.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://bbbc.broadinstitute.org/BBBC007">https://bbbc.broadinstitute.org/BBBC007</a></p>
</section>
<hr class="docutils" />
<section id="edam-bioimaging-the-ontology-of-bioimage-informatics-operations-topics-data-and-formats">
<h2>EDAM-bioimaging - The ontology of bioimage informatics operations, topics, data, and formats<a class="headerlink" href="#edam-bioimaging-the-ontology-of-bioimage-informatics-operations-topics-data-and-formats" title="Link to this heading">#</a></h2>
<p>Matúš Kalaš et al.</p>
<p>Licensed CC-BY-4.0</p>
<p>EDAM-bioimaging is an extension of the EDAM ontology, dedicated to bioimage analysis, bioimage informatics, and bioimaging.</p>
<p>Tags: Ontology, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Poster</p>
<p><a class="reference external" href="https://hal.science/hal-02267597/document">https://hal.science/hal-02267597/document</a></p>
</section>
<hr class="docutils" />
<section id="embl-ebi-material-collection">
<h2>EMBL-EBI material collection<a class="headerlink" href="#embl-ebi-material-collection" title="Link to this heading">#</a></h2>
<p>EMBL-EBI</p>
<p>Licensed CC0 (MOSTLY, BUT CAN DIFFER DEPENDING ON RESOURCE)</p>
<p>Online tutorial and webinar library, designed and delivered by EMBL-EBI experts</p>
<p>Tags: Bioinformatics, Exclude From Dalia</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://www.ebi.ac.uk/training/on-demand?facets=type:Course%20materials&amp;amp;query=">https://www.ebi.ac.uk/training/on-demand?facets=type:Course%20materials&amp;query=</a></p>
</section>
<hr class="docutils" />
<section id="embo-practical-course-advanced-methods-in-bioimage-analysis">
<h2>EMBO Practical Course Advanced methods in bioimage analysis<a class="headerlink" href="#embo-practical-course-advanced-methods-in-bioimage-analysis" title="Link to this heading">#</a></h2>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Event</p>
<p><a class="reference external" href="https://www.embl.org/about/info/course-and-conference-office/events/bia23-01/">https://www.embl.org/about/info/course-and-conference-office/events/bia23-01/</a></p>
</section>
<hr class="docutils" />
<section id="epflx-image-processing-and-analysis-for-life-scientists">
<h2>EPFLx: Image Processing and Analysis for Life Scientists<a class="headerlink" href="#epflx-image-processing-and-analysis-for-life-scientists" title="Link to this heading">#</a></h2>
<p>Licensed ALL RIGHTS RESERVED</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Online Tutorial</p>
<p><a class="reference external" href="https://www.edx.org/learn/image-analysis/ecole-polytechnique-federale-de-lausanne-image-processing-and-analysis-for-life-scientists">https://www.edx.org/learn/image-analysis/ecole-polytechnique-federale-de-lausanne-image-processing-and-analysis-for-life-scientists</a></p>
</section>
<hr class="docutils" />
<section id="effect-of-local-topography-on-cell-division-of-staphylococci-sp">
<h2>Effect of local topography on cell division of Staphylococci sp.<a class="headerlink" href="#effect-of-local-topography-on-cell-division-of-staphylococci-sp" title="Link to this heading">#</a></h2>
<p>Sorzabal Bellido, Ioritz, Luca Barbieri, Beckett, Alison J., Prior, Ian A., Arturo Susarrey-Arce, Tiggelaar, Roald M., Jo Forthergill, Rasmita Raval, Diaz Fernandez, Yuri A.</p>
<p>Published 2021-05-16</p>
<p>Licensed CC-BY-4.0</p>
<p>Dataset.zip</p>
<p>This dataset includes the raw and annotated images used to train a Stardist 2D deep learning model for segmentation of surface attached S.aureus as described in Effect of local topography on cell division of Staphylococci sp.</p>
<p> </p>
<p>Stardist2d_Model.zip</p>
<p>Stardist 2D deep learning model for segmentation of surface attached S.aureus, obtained using the StarDist 2D ZeroCostDL4Mic notebook (v 1.12.3).</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/4765599">https://zenodo.org/records/4765599</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4765599">https://doi.org/10.5281/zenodo.4765599</a></p>
</section>
<hr class="docutils" />
<section id="embedseg-repository">
<h2>EmbedSeg Repository<a class="headerlink" href="#embedseg-repository" title="Link to this heading">#</a></h2>
<p>Manan Lalit, Joran Deschamps, Florian Jug, Ajinkya Kulkarni</p>
<p>Licensed CC-BY-NC-4.0</p>
<p>Code Implementation for EmbedSeg, an Instance Segmentation Method for Microscopy Images</p>
<p>Tags: Bioimage Analysis, Instance Segmentation, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/juglab/EmbedSeg">juglab/EmbedSeg</a></p>
</section>
<hr class="docutils" />
<section id="embryonic-mice-ultrasound-volumes-with-body-and-brain-volume-segmentation-masks">
<h2>Embryonic mice ultrasound volumes with body and brain volume segmentation masks<a class="headerlink" href="#embryonic-mice-ultrasound-volumes-with-body-and-brain-volume-segmentation-masks" title="Link to this heading">#</a></h2>
<p>Ziming Qiu, Matthew Hartley</p>
<p>Published 2023-05-10</p>
<p>Licensed CC0-1.0</p>
<p>Ultrasound images of mouse embryos with body and brain volume segmentation masks</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://www.ebi.ac.uk/bioimage-archive/galleries/S-BIAD686-ai.html">https://www.ebi.ac.uk/bioimage-archive/galleries/S-BIAD686-ai.html</a></p>
</section>
<hr class="docutils" />
<section id="enabling-global-image-data-sharing-in-the-life-sciences">
<h2>Enabling Global Image Data Sharing in the Life Sciences<a class="headerlink" href="#enabling-global-image-data-sharing-in-the-life-sciences" title="Link to this heading">#</a></h2>
<p>Peter Bajcsy, Sreenivas Bhattiprolu, Katy Boerner, Beth A Cimini, Lucy Collinson, Jan Ellenberg, Reto Fiolka, Maryellen Giger, Wojtek Goscinski, Matthew Hartley, Nathan Hotaling, Rick Horwitz, Florian Jug, Anna Kreshuk, Emma Lundberg, Aastha Mathur, Kedar Narayan, Shuichi Onami, Anne L. Plant, Fred Prior, Jason Swedlow,, Adam Taylor, Antje Keppler</p>
<p>Published 2024-01-23</p>
<p>Licensed CC-BY-NC-SA-4.0 INTERNATIONAL</p>
<p>Coordinated collaboration is essential to realize the added value of and infrastructure requirements for global image data sharing in the life sciences. In this White Paper, we take a first step at presenting some of the most common use cases as well as critical/emerging use cases of (including the use of artificial intelligence for) biological and medical image data, which would benefit tremendously from better frameworks for sharing (including technical, resourcing, legal, and ethical aspects).</p>
<p>Tags: Research Data Management, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://arxiv.org/abs/2401.13023">https://arxiv.org/abs/2401.13023</a></p>
</section>
<hr class="docutils" />
<section id="erick-martins-ratamero-expanding-the-ome-ecosystem-for-imaging-data-management-scipy-2024">
<h2>Erick Martins Ratamero - Expanding the OME ecosystem for imaging data management | SciPy 2024<a class="headerlink" href="#erick-martins-ratamero-expanding-the-ome-ecosystem-for-imaging-data-management-scipy-2024" title="Link to this heading">#</a></h2>
<p>SciPy, Erick Martins Ratamero</p>
<p>Published 2024-08-19</p>
<p>Licensed YOUTUBE STANDARD LICENSE</p>
<p>Tags: OMERO, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Video, Presentation</p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=GmhyDNm1RsM">https://www.youtube.com/watch?v=GmhyDNm1RsM</a></p>
</section>
<hr class="docutils" />
<section id="euro-bioimaging-scientific-ambassadors-program">
<h2>Euro-BioImaging  Scientific Ambassadors Program<a class="headerlink" href="#euro-bioimaging-scientific-ambassadors-program" title="Link to this heading">#</a></h2>
<p>Beatriz Serrano-Solano</p>
<p>Published 2023-07-25</p>
<p>Licensed CC-BY-4.0</p>
<p>Graduation presentation for the 7th cohort of the Open Seeds mentoring &amp; training program for Open Science ambassadors. The project presented is called “Euro-BioImaging  Scientific Ambassadors Program”.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/8182154">https://zenodo.org/records/8182154</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8182154">https://doi.org/10.5281/zenodo.8182154</a></p>
</section>
<hr class="docutils" />
<section id="euro-bioimaging-annual-report-2020">
<h2>Euro-BioImaging Annual Report 2020<a class="headerlink" href="#euro-bioimaging-annual-report-2020" title="Link to this heading">#</a></h2>
<p>Euro-BioImaging ERIC</p>
<p>Published 2025-07-23</p>
<p>Licensed CC-BY-4.0</p>
<p>Euro-BioImaging ERIC is the European landmark research infrastructure for biological and biomedical imaging as recognized by the European Strategy Forum on Research Infrastructures (ESFRI). Euro-BioImaging is the gateway to world-class imaging facilities across Europe. This document is the Euro-BioImaging Annual Report for the year 2020.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16357209">https://zenodo.org/records/16357209</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16357209">https://doi.org/10.5281/zenodo.16357209</a></p>
</section>
<hr class="docutils" />
<section id="euro-bioimaging-annual-report-2021">
<h2>Euro-BioImaging Annual Report 2021<a class="headerlink" href="#euro-bioimaging-annual-report-2021" title="Link to this heading">#</a></h2>
<p>Euro-BioImaging ERIC</p>
<p>Published 2022-06-30</p>
<p>Licensed CC-BY-4.0</p>
<p>Euro-BioImaging ERIC is the European landmark research infrastructure for biological and biomedical imaging as recognized by the European Strategy Forum on Research Infrastructures (ESFRI). Euro-BioImaging is the gateway to world-class imaging facilities across Europe. This document is the Euro-BioImaging Annual Report for the year 2021.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16357461">https://zenodo.org/records/16357461</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16357461">https://doi.org/10.5281/zenodo.16357461</a></p>
</section>
<hr class="docutils" />
<section id="euro-bioimaging-annual-report-2023">
<h2>Euro-BioImaging Annual Report 2023<a class="headerlink" href="#euro-bioimaging-annual-report-2023" title="Link to this heading">#</a></h2>
<p>Euro-BioImaging ERIC</p>
<p>Published 2024-06-30</p>
<p>Licensed CC-BY-4.0</p>
<p>Euro-BioImaging ERIC is the European landmark research infrastructure for biological and biomedical imaging as recognized by the European Strategy Forum on Research Infrastructures (ESFRI). Euro-BioImaging is the gateway to world-class imaging facilities across Europe. This document is the Euro-BioImaging Annual Report for the year 2023.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16323251">https://zenodo.org/records/16323251</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16323251">https://doi.org/10.5281/zenodo.16323251</a></p>
</section>
<hr class="docutils" />
<section id="euro-bioimaging-annual-report-2024">
<h2>Euro-BioImaging Annual Report 2024<a class="headerlink" href="#euro-bioimaging-annual-report-2024" title="Link to this heading">#</a></h2>
<p>Euro-BioImaging ERIC</p>
<p>Published 2025-06-30</p>
<p>Licensed CC-BY-4.0</p>
<p>Euro-BioImaging ERIC is the European landmark research infrastructure for biological and biomedical imaging as recognized by the European Strategy Forum on Research Infrastructures (ESFRI). Euro-BioImaging is the gateway to world-class imaging facilities across Europe. This document is the Euro-BioImaging Annual Report for the year 2024.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16761197">https://zenodo.org/records/16761197</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16761197">https://doi.org/10.5281/zenodo.16761197</a></p>
</section>
<hr class="docutils" />
<section id="euro-bioimaging-communication-youtube-channel">
<h2>Euro-BioImaging Communication YouTube Channel<a class="headerlink" href="#euro-bioimaging-communication-youtube-channel" title="Link to this heading">#</a></h2>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Collection, Video</p>
<p><a class="reference external" href="https://www.youtube.com/c/eurobioimagingcommunication">https://www.youtube.com/c/eurobioimagingcommunication</a></p>
</section>
<hr class="docutils" />
<section id="euro-bioimaging-eric-annual-report-2022">
<h2>Euro-BioImaging ERIC Annual Report 2022<a class="headerlink" href="#euro-bioimaging-eric-annual-report-2022" title="Link to this heading">#</a></h2>
<p>Euro-BioImaging ERIC</p>
<p>Published 2023-07-14</p>
<p>Licensed CC-BY-4.0</p>
<p>Euro-BioImaging ERIC is the European landmark research infrastructure for biological and biomedical imaging as recognized by the European Strategy Forum on Research Infrastructures (ESFRI). Euro-BioImaging is the gateway to world-class imaging facilities across Europe. This document is the Euro-BioImaging Annual Report for the year 2022.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/8146412">https://zenodo.org/records/8146412</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8146412">https://doi.org/10.5281/zenodo.8146412</a></p>
</section>
<hr class="docutils" />
<section id="euro-bioimaging-s-template-for-research-data-management-plans">
<h2>Euro-BioImaging’s Template for Research Data Management Plans<a class="headerlink" href="#euro-bioimaging-s-template-for-research-data-management-plans" title="Link to this heading">#</a></h2>
<p>Isabel Kemmer, Euro-BioImaging ERIC</p>
<p>Published 2024-06-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Euro-BioImaging has developed a Data Management Plan (DMP) template with questions tailored to bioimaging research projects. Outlining data management practices in this way ensures traceability of project data, allowing for a continuous and unambiguous flow of information throughout the research project. This template can be used to satisfy the requirement to submit a DMP to certain funders. Regardless of the funder, Euro-BioImaging users are encouraged to provide a DMP and can use this template accordingly. 
This DMP template is available as a fillable PDF with further instructions and sample responses available by hovering over the fillable fields. </p>
<p>Tags: Bioimage Analysis, FAIR-Principles, Research Data Management, Exclude From Dalia</p>
<p>Content type: Collection, Tutorial</p>
<p><a class="reference external" href="https://zenodo.org/records/11473803">https://zenodo.org/records/11473803</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11473803">https://doi.org/10.5281/zenodo.11473803</a></p>
</section>
<hr class="docutils" />
<section id="euro-bioimaging-batchconvert-v0-0-4">
<h2>Euro-BioImaging/BatchConvert: v0.0.4<a class="headerlink" href="#euro-bioimaging-batchconvert-v0-0-4" title="Link to this heading">#</a></h2>
<p>bugraoezdemir</p>
<p>Published 2024-02-19</p>
<p>Licensed CC-BY-4.0</p>
<p>Changes implemented since v0.0.3</p>
<p>Support provided for file paths with spaces.
Support provided for globbing filenames from s3 for one-to-one conversion (parse_s3_filenames.py modified).
Support provided for single file import from s3 (parse_s3_filenames.py modified).
run_conversion.py replaces batchconvert_cli.sh and construct_cli.py, uniting them.
Error handling updated for each process</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/10679318">https://zenodo.org/records/10679318</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10679318">https://doi.org/10.5281/zenodo.10679318</a></p>
</section>
<hr class="docutils" />
<section id="evident-oir-sample-files-tiles-stitched-image-fv-4000">
<h2>Evident OIR sample files tiles + stitched image - FV 4000<a class="headerlink" href="#evident-oir-sample-files-tiles-stitched-image-fv-4000" title="Link to this heading">#</a></h2>
<p>Nicolas Chiaruttini</p>
<p>Published 2024-09-04</p>
<p>Licensed CC-BY-4.0</p>
<p>The files contained in this repository are confocal images taken with the Evident FV 4000 of a sample containing DAPI and mCherry stains, excited with a 405 nm laser and a 561 nm laser</p>
<p>individual tiles are named <code class="docutils literal notranslate"><span class="pre">tiling-sample-brain-section_A01_G001_{i}.oir</span></code>
The stiched image is named <code class="docutils literal notranslate"><span class="pre">Stitch_A01_G001</span></code> and contains an extra file <code class="docutils literal notranslate"><span class="pre">Stitch_A01_G001_00001</span></code>
Some metadata like the tiles positions are stored in the extra files (omp2info)</p>
<p> </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/13680725">https://zenodo.org/records/13680725</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13680725">https://doi.org/10.5281/zenodo.13680725</a></p>
</section>
<hr class="docutils" />
<section id="evident-oir-sample-files-with-lambda-scan-fv-4000">
<h2>Evident OIR sample files with lambda scan - FV 4000<a class="headerlink" href="#evident-oir-sample-files-with-lambda-scan-fv-4000" title="Link to this heading">#</a></h2>
<p>Nicolas Chiaruttini</p>
<p>Published 2024-07-18</p>
<p>Licensed CC-BY-4.0</p>
<p>The files contained in this repository are confocal images taken with the Evident FV 4000 of a sample containing DAPI and mCherry stains, excited with the 405 nm laser and images for different emission windows (lambda scan).
They are public sample files which goal is to help test edge cases of the bio-formats library (<a class="reference external" href="https://www.openmicroscopy.org/bio-formats/">https://www.openmicroscopy.org/bio-formats/</a>), in particular for the proper handling of lambda scans.</p>
<p>DAPI_mCherry_22Lambda-420-630-w10nm-s10nm.oir : 22 planes, each plane is an emission window, starting from 420 nm up to 630 nm by steps of 10 nm
DAPI_mCherry_4T_5Lambda-420-630-w10nm-s50nm.oir : 20 planes, 5 lambdas from 420 to 630 nm by steps of 50 nm, 4 timepoints
DAPI_mCherry_4Z_5Lambda-420-630-w10nm-s50nm.oir : 20 planes, 5 lambdas from 420 to 630 nm by steps of 50 nm, 4 slices
DAPI-mCherry_3T_4Z_5Lambda-420-630-w10nm-s50nm.oir : 60 planes, 5 lambdas from 420 to 630 nm by steps of 50 nm, 4 slices, 3 timepoints</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/12773657">https://zenodo.org/records/12773657</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12773657">https://doi.org/10.5281/zenodo.12773657</a></p>
</section>
<hr class="docutils" />
<section id="example-imaris-ims-datasets">
<h2>Example Imaris ims datasets.<a class="headerlink" href="#example-imaris-ims-datasets" title="Link to this heading">#</a></h2>
<p>Marco Stucchi</p>
<p>Published 2024-11-28</p>
<p>Licensed CC-BY-4.0</p>
<p>The files contained in this repository are example Imaris ims images.
 
Initially related to <a class="github reference external" href="https://github.com/ome/bioformats/pull/4249">ome/bioformats#4249</a></p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14235726">https://zenodo.org/records/14235726</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14235726">https://doi.org/10.5281/zenodo.14235726</a></p>
</section>
<hr class="docutils" />
<section id="example-microscopy-metadata-json-files-produced-using-micro-meta-app-to-document-example-microscopy-experiments-performed-at-individual-core-facilities">
<h2>Example Microscopy Metadata JSON files produced using Micro-Meta App to document example microscopy experiments performed at individual core facilities<a class="headerlink" href="#example-microscopy-metadata-json-files-produced-using-micro-meta-app-to-document-example-microscopy-experiments-performed-at-individual-core-facilities" title="Link to this heading">#</a></h2>
<p>Alessandro Rigano, Ulrike Boehm, Claire M. Brown, Joel Ryan, James J. Chambers, Robert A. Coleman, Orestis Faklaris, Thomas Guilbert, Michelle S. Itano, Judith Lacoste, Alex Laude, Marco Marcello, Paula Montero-Llopis, Glyn Nelson, Roland Nitschke, Jaime A. Pimentel, Stefanie Weidtkamp-Peters, Caterina Strambio-De-Castillia</p>
<p>Published 2022-01-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Example Microscopy Metadata (Microscope.JSON and Settings.JSON) files produced using Micro-Meta App to document the Hardware Specifications of example Microscopes and the Image Acquisition Settings utilized to acquire example images as listed in the table below.</p>
<p>For each facility, the dataset contains two JSON files:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Microscope.JSON file (e.g., 01_marcello_uliverpool_cci_zeiss_axioobserz1_lsm710.json)
Settings.JSON file (indicated with the name of the image and with the _AS suffix)
</pre></div>
</div>
<p>Micro-Meta App was developed as part of a global community initiative including the 4D Nucleome (4DN) Imaging Working Group, BioImaging North America (BINA) Quality Control and Data Management Working Group, and QUAlity and REProducibility for Instrument and Images in Light Microscopy (QUAREP-LiMi), to extend the Open Microscopy Environment (OME) data model.</p>
<p>The works of this global community effort resulted in multiple publications featured on a recent Nature Methods FOCUS ISSUE dedicated to Reporting and reproducibility in microscopy.</p>
<p>Learn More! For a thorough description of Micro-Meta App consult our recent Nature Methods and <a class="reference external" href="http://BioRxiv.org">BioRxiv.org</a> publications!</p>
<p> </p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>		Nr.
		Manufacturer
		Model
		Tier
		&amp;Epsilon;xperiment Type
		Facility Name
		Department and Institution
		URL
		References
	
	
		1
		Carl Zeiss Microscopy
		Axio Observer Z1 (with LSM 710 scan head)
		1
		3D visualization of superhydrophobic polymer-nanoparticles
		Centre for Cell Imaging (CCI)
		University of Liverpool
		https://cci.liv.ac.uk/equipment_710.html
		Upton et al., 2020
	
	
		2
		Carl Zeiss Microscopy
		Axio Observer (Axiovert 200M)
		2
		&amp;Mu;easurement of illumination stability on Chinese Hamster Ovary cells expressing Paxillin-EGFP
		Advanced BioImaging Facility (ABIF).
		McGill University
		https://www.mcgill.ca/abif/equipment/axiovert-1
		Kiepas et al., 2020
	
	
		3
		Carl Zeiss Microscopy
		Axio Observer Z1 (with Spinning Disk)
		2
		Immunofluorescence imaging of cryosection of Mouse kidney
		Imagerie Cellulaire; Quality Control managed by Miacellavie (https://miacellavie.com/)
		Centre de recherche du Centre Hospitalier Universit&amp;eacute; de Montr&amp;eacute;al (CR CHUM), University of Montreal
		https://www.chumontreal.qc.ca/crchum/plateformes-et-services&amp;nbsp; (the web site is for all core facilities, not specifically for the core facility hosting this microscope)
		Pilliod et al., 2020
	
	
		4
		Carl Zeiss Microscopy
		Axio Imager Z2 (with Apotome)
		2
		Immunofluorescence imaging of mitotic division in Hela cells using&amp;nbsp;&amp;nbsp;
		Bioimaging Unit
		Newcastle University
		https://www.ncl.ac.uk/bioimaging/
		Watson et al., 2020
	
	
		5
		Carl Zeiss Microscopy
		Axio Observer Z1
		2
		Fluorescence microscopy of human skin fibroblasts from Glycogen Storage Disease patients.
		Life Imaging Center (LIC)
		Centre for Integrative Signalling Analysis (CISA), University of Freiburg
		https://miap.eu/equipments/sd-i-abl/
		Hannibal et al., 2020
	
	
		6
		Leica Microsystems
		DMI6000B
		2
		3D immunofluorescence imaging&amp;nbsp; rhinovirus infected macrophages&amp;nbsp;
		IMAG&amp;#39;IC Confocal Microscopy Facility
		Institut Cochin, CNRS, INSERM, Universit&amp;eacute; de Paris
		https://www.institutcochin.fr/core_facilities/confocal-microscopy/cochin-imaging-photonic-microscopy/organigram_team/10054/view
		Jubrail et al., 2020
	
	
		7
		Leica Microsystems
		DM5500B
		2
		Immunofluorescence analysis of the colocalization of PML bodies with DNA double-strand breaks
		Bioimaging Unit
		Edwardson Building on the Campus for Ageing and Vitality, Newcastle University
		https://www.ncl.ac.uk/bioimaging/equipment/leica-dm5500/#overview
		da Silva et al., 2019; Nelson et al., 2012
		&amp;nbsp;&amp;nbsp;
	
	
		8
		Leica Microsystems
		DMI8-CS (with TCS SP8 STED 3X)
		2
		Live-cell imaging of N. benthamiana leaves cells-derived protoplasts
		Center for Advanced Imaging (CAi)
		School of Mathematics/Natural Sciences, Heinrich-Heine-Universit&amp;auml;t D&amp;uuml;sseldorf
		https://www.cai.hhu.de/en/equipment/super-resolution-microscopy/leica-tcs-sp8-sted-3x
		Singer et al., 2017; H&amp;auml;nsch et al., 2020
	
	
		9
		Nikon Instruments
		Eclipse Ti
		2
		Immunofluorescence analysis of the cytoskeleton structure in COS cells
		Advanced Imaging Center (AIC)
		Janelia Research Campus, Howard Hughes Medical Institute
		https://www.janelia.org/support-team/light-microscopy/equipment
		Abdelfattah et al., 2019; Qian et al., 2019; Grimm et al., 2020
	
	
		10
		Nikon Instruments
		Eclipse Ti-E (HCA)
		2
		&amp;Tau;ime-lapse analysis of the bursting behavior of amine-functionalized vesicular assemblies
		Light Microscopy Facility (IALS-LIF)
		Institute for Applied Life Sciences, University of Massachusetts at Amherst
		https://www.umass.edu/ials/light-microscopy
		Fernandez et al., 2020
	
	
		11
		Nikon Instruments/Coleman laboratory (customized)
		TIRF HILO Epifluorescence light Microscope (THEM)/ Eclipse Ti
		2
		Single-particle tracking of Halo-tagged PCNA in Lox cells
		Coleman laboratory
		Anatomy and Structural Biology Department, The Albert Einstein College of Medicine
		https://einsteinmed.org/faculty/12252/robert-coleman/
		Drosopoulos et al., 2020
	
	
		12
		Nikon Instruments
		Eclipse Ti (with Andor Dragon Fly Spinning Disk)
		2
		Investigation of the 3D structure of cerebral organoids
		Montpellier Resources Imagerie
		Centre de Recherche de Biologie cellulaire de Montpellier (MRI-CRBM), CNRS, Univerity of Montpellier
		https://www.mri.cnrs.fr/en/optical-imaging/our-facilities/mri-crbm.html
		Ayala-Nunez et al., 2019
	
	
		13
		Nikon Instruments
		Eclipse Ti2
		2
		&amp;Iota;mmunofluorescence imaging of cryosections of mouse hearth myocardium&amp;nbsp;
		Neuroscience Center Microscopy Core
		Neuroscience Center, University of North Carolina
		https://www.med.unc.edu/neuroscience/core-facilities/neuro-microscopy/
		Aghajanian et al., 2021
	
	
		14
		Nikon Instruments
		Eclipse Ti2
		2
		Live-cell imaging of bacterial cells expressing GFP-PopZ
		Microscopy Resources on the North Quad (MicRoN)
		Harvard Medical School&amp;nbsp;
		https://micron.hms.harvard.edu/
		Lim and Bernhardt 2019; Lim et al., 2019
	
	
		15
		Olympus/Biomedical Imaging Group (customized)
		TIRF Epifluorescence Structured light Microscope (TESM)/IX71
		3
		3D distribution of HIV-1 in the nucleus of human cells
		Biomedical Imaging Group
		Program in Molecular Medicine, University of Massachusetts Medical School
		https://trello.com/b/BQ8zCcQC/tirf-epi-fluorescence-structured-light-microscope
		Navaroli et al., 2012
	
	
		16
		Olympus/Computer Vision Laboratory (customized)
		3D BrightField Scanner/IX71
		3
		Transmitted light brightfield visualization of swimming spermatocytes
		Laboratorio Nacional de Microscopia Avanzada (LNMA) and Computer Vision Laboratory of the Institute of Biotechnology
		Universidad Nacional Autonoma de Mexico (UNAM)
		https://lnma.unam.mx/wp/
		Pimentel et al., 2012; Silva-Villalobos et al., 2014
</pre></div>
</div>
<p>Getting started</p>
<p>Use these videos to get started with using Micro-Meta App after installation into OMERO and downloading the example data files:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Video 1
Video 2
</pre></div>
</div>
<p>More information</p>
<p>For full information on how to use Micro-Meta App please utilize the following resources:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Micro-Meta App website
Full documentation
Installation instructions
Step-by-Step Instructions
Tutorial Videos
</pre></div>
</div>
<p>Background</p>
<p>If you want to learn more about the importance of metadata and quality control to ensure full reproducibility, quality and scientific value in light microscopy, please take a look at our recent publications describing the development of community-driven light 4DN-BINA-OME Microscopy Metadata specifications Nature Methods and <a class="reference external" href="http://BioRxiv.org">BioRxiv.org</a> and our overview manuscript entitled A perspective on Microscopy Metadata: data provenance and quality control.</p>
<p> </p>
<p> </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/5847477">https://zenodo.org/records/5847477</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5847477">https://doi.org/10.5281/zenodo.5847477</a></p>
</section>
<hr class="docutils" />
<section id="example-operetta-dataset">
<h2>Example Operetta Dataset<a class="headerlink" href="#example-operetta-dataset" title="Link to this heading">#</a></h2>
<p>Nicolas Chiaruttini</p>
<p>Published 2023-07-17</p>
<p>Licensed CC-BY-4.0</p>
<p>This is a microscopy image dataset generated by the Perkin Elmer Operetta HCS microscope by of the user of the PTBIOP EPFL facility.
As of the 17th of July 2023, opening this file in ImageJ/Fiji using the BioFormats 6.14 library, this dataset generates a Null Pointer Exception.</p>
<p>A post on <a class="reference external" href="http://forum.image.sc">forum.image.sc</a> is linked to this issue:</p>
<p><a class="reference external" href="https://forum.image.sc/t/null-pointer-exception-in-perkin-elmer-operetta-dataset-with-bio-formats-6-14/83784">https://forum.image.sc/t/null-pointer-exception-in-perkin-elmer-operetta-dataset-with-bio-formats-6-14/83784</a></p>
<p> </p>
<p> </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/8153907">https://zenodo.org/records/8153907</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8153907">https://doi.org/10.5281/zenodo.8153907</a></p>
</section>
<hr class="docutils" />
<section id="example-pipeline-tutorial">
<h2>Example Pipeline Tutorial<a class="headerlink" href="#example-pipeline-tutorial" title="Link to this heading">#</a></h2>
<p>Tim Monko</p>
<p>Published 2024-10-28</p>
<p>Licensed BSD-3-CLAUSE</p>
<p>Napari-ndev is a collection of widgets intended to serve any person seeking to process microscopy images from start to finish. The goal of this example pipeline is to get the user familiar with working with napari-ndev for batch processing and reproducibility (view Image Utilities and Workflow Widget).</p>
<p>Tags: Napari, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Documentation, Github Repository, Tutorial</p>
<p><a class="reference external" href="https://timmonko.github.io/napari-ndev/tutorial/01_example_pipeline/">https://timmonko.github.io/napari-ndev/tutorial/01_example_pipeline/</a></p>
<p><a class="github reference external" href="https://github.com/timmonko/napari-ndev">timmonko/napari-ndev</a></p>
</section>
<hr class="docutils" />
<section id="excel-template-for-adding-key-value-pairs-to-images">
<h2>Excel template for adding Key-Value Pairs to images<a class="headerlink" href="#excel-template-for-adding-key-value-pairs-to-images" title="Link to this heading">#</a></h2>
<p>Thomas Zobel, Jens Wendt</p>
<p>Published 2024-10-30</p>
<p>Licensed CC-BY-4.0</p>
<p>This Excel Workbook contains some simple Macros to help with the generation of a .csv in the necessary format for Key-Value pair annotations of images in OMERO.
The format is tailored for the <a class="reference external" href="http://OMERO.web">OMERO.web</a> script “KeyVal_from_csv.py”  (from the version &lt;=5.8.3 of the core omero-scripts).
Attached is also a video of Thomas Zobel, the head of the imaging core facility Uni Münster, showcasing the use of the Excel workbook.The video uses a slightly older version of the workbook and OMERO, but the core functionality remains unchanged.
Please keep in mind, that the <a class="reference external" href="http://OMERO.web">OMERO.web</a> script(s) to handle Key-Value Pairs from/to .csv files will undergo a major change very soon.This might break the compatibility with the format used now for the generated .csv from the workbook.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14014252">https://zenodo.org/records/14014252</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14014252">https://doi.org/10.5281/zenodo.14014252</a></p>
</section>
<hr class="docutils" />
<section id="fair-bioimage-data">
<h2>FAIR BioImage Data<a class="headerlink" href="#fair-bioimage-data" title="Link to this heading">#</a></h2>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Research Data Management, Fair, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Collection, Video</p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=8zd4KTy-oYI&amp;amp;list=PLW-oxncaXRqU4XqduJzwFHvWLF06PvdVm">https://www.youtube.com/watch?v=8zd4KTy-oYI&amp;list=PLW-oxncaXRqU4XqduJzwFHvWLF06PvdVm</a></p>
</section>
<hr class="docutils" />
<section id="fair-high-content-screening-in-bioimaging">
<h2>FAIR High Content Screening in Bioimaging<a class="headerlink" href="#fair-high-content-screening-in-bioimaging" title="Link to this heading">#</a></h2>
<p>Rohola Hosseini, Matthijs Vlasveld, Joost Willemse, Bob van de Water, Sylvia E. Le Dévédec, Katherine J. Wolstencroft</p>
<p>Published 2023-07-17</p>
<p>Licensed CC-BY-4.0</p>
<p>The authors show the utility of Minimum Information for High Content Screening Microscopy Experiments (MIHCSME) for High Content Screening (HCS) data using multiple examples from the Leiden FAIR Cell Observatory, a Euro-Bioimaging flagship node for high content screening and the pilot node for implementing FAIR bioimaging data throughout the Netherlands Bioimaging network.</p>
<p>Tags: FAIR-Principles, Metadata, Research Data Management, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.nature.com/articles/s41597-023-02367-w">https://www.nature.com/articles/s41597-023-02367-w</a></p>
</section>
<hr class="docutils" />
<section id="fiber-and-vessel-dataset-for-segmentation-and-characterization">
<h2>Fiber and vessel dataset for segmentation and characterization<a class="headerlink" href="#fiber-and-vessel-dataset-for-segmentation-and-characterization" title="Link to this heading">#</a></h2>
<p>Saqib Qamar, Baba, Abu Imran, Stèphane Verger, Magnus Andersson</p>
<p>Published 2024-05-03</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository hosts a comprehensive collection of datasets used to develop an innovative deep learning model designed to enhance the segmentation and characterization of macerated fibers and vessel forms in microscopy images. Included in the deposit are raw images, alongside meticulously prepared training and validation datasets. We present an automated segmentation approach that utilizes the one-stage YOLOv8 model, which has been specifically adapted to process high-resolution microscopy images up to 32640 x 25920 pixels. Our model excels in cell detection and segmentation, demonstrating exceptional proficiency.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/10913446">https://zenodo.org/records/10913446</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10913446">https://doi.org/10.5281/zenodo.10913446</a></p>
</section>
<hr class="docutils" />
<section id="fiji">
<h2>Fiji<a class="headerlink" href="#fiji" title="Link to this heading">#</a></h2>
<p>Licensed BSD-2-CLAUSE</p>
<p>Fiji is a popular free open-source image processing package based on ImageJ.</p>
<p>Tags: Imagej, OMERO, Exclude From Dalia</p>
<p>Content type: Online Tutorial</p>
<p><a class="reference external" href="https://omero-guides.readthedocs.io/en/latest/fiji/docs/index.html">https://omero-guides.readthedocs.io/en/latest/fiji/docs/index.html</a></p>
</section>
<hr class="docutils" />
<section id="fiji-is-just-imagej-tutorials">
<h2>Fiji Is Just ImageJ Tutorials<a class="headerlink" href="#fiji-is-just-imagej-tutorials" title="Link to this heading">#</a></h2>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Collection, Video</p>
<p><a class="reference external" href="https://www.youtube.com/playlist?list=PL5Edc1v41fyCLFZbBCLo41zFO-_cXBfAb">https://www.youtube.com/playlist?list=PL5Edc1v41fyCLFZbBCLo41zFO-_cXBfAb</a></p>
</section>
<hr class="docutils" />
<section id="fit-for-omero-how-imaging-facilities-and-it-departments-work-together-to-enable-rdm-for-bioimaging">
<h2>Fit for OMERO: How imaging facilities and IT departments work together to enable RDM for bioimaging<a class="headerlink" href="#fit-for-omero-how-imaging-facilities-and-it-departments-work-together-to-enable-rdm-for-bioimaging" title="Link to this heading">#</a></h2>
<p>Starts Oct 16, 2024, 9:00 AM, Ends Oct 17, 2024, 5:00 PM</p>
<p>Tags: Bioimage Analysis, OMERO, Research Data Management, Exclude From Dalia</p>
<p>Content type: Workshop</p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14013025">https://doi.org/10.5281/zenodo.14013025</a></p>
</section>
<hr class="docutils" />
<section id="forschungsdatenmanagement-zukunftsfest-gestalten-impulse-fur-die-strukturevaluation-der-nationalen-forschungsdateninfrastruktur-nfdi">
<h2>Forschungsdatenmanagement zukunftsfest gestalten – Impulse für die   Strukturevaluation der Nationalen Forschungsdateninfrastruktur (NFDI)<a class="headerlink" href="#forschungsdatenmanagement-zukunftsfest-gestalten-impulse-fur-die-strukturevaluation-der-nationalen-forschungsdateninfrastruktur-nfdi" title="Link to this heading">#</a></h2>
<p>Steuerungsgremium Allianz-Schwerpunkt, Alexander von Humboldt Foundation, Deutsche Forschungsgemeinschaft, Fraunhofer Society, German Rectors’ Conference, Leibniz Association, German National Academy of Sciences Leopoldina, German Academic Exchange Service, Helmholtz Association of German Research Centres, Max Planck Society</p>
<p>Published 2024-11-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Arbeitspapier des Steuerungsgremiums des Allianz-Schwerpunkts “Digitalität in der Wissenschaft”</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14032908">https://zenodo.org/records/14032908</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14032908">https://doi.org/10.5281/zenodo.14032908</a></p>
</section>
<hr class="docutils" />
<section id="fractal-documentation">
<h2>Fractal Documentation<a class="headerlink" href="#fractal-documentation" title="Link to this heading">#</a></h2>
<p>Fractal is a framework to process high-content imaging data at scale and prepare it for interactive visualization.</p>
<p>Tags: Workflow Engine, Python, Exclude From Dalia</p>
<p>Content type: Documentation</p>
<p><a class="reference external" href="https://fractal-analytics-platform.github.io/">https://fractal-analytics-platform.github.io/</a></p>
</section>
<hr class="docutils" />
<section id="galaxy-documentation">
<h2>Galaxy Documentation<a class="headerlink" href="#galaxy-documentation" title="Link to this heading">#</a></h2>
<p>Galaxy is an open source, web-based platform for data intensive biomedical research.</p>
<p>Tags: Workflow Engine, Exclude From Dalia</p>
<p>Content type: Documentation</p>
<p><a class="reference external" href="https://usegalaxy.org/">https://usegalaxy.org/</a></p>
</section>
<hr class="docutils" />
<section id="galaxy-imaging">
<h2>Galaxy Imaging<a class="headerlink" href="#galaxy-imaging" title="Link to this heading">#</a></h2>
<p>Galaxy Team</p>
<p>Licensed [‘ACADEMIC FREE LICENSE VERSION 3.0’, ‘CREATIVE COMMONS ATTRIBUTION 3.0 (CC BY 3.0) LICENSE’]</p>
<p>Galaxy is an open source tool that offers a filtered set of tools that you can assemble into workflows to manage image data, and perform image analysis and processing.</p>
<p>Tags: Galaxy, Bioinformatics, Exclude From Dalia</p>
<p>Content type: Tool</p>
<p><a class="reference external" href="https://imaging.usegalaxy.eu">https://imaging.usegalaxy.eu</a></p>
</section>
<hr class="docutils" />
<section id="galaxy-training">
<h2>Galaxy Training<a class="headerlink" href="#galaxy-training" title="Link to this heading">#</a></h2>
<p>Published None</p>
<p>Licensed CC-BY-4.0</p>
<p>Collection of tutorials developed and maintained by the worldwide Galaxy community.</p>
<p>Tags: Bioimage Analysis, Data Analysis, Exclude From Dalia</p>
<p>Content type: Collection, Tutorial</p>
<p><a class="reference external" href="https://training.galaxyproject.org/">https://training.galaxyproject.org/</a></p>
</section>
<hr class="docutils" />
<section id="galaxy-training-material">
<h2>Galaxy Training Material<a class="headerlink" href="#galaxy-training-material" title="Link to this heading">#</a></h2>
<p>Licensed MIT</p>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Slides, Tutorial</p>
<p><a class="github reference external" href="https://github.com/galaxyproject/training-material">galaxyproject/training-material</a></p>
</section>
<hr class="docutils" />
<section id="galaxyproject-youtube-channel">
<h2>GalaxyProject YouTube Channel<a class="headerlink" href="#galaxyproject-youtube-channel" title="Link to this heading">#</a></h2>
<p>Galaxy Team</p>
<p>Published 2020-06-16</p>
<p>Licensed UNKNOWN</p>
<p>Galaxy is an open, web-based platform for accessible, reproducible, and transparent computational research.</p>
<p>Tags: Galaxy, Bioinformatics, Exclude From Dalia</p>
<p>Content type: Youtube Channel</p>
<p><a class="reference external" href="https://www.youtube.com/c/galaxyproject">https://www.youtube.com/c/galaxyproject</a></p>
</section>
<hr class="docutils" />
<section id="gerbi-teaching-resources-link-list">
<h2>GerBI Teaching Resources Link List<a class="headerlink" href="#gerbi-teaching-resources-link-list" title="Link to this heading">#</a></h2>
<p>Licensed UNKNOWN</p>
<p>List of training materials by the German BioImaging community provided by facilities, the scientific community, and companies.</p>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://gerbi-gmb.de/resources/teaching-resources/">https://gerbi-gmb.de/resources/teaching-resources/</a></p>
</section>
<hr class="docutils" />
<section id="gerbi-chat-teil-1-vom-bedarf-bis-zum-groszgerateantrag-schreiben">
<h2>GerBI-Chat: Teil 1 - Vom Bedarf bis zum Großgeräteantrag-Schreiben<a class="headerlink" href="#gerbi-chat-teil-1-vom-bedarf-bis-zum-groszgerateantrag-schreiben" title="Link to this heading">#</a></h2>
<p>Financial &amp; Legal Framework of Core Facilities, Elmar Endl, Jana Hedrich, Juliane Hoth, Julia Nagy, Astrid Schauss, Nina Schulze, Silke Tulok</p>
<p>Published 2024-09-11</p>
<p>Licensed CC-BY-4.0</p>
<p>Die GermanBioImaging (GerBI-GMB) - Deutsche Gesellschaft für Mikroskopie und Bildanalyse e.V. bietet über regelmäßig stattfindende Treffen (GerBI-Chats) die Möglichkeit zum aktiven Austausch der Mitglieder untereinander. Das GerBI-GMB Team “Legal und Finacial Framwork”, welches sich mit administrativen Aufgaben rund um das Core Facility Management beschäftigt, nutzt diese Möglichkeit zum aktiven Austausch innerhalb des Netzwerkes und darüber hinaus. 
Der Beschaffungsprozess von Forschungsgroßgeräten ist komplex und je nach Institution unterschiedlich geregelt. Aus unserer Sicht lässt sich dieser Prozess grob in drei Stufen aufteilen:</p>
<p>Bedarfsanmeldung
Antragsvorbereitung und -fertigstellung
Antragsbewilligung und Nutzung </p>
<p>Dieser hier enthaltene Beitrag ist der Initialvortrag des GerBi-Chats zum Teil 1 - Von der Bedarfsanmeldung bis zum Beginn der Antragststellung. Die weiteren Stufen der Großgerätebeschaffung werden in nachfolgenden Beiträgen behandelt.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/13810879">https://zenodo.org/records/13810879</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13810879">https://doi.org/10.5281/zenodo.13810879</a></p>
</section>
<hr class="docutils" />
<section id="gerbi-chat-teil-2-wie-schreibe-ich-am-besten-einen-groszegrateantrag">
<h2>GerBI-Chat: Teil 2 - Wie schreibe ich am besten einen Großegräteantrag<a class="headerlink" href="#gerbi-chat-teil-2-wie-schreibe-ich-am-besten-einen-groszegrateantrag" title="Link to this heading">#</a></h2>
<p>Financial &amp; Legal Framework of Core Facilities, Elmar Endl, Jana Hedrich, Juliane Hoth, Julia Nagy, Astrid Schauss, Nina Schulze, Silke Tulok</p>
<p>Published 2024-10-02</p>
<p>Licensed CC-BY-4.0</p>
<p>Die GermanBioImaging (GerBI-GMB) - Deutsche Gesellschaft für Mikroskopie und Bildanalyse e.V. bietet über regelmäßig stattfindende Treffen (GerBI-Chats) die Möglichkeit zum aktiven Austausch der Mitglieder untereinander. Das GerBI-GMB Team “Legal und Finacial Framwork”, welches sich mit administrativen Aufgaben rund um das Core Facility Management beschäftigt, nutzt diese Möglichkeit zum aktiven Austausch innerhalb des Netzwerkes und darüber hinaus. 
Der Beschaffungsprozess von Forschungsgroßgeräten ist komplex und je nach Institution unterschiedlich geregelt. Aus unserer Sicht lässt sich dieser Prozess grob in drei Stufen aufteilen:</p>
<p>Bedarfsanmeldung
Antragsvorbereitung und -fertigstellung
Antragsbewilligung und Nutzung </p>
<p>Nach dem Initialvortrag der GerBI-Chat Reihe, in dem das Thema Bedarfsanmeldung im Fokus stand, geht es im hier enthaltenen zweiten Teil „Antragsvorbereitung und -fertigstellung: Wie schreibe ich am besten einen Großgeräteantrag?“ um die Beantragung von Forschungsgroßgeräten nach Art. 91b GG.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/13807114">https://zenodo.org/records/13807114</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13807114">https://doi.org/10.5281/zenodo.13807114</a></p>
</section>
<hr class="docutils" />
<section id="get-started-accessing-the-de-nbi-cloud">
<h2>Get started accessing the de.NBI cloud.<a class="headerlink" href="#get-started-accessing-the-de-nbi-cloud" title="Link to this heading">#</a></h2>
<p>de.NBI</p>
<p>Licensed UNKNOWN</p>
<p>Tutorial for accessing de.NBI cloud</p>
<p>Tags: Bioinformatics, Cloud Computing, Exclude From Dalia</p>
<p>Content type: Tutorial</p>
<p><a class="reference external" href="https://cloud.denbi.de/get-started/">https://cloud.denbi.de/get-started/</a></p>
</section>
<hr class="docutils" />
<section id="ghent-university-research-data-management-rdm-policy-and-support">
<h2>Ghent University Research Data Management (RDM) - policy and support<a class="headerlink" href="#ghent-university-research-data-management-rdm-policy-and-support" title="Link to this heading">#</a></h2>
<p>University of Ghent</p>
<p>Licensed UNKNOWN</p>
<p>The website provides resources and guidelines for managing research data efficiently and responsibly. Its focus is to ensure that data are properly organized, stored, documented, and shared throughout a research project, and even beyond, in a way that aligns with Open Science principles.</p>
<p>Tags: Research Data Management, Exclude From Dalia</p>
<p>Content type: Website</p>
<p><a class="reference external" href="https://www.ugent.be/en/research/openscience/datamanagement">https://www.ugent.be/en/research/openscience/datamanagement</a></p>
</section>
<hr class="docutils" />
<section id="glencoe-software-webinars">
<h2>Glencoe Software Webinars<a class="headerlink" href="#glencoe-software-webinars" title="Link to this heading">#</a></h2>
<p>Chris Allan, Emil Rozbicki</p>
<p>Licensed UNKNOWN</p>
<p>Example Workflows / usage of the Glencoe Software.</p>
<p>Tags: OMERO, Exclude From Dalia</p>
<p>Content type: Video, Tutorial, Collection</p>
<p><a class="reference external" href="https://www.glencoesoftware.com/media/webinars/">https://www.glencoesoftware.com/media/webinars/</a></p>
</section>
<hr class="docutils" />
<section id="globias">
<h2>GloBIAS<a class="headerlink" href="#globias" title="Link to this heading">#</a></h2>
<p>GloBIAS</p>
<p>Published 2024-07-17</p>
<p>Licensed UNKNOWN</p>
<p>This is the YouTube channel of GloBIAS, the Global BioImage Analysts Society. GloBIAS is a non-profit association officially constituted in October 2024.</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Youtube Channel</p>
<p><a class="reference external" href="https://www.youtube.com/&#64;globias">https://www.youtube.com/&#64;globias</a></p>
</section>
<hr class="docutils" />
<section id="globias-in-person-workshop-2024">
<h2>GloBIAS in-person workshop 2024<a class="headerlink" href="#globias-in-person-workshop-2024" title="Link to this heading">#</a></h2>
<p>Christa Walther</p>
<p>Published 2025-04-07</p>
<p>Licensed CC-BY-4.0</p>
<p>This document reports on the first in-person workshop supported by GloBIAS. Each session has its own chapter provided by the people chairing the sessions, summarising the outputs achieved. </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15168241">https://zenodo.org/records/15168241</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15168241">https://doi.org/10.5281/zenodo.15168241</a></p>
</section>
<hr class="docutils" />
<section id="global-bioimaging-training-database">
<h2>Global BioImaging Training Database<a class="headerlink" href="#global-bioimaging-training-database" title="Link to this heading">#</a></h2>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Collection, Event</p>
<p><a class="reference external" href="https://globalbioimaging.org/international-training-courses">https://globalbioimaging.org/international-training-courses</a></p>
</section>
<hr class="docutils" />
<section id="global-bioimaging-youtube-channel">
<h2>Global BioImaging YouTube channel<a class="headerlink" href="#global-bioimaging-youtube-channel" title="Link to this heading">#</a></h2>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Collection, Video</p>
<p><a class="reference external" href="https://www.youtube.com/GlobalBioImaging">https://www.youtube.com/GlobalBioImaging</a></p>
</section>
<hr class="docutils" />
<section id="go-nuclear-a-deep-learning-based-toolkit-for-3d-nuclei-segmentation-and-quantitative-analysis-in-cellular-and-tissue-context">
<h2>Go-Nuclear. A deep learning-based toolkit for 3D nuclei segmentation and quantitative analysis in cellular and tissue context<a class="headerlink" href="#go-nuclear-a-deep-learning-based-toolkit-for-3d-nuclei-segmentation-and-quantitative-analysis-in-cellular-and-tissue-context" title="Link to this heading">#</a></h2>
<p>Kay Schneitz, Athul Vijayan, Tejasvinee Mody</p>
<p>Published 2024-06-29</p>
<p>Licensed CC0-1.0</p>
<p>We present computational tools that allow versatile and accurate 3D nuclear segmentation in plant organs, enable the analysis of cell-nucleus geometric relationships, and improve the accuracy of 3D cell segmentation. This biostudies submission includes Arabidopsis ovule model training dataset used in the study. The training dataset is composed of strong and weak nuclei image channels, corresponding ground truth segmentation, cell wall image and associated cell segmentation mentioned in the study. Trained models from the study, a total of 47 trained models are made available from this study. This included 15 initial models, 30 gold models, and 2 platinum models. Models were trained using PlantSeg, Stardist and Cellpose. All image datasets and its segmentation as part of the figures in this study is also available as separate zip files. This includes image dataset from different species and organs as listed below.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://www.ebi.ac.uk/bioimage-archive/galleries/ai/analysed-dataset/S-BIAD1026/">https://www.ebi.ac.uk/bioimage-archive/galleries/ai/analysed-dataset/S-BIAD1026/</a></p>
</section>
<hr class="docutils" />
<section id="ground-truth-cell-body-segmentation-used-for-starfinity-training">
<h2>Ground-truth cell body segmentation used for Starfinity training<a class="headerlink" href="#ground-truth-cell-body-segmentation-used-for-starfinity-training" title="Link to this heading">#</a></h2>
<p>Yuhan Wang, Martin Weigert, Uwe Schmidt, Stephan Saalfeld, Eugene W. Myers, Tim Wang, Karel Svoboda, Mark Eddison, Greg Fleishman, Shengjin Xu, Fredrick E. Henry, Andrew L. Lemire, Hui Yang, Konrad Rokicki, Cristian Goina, Eugene W Myers, Wyatt Korff, Scott M. Sternson, Paul W. Tillberg</p>
<p>Published 2021-03-05</p>
<p>Licensed CC-BY-4.0</p>
<p>Accurate segmentation of volumetric fluorescence image data has been a long-standing challenge and it can considerably degrade the accuracy of multiplexed fluorescence in situ hybridization (FISH) analysis. To overcome this challenge, we developed a deep learning-based automatic 3D segmentation algorithm, called Starfinity. It first predicts its cell center probability and its radial distances to the nearest cell borders for each pixel. It then aggregates pixel affinity maps from the densely predicted distances and applies a watershed segmentation on the affinity maps using the thresholded center probability as seeds.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://janelia.figshare.com/articles/dataset/Ground-truth_cell_body_segmentation_used_for_Starfinity_training/13624268">https://janelia.figshare.com/articles/dataset/Ground-truth_cell_body_segmentation_used_for_Starfinity_training/13624268</a></p>
</section>
<hr class="docutils" />
<section id="gut-analysis-toolbox">
<h2>Gut Analysis Toolbox<a class="headerlink" href="#gut-analysis-toolbox" title="Link to this heading">#</a></h2>
<p>Luke Sorensen, Ayame Saito, Sabrina Poon, Noe Han, Myat, Ryan Hamnett, Peter Neckel, Adam Humenick, Keith Mutunduwe, Christie Glennan, Narges Mahdavian, JH Brookes, Simon, M McQuade, Rachel, PP Foong, Jaime, Estibaliz Gómez-de-Mariscal, Muñoz Barrutia, Arrate, Kaltschmidt, Julia A., King, Sebastian K., Robert Haase, Simona Carbone, A. Veldhuis, Nicholas, P. Poole, Daniel, Pradeep Rajasekhar</p>
<p>Published 2025-07-24</p>
<p>Licensed BSD-3-CLAUSE</p>
<p>Reverted to StarDist for neuron segmentation. Used this bugfix for stardist plugin issue. protobuf-java-3.23.4.jar is being shipped as part of GAT update site.
Added StarDist models back and removed deepimageJ models for neuron segmentation
Updated documentation website to use a stable Fiji download: <a class="reference external" href="https://gut-analysis-toolbox.gitbook.io/docs#installation-and-configuration">https://gut-analysis-toolbox.gitbook.io/docs#installation-and-configuration</a></p>
<p>Full Changelog: <a class="reference external" href="https://github.com/pr4deepr/GutAnalysisToolbox/compare/v1.0...v1.1">https://github.com/pr4deepr/GutAnalysisToolbox/compare/v1.0…v1.1</a></p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16396219">https://zenodo.org/records/16396219</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16396219">https://doi.org/10.5281/zenodo.16396219</a></p>
</section>
<hr class="docutils" />
<section id="gut-analysis-toolbox-training-data-and-2d-models-for-segmenting-enteric-neurons-neuronal-subtypes-and-ganglia">
<h2>Gut Analysis Toolbox: Training data and 2D models for segmenting enteric neurons, neuronal subtypes and ganglia<a class="headerlink" href="#gut-analysis-toolbox-training-data-and-2d-models-for-segmenting-enteric-neurons-neuronal-subtypes-and-ganglia" title="Link to this heading">#</a></h2>
<p>Luke Sorensen, Ayame Saito, Sabrina Poon, Myat Noe Han, Adam Humenick, Peter Neckel, Keith Mutunduwe, Christie Glennan, Narges Mahdavian, Simon JH Brookes, Rachel M McQuade, Jaime PP Foong, Sebastian K. King, Estibaliz  Gómez-de-Mariscal, Arrate Muñoz-Barrutia, Robert Haase, Simona Carbone, Nicholas A. Veldhuis, Daniel P. Poole, Pradeep Rajasekhar</p>
<p>Published 2025-05-01</p>
<p>Licensed CC-BY-4.0</p>
<p>This upload is associated with the software, Gut Analysis Toolbox (GAT).
If you use it please cite:
Sorensen et al. Gut Analysis Toolbox: Automating quantitative analysis of enteric neurons. J Cell Sci 2024; jcs.261950. doi: <a class="reference external" href="https://doi.org/10.1242/jcs.261950">https://doi.org/10.1242/jcs.261950</a>
The upload contains StarDist models for segmenting enteric neurons in 2D, enteric neuronal subtypes in 2D and FPN+ResNet101 model for enteric ganglia in 2D in gut wholemount tissue. GAT is implemented in Fiji, but the models can be used in any software that supports StarDist and the use of 2D UNet models. The files here also consist of Python notebooks (Google Colab), training and test data as well as reports on model performance.
Note: The enteric ganglia model is has been updated to v3 which uses pytorch and is a different architecture (FPN+ResNet101).
The model files are located in the respective folders as zip files. The folders have also been zipped:</p>
<p>Neuron (Hu; StarDist model):</p>
<p>Main folder: 2D_enteric_neuron_model_QA.zip
StarDist Model File:2D_enteric_neuron_v4_1.zip 
DeepImageJ compatible model: 2D_enteric_neuron.bioimage.io.model.zip (used currently in GAT)</p>
<p>Neuronal subtype (StarDist model): </p>
<p>Main folder: 2D_enteric_neuron_subtype_model_QA.zip
Model File: 2D_enteric_neuron_subtype_v4.zip
DeepImageJ compatible model: 2D_enteric_neuron_subtype.bioimage.io.model.zip (used currently in GAT)</p>
<p>Enteric ganglia (2D FPN_ResNet101; Use in FIJI with deepImageJ)</p>
<p>Main folder: 2D_enteric_ganglia_v3_training.zip
Model File: 2D_Ganglia_RGB_v3.bioimage.io.model.zip (used currently in GAT)</p>
<p>For the all models, files included are:</p>
<p>Model for segmenting cells or ganglia in 2D FIJI. StarDist or 2D UNet.
Training and Test datasets used for training.
Google Colab notebooks used for training and quality assurance (ZeroCost DL4Mic notebooks).
Python notebook and code for training ganglia model with QA.
Quality assurance reports generated from above notebooks.
StarDist model exported for use in QuPath.</p>
<p>The model files can be used within can be used within the software, StarDist. They are intended to be used within FIJI or QuPath, but can be used in any software that supports the implementation of StarDist in 2D.
Data:
All the images were collected from 4 different research labs and a public database (SPARC database) to account for variations in image acquisition, sample preparation and immunolabelling.
For enteric neurons the pan-neuronal marker, Hu has been used and the  2D wholemounts images from mouse, rat and human tissue.
For enteric neuronal subtypes, 2D images for nNOS, MOR, DOR, ChAT, Calretinin, Calbindin, Neurofilament, CGRP and SST from mouse tissue have been used..
25 images were used from the following entries in the SPARC database:</p>
<p>Howard, M. (2021). 3D imaging of enteric neurons in mouse (Version 1) [Data set]. SPARC Consortium.
Graham, K. D., Huerta-Lopez, S., Sengupta, R., Shenoy, A., Schneider, S., Wright, C. M., Feldman, M., Furth, E., Lemke, A., Wilkins, B. J., Naji, A., Doolin, E., Howard, M., &amp; Heuckeroth, R. (2020). Robust 3-Dimensional visualization of human colon enteric nervous system without tissue sectioning (Version 1) [Data set]. SPARC Consortium.
Wang, L., Yuan, P.-Q., Gould, T. and Tache, Y. (2021). Antibodies Tested in theColon – Mouse (Version 1) [Data set]. SPARC Consortium. doi:10.26275/i7dl-58h</p>
<p>Additional images for new ganglia model:</p>
<p>Hamnett, R., Dershowitz, L. B., Sampathkumar, V., Wang, Z., Gomez-Frittelli, J., De Andrade, V., Kasthuri, N., Druckmann, S. and Kaltschmidt, J. A. (2022b). Regional cytoarchitecture of the adult and developing mouse enteric nervous system. Curr. Biol. 32, 4483-4492.e5.</p>
<p>The images have been acquired using a combination different microscopes. The images for the mouse tissue were acquired using: </p>
<p>Leica TCS-SP8 confocal system (20x HC PL APO NA 1.33, 40 x HC PL APO NA 1.3) </p>
<p>Leica TCS-SP8 lightning confocal system (20x HC PL APO NA 0.88) </p>
<p>Zeiss Axio Imager M2 (20X HC PL APO NA 0.3) </p>
<p>Zeiss Axio Imager Z1 (10X HC PL APO NA 0.45) </p>
<p>Human tissue images were acquired using: </p>
<p>IX71 Olympus microscope (10X HC PL APO NA 0.3) </p>
<p>For more information, visit the Documentation website.
NOTE: The images for enteric neurons and neuronal subtypes have been rescaled to 0.568 µm/pixel for mouse and rat. For human neurons, it has been rescaled to 0.9 µm/pixel . This is to ensure the neuronal cell bodies have similar pixel area across images. The area of cells in pixels can vary based on resolution of image, magnification of objective used, animal species (larger animals -&gt; larger neurons) and potentially how the tissue is stretched during wholemount preparation 
Average neuron area for neuronal model: 701.2 ± 195.9 pixel2 (Mean ± SD, 6267 cells)
Average neuron area for neuronal subtype model: 880.9 ± 316 pixel2 (Mean ± SD, 924 cells)
Software References:
Stardist
Schmidt, U., Weigert, M., Broaddus, C., &amp; Myers, G. (2018, September). Cell detection with star-convex polygons. In International Conference on Medical Image Computing and Computer-Assisted Intervention (pp. 265-273). Springer, Cham.
deepImageJ
Gómez-de-Mariscal, E., García-López-de-Haro, C., Ouyang, W., Donati, L., Lundberg, E., Unser, M., Muñoz-Barrutia, A. and Sage, D., 2021. DeepImageJ: A user-friendly environment to run deep learning models in ImageJ. Nature Methods, 18(10), pp.1192-1195.
ZeroCost DL4Mic
von Chamier, L., Laine, R.F., Jukkala, J., Spahn, C., Krentzel, D., Nehme, E., Lerche, M., Hernández-Pérez, S., Mattila, P.K., Karinou, E. and Holden, S., 2021. Democratising deep learning for microscopy with ZeroCostDL4Mic. Nature communications, 12(1), pp.1-18.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15314214">https://zenodo.org/records/15314214</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15314214">https://doi.org/10.5281/zenodo.15314214</a></p>
</section>
<hr class="docutils" />
<section id="hpa-nucleus-segmentation-dpnunet">
<h2>HPA Nucleus Segmentation (DPNUnet)<a class="headerlink" href="#hpa-nucleus-segmentation-dpnunet" title="Link to this heading">#</a></h2>
<p>Hao Xu, Wei Ouyang</p>
<p>Published 2023-03-02</p>
<p>Licensed CC-BY-4.0</p>
<p>Download RDF Package</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/7690494">https://zenodo.org/records/7690494</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7690494">https://doi.org/10.5281/zenodo.7690494</a></p>
</section>
<hr class="docutils" />
<section id="ht1080wt-cells-embedded-in-3d-collagen-type-i-matrices-manual-annotations-for-cell-instance-segmentation-and-tracking">
<h2>HT1080WT cells embedded in 3D collagen type I matrices - manual annotations for cell instance segmentation and tracking<a class="headerlink" href="#ht1080wt-cells-embedded-in-3d-collagen-type-i-matrices-manual-annotations-for-cell-instance-segmentation-and-tracking" title="Link to this heading">#</a></h2>
<p>Estibaliz Gómez-de-Mariscal, Hasini Jayatilaka, Denis Wirtz, Arrate Muñoz-Barrutia</p>
<p>Published 2021-12-13</p>
<p>Licensed CC-BY-4.0</p>
<p>Human fibrosarcoma HT1080WT (ATCC) cells at low cell densities embedded in 3D collagen type I matrices [1]. The time-lapse videos were recorded every 2 minutes for 16.7 hours and covered a field of view of 1002 pixels × 1004 pixels with a pixel size of 0.802 μm/pixel The videos were pre-processed to correct frame-to-frame drift artifacts, resulting in a final size of 983 pixels × 985 pixels pixels.</p>
<p>Hasini Jayatilaka, Anjil Giri, Michelle Karl, Ivie Aifuwa, Nicholaus J Trenton, Jude M Phillip, Shyam Khatau, and Denis Wirtz. EB1 and cytoplasmic dynein mediate protrusion dynamics for efficient 3-dimensional cell migration. FASEB J., 32(3):1207–1221, 2018. ISSN 0892-6638. doi: 10.1096/fj.201700444RR.</p>
<p>Further information about how to use this data is given in <a class="github reference external" href="https://github.com/esgomezm/microscopy-dl-suite-tf">esgomezm/microscopy-dl-suite-tf</a></p>
<p>This dataset is provided together with the following preprint and if you use it, we would like to kindly ask you to cite it properly:</p>
<p>Estibaliz Gómez-de-Mariscal, Hasini Jayatilaka, Özgün Çiçek, Thomas Brox, Denis Wirtz, Arrate Muñoz-Barrutia, <em>Search for temporal cell segmentation robustness in phase-contrast microscopy videos</em>, arXiv 2021 (arXiv:2112.08817)</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/5979761">https://zenodo.org/records/5979761</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5979761">https://doi.org/10.5281/zenodo.5979761</a></p>
</section>
<hr class="docutils" />
<section id="hackaton-results-conversion-of-knime-image-analysis-workflows-to-galaxy">
<h2>Hackaton Results - Conversion of KNIME image analysis workflows to Galaxy<a class="headerlink" href="#hackaton-results-conversion-of-knime-image-analysis-workflows-to-galaxy" title="Link to this heading">#</a></h2>
<p>Riccardo Massei</p>
<p>Published 2024-03-07</p>
<p>Licensed CC-BY-4.0</p>
<p>Results of the project “Conversion of KNIME image analysis workflows to Galaxy” during the Hackathon “Image Analysis in Galaxy” (Freiburg 26 Feb - 01 Mar 2024)
 </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/10793700">https://zenodo.org/records/10793700</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10793700">https://doi.org/10.5281/zenodo.10793700</a></p>
</section>
<hr class="docutils" />
<section id="harmonizing-the-generation-and-pre-publication-stewardship-of-fair-image-data">
<h2>Harmonizing the Generation and Pre-publication Stewardship of FAIR Image Data<a class="headerlink" href="#harmonizing-the-generation-and-pre-publication-stewardship-of-fair-image-data" title="Link to this heading">#</a></h2>
<p>Nikki Bialy, Frank Alber, Brenda Andrews, Michael Angelo, Brian Beliveau, Lacramioara Bintu, Alistair Boettiger, Ulrike Boehm, Claire M. Brown, Mahmoud Bukar Maina, James J. Chambers, Beth A. Cimini, Kevin Eliceiri, Rachel Errington, Orestis Faklaris, Nathalie Gaudreault, Ronald N. Germain, Wojtek Goscinski, David Grunwald, Michael Halter, Dorit Hanein, John W. Hickey, Judith Lacoste, Alex Laude, Emma Lundberg, Jian Ma, Leonel Malacrida, Josh Moore, Glyn Nelson, Elizabeth Kathleen Neumann, Roland Nitschke, Shuichi Onami, Jaime A. Pimentel, Anne L. Plant, Andrea J. Radtke, Bikash Sabata, Denis Schapiro, Johannes Schöneberg, Jeffrey M. Spraggins, Damir Sudar, Wouter-Michiel Adrien Maria Vierdag, Niels Volkmann, Carolina Wählby, Siyuan (Steven)Wang, Ziv Yaniv, Caterina Strambio-De-Castillia</p>
<p>Published 2024-08-30</p>
<p>Licensed CC-BY-NC-SA-4.0 INTERNATIONAL</p>
<p>Together with the molecular knowledge of genes and proteins, biological images promise to significantly enhance the scientific understanding of complex cellular systems and to advance predictive and personalized therapeutic products for human health. For this potential to be realized, quality-assured image data must be shared among labs at a global scale to be compared, pooled, and reanalyzed, thus unleashing untold potential beyond the original purpose for which the data was generated.</p>
<p>Tags: Research Data Management, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://arxiv.org/abs/2401.13022">https://arxiv.org/abs/2401.13022</a></p>
</section>
<hr class="docutils" />
<section id="hela-kyoto-cells-under-the-scope">
<h2>HeLa “Kyoto” cells under the scope<a class="headerlink" href="#hela-kyoto-cells-under-the-scope" title="Link to this heading">#</a></h2>
<p>Romain Guiet</p>
<p>Published 2022-02-25</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: HeLa “Kyoto” cells under the scope</p>
<p>Microscope: Perkin Elmer Operetta microscope with a 20x N.A. 0.8 objective and an Andor Zyla 5.5 camera.</p>
<p>Microscopy data type: The time-lapse datasets were acquired every 15 minutes, for 60 hours. From the individual plan images (channels, time-points, field of view exported by the PerkinElmer software Harmony) multi-dimension images were generated using the Operetta_Importer-0.1.21  with a downscaling of 4. </p>
<p>Channel 1 : Low Contrast DPC (Digital Phase Contrast)</p>
<p>Channel 2 : High Contrast DPC</p>
<p>Channel 3 : Brightfield</p>
<p>Channel 4 : EGFP-α-tubulin</p>
<p>Channel 5 : mCherry-H2B</p>
<p>File format: .tif (16-bit)</p>
<p>Image size: 540x540 (Pixel size: 0.299 nm), 5c, 1z , 240t</p>
<p> </p>
<p>Cell type: HeLa “Kyoto” cells, expressing EGFP-α-tubulin and mCherry-H2B ( Schmitz et al, 2010 )</p>
<p>Protocol: Cells were resuspended in Imaging media and were seeded in a microscopy grade 96 wells plate ( CellCarrier Ultra 96, Perkin Elmer). The day after seeding, and for 60 hours, images were acquired in 3 wells, in 25 different fields of view, every 15 minutes.</p>
<p>Imaging media: DMEM red-phenol-free media (FluoroBrite™ DMEM, Gibco) complemented with Fetal Calf Serum and Glutamax.</p>
<p> </p>
<p>NOTE: This dataset was used to automatically generate label images in the following Zenodo entry:  <a class="reference external" href="https://doi.org/10.5281/zenodo.6140064">https://doi.org/10.5281/zenodo.6140064</a></p>
<p>NOTE: This dataset was used to train the cellpose models in the following Zenodo entry: <a class="reference external" href="https://doi.org/10.5281/zenodo.6140111">https://doi.org/10.5281/zenodo.6140111</a></p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/6139958">https://zenodo.org/records/6139958</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6139958">https://doi.org/10.5281/zenodo.6139958</a></p>
</section>
<hr class="docutils" />
<section id="hitchhiking-through-a-diverse-bio-image-analysis-software-universe">
<h2>Hitchhiking through a diverse Bio-image Analysis Software Universe<a class="headerlink" href="#hitchhiking-through-a-diverse-bio-image-analysis-software-universe" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2022-07-22</p>
<p>Licensed CC-BY-4.0</p>
<p>Overview about decision making and how to influence decisions in the bio-image analysis software context.</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Slides, Presentation</p>
<p><a class="reference external" href="https://f1000research.com/slides/11-746">https://f1000research.com/slides/11-746</a></p>
<p><a class="reference external" href="https://doi.org/10.7490/f1000research.1119026.1">https://doi.org/10.7490/f1000research.1119026.1</a></p>
</section>
<hr class="docutils" />
<section id="how-open-source-software-could-finally-get-the-worlds-microscopes-speaking-the-same-language">
<h2>How open-source software could finally get the world’s microscopes speaking the same language<a class="headerlink" href="#how-open-source-software-could-finally-get-the-worlds-microscopes-speaking-the-same-language" title="Link to this heading">#</a></h2>
<p>Michael Brooks</p>
<p>Published 2023-10-02</p>
<p>Licensed UNKNOWN</p>
<p>A plethora of standards mean shareable and verifiable microscopy data often get lost in translation. Biologists are working on a solution.</p>
<p>Tags: Research Data Management, Microscopy, Exclude From Dalia</p>
<p>Content type: Blog Post</p>
<p><a class="reference external" href="https://www.nature.com/articles/d41586-023-03064-9">https://www.nature.com/articles/d41586-023-03064-9</a></p>
</section>
<hr class="docutils" />
<section id="how-to-get-started-with-jupyter-and-colab">
<h2>How to get started with Jupyter and Colab<a class="headerlink" href="#how-to-get-started-with-jupyter-and-colab" title="Link to this heading">#</a></h2>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Video</p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=OH3VKI7ErAE">https://www.youtube.com/watch?v=OH3VKI7ErAE</a></p>
</section>
<hr class="docutils" />
<section id="how-to-make-cartographic-projections-using-imsane">
<h2>How to make cartographic projections using ImSAnE<a class="headerlink" href="#how-to-make-cartographic-projections-using-imsane" title="Link to this heading">#</a></h2>
<p>Vellutini, Bruno C.</p>
<p>Published 2022-03-29</p>
<p>Licensed GPL-2.0</p>
<p>This tutorial shows how to make cartographic projections of fly embryos using the ImSAnE Toolbox (Heemskerk and Streichan 2015).</p>
<p>Instructions: download and open the imsane-tutorial.html file on your browser.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/7628300">https://zenodo.org/records/7628300</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7628300">https://doi.org/10.5281/zenodo.7628300</a></p>
</section>
<hr class="docutils" />
<section id="human-dab-staining-axioscan-bf-20x">
<h2>Human DAB staining Axioscan BF 20x<a class="headerlink" href="#human-dab-staining-axioscan-bf-20x" title="Link to this heading">#</a></h2>
<p>Mario Garcia</p>
<p>Published 2024-05-21</p>
<p>Licensed CC-BY-4.0</p>
<p>Human brain tissue with DAB immunostaining. Image acquired by BF microscopy in  Zeiss Axioscan at 20x. </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/11234863">https://zenodo.org/records/11234863</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11234863">https://doi.org/10.5281/zenodo.11234863</a></p>
</section>
<hr class="docutils" />
<section id="human-ht29-colon-cancer-cells">
<h2>Human HT29 colon-cancer cells<a class="headerlink" href="#human-ht29-colon-cancer-cells" title="Link to this heading">#</a></h2>
<p>Vebjorn Ljosa, Katherine L. Sokolnicki, Anne E. Carpenter</p>
<p>Published 2012-06-28</p>
<p>Licensed CC-BY-NC-SA-3.0</p>
<p>These images are of human HT29 colon cancer cells, a cell line that has been widely used for the study of many normal and neoplastic processes. A set of about 43,000 such images was used by Moffat et al. (Cell, 2006) to screen for mitotic regulators. The analysis followed the common pattern of identifying and counting cells with a phenotype of interest (in this case, cells that were in mitosis), then normalizing the count by dividing by the total number of cells. Such experiments present two image analysis problems. First, identifying the cells that have the phenotype of interest requires that the nuclei and cells be segmented. Second, normalizing requires an accurate cell count.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://bbbc.broadinstitute.org/BBBC008">https://bbbc.broadinstitute.org/BBBC008</a></p>
</section>
<hr class="docutils" />
<section id="human-hepatocyte-and-murine-fibroblast-cells-co-culture-experiment">
<h2>Human Hepatocyte and Murine Fibroblast cells Co-culture experiment<a class="headerlink" href="#human-hepatocyte-and-murine-fibroblast-cells-co-culture-experiment" title="Link to this heading">#</a></h2>
<p>David J. Logan, Jing Shan, Sangeeta N. Bhatia, Anne E. Carpenter</p>
<p>Published 2016-03-01</p>
<p>Licensed CC-BY-3.0</p>
<p>This 384-well plate has images of co-cultured hepatocytes and fibroblasts. Every other well is populated (A01, A03, …, C01, C03, …) such that 96 wells comprise the data. Each well has 9 sites and thus 9 images associated, totaling 864 images.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://bbbc.broadinstitute.org/BBBC026">https://bbbc.broadinstitute.org/BBBC026</a></p>
</section>
<hr class="docutils" />
<section id="human-lung-tissue-microscopy-dic-fluorescence-cell-and-nuclei-semantic-instance-annotations">
<h2>Human Lung Tissue Microscopy (DIC, Fluorescence, Cell and Nuclei Semantic Instance Annotations)<a class="headerlink" href="#human-lung-tissue-microscopy-dic-fluorescence-cell-and-nuclei-semantic-instance-annotations" title="Link to this heading">#</a></h2>
<p>Melanie Dohmen, Mirja Mittermaier, Andreas Hocke</p>
<p>Published 2024-02-22</p>
<p>The zip file contains 3 folders (annotations, images and training_splits).The annotation folder contains 3 folders (cell_instances, nuclei_instances and semantic). Cell and nuclei instance annotations are long int tif images, containing numbered instance ids and 0 in the background. Semantic annotations are 8-bit int png files containing the class ids (0: background, 1: normal tissue, 2: erythrocytes, 3: alveolar epithelial type 2 cells, 4: alveolar macrophages, 5: other nuclei, 6: alveolar epithelial type 2 cell nuclei, 7: alveolar macrophage nuclei, 8: cell debris).
The image folder contains 4 folders (CD68, DAPI, DIC, proSPC), where DIC contains float valued background-corrected differential interference contrast images, the others contain normalized float-valued fluorescence channels of a multi-plex staining with CD-68 (whole alveolar macrophages), DAPI (any cell nuclei), proSPC (cytoplasm of alveolar epithelial type 2 cell). All images are in tif format.
The training split folder contains 3 text files, with the image prefix (compared to images and annotations without ending, i.e. e.g. without “_DIC.tif”) of all cases in the respective subset. With a total of 68 cases, there are 51 cases in the train set, 7 cases in the validation set and 10 cases in the test set.The lung tissue origins from lung surgery of patients, but does not include resected tumors. Please see reference [1]. The images were acquired with a laser scanning microscope with 40x magnification and 1024 x 1024 pixels per image.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/10669918">https://zenodo.org/records/10669918</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10669918">https://doi.org/10.5281/zenodo.10669918</a></p>
</section>
<hr class="docutils" />
<section id="human-u2os-cells-out-of-focus">
<h2>Human U2OS cells (out of focus)<a class="headerlink" href="#human-u2os-cells-out-of-focus" title="Link to this heading">#</a></h2>
<p>Vebjorn Ljosa, Katherine L. Sokolnicki, Anne E. Carpenter</p>
<p>Published 2012-06-28</p>
<p>Licensed CC0-1.0</p>
<p>Since robust foreground/background separation and segmentation of cellular objects (i.e., identification of which pixels below to which objects) strongly depends on image quality, focus artifacts are detrimental to data quality. This image set provides examples of in- and out-of-focus HCS images which can be used for validation of focus metrics.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://bbbc.broadinstitute.org/BBBC006">https://bbbc.broadinstitute.org/BBBC006</a></p>
</section>
<hr class="docutils" />
<section id="i3d-bio-information-infrastructure-for-bioimage-data-bioimage-metadata">
<h2>I3D bio – Information Infrastructure for BioImage Data - Bioimage Metadata<a class="headerlink" href="#i3d-bio-information-infrastructure-for-bioimage-data-bioimage-metadata" title="Link to this heading">#</a></h2>
<p>Christian Schmidt</p>
<p>Licensed UNKNOWN</p>
<p>A Microscopy Research Data Management Resource.</p>
<p>Tags: Metadata, I3Dbio, Research Data Management, Exclude From Dalia</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://gerbi-gmb.de/i3dbio/i3dbio-rdm/i3dbio-bioimage-metadata/">https://gerbi-gmb.de/i3dbio/i3dbio-rdm/i3dbio-bioimage-metadata/</a></p>
</section>
<hr class="docutils" />
<section id="i3d-bio-list-of-online-training-material">
<h2>I3D:bio list of online training material<a class="headerlink" href="#i3d-bio-list-of-online-training-material" title="Link to this heading">#</a></h2>
<p>Licensed UNKNOWN</p>
<p>List of links to training materials by the I3D:bio community.</p>
<p>Tags: Research Data Management, Exclude From Dalia</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://gerbi-gmb.de/i3dbio/i3dbio-teaching/train-mat/bioimagelist/">https://gerbi-gmb.de/i3dbio/i3dbio-teaching/train-mat/bioimagelist/</a></p>
</section>
<hr class="docutils" />
<section id="ics-ids-stitched-file">
<h2>ICS/IDS stitched file<a class="headerlink" href="#ics-ids-stitched-file" title="Link to this heading">#</a></h2>
<p>IMCF</p>
<p>Published 2024-06-13</p>
<p>Licensed CC-BY-4.0</p>
<p>Hi &#64;ome team !
We usually use ICS/IDS file formats as an output to our stitching pipeline as the reading and writing is pretty fast. However, it seems that since Bio-Formats 7.x opening the files is not working anymore.
I tried with a Fiji with Bio-Formats 6.10.1 and the files open, but more recent versions give an issue.
 
java.lang.NullPointerException
at loci.formats.in.ICSReader.initFile(ICSReader.java:1481)
at loci.formats.FormatReader.setId(FormatReader.java:1480)
at loci.plugins.in.ImportProcess.initializeFile(ImportProcess.java:498)
at loci.plugins.in.ImportProcess.execute(ImportProcess.java:141)
at loci.plugins.in.Importer.showDialogs(Importer.java:156)
at loci.plugins.in.Importer.run(Importer.java:77)
at loci.plugins.LociImporter.run(LociImporter.java:78)
at ij.IJ.runUserPlugIn(IJ.java:244)
at ij.IJ.runPlugIn(IJ.java:210)
at ij.Executer.runCommand(Executer.java:152)
at ij.Executer.run(Executer.java:70)
at ij.IJ.run(IJ.java:326)
at ij.IJ.run(IJ.java:337)
at ij.macro.Functions.doRun(Functions.java:703)
at ij.macro.Functions.doFunction(Functions.java:99)
at ij.macro.Interpreter.doStatement(Interpreter.java:281)
at ij.macro.Interpreter.doStatements(Interpreter.java:267)
at ij.macro.Interpreter.run(Interpreter.java:163)
at ij.macro.Interpreter.run(Interpreter.java:93)
at ij.macro.MacroRunner.run(MacroRunner.java:146)
at java.lang.Thread.run(Thread.java:750)</p>
<p>You can find one example file at this link 1.
Thanks for your help !Best,Laurent</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/11637422">https://zenodo.org/records/11637422</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11637422">https://doi.org/10.5281/zenodo.11637422</a></p>
</section>
<hr class="docutils" />
<section id="itkelastix-examples">
<h2>ITKElastix Examples<a class="headerlink" href="#itkelastix-examples" title="Link to this heading">#</a></h2>
<p>Licensed APACHE-2.0</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p><a class="github reference external" href="https://github.com/InsightSoftwareConsortium/ITKElastix/tree/main/examples">InsightSoftwareConsortium/ITKElastix</a></p>
</section>
<hr class="docutils" />
<section id="ibiology-bioimage-analysis-course-the-life-cycle-of-an-image-data-set">
<h2>Ibiology. Bioimage Analysis Course. The Life Cycle of an Image Data Set<a class="headerlink" href="#ibiology-bioimage-analysis-course-the-life-cycle-of-an-image-data-set" title="Link to this heading">#</a></h2>
<p>Licensed CC BY-NC-ND 3.0 DEED</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Collection, Video</p>
<p><a class="reference external" href="https://www.ibiology.org/online-biology-courses/bioimage-analysis-course/">https://www.ibiology.org/online-biology-courses/bioimage-analysis-course/</a></p>
</section>
<hr class="docutils" />
<section id="image-data-resources">
<h2>Image Data Resources<a class="headerlink" href="#image-data-resources" title="Link to this heading">#</a></h2>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Collection, Data, Publication</p>
<p><a class="reference external" href="https://idr.openmicroscopy.org/">https://idr.openmicroscopy.org/</a></p>
<p><a class="reference external" href="https://www.nature.com/articles/nmeth.4326">https://www.nature.com/articles/nmeth.4326</a></p>
</section>
<hr class="docutils" />
<section id="image-data-services-at-euro-bioimaging-community-efforts-towards-fair-image-data-and-analysis-services">
<h2>Image Data Services at Euro-BioImaging: Community efforts towards FAIR Image Data and Analysis Services<a class="headerlink" href="#image-data-services-at-euro-bioimaging-community-efforts-towards-fair-image-data-and-analysis-services" title="Link to this heading">#</a></h2>
<p>Aastha Mathur</p>
<p>Licensed UNKNOWN</p>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://docs.google.com/presentation/d/1henPIDTpHT3bc1Y26AltItAHJ2C5xCOl/edit#slide=id.p1">https://docs.google.com/presentation/d/1henPIDTpHT3bc1Y26AltItAHJ2C5xCOl/edit#slide=id.p1</a></p>
</section>
<hr class="docutils" />
<section id="image-analysis-in-galaxy">
<h2>Image analysis in Galaxy<a class="headerlink" href="#image-analysis-in-galaxy" title="Link to this heading">#</a></h2>
<p>Beatriz Serrano-Solano, Björn Grüning</p>
<p>Licensed UNKNOWN</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://docs.google.com/presentation/d/1WG_4307XmKsGfWT3taxMvX2rZiG1k0SM1E7SAENJQkI/edit#slide=id.p">https://docs.google.com/presentation/d/1WG_4307XmKsGfWT3taxMvX2rZiG1k0SM1E7SAENJQkI/edit#slide=id.p</a></p>
</section>
<hr class="docutils" />
<section id="imagej-bioformats-8-3-0-importer-incorrectly-reading-nd2-metadata">
<h2>ImageJ Bioformats 8.3.0 Importer Incorrectly Reading ND2 Metadata<a class="headerlink" href="#imagej-bioformats-8-3-0-importer-incorrectly-reading-nd2-metadata" title="Link to this heading">#</a></h2>
<p>Snyder, Erika, Erika Thomas, Erika T.</p>
<p>Published 2025-08-21</p>
<p>Licensed CC-BY-4.0</p>
<p>Hi all,I was referred to this community from the <a class="reference external" href="http://Image.sc">Image.sc</a> Forum original post: <a class="reference external" href="https://forum.image.sc/t/imagej-bioformats-importer-incorrectly-reading-metadata/115943">https://forum.image.sc/t/imagej-bioformats-importer-incorrectly-reading-metadata/115943</a>
I have an ND2 file, 3 color channels, 2 positions in the well, and 81 timepoints. However, when I open this as I normally would in ImageJ as a hyperstack, the stack interpretation is totally incorrect. It is including my Z-positions as frames in the timelapse. Even when I open the series for the positions independently, images from the other series will appear within it. I am running Bioformats 8.3.0. 
I have tried swapping dimensions. That did not work. I have tried creating substacks to parse out one series from the other, this also did not work.
The only thing I can think of that is different from before is that I was previously aquiring z-stacks with our MCL nanodrive Piezo, and we had to have that serviced so in the meantime I used the Ti2 eclipse camera drive for z-stack aquisiton. I have opened the metadata to compare aquisitions between the two, and the stack order appears exactly the same, although Bioformats has no problem reading the metadata for aquisitions with the Piezo. I have also opened this file in NIS elements viewer, and all the information for the stacks appears correctly, so I dont think aquisitions is the issue.
I have also tried opening this file on multiple computers with multiple versions of imageJ, and the issue persists.
Any advice would be greatly appreciated I am panicking a bit because this is a few months worth of data I am suddenly not able to analyze. 
Please let me know if there’s anything else needed to help figure this out. </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16921650">https://zenodo.org/records/16921650</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16921650">https://doi.org/10.5281/zenodo.16921650</a></p>
</section>
<hr class="docutils" />
<section id="imagej-tool-for-percentage-estimation-of-pneumonia-in-lungs">
<h2>ImageJ tool for percentage estimation of pneumonia in lungs<a class="headerlink" href="#imagej-tool-for-percentage-estimation-of-pneumonia-in-lungs" title="Link to this heading">#</a></h2>
<p>Martin Schätz, Olga Rubešová, Jan Mareš, Alan Spark</p>
<p>Published 2025-07-07</p>
<p>Licensed CC-BY-4.0</p>
<p>The software tool is developed on demand of Radiological Department of Faculty Hospital of Královské Vinohrady, with the aim to provide a tool to estimate the percentage of pneumonia (or COVID-19 presence) in lungs. Paper Estimation of Covid-19 lungs damage based on computer tomography images analysis presenting the tool is available on F1000reserach DOI: 10.12688/f1000research.109020.1. The underlying dataset is published in Zenodo (DOI:10.5281/zenodo.5805939). One of the challenges was to design a tool that would be available without complicated install procedures and would process data in a reasonable time even on office computers. For this reason, 8-bit and 16-bit version of the tool exists. The FIJI software (or ImageJ with Bio-Formats plugin installed) was selected as the best candidate. Examples of use and tutorials are available at GitHub. 
The third version includes an intra-variabilty analysis, containing evaluation both for percentage and score metrics.
Underlying data:DOI:10.5281/zenodo.5805939The first five datasets are analyzed using this tool, with results and parameters to repeat the analysis in results_csv.csv or results.xlsx.
Contributions:Martin SCHÄTZ:       Coding, tool testing, data curation, data set analysisOlga RUBEŠOVÁ:    Code review, tutorial preparation, tool testing, data set analysisJan MAREŠ:             Tool testing, data set analysis, funding acquisitionAlan SPARK:             Tool testing
The work was funded by the Ministry of Education, Youth and Sports by grant ‘Development of Advanced Computational Algorithms for evaluating post-surgery rehabilitation’ number LTAIN19007. The work was also supported from the grant of Specific university research – grant No FCHI 2022-001.
 </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15827771">https://zenodo.org/records/15827771</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15827771">https://doi.org/10.5281/zenodo.15827771</a></p>
</section>
<hr class="docutils" />
<section id="images-acquired-with-zeiss-sigma-300-images-with-low-magnification-are-corrently-not-handeled-correctly">
<h2>Images acquired with Zeiss Sigma 300 - Images with low magnification are corrently not handeled correctly<a class="headerlink" href="#images-acquired-with-zeiss-sigma-300-images-with-low-magnification-are-corrently-not-handeled-correctly" title="Link to this heading">#</a></h2>
<p>Johannes Preußner</p>
<p>Published 2025-08-07</p>
<p>Licensed CC-BY-4.0</p>
<p>When using bioformats the images are not scaled correctly. The problem arises with low magnifications where the lengths in the metadata are given in µm (not in nm). Attached are two pictures. Only with the picture with the ending “Correct_scale_bar” the import is working correctly. One issue might be that the metadata information of the images are stored in iso-8859-1 </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16760282">https://zenodo.org/records/16760282</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16760282">https://doi.org/10.5281/zenodo.16760282</a></p>
</section>
<hr class="docutils" />
<section id="imaris-tutorials">
<h2>Imaris Tutorials<a class="headerlink" href="#imaris-tutorials" title="Link to this heading">#</a></h2>
<p>Licensed ALL RIGHTS RESERVED</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Collection, Video</p>
<p><a class="reference external" href="https://imaris.oxinst.com/tutorials">https://imaris.oxinst.com/tutorials</a></p>
</section>
<hr class="docutils" />
<section id="implantation-of-abdominal-imaging-windows-on-the-mouse-kidney">
<h2>Implantation of abdominal imaging windows on the mouse kidney<a class="headerlink" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-kidney" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-09-04</p>
<p>Licensed CC-BY-ND-4.0</p>
<p>This video describes the surgical process of implanting an abdominal imaging window (AIW) on the kidney of mice. This window can be used for acute or longitudinal imaging. All experiments have been reviewed and approved by the local authorities (Landesdirektion Sachsen).
Implantation of chronic abdominal windows allows for microscopical investigation of highly dynamic processes in physiological and pathological circumstances and is generally tolerated well by experimental animals. It enables insights which otherwise could only be obtained using high numbers of experimental animals. The method can be regarded as reduction approach in terms of 3R implementation.
This upload contains the full version and is distributed under CC BY-ND 4.0 license to inhibit decontextualized misuse. Please check license terms for usage, especially for remixing/transforming! If you want to remix the material, get in contact with the author.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/13682928">https://zenodo.org/records/13682928</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13682928">https://doi.org/10.5281/zenodo.13682928</a></p>
</section>
<hr class="docutils" />
<section id="implantation-of-abdominal-imaging-windows-on-the-mouse-kidney-short-version">
<h2>Implantation of abdominal imaging windows on the mouse kidney - short version<a class="headerlink" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-kidney-short-version" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-09-09</p>
<p>Licensed CC-BY-ND-4.0</p>
<p>This video describes the surgical process of implanting an abdominal imaging window (AIW) on the kidney of mice. This window can be used for acute or longitudinal imaging. All experiments have been reviewed and approved by the local authorities (Landesdirektion Sachsen).
Implantation of chronic abdominal windows allows for microscopical investigation of highly dynamic processes in physiological and pathological circumstances and is generally tolerated well by experimental animals. It enables insights which otherwise could only be obtained using high numbers of experimental animals. The method can be regarded as reduction approach in terms of 3R implementation.
This upload contains the shortened version and is distributed under CC BY-ND 4.0 license to inhibit decontextualized misuse. Please check license terms for usage, especially for remixing/transforming! If you want to remix the material, get in contact with the author.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/13736240">https://zenodo.org/records/13736240</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13736240">https://doi.org/10.5281/zenodo.13736240</a></p>
</section>
<hr class="docutils" />
<section id="implantation-of-abdominal-imaging-windows-on-the-mouse-liver">
<h2>Implantation of abdominal imaging windows on the mouse liver<a class="headerlink" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-liver" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-09-04</p>
<p>Licensed CC-BY-ND-4.0</p>
<p>This video describes the surgical process of implanting an abdominal imaging window (AIW) on the liver of mice. This window can be used for acute or longitudinal imaging. All experiments have been reviewed and approved by the local authorities (Landesdirektion Sachsen).
Implantation of chronic abdominal windows allows for microscopical investigation of highly dynamic processes in physiological and pathological circumstances and is generally tolerated well by experimental animals. It enables insights which otherwise could only be obtained using high numbers of experimental animals. The method can be regarded as reduction approach in terms of 3R implementation.
This upload contains the full version and is distributed under CC BY-ND 4.0 license to inhibit decontextualized misuse. Please check license terms for usage, especially for remixing/transforming! If you want to remix the material, get in contact with the author.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/13683167">https://zenodo.org/records/13683167</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13683167">https://doi.org/10.5281/zenodo.13683167</a></p>
</section>
<hr class="docutils" />
<section id="implantation-of-abdominal-imaging-windows-on-the-mouse-liver-short-version">
<h2>Implantation of abdominal imaging windows on the mouse liver - short version<a class="headerlink" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-liver-short-version" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-09-09</p>
<p>Licensed CC-BY-ND-4.0</p>
<p>This video describes the surgical process of implanting an abdominal imaging window (AIW) on the liver of mice. This window can be used for acute or longitudinal imaging. All experiments have been reviewed and approved by the local authorities (Landesdirektion Sachsen).
Implantation of chronic abdominal windows allows for microscopical investigation of highly dynamic processes in physiological and pathological circumstances and is generally tolerated well by experimental animals. It enables insights which otherwise could only be obtained using high numbers of experimental animals. The method can be regarded as reduction approach in terms of 3R implementation.
This upload contains the short version and is distributed under CC BY-ND 4.0 license to inhibit decontextualized misuse. Please check license terms for usage, especially for remixing/transforming! If you want to remix the material, get in contact with the author.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/13736218">https://zenodo.org/records/13736218</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13736218">https://doi.org/10.5281/zenodo.13736218</a></p>
</section>
<hr class="docutils" />
<section id="incell-datasets-with-mix-of-2d-and-3d-failed-to-be-read">
<h2>InCell datasets with mix of 2D and 3D failed to be read<a class="headerlink" href="#incell-datasets-with-mix-of-2d-and-3d-failed-to-be-read" title="Link to this heading">#</a></h2>
<p>Fabien Kuttler, Rémy Dornier</p>
<p>Published 2025-01-31</p>
<p>Licensed CC-BY-4.0</p>
<p>The provided dataset contains 2 wells, 4 fields of view, 4 channels, no T but different number of Z according to the channel</p>
<p>Cy3 : 1 Z
DAPI : 16 Z
FITC : 1 Z
Brightfield : 1 Z</p>
<p>The mix 2D/3D is not correctly supported and the .xcde file cannot be read.
A discussion thread is already open on that topic.
Bio-Formats version : 8.0.1
 </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14777242">https://zenodo.org/records/14777242</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14777242">https://doi.org/10.5281/zenodo.14777242</a></p>
</section>
<hr class="docutils" />
<section id="ink-in-a-dish">
<h2>Ink in a dish<a class="headerlink" href="#ink-in-a-dish" title="Link to this heading">#</a></h2>
<p>Cavanagh</p>
<p>Published 2024-09-03</p>
<p>Licensed CC0-1.0</p>
<p>A test data set for troublshooting. no scientific meaning.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/13642395">https://zenodo.org/records/13642395</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13642395">https://doi.org/10.5281/zenodo.13642395</a></p>
</section>
<hr class="docutils" />
<section id="insights-and-impact-from-five-cycles-of-essential-open-source-software-for-science">
<h2>Insights and Impact From Five Cycles of Essential Open Source Software for Science<a class="headerlink" href="#insights-and-impact-from-five-cycles-of-essential-open-source-software-for-science" title="Link to this heading">#</a></h2>
<p>Kate Hertweck, Carly Strasser, Dario Taraborelli</p>
<p>Licensed CC-BY-4.0</p>
<p>Open source software (OSS) is essential for advancing scientific discovery, particularly in biomedical research, yet funding to support these vital tools has been limited. The Chan Zuckerberg Initiative’s Essential Open Source Software for Science (EOSS) program has significantly contributed to this field by providing $51.8 million in funding over five years to support the maintenance, growth, and community engagement of critical OSS tools. The program has impacted scientific OSS projects by improving their technical outputs, community building, and sustainability practices, and fostering collaborations within the OSS community. Additionally, EOSS funding has enhanced diversity, equity, and inclusion within the OSS community, although changes in principal investigator demographics were not observed. The funded projects have had a substantial impact on biomedical research by improving the usability and accessibility of scientific software, which has led to increased adoption and advancements in various biomedical fields.</p>
<p>Tags: Open Source Software, Funding, Sustainability, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://zenodo.org/records/11201216">https://zenodo.org/records/11201216</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11201216">https://doi.org/10.5281/zenodo.11201216</a></p>
</section>
<hr class="docutils" />
<section id="insights-from-acquiring-open-medical-imaging-datasets-for-foundation-model-development">
<h2>Insights from Acquiring Open Medical Imaging  Datasets for Foundation Model Development<a class="headerlink" href="#insights-from-acquiring-open-medical-imaging-datasets-for-foundation-model-development" title="Link to this heading">#</a></h2>
<p>Stefan Dvoretskii</p>
<p>Published 2024-04-10</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/11503289">https://zenodo.org/records/11503289</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11503289">https://doi.org/10.5281/zenodo.11503289</a></p>
</section>
<hr class="docutils" />
<section id="id1">
<h2>Insights from Acquiring Open Medical Imaging Datasets for Foundation Model Development<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>Stefan Dvoretskii</p>
<p>Published 2024-04-10</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/13380289">https://zenodo.org/records/13380289</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13380289">https://doi.org/10.5281/zenodo.13380289</a></p>
</section>
<hr class="docutils" />
<section id="institutionalization-and-collaboration-as-a-way-of-addressing-the-challenges-open-science-presents-to-libraries-the-university-of-konstanz-as-a-national-pioneer">
<h2>Institutionalization and Collaboration as a Way of Addressing the Challenges Open Science Presents to Libraries: The University of Konstanz as a National Pioneer<a class="headerlink" href="#institutionalization-and-collaboration-as-a-way-of-addressing-the-challenges-open-science-presents-to-libraries-the-university-of-konstanz-as-a-national-pioneer" title="Link to this heading">#</a></h2>
<p>Sophie Habinger, Maximilian Heber, Sonja Kralj, Emilia Mikautsch</p>
<p>Published 2024-07-09</p>
<p>Licensed CC-BY-4.0</p>
<p>The rise of Open Science (OS) and the academic community’s needs that come with it bring about a range of challenges for academic libraries. To face these challenges, the University of Konstanz has created a competence unit called Team Open Science in the Communication, Information, Media Center (KIM) - a joint unit of library and IT infrastructure. The Team creates synergies within itself and across the library. In December 2023, it involved 12 staff members specialising in open access (OA), research data management (RDM), open educational resources (OER) and virtual research environments (VRE). It collaborates closely with other KIM departments. This submission shall serve as a best practice example for the impact of OS on research libraries and, beyond that, the impact of research libraries on universities.
To enhance and foster OS, the Team provides individual consultations, services and office hours for researchers. Here, it collaborates closely with other librarians like subject specialists and the Team University Publications. Along similar lines, the KIM offers institutional repositories for publications (KOPS) and research data (KonDATA). Beyond that, the Team provides solutions to host OA journals and analyses researchers’ VRE needs to decide on implementation options. In sum, the Team is the central OS contact point for the entire university, underlining the major role the library holds in making institutional impact.
Furthermore, the Team had the leading role in creating the University of Konstanz’ OS Policy, one of the first ones passed by a German university. This policy stands out because it encompasses various OS domains. It demands, among other things, that text publications be made OA and that research data be managed according to relevant subject-specific standards. If permissible and reasonable, it demands that research data should be made publicly available at the earliest possible time. Along these lines, the policy has a large impact on how the library handles closed access books and subscription-based journals. As a consequence, OA is pursued wherever possible, leading to the highest OA quota of all German universities. In that sense, the Team is a crucial driving force of OS in the University of Konstanz, which ties in with the library’s major role of open research transformation.
Beyond the University of Konstanz, the Team is involved in a range of national and international projects collaborating with other libraries. On a national level, they lead the project open.access-network which provides an information platform for researchers and librarians and connects the German-speaking OA community through events like bar camps. The project KOALA-AV supports libraries in establishing consortial solutions for financing Diamond OA publications. Moreover, the Team is involved in the federal state initiative for RDM in Baden-Württemberg (bwFDM). Here, the Team is in charge of <a class="reference external" href="http://forschungsdaten.info">forschungsdaten.info</a>, the German-speaking countries’ leading RDM information platform, which will be offered in English within the next years. Internationally, the Team cooperates with librarians and other OS professionals from the European Reform University Alliance (ERUA) and the European University for Well-Being (EUniWell), establishing formats for best practice exchange, such as monthly OS Meet-Ups.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/12699637">https://zenodo.org/records/12699637</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12699637">https://doi.org/10.5281/zenodo.12699637</a></p>
</section>
<hr class="docutils" />
<section id="integration-of-bioimage-and-omics-data-resources">
<h2>Integration of Bioimage and *Omics data resources<a class="headerlink" href="#integration-of-bioimage-and-omics-data-resources" title="Link to this heading">#</a></h2>
<p>Carsten Fortmann-Grote, Mariana Meireles</p>
<p>Published 2025-02-03</p>
<p>This Poster was presented at the 2025 All Hands Meeting of the NFDI4BIOIMAGE Consortium. It presents the current state of data integration activities at the MPI for Evolutionary Biology. Various data and metadata resources such as the internal image data repository OMERO and the Electronic Lab Notebook System OpenBIS are converted into a RDF Knowledge Graph utilizing a R2RML mapping scheme based on the Ontop-VKG framework. The materialized Knowledge Graph is then served via the QLever SPARQL endpoint and user interface. A graphical query editor (SPARNatural) assists users with no SPARQL knowledge in constructing their queries by selecting triple elements from dropdown menus and other widgets. We also present a benchmark comparison of query response times on 10 selected SPARQL queries run against three different endpoint/triplestore implementations. </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14792534">https://zenodo.org/records/14792534</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14792534">https://doi.org/10.5281/zenodo.14792534</a></p>
</section>
<hr class="docutils" />
<section id="intravital-microscopy-contrasting-agents-for-application-database">
<h2>Intravital microscopy contrasting agents for application - Database<a class="headerlink" href="#intravital-microscopy-contrasting-agents-for-application-database" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-06-19</p>
<p>Licensed CC-BY-4.0</p>
<p>This is a set of databases containing published use of substances which can be applied to rodents in order to contrast specific structures for optical intravital microscopy.
The first dataset contains applied final dosages, calculated for 25g-mice, as well as the orignally published amounts, concentrations and application routes of agents directly applied into the target organism.
The second dataset contains dosages and cell numbers for the external contrastation and subsequent application of cells into the target organism.
Filtering possible for organ system and contrasted structure/cell type in both datasets, substance class and fluorescent detection windows can be filtered in the dataset for direct agent application.
Source publications are listed by DOI.
 </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/12166710">https://zenodo.org/records/12166710</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12166710">https://doi.org/10.5281/zenodo.12166710</a></p>
</section>
<hr class="docutils" />
<section id="introducing-omero-vitessce-an-omero-web-plugin-for-multi-modal-data">
<h2>Introducing OMERO-vitessce: an <a class="reference external" href="http://OMERO.web">OMERO.web</a> plugin for multi-modal data<a class="headerlink" href="#introducing-omero-vitessce-an-omero-web-plugin-for-multi-modal-data" title="Link to this heading">#</a></h2>
<p>Michele Bortolomeazzi, Christian Schmidt, Jan-Philipp Mallm</p>
<p>Published 2025-02-07</p>
<p>Licensed CC-BY-4.0</p>
<p>omero-vitessce: an <a class="reference external" href="http://OMERO.web">OMERO.web</a> plugin for multi-modal data viewing.
OMERO is the most used research data management system (RDM) in the bioimaging domain, and has been adopted as a centralized RDM solution by several academic and research institutions. A main reason for this is the ability to directly view and annotate images from a web-based interface. However, this feature of OMERO is currently underpowered for the visualization of very large or multimodal datasets. These datasets, are becoming a more and more common foundation for biological and biomedical studies, due to the recent developments in imaging, and sequencing technologies which enabled their application to spatial-omics. In order to begin to provide this multimodal-data capability to OMERO, we developed omero-vitessce (<a class="github reference external" href="https://github.com/NFDI4BIOIMAGE/omero-vitessce/tree/main">NFDI4BIOIMAGE/omero-vitessce</a>), a new <a class="reference external" href="http://OMERO.web">OMERO.web</a> plugin for viewing data stored in OMERO with the Vitessce (<a class="reference external" href="http://vitessce.io/">http://vitessce.io/</a>) multimodal data viewer. omero-vitessce can be installed as an <a class="reference external" href="http://OMERO.web">OMERO.web</a> plugin with PiPy (<a class="reference external" href="https://pypi.org/project/omero-vitessce/">https://pypi.org/project/omero-vitessce/</a>), and allows users to set up interactive visualizations of their images of cells and tissues through interactive plots which are directly linked to the image. This enables the visual exploration of bioimage-analysis results and of multimodal data such as those generated through spatial-omics experiments. The data visualization is highly customizable and can be configured not only through custom configuration files, but also with the graphical interface provided by the plugin, thus making omero-vitessce a highly user-friendly solution for multimodal data viewing. most biological datasets. We plan to extend the interoperability of omero-vitessce with the OME-NGFF and SpatialData file formats to leverage the efficiency of these cloud optimized formats.
The three files in this Zenodo Record are all the same poster saved in different format all with high resolution images.</p>
<p>Tags: Nfdi4Bioimage, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14832855">https://zenodo.org/records/14832855</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14832855">https://doi.org/10.5281/zenodo.14832855</a></p>
</section>
<hr class="docutils" />
<section id="introduction-to-light-microscopy-widefield-microscopy">
<h2>Introduction to light-microscopy / Widefield microscopy<a class="headerlink" href="#introduction-to-light-microscopy-widefield-microscopy" title="Link to this heading">#</a></h2>
<p>Thomas Laurent</p>
<p>Published 2022-05-10</p>
<p>Licensed OTHER-AT</p>
<p>This is a short introduction to light-microscopy, illustrated with widefield microscopy.</p>
<p>It introduces :</p>
<ul class="simple">
<li><p>upright and inverted widefield microscopes</p></li>
<li><p>the transmitted and fluorescent light-path</p></li>
</ul>
<p>- contrasting methods (optical and at the sample level)</p>
<ul class="simple">
<li><p>the molecular principle of fluorescence (Perrin-Jablonski)</p></li>
<li><p>objective, resolution and limitations of the method (diffraction, diffusion/scattering)</p></li>
</ul>
<p>In addition to the PPT (with few animations), a lighter PDF version is provided for preview in Zenodo.</p>
<p> </p>
<p>Illustrations are mostly extracted from the ThermoFisher Molecular Probes School of Fluorescence educator packet and from the course material from Micron Facility in Oxford.</p>
<p>As stated in the presentation, illustrations are copyrighted but can be reproduced provided the original attribution is conserved.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/6535296">https://zenodo.org/records/6535296</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6535296">https://doi.org/10.5281/zenodo.6535296</a></p>
</section>
<hr class="docutils" />
<section id="jipipe-visual-batch-processing-for-imagej">
<h2>JIPipe: visual batch processing for ImageJ<a class="headerlink" href="#jipipe-visual-batch-processing-for-imagej" title="Link to this heading">#</a></h2>
<p>Ruman Gerst, Zoltán Cseresnyés, Marc Thilo Figge</p>
<p>JIPipe is an open-source visual programming language for easy-access pipeline development</p>
<p>Tags: Workflow Engine, Imagej, Exclude From Dalia</p>
<p>Content type: Publication, Documentation</p>
<p><a class="reference external" href="https://www.nature.com/articles/s41592-022-01744-4">https://www.nature.com/articles/s41592-022-01744-4</a></p>
<p><a class="reference external" href="https://jipipe.hki-jena.de/">https://jipipe.hki-jena.de/</a></p>
</section>
<hr class="docutils" />
<section id="jupyter-for-interactive-cloud-computing">
<h2>Jupyter for interactive cloud computing<a class="headerlink" href="#jupyter-for-interactive-cloud-computing" title="Link to this heading">#</a></h2>
<p>Guillaume Witz</p>
<p>Licensed UNKNOWN</p>
<p>Tags: Neubias, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://docs.google.com/presentation/d/1q8q1xE-c35tvCsRXZay98s2UYWwXpp0cfCljBmMFpco/edit#slide=id.ga456d5535c_2_53">https://docs.google.com/presentation/d/1q8q1xE-c35tvCsRXZay98s2UYWwXpp0cfCljBmMFpco/edit#slide=id.ga456d5535c_2_53</a></p>
</section>
<hr class="docutils" />
<section id="knime-image-processing">
<h2>KNIME Image Processing<a class="headerlink" href="#knime-image-processing" title="Link to this heading">#</a></h2>
<p>None</p>
<p>Licensed GPL-3.0</p>
<p>The KNIME Image Processing Extension allows you to read in more than 140 different kinds of images and to apply well known methods on images, like preprocessing. segmentation, feature extraction, tracking and classification in KNIME.</p>
<p>Tags: Imagej, OMERO, Workflow, Exclude From Dalia</p>
<p>Content type: Tutorial, Online Tutorial, Documentation</p>
<p><a class="reference external" href="https://www.knime.com/community/image-processing">https://www.knime.com/community/image-processing</a></p>
</section>
<hr class="docutils" />
<section id="key-value-pair-template-for-annotation-in-omero-for-light-microscopy-data-acquired-with-axioscan7-core-facility-cellular-imaging-cfci">
<h2>Key-Value pair template for annotation in OMERO for light microscopy data acquired with AxioScan7 - Core Facility Cellular Imaging (CFCI)<a class="headerlink" href="#key-value-pair-template-for-annotation-in-omero-for-light-microscopy-data-acquired-with-axioscan7-core-facility-cellular-imaging-cfci" title="Link to this heading">#</a></h2>
<p>Silke Tulok, Anja Nobst, Anett Jannasch, Tom Boissonnet, Gunar Fabig</p>
<p>Published 2024-06-28</p>
<p>Licensed CC-BY-4.0</p>
<p>This Key-Value pair template is used for the data documentation during imaging experiments and the later data annotation in OMERO. It is tailored for the usage and image acquisition at the slide scanning system Zeiss AxioScan 7 in the Core Facility Cellular Imaging (CFCI). It contains important metadata of the imaging experiment, which are not saved in the corresponding imaging files. All users of the Core Facility Cellular Imaging are trained to use that file to document their imaging parameters directly during the data acquisition with the possibility for a later upload to OMERO. Furthermore, there is a corresponding public example image used in the publication “Setting up an institutional OMERO environment for bioimage data: perspectives from both facility staff and users” and is available here:
<a class="reference external" href="https://omero.med.tu-dresden.de/webclient/?show=image-33248">https://omero.med.tu-dresden.de/webclient/?show=image-33248</a>
This template was developed by the CFCI staff during the setup and usage of the AxioScan 7 and is based on the REMBI recommendations (<a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015</a>).
With this template it is possible to create a csv-file, that can be used to annotate an image or dataset in OMERO using the annotation script (<a class="github reference external" href="https://github.com/ome/omero-scripts/blob/develop/omero/annotation_scripts/">ome/omero-scripts</a>).
How to use:</p>
<p>fill the template sheet  with your metadata
select and copy the data range containing the Keys and Values
open a new excel sheet and paste transpose in cell A1 
Important: cell A1 contains always the name ‘dataset’ and cell A2 contains the exact name of the image/dataset, which should be annotated in OMERO
save the new excel sheet in csv-file (comma separated values) format</p>
<p>An example can be seen in sheet 3 ‘csv_AxioScan’.
Important note: The code has to be 8-Bit UCS transformation format (UTF-8) otherwise several characters (for example µ, %,°) might be not able to decode by the annotation script. We encountered this issue with old Microsoft-Office versions (MS Office 2016). 
Note: By filling the values in the excel sheet, avoid the usage of comma as decimal delimiter.
See cross reference:
10.5281/zenodo.12547566 Key-Value pair template for annotation of datasets in OMERO for light- and electron microscopy data within the research group of Prof. Mueller-Reichert
10.5281/zenodo.12546808 Key-Value pair template for annotation of datasets in OMERO (PERIKLES study)</p>
<p>Tags: Nfdi4Bioimage, Research Data Management, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/12578084">https://zenodo.org/records/12578084</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12578084">https://doi.org/10.5281/zenodo.12578084</a></p>
</section>
<hr class="docutils" />
<section id="key-value-pair-template-for-annotation-of-datasets-in-omero-perikles-study">
<h2>Key-Value pair template for annotation of datasets in OMERO (PERIKLES study)<a class="headerlink" href="#key-value-pair-template-for-annotation-of-datasets-in-omero-perikles-study" title="Link to this heading">#</a></h2>
<p>Anett Jannasch, Silke Tulok, Vanessa Aphaia Fiona Fuchs, Tom Boissonnet, Christian Schmidt, Michele Bortolomeazzi, Gunar Fabig, Chukwuebuka Okafornta</p>
<p>Published 2024-06-26</p>
<p>Licensed CC-BY-4.0</p>
<p>This is a Key-Value pair template used for the annotation of datasets in OMERO. It is tailored for a research study (PERIKLES project) on the biocompatibility of newly designed biomaterials out of pericardial tissue for cardiovascular substitutes (<a class="reference external" href="https://doi.org/10.1063/5.0182672">https://doi.org/10.1063/5.0182672</a>) conducted in the research department of Cardiac Surgery at the Faculty of Medicine Carl Gustav Carus at the Technische Universität Dresden . A corresponding public example dataset is used in the publication “Setting up an institutional OMERO environment for bioimage data: perspectives from both facility staff and users” and is available here
(<a class="reference external" href="https://omero.med.tu-dresden.de/webclient/?show=dataset-1557">https://omero.med.tu-dresden.de/webclient/?show=dataset-1557</a>).
The template is based on the REMBI recommendations (<a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015</a>) and it was developed during the PoL-Bio-Image Analysis Symposium in Dresden Aug 28th- Sept 1th 2023. 
With this template it is possible to create a csv-file, that can be used to annotate a dataset in OMERO using the annotation script (<a class="github reference external" href="https://github.com/ome/omero-scripts/blob/develop/omero/annotation_scripts/">ome/omero-scripts</a>).
How to use:
select and copy the data range containing Keys and Values
open a new excel sheet and paste transpose in column B1
type in A1 ‘dataset’
insert in A2 the exact name of the dataset, which should be annotated in OMERO
save the new excel sheet in csv- (comma seperated values) file format</p>
<p>Example can be seen in sheet 1 ‘csv import’. Important note; the code has to be 8-Bit UCS transformation format (UTF-8) otherwise several characters (for example µ, %,°) might not be able to decode by the annotation script. We encountered this issue with old Microsoft Office versions (e.g. MS Office 2016). 
Note: By filling the values in the excel sheet, avoid the usage of decimal delimiter.
 
See cross reference:
10.5281/zenodo.12547566 Key-Value pair template for annotation of datasets in OMERO (light- and electron microscopy data within the research group of Prof. Mueller-Reichert)
10.5281/zenodo.12578084 Key-Value pair template for annotation in OMERO for light microscopy data acquired with AxioScan7 - Core Facility Cellular Imaging (CFCI)</p>
<p>Tags: Nfdi4Bioimage, Research Data Management, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/12546808">https://zenodo.org/records/12546808</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12546808">https://doi.org/10.5281/zenodo.12546808</a></p>
</section>
<hr class="docutils" />
<section id="key-value-pair-template-for-annotation-of-datasets-in-omero-for-light-and-electron-microscopy-data-within-the-research-group-of-prof-muller-reichert">
<h2>Key-Value pair template for annotation of datasets in OMERO for light- and electron microscopy data within the research group of Prof. Müller-Reichert<a class="headerlink" href="#key-value-pair-template-for-annotation-of-datasets-in-omero-for-light-and-electron-microscopy-data-within-the-research-group-of-prof-muller-reichert" title="Link to this heading">#</a></h2>
<p>Gunar Fabig, Anett Jannasch, Chukwuebuka Okafornta, Tom Boissonnet, Christian Schmidt, Michele Bortolomeazzi, Vanessa Aphaia Fiona Fuchs, Maria Koeckert, Aayush Poddar, Martin Vogel, Hanna-Margareta Schwarzbach, Andy Vogelsang, Michael Gerlach, Anja Nobst, Thomas Müller-Reichert, Silke Tulok</p>
<p>Published 2024-06-26</p>
<p>Licensed CC-BY-4.0</p>
<p>This are a two Key-Value pair templates used for the annotation of datasets in OMERO. They are tailored for light- and electron microcopy data for all research projects of the research group of Prof. T. Mueller-Reichert.  All members of the Core Facility Cellular Imaging agreed for using these templates to annotate data in OMERO. Furthermore, there are a corresponding public example datasets used in the publication “Setting up an institutional OMERO environment for bioimage data: perspectives from both facility staff and users” and are available here:
<a class="reference external" href="https://omero.med.tu-dresden.de/webclient/?show=dataset-1552">https://omero.med.tu-dresden.de/webclient/?show=dataset-1552</a> –&gt; for lattice-light sheet microscopy
<a class="reference external" href="https://omero.med.tu-dresden.de/webclient/?show=dataset-1555--&amp;amp;gt">https://omero.med.tu-dresden.de/webclient/?show=dataset-1555–&amp;gt</a>; for electron microscopy data
That templates are based on the REMBI recommendations (<a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015</a>) and were developed during the PoL-Bio-Image Analysis Symposium in Dresden Aug 28th- Sept 1st in 2023 and further adapeted during the usage of OMERO. 
With every template it is possible to create a csv-file, that can be used to annotate a dataset in OMERO using the annotation script (<a class="github reference external" href="https://github.com/ome/omero-scripts/blob/develop/omero/annotation_scripts/">ome/omero-scripts</a>).
How to use:</p>
<p>fill the template with metadata
select and copy the data range containing the Keys and Values
open a new excel sheet and paste transpose in cell A1
Important: cell A1 contains always the name ‘dataset’ and cell A2 contains the exact name of the dataset, which should be annotated in OMERO
save the new excel sheet in csv-file (comma separated values) format</p>
<p>Examples can be seen in sheet 3 ‘csv_TOMO’ and sheet 5 csv_TEM’.
Important note: The code has to be 8-Bit UCS transformation format (UTF-8) otherwise several characters (for example µ, %,°) might be not able to decode by the annotation script. We encountered this issue with old Microsoft-Office versions (MS Office 2016). 
Note: By filling the values in the excel sheet, avoid the usage of comma as decimal delimiter.
See cross reference:
10.5281/zenodo.12546808 Key-Value pair template for annotation of datasets in OMERO (PERIKLES study)
10.5281/zenodo.12578084 Key-Value pair template for annotation in OMERO for light microscopy data acquired with AxioScan7 - Core Facility Cellular Imaging (CFCI)
 </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/12547566">https://zenodo.org/records/12547566</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.12547566">https://doi.org/10.5281/zenodo.12547566</a></p>
</section>
<hr class="docutils" />
<section id="key-value-pairs-scripts">
<h2>Key-Value pairs scripts<a class="headerlink" href="#key-value-pairs-scripts" title="Link to this heading">#</a></h2>
<p>Licensed UNKNOWN</p>
<p>The key-value pairs are annotations in OMERO useful to describe thoroughly the data and can be added &amp; edited via the <a class="reference external" href="http://OMERO.web">OMERO.web</a> interface.</p>
<p>Tags: OMERO, Exclude From Dalia</p>
<p>Content type: Documentation, Collection</p>
<p><a class="reference external" href="https://guide-kvpairs-scripts.readthedocs.io/en/latest/">https://guide-kvpairs-scripts.readthedocs.io/en/latest/</a></p>
</section>
<hr class="docutils" />
<section id="leo">
<h2>LEO<a class="headerlink" href="#leo" title="Link to this heading">#</a></h2>
<p>Rodrigo Escobar Diaz Guerrero</p>
<p>Published 2025-01-08T10:20:30+00:00</p>
<p>Licensed MIT</p>
<p>Linking Electronic Lab Notebooks and other sources with OMERO objects</p>
<p>Tags: OMERO, Research Data Management, Electronic Lab Notebooks, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/NFDI4BIOIMAGE/LEO">NFDI4BIOIMAGE/LEO</a></p>
</section>
<hr class="docutils" />
<section id="leo-linking-eln-with-omero">
<h2>LEO: Linking ELN with OMERO<a class="headerlink" href="#leo-linking-eln-with-omero" title="Link to this heading">#</a></h2>
<p>Escobar Diaz Guerrero, Rodrigo</p>
<p>Published 2024-05-08</p>
<p>Licensed CC-BY-4.0</p>
<p>First updates of LEO (Linking ELN with OMERO)</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/11146807">https://zenodo.org/records/11146807</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11146807">https://doi.org/10.5281/zenodo.11146807</a></p>
</section>
<hr class="docutils" />
<section id="lmrg-image-analysis-study-fish-datasets">
<h2>LMRG Image Analysis Study - FISH datasets<a class="headerlink" href="#lmrg-image-analysis-study-fish-datasets" title="Link to this heading">#</a></h2>
<p>Kristopoher Kubow, Thomas Pengo</p>
<p>Published 2022-05-18</p>
<p>Licensed CC-BY-4.0</p>
<p>Original image files, label (ground truth) files, and PSF files used in the ABRF Light Microscopy Research Group (LMRG) image analysis study. Simulated 3D confocal fluorescence images of sub-diffraction punctate staining (fluorescence in situ hybridization (FISH) in C. elegans).</p>
<p>See <a class="github reference external" href="https://github.com/ABRFLMRG/image-analysis-study">ABRFLMRG/image-analysis-study</a> for more details.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/6560910">https://zenodo.org/records/6560910</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6560910">https://doi.org/10.5281/zenodo.6560910</a></p>
</section>
<hr class="docutils" />
<section id="lmrg-image-analysis-study-nuclei-datasets">
<h2>LMRG Image Analysis Study - nuclei datasets<a class="headerlink" href="#lmrg-image-analysis-study-nuclei-datasets" title="Link to this heading">#</a></h2>
<p>Kristopher Kubow, Thomas Pengo</p>
<p>Published 2022-05-18</p>
<p>Licensed CC-BY-4.0</p>
<p>Original image files, label (ground truth) files, and PSF files used in the ABRF Light Microscopy Research Group (LMRG) image analysis study. Simulated 3D widefield fluorescence images of nuclei.</p>
<p>See <a class="github reference external" href="https://github.com/ABRFLMRG/image-analysis-study">ABRFLMRG/image-analysis-study</a> for more details.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/6560759">https://zenodo.org/records/6560759</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6560759">https://doi.org/10.5281/zenodo.6560759</a></p>
</section>
<hr class="docutils" />
<section id="lsm-example-j-dubrulle">
<h2>LSM example J. Dubrulle<a class="headerlink" href="#lsm-example-j-dubrulle" title="Link to this heading">#</a></h2>
<p>Salama Lab Fred Hutchinson Cancer Center</p>
<p>Published 2024-12-17</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14510432">https://zenodo.org/records/14510432</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14510432">https://doi.org/10.5281/zenodo.14510432</a></p>
</section>
<hr class="docutils" />
<section id="lz4-compressed-imaris-ims-example-datasets">
<h2>LZ4-compressed Imaris ims example datasets.<a class="headerlink" href="#lz4-compressed-imaris-ims-example-datasets" title="Link to this heading">#</a></h2>
<p>Marco Stucchi</p>
<p>Published 2024-11-21</p>
<p>Licensed CC-BY-4.0</p>
<p>The files contained in this repository are cropped versions of Imaris demo images compressed with LZ4.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14197622">https://zenodo.org/records/14197622</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14197622">https://doi.org/10.5281/zenodo.14197622</a></p>
</section>
<hr class="docutils" />
<section id="large-tiling-confocal-acquisition-rat-brain">
<h2>Large tiling confocal acquisition (rat brain)<a class="headerlink" href="#large-tiling-confocal-acquisition-rat-brain" title="Link to this heading">#</a></h2>
<p>Julie Meystre</p>
<p>Published 2022-06-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: Large tiling confocal acquisition (rat brain)</p>
<p>Microscope: Zeiss LSM700</p>
<p>Microscopy data type: 108 tiles, each with 62 z-slices and 2 channels :
Channel 1: DAPI
Channel 2: cck staining</p>
<p>File format: .lsm (16-bit)</p>
<p>Image size: 1024x1024x62 (Pixel size: 0.152 x 0.152 x 1 micron), 2 channels.</p>
<p> </p>
<p>NOTE : Some tiles were annotated and used to train a StarDist3D model (<a class="reference external" href="https://doi.org/10.5281/zenodo.6645978">https://doi.org/10.5281/zenodo.6645978</a>   )</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/6646128">https://zenodo.org/records/6646128</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6646128">https://doi.org/10.5281/zenodo.6646128</a></p>
</section>
<hr class="docutils" />
<section id="laser-perturbation-imaging-data-for-patterned-invagination-prevents-mechanical-instability-during-gastrulation">
<h2>Laser perturbation imaging data for: Patterned invagination prevents mechanical instability during gastrulation<a class="headerlink" href="#laser-perturbation-imaging-data-for-patterned-invagination-prevents-mechanical-instability-during-gastrulation" title="Link to this heading">#</a></h2>
<p>Vellutini, Bruno C., Cuenca, Marina B., Abhijeet Krishna, Alicja Szałapak, Modes, Carl D., Pavel Tomančák</p>
<p>Published 2025-07-14</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository contains the imaging data for the laser perturbation experiments of the manuscript:
Vellutini BC, Cuenca MB, Krishna A, Szałapak A, Modes CD, Tomančák P. Patterned embryonic invagination evolved in response to mechanical instability. bioRxiv (2023) doi:10.1101/2023.03.30.534554
Please refer to the main repository for more information: <a class="reference external" href="https://doi.org/10.5281/zenodo.7781947">https://doi.org/10.5281/zenodo.7781947</a></p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15876646">https://zenodo.org/records/15876646</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15876646">https://doi.org/10.5281/zenodo.15876646</a></p>
</section>
<hr class="docutils" />
<section id="laulauthom-maskfromrois-fiji-masks-from-rois-plugins-for-fiji-initial-release">
<h2>LauLauThom/MaskFromRois-Fiji: Masks from ROIs plugins for Fiji - initial release<a class="headerlink" href="#laulauthom-maskfromrois-fiji-masks-from-rois-plugins-for-fiji-initial-release" title="Link to this heading">#</a></h2>
<p>Laurent Thomas, Pierre Trehin</p>
<p>Published 2021-07-22</p>
<p>Licensed MIT</p>
<p>Fiji plugins for the creation of binary and semantic masks from ROIs in the RoiManager. Works with stacks too.</p>
<p>Installation in Fiji: activate the Rois from masks update site in Fiji.</p>
<p>See GitHub readme for the documentation.</p>
<p>Latest tested with Fiji 2.1.0/ImageJ 1.53j</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/5121890">https://zenodo.org/records/5121890</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5121890">https://doi.org/10.5281/zenodo.5121890</a></p>
</section>
<hr class="docutils" />
<section id="laulauthom-maskfromrois-fiji-v1-0-1-better-handle-cancel">
<h2>LauLauThom/MaskFromRois-Fiji: v1.0.1 - better handle “cancel”<a class="headerlink" href="#laulauthom-maskfromrois-fiji-v1-0-1-better-handle-cancel" title="Link to this heading">#</a></h2>
<p>Laurent Thomas, Pierre Trehin</p>
<p>Published 2025-02-24</p>
<p>Licensed MIT</p>
<p>Also re-uploaded the compiled FilenameGetter.py$class to the update site, to fix <a class="github reference external" href="https://github.com/LauLauThom/MaskFromRois-Fiji/issues/7">LauLauThom/MaskFromRois-Fiji#7</a></p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14917722">https://zenodo.org/records/14917722</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14917722">https://doi.org/10.5281/zenodo.14917722</a></p>
</section>
<hr class="docutils" />
<section id="lecture-materials-of-the-deeplife-course">
<h2>Lecture-materials of the DeepLife course<a class="headerlink" href="#lecture-materials-of-the-deeplife-course" title="Link to this heading">#</a></h2>
<p>Carl Herrmann, annavonbachmann, David Hoksza, Martin Schätz, Dario Malchiodi, jnguyenvan, Britta Velten, Elodie Laine, JanaBraunger, barwil</p>
<p>Published 2023-12-06</p>
<p>Licensed UNKNOWN</p>
<p>Tags: Bioinformatics, Exclude From Dalia</p>
<p>Content type: Github Repository, Slides, Notebook</p>
<p><a class="github reference external" href="https://github.com/deeplife4eu/Lecture-materials/">deeplife4eu/Lecture-materials</a></p>
</section>
<hr class="docutils" />
<section id="leica-lif-file-with-errors-in-channel-order-when-imported-with-bio-formats">
<h2>Leica (.lif) file with errors in channel order when imported with Bio-formats<a class="headerlink" href="#leica-lif-file-with-errors-in-channel-order-when-imported-with-bio-formats" title="Link to this heading">#</a></h2>
<p>Areli Rodriguez</p>
<p>Published 2025-02-26</p>
<p>The blue and red channels get swapped when imported with Bio-formats. Happens consistently with .lif imports in QuPath and ImageJ.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14933318">https://zenodo.org/records/14933318</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14933318">https://doi.org/10.5281/zenodo.14933318</a></p>
</section>
<hr class="docutils" />
<section id="leitlinie-grundsatze-policy-richtlinie-forschungsdaten-policies-an-deutschen-universitaten">
<h2>Leitlinie? Grundsätze? Policy? Richtlinie? – Forschungsdaten-Policies an deutschen Universitäten<a class="headerlink" href="#leitlinie-grundsatze-policy-richtlinie-forschungsdaten-policies-an-deutschen-universitaten" title="Link to this heading">#</a></h2>
<p>Bea Hiemenz, Monika Kuberek</p>
<p>Published 2018-07-13</p>
<p>Licensed CC-BY-4.0</p>
<p>As a methodological approach, research data policies of German universities are collected and evaluated, and compared to international recommendations on research data policies.</p>
<p>Tags: Research Data Management, FAIR-Principles, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.o-bib.de/bib/article/view/2018H2S1-13">https://www.o-bib.de/bib/article/view/2018H2S1-13</a></p>
</section>
<hr class="docutils" />
<section id="life-science-competence-centres-open-by-design">
<h2>Life Science Competence Centres: Open by Design<a class="headerlink" href="#life-science-competence-centres-open-by-design" title="Link to this heading">#</a></h2>
<p>Romain David, Nektarios Liaskos, Arina Rybina, Christos Arvanitidis, Anne-Sophie Bage, Carvajal-Vallejos, Patricia K., Sudeep Das, De Pascalis, Francesca, Dorothea Dörr, Katrina Exter, Petr Holub, Gurwitz, Kim Tamara, Fabio Liberante, Philippe Lieutaud, Allyson Lister, Joaquin Lopez, Bénédicte Madon, Marzia Massimi, Rafaele Matteoni, Maria Mîrza, Sarah Morgan, Bugra Oezdemir, Maria Panagiotopoulou, Christina Pavloudi, P. Melo, Ana M., Susanna-Assunta Sansone, Harald Schwalbe, Beatriz Serrano-Solano, Sorzano, Carlos Oscar, Emilio Urbinati, Jing Tang, Jonathan Tedds, Gary Saunders, Jonathan Ewbank</p>
<p>Published 2025-07</p>
<p>Licensed CC-BY-4.0</p>
<p>Preprint in submission process to GigaScience journal
Abstract:
European Life Science Research Infrastructures (LS-RIs), one of the five major RI Science Clusters in Europe, were established to provide access to cutting-edge technologies to the scientific community. Individually, and collectively as the LS-RI cluster, they contribute to the development of the European Open Science Cloud (EOSC), under the aegis of the EOSC Federation. They are actively involved in the design and implementation of Competence Centres (CCs). These aim to increase the accessibility of domain-specific knowledge and tools, enhance interoperability, facilitate sharing and harmonisation of procedures, and promote Open Science and FAIR (Findable, Accessible, Interoperable, Reusable) practices. In this paper, we report a landscape mapping of the existing resources that formed the basis for the construction of CCs. We describe the possible design of CCs and their articulation with the LS-RIs. We focus on community-based ideas and recommendations to increase the potential of CCs to address long-standing challenges in sustainability, governance, scalability, and interoperability of Open Science within EOSC and the European Research Area (ERA) more generally.This paper provides a description of the nascent LS CCs, built following a survey of needs and services of existing LS-RI communities. When fully implemented, the LS CCs will serve as dynamic hubs to foster innovation, contribute to the EOSC’s future FAIR web of data, and support ongoing developments of the EOSC Federation. They will act as drivers of collaborative and impactful LS research in Europe and beyond. We explore the underlying challenges, and propose solutions, to ensure that the establishment of CCs will add value to the LS RI community, and to the EOSC, in a sustainable way.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15798751">https://zenodo.org/records/15798751</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15798751">https://doi.org/10.5281/zenodo.15798751</a></p>
</section>
<hr class="docutils" />
<section id="lightsheet-and-in-situ-imaging-data-for-patterned-invagination-prevents-mechanical-instability-during-gastrulation">
<h2>Lightsheet and in situ imaging data for: Patterned invagination prevents mechanical instability during gastrulation<a class="headerlink" href="#lightsheet-and-in-situ-imaging-data-for-patterned-invagination-prevents-mechanical-instability-during-gastrulation" title="Link to this heading">#</a></h2>
<p>Vellutini, Bruno C., Cuenca, Marina B., Abhijeet Krishna, Alicja Szałapak, Modes, Carl D., Pavel Tomančák</p>
<p>Published 2025-07-14</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository contains the lightsheet and in situ hybridization imaging data for the manuscript:
Vellutini BC, Cuenca MB, Krishna A, Szałapak A, Modes CD, Tomančák P. Patterned embryonic invagination evolved in response to mechanical instability. bioRxiv (2023) doi:10.1101/2023.03.30.534554
Please refer to the main repository for more information: <a class="reference external" href="https://doi.org/10.5281/zenodo.7781947">https://doi.org/10.5281/zenodo.7781947</a></p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15876638">https://zenodo.org/records/15876638</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15876638">https://doi.org/10.5281/zenodo.15876638</a></p>
</section>
<hr class="docutils" />
<section id="limeseg-test-datasets">
<h2>LimeSeg Test Datasets<a class="headerlink" href="#limeseg-test-datasets" title="Link to this heading">#</a></h2>
<p>Sarah Machado, Vincent Mercier, Nicolas Chiaruttini</p>
<p>Published 2018-10-27</p>
<p>Licensed CC-BY-4.0</p>
<p>Image datasets from the publication : LimeSeg: A coarse-grained lipid membrane simulation for 3D image segmentation</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Vesicles.tif: spinning-disc confocal images of giant unilamellar vesicles
HelaCell-FIBSEM.tif:&amp;nbsp;a 3D Electron&amp;nbsp;Microscopy (EM)&amp;nbsp;dataset of nearly isotropic sections of a Hela cell, acquired with a focused ion beam scanning electron microscope (FIB-SEM). Sections are aligned with TrackEm2 (doi: ), without additional preprocessing.
DrosophilaEggChamber.tif: point scanning confocal images of a Drosophila egg chamber. Channel&amp;nbsp;1: cell nuclei &amp;nbsp;stained with DAPI. Channel 2:&amp;nbsp;cell membranes visualized with fused membrane proteins Nrg::GFP and Bsg::GFP.&amp;nbsp;
</pre></div>
</div>
<p>Image metadata contains extra information including voxel sizes.</p>
<p> </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/1472859">https://zenodo.org/records/1472859</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.1472859">https://doi.org/10.5281/zenodo.1472859</a></p>
</section>
<hr class="docutils" />
<section id="linked-open-data-for-microbial-population-biology">
<h2>Linked (Open) Data for Microbial Population Biology<a class="headerlink" href="#linked-open-data-for-microbial-population-biology" title="Link to this heading">#</a></h2>
<p>Carsten Fortmann-Grote</p>
<p>Published 2024-03-12</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/10808486">https://zenodo.org/records/10808486</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10808486">https://doi.org/10.5281/zenodo.10808486</a></p>
</section>
<hr class="docutils" />
<section id="linking-of-research-meta-data-in-omero-to-foster-fair-data-in-plasma-science">
<h2>Linking of Research (Meta-)data in OMERO to Foster FAIR Data in Plasma Science<a class="headerlink" href="#linking-of-research-meta-data-in-omero-to-foster-fair-data-in-plasma-science" title="Link to this heading">#</a></h2>
<p>Robert Wagner, Mohsen Ahmadi, Dagmar Waltemath, Kristina Yordanova, Becker, Markus M.</p>
<p>Published 2025-09-10</p>
<p>Licensed CC-BY-4.0</p>
<p>Applied plasma research involves several disciplines such as physics, medicine and biology to solve application-oriented problems, often generating large and heterogeneous experimental data sets. The descriptions and metadata describing these interdisciplinary scientific investiga-tions is stored in distributed systems (e.g., physical laboratory notebooks or electronic labora-tory notebooks (ELN) like eLabFTW [1]), and the experimental data are either stored locally within the laboratories or on centralized institutional storage systems. As a result, the collected information often has to be tediously assembled for processing into publications. The workflow represented in Figure 1 addresses this suboptimal situation and promotes the combination of the image database OMERO [2], the ELN system eLabFTW, the research data management tool Adamant [3] and Python scripts for handling microscopy images in plasma life science and plasma medicine [4]. This workflow highlights how the developments from the NFDI4BIOIMAGE consortium can be brought into practical applications by addressing the specific demands of plasma science, where domain-specific metadata is essential for effective data interpretation and reuse. It showcases the benefits of FAIR [5] metadata combining do-main-specific requirements with method-specific solutions. Similar to most imaging workflows, image analysis in plasma research requires metadata from several sections of the experiment. Moreover, the plasma-related metadata are essential for the experimental context and must be included in the analysis, e.g. to describe the influence of plasma on the treated sample. Therefore, the metadata schema Plasma-MDS [6] is adapted to collect plasma-related metadata, such as information on the plasma species having a major impact on the treated samples. Alongside Plasma-MDS, the Recommended Metadata for Bio-logical Images (REMBI) standard [7] is used for the biological metadata such as the sample preparation and treatment procedures. The collection of these metadata is realized using Adamant, which enables the beginner-friendly collection of structured metadata. The tool presents JSON schemas in easy-to-read and easy-to-fill HTML forms, enabling metadata validation. Once completed and validated, the metadata are uploaded directly to eLabFTW using Adamant’s workflow functionalities. The images from the treated samples are uploaded to OMERO by OMERO.insight and afterwards automatically annotated via Python scripts. These scripts take previously collected metadata from the related eLabFTW experiments and the microscope description metadata collected by the Micro Meta App [8], which are also stored in eLabFTW. The metadata is categorized and annotated according to the various data organizational levels within OMERO, specifically fo-cusing on project and dataset hierarchies, as well as screens that are composed of plates, which in turn contain wells. Screens resemble microwell plates, commonly used in a variety of biological experiments. The hieraic organization of metadata significantly enhances the ease of reusing images and associated metadata for subsequent processing and analysis. By efficiently distributing and reducing large metadata sets to an acceptable level, while simultaneously eliminating redun-dancies, this approach facilitates straightforward analyses with tools like ImageJ [9] and FIJI [10], thanks to the close association of metadata with the images themselves. In summary, one of the application-specific developments within the NFDI4BIOIMAGE consor-tium is presented, which contributes to the adoption of the FAIR principles in laboratory envi-ronments. Further work will address the integration of ontologies for the semantic description of data and metadata.</p>
<p>Tags: Nfdi4Bioimage, Bioimage Analysis, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/17092348">https://zenodo.org/records/17092348</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.17092348">https://doi.org/10.5281/zenodo.17092348</a></p>
</section>
<hr class="docutils" />
<section id="lund-declaration-on-maximising-the-benefits-of-research-data">
<h2>Lund Declaration on Maximising the Benefits of Research Data<a class="headerlink" href="#lund-declaration-on-maximising-the-benefits-of-research-data" title="Link to this heading">#</a></h2>
<p>Tags: Research Data Management, Exclude From Dalia</p>
<p>Content type: Document</p>
<p><a class="reference external" href="https://www.regeringen.se/contentassets/55e7d8fbf6df4a54ac56942b98d94e4f/lund-declaration-on-maximising-the-benefits-of-research-data-pa-engelska.pdf">https://www.regeringen.se/contentassets/55e7d8fbf6df4a54ac56942b98d94e4f/lund-declaration-on-maximising-the-benefits-of-research-data-pa-engelska.pdf</a></p>
</section>
<hr class="docutils" />
<section id="lynsec-lymphoma-nuclear-segmentation-and-classification">
<h2>LyNSeC: Lymphoma Nuclear Segmentation and Classification<a class="headerlink" href="#lynsec-lymphoma-nuclear-segmentation-and-classification" title="Link to this heading">#</a></h2>
<p>Naji Hussein, Büttner Reinhard, Simon Adrian, Eich Marie-Lisa, Lohneis Philipp, Bozek Katarzyna</p>
<p>Published 2023-06-21</p>
<p>Licensed CC-BY-4.0</p>
<p>Over the last years, there has been large progress in automated segmentation and classification methods in histological whole slide images (WSIs) stained with hematoxylin and eosin (H&amp;E). Current state-of-the-art techniques are based on diverse datasets of H&amp;E-stained WSIs of different types of predominantly solid cancer. However, there is a lack of publicly available annotated datasets of lymphoma, which is why we generated a labeled diffuse large B-cell lymphoma dataset and denoted it LyNSeC (lymphoma nuclear segmentation and classification). LyNSeC comprises three subsets: LyNSeC 1 consists of 379 IHC images of size 512 x 512 pixels at 40x magnification. In the images, we annotated the contours of each cell nuclei and the cell class: marker-positive or marker-negative.</p>
<p>In total, LyNSeC 1 contains 87,316 annotated cell nuclei of four different cases, with 48,171 of them assigned the class negative and 39,145 positive. We included three markers in this dataset showing visually different staining patterns: cluster of differentiation 3 (CD3), Ki67 as a marker of proliferation, and erythroblast transformation-specific (EST)-related gene (ERG).</p>
<p>LyNSeC 2 and 3 contain H&amp;E-stained images of 70 different patients. LyNSeC 2 consists of 280 images and LyNSeC 3 of 40 images of size 512 x 512 pixels at 40x magnification. 65,479 and 8,452 nuclei were annotated in LyNSeC 2 and 3, respectively. In LyNSeC 3, the nuclei were also assigned a class label (tumor and non-tumor). 3,747 nuclei were identified as tumors and 4,705 as non-tumors.</p>
<p>In the annotation procedure, the contours of the H&amp;E images (LyNSeC 2 and LyNSeC 3) were annotated by two pathologists and by two students (trained by the pathologists). Annotation of the cell classes in LyNSeC 3 was done by the pathologists only. LyNSeC 1 was annotated by the two students who were additionally trained to annotate the contours and to distinguish marker-positive and marker-negative cells. The pathologists inspected and (if necessary) adjusted the LyNSeC 3 annotations.</p>
<p>The files are uploaded in ‘.npy’ format. The files of LyNSeC 1 (x_l1.npy) and LyNSeC 3 (x_l3.npy) contain five channels, respectively: the first three are the RGB channels of the images, channel 4 contains the instance maps, and channel 5 the class type maps (for LyNSeC 1 a pixel value of 1 corresponds to the class negative and 2 to the class positive, whereas in LyNSeC 3 1 corresponds to the class non-tumor and 2 to the class tumor). The files of LyNSeC 2 (x_l2.npy) have 4 channels (without the class type map).</p>
<p>Additionally, we also make our HoVer-Net-based pre-trained nuclei segmentation and classification models available (he.tar for H&amp;E images and ihc.tar for IHC images).</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/8065174">https://zenodo.org/records/8065174</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8065174">https://doi.org/10.5281/zenodo.8065174</a></p>
</section>
<hr class="docutils" />
<section id="mdemic-a-metadata-annotation-tool-to-facilitate-management-of-fair-image-data-in-the-bioimaging-community">
<h2>MDEmic: a metadata annotation tool to facilitate management of FAIR image data in the bioimaging community<a class="headerlink" href="#mdemic-a-metadata-annotation-tool-to-facilitate-management-of-fair-image-data-in-the-bioimaging-community" title="Link to this heading">#</a></h2>
<p>Susanne Kunis, Sebastian Hänsch, Christian Schmidt, Frances Wong, Caterina Strambio-De-Castillia, Stefanie Weidtkamp-Peters</p>
<p>Licensed ALL RIGHTS RESERVED</p>
<p>Tags: Research Data Management, Metadata, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.nature.com/articles/s41592-021-01288-z">https://www.nature.com/articles/s41592-021-01288-z</a></p>
</section>
<hr class="docutils" />
<section id="midog-2021">
<h2>MIDOG 2021<a class="headerlink" href="#midog-2021" title="Link to this heading">#</a></h2>
<p>Marc Aubreville, Frauke Wilm</p>
<p>Published 2021-03-16</p>
<p>Licensed UNLICENSED</p>
<p>Mitosis domain generation. Here you can find code of our own evaluations and a dockered reference algorithm for mitotic figures to use as a template.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="github reference external" href="https://github.com/DeepMicroscopy/MIDOG">DeepMicroscopy/MIDOG</a></p>
</section>
<hr class="docutils" />
<section id="mri-physics">
<h2>MRI Physics<a class="headerlink" href="#mri-physics" title="Link to this heading">#</a></h2>
<p>Radiology Tutorials</p>
<p>Published 2025-01-01</p>
<p>Licensed UNKNOWN</p>
<p>This is a playlist of videos about how MRI works</p>
<p>Tags: Imaging, Exclude From Dalia</p>
<p>Content type: Video</p>
<p><a class="reference external" href="https://youtube.com/playlist?list=PLWfaNqiSdtzVkfJW2gO-unAYjcDji7-9i&amp;amp;si=U5gvYtUYvmLHxi0z">https://youtube.com/playlist?list=PLWfaNqiSdtzVkfJW2gO-unAYjcDji7-9i&amp;si=U5gvYtUYvmLHxi0z</a></p>
</section>
<hr class="docutils" />
<section id="machine-and-deep-learning-on-the-cloud-segmentation">
<h2>Machine and Deep Learning on the cloud: Segmentation<a class="headerlink" href="#machine-and-deep-learning-on-the-cloud-segmentation" title="Link to this heading">#</a></h2>
<p>Ignacio Arganda-Carreras</p>
<p>Licensed UNKNOWN</p>
<p>Tags: Neubias, Artificial Intelligence, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://docs.google.com/presentation/d/1oJoy9gHmUuSmUwCkPs_InJf_WZAzmLlUNvK1FUEB4PA/edit#slide=id.ge3a24e733b_0_54">https://docs.google.com/presentation/d/1oJoy9gHmUuSmUwCkPs_InJf_WZAzmLlUNvK1FUEB4PA/edit#slide=id.ge3a24e733b_0_54</a></p>
</section>
<hr class="docutils" />
<section id="masterclasses-from-the-euro-bioimaging-evolve-mentoring-programme-2025">
<h2>Masterclasses from the Euro-Bioimaging EVOLVE Mentoring programme 2025<a class="headerlink" href="#masterclasses-from-the-euro-bioimaging-evolve-mentoring-programme-2025" title="Link to this heading">#</a></h2>
<p>Euro-BioImaging ERIC</p>
<p>Published 2025-06-26</p>
<p>Licensed CC-BY-4.0</p>
<p>EVOLVE Mentoring Masterclasses
Description:This series captures the class guides of the 2025 masterclasses from Euro‑BioImaging’s EVOLVE Mentoring Program.
Included Masterclasses:</p>
<p>Peter O’Toole – “Entrepreneurship &amp; Leadership in Imaging Core Facilities” Peter O’Toole, President of the Royal Microscopical Society and Director of the Bioscience Technology Facility (University of York), kicks off the series with a deep dive into entrepreneurial leadership. He highlights how to balance science, business, and technology, emphasizing stakeholder engagement, staff investment, cross-training, and using social media to boost visibility and unlock funding.
Ilaria Testa – “Interdisciplinary Science, SMART Microscopy &amp; Team Building” Professor Ilaria Testa (SciLifeLab &amp; KTH) reflects on her transition from physics to super-resolution microscopy and team leadership. Her session underscores the power of crossing disciplinary boundaries, mentorship, and innovation in live-cell imaging .
Daphna Link‑Sourani – “Leadership, Facility Management &amp; Work‑Life Balance” Dr. Daphna Link‑Sourani (Technion Human MRI Research Center) challenges hierarchical notions of leadership, advocating instead for integrity, empathy, and strategic vision. She draws on her experience establishing an MRI facility to discuss crisis management, user engagement, and balancing career demands.
Muriel Mari – “Women in Science: Normalizing, Supporting &amp; Leading”                                                                           Dr. Muriel Mari (Aarhus University) leads a powerful reflection on gender equity in science. Her masterclass goes beyond barriers—focusing on cultural shifts, inclusive leadership, and redefining success. She encourages institutions and individuals alike to move from tokenism to transformative support, and to recognize the diverse paths women take in STEM.
Sylvia E. Le Dévédec – “Image Data Management &amp; FAIR Core Facilities”                                                                     Dr. Sylvia Le Dévédec (Leiden University) discusses how to integrate FAIR data principles in imaging core facilities. Drawing on her experience with high-content imaging and Open Science advocacy, she outlines actionable steps toward sustainable, reusable, and accessible data workflows.</p>
<p>Why Archive These Sessions?These masterclasses offer invaluable insights for core facility managers, imaging scientists, and team leaders in life sciences. They blend hands-on leadership strategies, technical facility growth advice, and real-world experience—making them essential viewing for professionals and institutions aiming to build sustainable, people-centred imaging infrastructures.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15837532">https://zenodo.org/records/15837532</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15837532">https://doi.org/10.5281/zenodo.15837532</a></p>
</section>
<hr class="docutils" />
<section id="materials-for-embl-coding-club-mini-tutorials">
<h2>Materials for EMBL Coding Club Mini-Tutorials<a class="headerlink" href="#materials-for-embl-coding-club-mini-tutorials" title="Link to this heading">#</a></h2>
<p>Jonas Hartmann, et al.</p>
<p>Licensed UNKNOWN</p>
<p>Tags: Python, Exclude From Dalia</p>
<p>Content type: Code, Notebook</p>
<p><a class="github reference external" href="https://github.com/WhoIsJack/EMBL-CodingClub">WhoIsJack/EMBL-CodingClub</a></p>
<p><a class="reference external" href="https://bio-it.embl.de/Coding%20Club/Curated%20Tutorials/">https://bio-it.embl.de/Coding%20Club/Curated%20Tutorials/</a></p>
</section>
<hr class="docutils" />
<section id="measuring-reporter-activity-domain-in-epi-aggregates-and-gastruloids-ijm">
<h2>Measuring reporter activity domain in EPI aggregates and Gastruloids.ijm<a class="headerlink" href="#measuring-reporter-activity-domain-in-epi-aggregates-and-gastruloids-ijm" title="Link to this heading">#</a></h2>
<p>Romain Guiet, Olivier Burri, Mehmet Girgin, Matthias Lutolf</p>
<p>Published 2022-12-07</p>
<p>Licensed CC-BY-4.0</p>
<p>This imagej macro analyses the reporter intensity activity and expression domain in EPI aggregates and Gastruloids.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/7409423">https://zenodo.org/records/7409423</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7409423">https://doi.org/10.5281/zenodo.7409423</a></p>
</section>
<hr class="docutils" />
<section id="melanoma-histopathology-dataset-with-tissue-and-nuclei-annotations">
<h2>Melanoma Histopathology Dataset with Tissue and Nuclei Annotations<a class="headerlink" href="#melanoma-histopathology-dataset-with-tissue-and-nuclei-annotations" title="Link to this heading">#</a></h2>
<p>Mark Schuiveling</p>
<p>Published 2025-03-19</p>
<p>Licensed CC-ZERO</p>
<p>Description:
This dataset is designed for development of deep learning models for segmentation of nuclei and tissue in melanoma H&amp;E stained histopathology. Existing nuclei segmentation models that are trained on non-melanoma specific datasets have low performance due to the ability of melanocytes to mimic other cell types, whereas existing melanoma specific models utilize older, sub-optimal techniques. Moreover, these models do not provide tissue annotations necessary for determining the localization of tumor-infiltrating lymphocytes, which may hold value for predictive and prognostic tasks. To address this, we created a melanoma specific dataset with nuclei and tissue annotations. 
Methodology:
Sample Collection:
Regions of interest (ROIs) were sampled from H&amp;E stained slides of 103 primary melanoma specimens and 102 metastatic melanoma specimens, scanned using a Hamamatsu scanner at 40× magnification (0.23 μm per pixel). All slides were obtained from regular diagnostic procedures.From each specimen, a 40× magnified ROI of 1024×1024 pixels was selected for annotation. Additionally, a context ROI of 5120×5120 pixels was sampled to provide information about the broader context for the annotation process. Selection was performed by a trained medical expert (M.S.) and subsequently verified by a dermatopathologist (W.B.). Manual ROI selection ensured the inclusion of diverse tissue and nuclei types.
Annotation Process:</p>
<p>Nuclei segmentationNuclei segmentations were generated using Hover-Net pretrained on the PanNuke dataset. Manual annotation adjustments were performed by author M.S. using QuPath, with the following nuclei categories: tumor, stroma, vascular endothelium, histiocyte, melanophage, lymphocyte, plasma cell, neutrophil, apoptotic cell, and epithelium. All annotations were reviewed and corrected, where needed, by a dermatopathologist (W.B.).
Tissue segmentationTissue segmentations were created manually using QuPath by M.S., with the following categories: tumor, stroma, epidermis, necrosis, blood vessel, and background. Annotations were reviewed and corrected, where needed, by a dermatopathologist (W.B.).</p>
<p>Quality Control: To assess the reliability of the annotations, intra- and interobserver agreement (by pathologist G.B.) were determined on 12 randomly selected ROIs.</p>
<p>Nuclei segmentationThe intraobserver overall precision was 84.89%, with a recall of 86.45%, and an F1 score of 85.66%. Interobserver overall precision was 80.34%, with a recall of 80.62%, and an F1 score of 80.20%. These results are based on the sum of all true positive, false positive, and false negative counts for the 12 ROIs.
Tissue segmentationThe DICE score was determined on the same 12 randomly selected ROIs. The average intraobserver DICE score was 0.90, and the interobserver DICE score was also 0.90.</p>
<p> 
Version 3:Removed sample “training_set_metastatic_roi_103” due to inconsistencies in annotation file.
Version 4:Sample training_set_metastatic_roi_088 missed one color annotation for a nuclei_apoptosis in the geojson file rendering it qupath uncompatible. This is fixed in the new version. 
Version 5:Addition of correct sample of training_set_metastatic_roi_103” after deadline of panoptic segmentation of nuclei and tissue in advanced melanoma challenge test phase. </p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/15050523">https://zenodo.org/records/15050523</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15050523">https://doi.org/10.5281/zenodo.15050523</a></p>
</section>
<hr class="docutils" />
<section id="melbourne-advanced-microscopy-facility">
<h2>Melbourne Advanced Microscopy Facility<a class="headerlink" href="#melbourne-advanced-microscopy-facility" title="Link to this heading">#</a></h2>
<p>Collection of tutorial videos for Fiji users</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Collection, Video</p>
<p><a class="reference external" href="https://www.youtube.com/&#64;melbourneadvancedmicroscop2617">https://www.youtube.com/&#64;melbourneadvancedmicroscop2617</a></p>
</section>
<hr class="docutils" />
<section id="membrain-seg-training-data">
<h2>MemBrain-seg training data<a class="headerlink" href="#membrain-seg-training-data" title="Link to this heading">#</a></h2>
<p>Lorenz Lamm</p>
<p>Published 2023-03-16</p>
<p>Licensed CC-BY-4.0</p>
<p>This dataset contains training data for segmenting membranes in cryo-electron tomograms.</p>
<p>More details will follow.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/7739793">https://zenodo.org/records/7739793</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7739793">https://doi.org/10.5281/zenodo.7739793</a></p>
</section>
<hr class="docutils" />
<section id="memorandum-of-understanding-of-nfdi-consortia-from-earth-chemical-and-life-sciences-to-support-a-network-called-the-geo-chem-life-science-helpdesk-cluster">
<h2>Memorandum of Understanding of NFDI consortia from Earth-, Chemical and Life Sciences to support a network called the Geo-Chem-Life Science Helpdesk Cluster<a class="headerlink" href="#memorandum-of-understanding-of-nfdi-consortia-from-earth-chemical-and-life-sciences-to-support-a-network-called-the-geo-chem-life-science-helpdesk-cluster" title="Link to this heading">#</a></h2>
<p>Lars Bernard, Maike Brück, Christian Busse, Judith Engel, Jan Eufinger, Frank Ewert, Juliane Fluck, Konrad Förstner, Julia Fürst, Holger Gauza, Klaus Getzlaff, Glöckner, Frank Oliver, Johannes Hunold, Oliver Koepler, Ksenia Krooß, Birte Lindstädt, McHardy, Alice C., Hela Mehrtens, Elena Rey-Mazon, Marcus Schmidt, Isabel Schober, Annett Schröter, Oliver Stegle, Christoph Steinbeck, Feray Steinhart, von Suchodoletz, Dirk, Stefanie Weidtkamp-Peters, Jens Wendt, Conni Wetzker</p>
<p>Published 2025-04-02</p>
<p>Licensed CC-BY-4.0</p>
<p>In a Memorandum of Understanding, the undersigned consortia agree to work together to enhance their support capabilities (helpdesks) to meet the needs of interdisciplinary research in Earth-, Chemical and Life Sciences.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15065070">https://zenodo.org/records/15065070</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15065070">https://doi.org/10.5281/zenodo.15065070</a></p>
</section>
<hr class="docutils" />
<section id="metadata-annotation-workflow-for-omero-with-tabbles">
<h2>Metadata Annotation Workflow for OMERO with Tabbles<a class="headerlink" href="#metadata-annotation-workflow-for-omero-with-tabbles" title="Link to this heading">#</a></h2>
<p>Wendt Jens</p>
<p>Published 2023-09-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Short presentation given at at PoL BioImage Analysis Symposium Dresden 2023</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/8314968">https://zenodo.org/records/8314968</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8314968">https://doi.org/10.5281/zenodo.8314968</a></p>
</section>
<hr class="docutils" />
<section id="metadata-in-bioimaging">
<h2>Metadata in Bioimaging<a class="headerlink" href="#metadata-in-bioimaging" title="Link to this heading">#</a></h2>
<p>Josh Moore, Susanne Kunis</p>
<p>Published 2025-03-25</p>
<p>Licensed CC-BY-4.0</p>
<p>Presentation given to the Search &amp; Harvesting workgroup of the Metadata section of NFDI on March 25th, 2025</p>
<p>Tags: Nfdi4Bioimage, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15083018">https://zenodo.org/records/15083018</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15083018">https://doi.org/10.5281/zenodo.15083018</a></p>
</section>
<hr class="docutils" />
<section id="methodsj2-a-software-tool-to-capture-metadata-and-generate-comprehensive-microscopy-methods-text">
<h2>MethodsJ2: a software tool to capture metadata and generate comprehensive microscopy methods text<a class="headerlink" href="#methodsj2-a-software-tool-to-capture-metadata-and-generate-comprehensive-microscopy-methods-text" title="Link to this heading">#</a></h2>
<p>Joel Ryan, Thomas Pengo, Alex Rigano, Paula Montero Llopis, Michelle S. Itano, Lisa A. Cameron, Guillermo Marqués, Caterina Strambio-De-Castillia, Mark A. Sanders, Claire M. Brown</p>
<p>Tags: Metadata, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.nature.com/articles/s41592-021-01290-5">https://www.nature.com/articles/s41592-021-01290-5</a></p>
</section>
<hr class="docutils" />
<section id="metrics-reloaded-a-framework-for-trustworthy-image-analysis-validation">
<h2>Metrics Reloaded - A framework for trustworthy image analysis validation<a class="headerlink" href="#metrics-reloaded-a-framework-for-trustworthy-image-analysis-validation" title="Link to this heading">#</a></h2>
<p>Licensed UNKNOWN</p>
<p>The mission of Metrics Reloaded is to guide researchers in the selection of appropriate performance metrics for biomedical image analysis problems, as well as provide a comprehensive online resource for metric-related information and pitfalls</p>
<p>Tags: Bioimage Analysis, Quality Control, Exclude From Dalia</p>
<p>Content type: Website, Collection</p>
<p><a class="reference external" href="https://metrics-reloaded.dkfz.de/">https://metrics-reloaded.dkfz.de/</a></p>
</section>
<hr class="docutils" />
<section id="mitobo-a-toolbox-for-image-processing-and-analysis">
<h2>MiToBo - A Toolbox for Image Processing and Analysis<a class="headerlink" href="#mitobo-a-toolbox-for-image-processing-and-analysis" title="Link to this heading">#</a></h2>
<p>Birgit Möller, Markus Glaß, Danny Misiak, Stefan Posch</p>
<p>The Microscope Image Analysis Toolbox is a toolbox with a collection of algorithms for processing and analyzing digital images.</p>
<p>Tags: Workflow Engine, Imagej, Exclude From Dalia</p>
<p>Content type: Publication, Documentation</p>
<p><a class="reference external" href="https://openresearchsoftware.metajnl.com/articles/10.5334/jors.103">https://openresearchsoftware.metajnl.com/articles/10.5334/jors.103</a></p>
<p><a class="reference external" href="https://mitobo.informatik.uni-halle.de/">https://mitobo.informatik.uni-halle.de/</a></p>
</section>
<hr class="docutils" />
<section id="micro-meta-app-an-interactive-tool-for-collecting-microscopy-metadata-based-on-community-specifications">
<h2>Micro-Meta App: an interactive tool for collecting microscopy metadata based on community specifications<a class="headerlink" href="#micro-meta-app-an-interactive-tool-for-collecting-microscopy-metadata-based-on-community-specifications" title="Link to this heading">#</a></h2>
<p>Alessandro Rigano, et al.</p>
<p>Tags: Metadata, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://doi.org/10.1038/s41592-021-01315-z">https://doi.org/10.1038/s41592-021-01315-z</a></p>
</section>
<hr class="docutils" />
<section id="microsam-talks">
<h2>MicroSam-Talks<a class="headerlink" href="#microsam-talks" title="Link to this heading">#</a></h2>
<p>Constantin Pape</p>
<p>Published 2024-05-23</p>
<p>Licensed CC-BY-4.0</p>
<p>Talks about Segment Anything for Microscopy: <a class="github reference external" href="https://github.com/computational-cell-analytics/micro-sam">computational-cell-analytics/micro-sam</a>.
Currently contains slides for two talks:</p>
<p>Overview of Segment Anythign for Microscopy given at the SWISSBIAS online meeting in April 2024
Talk about vision foundation models and Segment Anything for Microscopy given at Human Technopole as part of the EMBO Deep Learning Course in May 2024</p>
<p>Tags: Bioimage Analysis, Artificial Intelligence, Exclude From Dalia</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/11265038">https://zenodo.org/records/11265038</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11265038">https://doi.org/10.5281/zenodo.11265038</a></p>
</section>
<hr class="docutils" />
<section id="microscopy-bids-an-extension-to-the-brain-imaging-data-structure-for-microscopy-data">
<h2>Microscopy-BIDS - An Extension to the Brain Imaging Data Structure for Microscopy Data<a class="headerlink" href="#microscopy-bids-an-extension-to-the-brain-imaging-data-structure-for-microscopy-data" title="Link to this heading">#</a></h2>
<p>Marie-Hélène Bourget, Lee Kamentsky, Satrajit S. Ghosh, Giacomo Mazzamuto, Alberto Lazari, et al.</p>
<p>Published 2022-04-19</p>
<p>Licensed CC-BY-4.0</p>
<p>The Brain Imaging Data Structure (BIDS) is a specification for organizing, sharing, and archiving neuroimaging data and metadata in a reusable way.</p>
<p>Tags: Research Data Management, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2022.871228/full">https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2022.871228/full</a></p>
</section>
<hr class="docutils" />
<section id="microscopydb">
<h2>MicroscopyDB<a class="headerlink" href="#microscopydb" title="Link to this heading">#</a></h2>
<p>Licensed ALL RIGHTS RESERVED</p>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://microscopydb.io/">https://microscopydb.io/</a></p>
</section>
<hr class="docutils" />
<section id="monuseg-dataset">
<h2>MoNuSeg Dataset<a class="headerlink" href="#monuseg-dataset" title="Link to this heading">#</a></h2>
<p>Neeraj Kumar, Ruchika Verma, Sanuj Sharma, Surabhi Bhargava, Abhishek Vahadane, Amit Sethi</p>
<p>Published 2017-07-01</p>
<p>Licensed CC-BY-NC-SA-4.0</p>
<p>The dataset for this challenge was obtained by carefully annotating tissue images of several patients with tumors of different organs and who were diagnosed at multiple hospitals. This dataset was created by downloading H&amp;E stained tissue images captured at 40x magnification from TCGA archive. H&amp;E staining is a routine protocol to enhance the contrast of a tissue section and is commonly used for tumor assessment (grading, staging, etc.). Given the diversity of nuclei appearances across multiple organs and patients, and the richness of staining protocols adopted at multiple hospitals, the training datatset will enable the development of robust and generalizable nuclei segmentation techniques that will work right out of the box.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://monuseg.grand-challenge.org/Data/">https://monuseg.grand-challenge.org/Data/</a></p>
</section>
<hr class="docutils" />
<section id="model-and-simulations-for-patterned-invagination-prevents-mechanical-instability-during-gastrulation">
<h2>Model and simulations for: Patterned invagination prevents mechanical instability during gastrulation<a class="headerlink" href="#model-and-simulations-for-patterned-invagination-prevents-mechanical-instability-during-gastrulation" title="Link to this heading">#</a></h2>
<p>Abhijeet Krishna, Alicja Szałapak, Vellutini, Bruno C., Cuenca, Marina B., Pavel Tomančák, Modes, Carl D.</p>
<p>Published 2025-07-14</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository contains the code and simulations for the manuscript:
Vellutini BC, Cuenca MB, Krishna A, Szałapak A, Modes CD, Tomančák P. Patterned embryonic invagination evolved in response to mechanical instability. bioRxiv (2023) doi:10.1101/2023.03.30.534554
Please refer to the main repository for more information: <a class="reference external" href="https://doi.org/10.5281/zenodo.7781947">https://doi.org/10.5281/zenodo.7781947</a></p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15869598">https://zenodo.org/records/15869598</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15869598">https://doi.org/10.5281/zenodo.15869598</a></p>
</section>
<hr class="docutils" />
<section id="modeling-community-standards-for-metadata-as-templates-makes-data-fair">
<h2>Modeling community standards for metadata as templates makes data FAIR<a class="headerlink" href="#modeling-community-standards-for-metadata-as-templates-makes-data-fair" title="Link to this heading">#</a></h2>
<p>Mark A Musen, Martin J O’Connor, Erik Schultes, Marcos Martínez-Romero, Josef Hardi, John Graybeal</p>
<p>Published 2022-11-12</p>
<p>Licensed CC-BY-4.0</p>
<p>The authors have developed a model for scientific metadata, and they have made that model usable by both CEDAR and FAIRware. The approach shows that a formal metadata model can standardize reporting guidelines and that it can enable separate software systems to assist (1) in the authoring of standards-adherent metadata and (2) in the evaluation of existing metadata.</p>
<p>Tags: Data Stewardship, FAIR-Principles, Metadata, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/36371407/">https://pubmed.ncbi.nlm.nih.gov/36371407/</a></p>
<p><a class="reference external" href="https://www.nature.com/articles/s41597-022-01815-3">https://www.nature.com/articles/s41597-022-01815-3</a></p>
</section>
<hr class="docutils" />
<section id="models-and-applications-for-bioimage-io">
<h2>Models and Applications for <a class="reference external" href="http://BioImage.IO">BioImage.IO</a><a class="headerlink" href="#models-and-applications-for-bioimage-io" title="Link to this heading">#</a></h2>
<p>Wei Ouyang, et al.</p>
<p>Licensed UNKNOWN</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="github reference external" href="https://github.com/imjoy-team/bioimage-io-resources">imjoy-team/bioimage-io-resources</a></p>
</section>
<hr class="docutils" />
<section id="modular-training-resources-for-bioimage-analysis">
<h2>Modular training resources for bioimage analysis<a class="headerlink" href="#modular-training-resources-for-bioimage-analysis" title="Link to this heading">#</a></h2>
<p>Christian Tischer, Antonio Politi, Tim-Oliver Buchholz, Elnaz Fazeli, Nicola Gritti, Aliaksandr Halavatyi, Gonzalez Tirado, Sebastian, Julian Hennies, Toby Hodges, Arif Khan, Dominik Kutra, Stefania Marcotti, Bugra Oezdemir, Felix Schneider, Martin Schorb, Anniek Stokkermans, Yi Sun, Nima Vakili</p>
<p>Published 2025-01-21</p>
<p>Licensed CC-BY-4.0</p>
<p>The newly developed image data formats course was taught for the first time: <a class="github reference external" href="https://github.com/NEUBIAS/training-resources/blob/master/courses/2025_01_EMBL_image_data_formats.md">NEUBIAS/training-resources</a></p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14710820">https://zenodo.org/records/14710820</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14710820">https://doi.org/10.5281/zenodo.14710820</a></p>
</section>
<hr class="docutils" />
<section id="modularimageanalysis-mia-assembly-of-modularisedimage-and-object-analysis-workflows-in-imagej">
<h2>ModularImageAnalysis (MIA): Assembly of modularisedimage and object analysis workflows in ImageJ<a class="headerlink" href="#modularimageanalysis-mia-assembly-of-modularisedimage-and-object-analysis-workflows-in-imagej" title="Link to this heading">#</a></h2>
<p>Stephen J. Cross, Jordan D. J. R. Fisher, Mark A. Jepson</p>
<p>ModularImageAnalysis is a Fiji plugin providing a modular framework for assembling image and object analysis workflows</p>
<p>Tags: Workflow Engine, Imagej, Exclude From Dalia</p>
<p>Content type: Publication, Documentation</p>
<p><a class="reference external" href="https://doi.org/10.1111/jmi.13227">https://doi.org/10.1111/jmi.13227</a></p>
<p><a class="reference external" href="https://mianalysis.github.io/">https://mianalysis.github.io/</a></p>
</section>
<hr class="docutils" />
<section id="monusac-2020">
<h2>MonuSAC 2020<a class="headerlink" href="#monusac-2020" title="Link to this heading">#</a></h2>
<p>Ruchika Verma, Neeraj Kumar, Abhijeet Patil, Nikhil Cherian Kurian, Swapnil Rane, Simon Graham</p>
<p>Published 2021-06-04</p>
<p>Licensed CC-BY-NC-SA-4.0</p>
<p>H&amp;E staining of human tissue sections is a routine and most common protocol used by pathologists to enhance the contrast of tissue sections for tumor assessment (grading, staging, etc.) at multiple microscopic resolutions. Hence, we will provide the annotated dataset of H&amp;E stained digitized tissue images of several patients acquired at multiple hospitals using one of the most common 40x scanner magnification. The annotations will be done with the help of expert pathologists.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://monusac-2020.grand-challenge.org/Data/">https://monusac-2020.grand-challenge.org/Data/</a></p>
</section>
<hr class="docutils" />
<section id="morpholibj-documentation">
<h2>MorphoLibJ documentation<a class="headerlink" href="#morpholibj-documentation" title="Link to this heading">#</a></h2>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Document</p>
<p><a class="reference external" href="https://imagej.net/plugins/morpholibj">https://imagej.net/plugins/morpholibj</a></p>
</section>
<hr class="docutils" />
<section id="mouse-embryo-blastocyst-cells">
<h2>Mouse embryo blastocyst cells<a class="headerlink" href="#mouse-embryo-blastocyst-cells" title="Link to this heading">#</a></h2>
<p>Vebjorn Ljosa, Katherine L. Sokolnicki, Anne E. Carpenter</p>
<p>Published 2012-06-28</p>
<p>Licensed CC0-1.0</p>
<p>Segmenting nuclei in 3D images can be challenging especially when nuclei are clustered not only in XY plane but also in XZ and YZ planes. Manually annotated ground truth provides a reference for image analysis software testing purposes. These images of mouse embryo blastocyst cells also have changing nuclei intensity in Z plane which makes finding the right threshold for successful segmentation a difficult task. This image set also contains GAPDH transcripts that can be quantified in each cell.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://bbbc.broadinstitute.org/BBBC032">https://bbbc.broadinstitute.org/BBBC032</a></p>
</section>
<hr class="docutils" />
<section id="multimodal-large-language-models-for-bioimage-analysis">
<h2>Multimodal large language models for bioimage analysis<a class="headerlink" href="#multimodal-large-language-models-for-bioimage-analysis" title="Link to this heading">#</a></h2>
<p>Shanghang Zhang, Gaole Dai, Tiejun Huang, Jianxu Chen</p>
<p>Licensed CC-BY-NC-SA</p>
<p>Multimodal large language models have been recognized as a historical milestone in the field of artificial intelligence and have demonstrated revolutionary potentials not only in commercial applications, but also for many scientific fields. Here we give a brief overview of multimodal large language models through the lens of bioimage analysis and discuss how we could build these models as a community to facilitate biology research</p>
<p>Tags: Bioimage Analysis, FAIR-Principles, Workflow, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.nature.com/articles/s41592-024-02334-2">https://www.nature.com/articles/s41592-024-02334-2</a></p>
<p><a class="reference external" href="https://arxiv.org/abs/2407.19778">https://arxiv.org/abs/2407.19778</a></p>
</section>
<hr class="docutils" />
<section id="multiplexed-histology-of-covid-19-post-mortem-lung-samples-control-case-1-fov1">
<h2>Multiplexed histology of COVID-19 post-mortem lung samples - CONTROL CASE 1 FOV1<a class="headerlink" href="#multiplexed-histology-of-covid-19-post-mortem-lung-samples-control-case-1-fov1" title="Link to this heading">#</a></h2>
<p>Anna Pascual Reguant, Ronja Mothes, Helena Radbruch, Anja E. Hauser</p>
<p>Published 2022-12-16</p>
<p>Licensed CC-BY-4.0</p>
<p>Image-based data set of a post-mortem lung sample from a non-COVID-related pneumonia donor (CONTROL CASE 1, FOV1)</p>
<p>Each image shows the same field of view (FOV), sequentially stained with the depicted fluorescence-labelled antibodies, including surface proteins, intracellular proteins and transcription factors. Images contain 2024 x 2024 pixels and are generated using an inverted wide-field fluorescence microscope with a 20x objective, a lateral resolution of 325 nm and an axial resolution above 5 µm. Images have been normalized and intensities adjusted.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/7447491">https://zenodo.org/records/7447491</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7447491">https://doi.org/10.5281/zenodo.7447491</a></p>
</section>
<hr class="docutils" />
<section id="neubias-youtube-channel">
<h2>NEUBIAS YouTube Channel<a class="headerlink" href="#neubias-youtube-channel" title="Link to this heading">#</a></h2>
<p>A collection of bio-image analysis webinars where commonly authors of open-source bio-image analysis software explain how to use their tools.</p>
<p>Tags: Neubias, Exclude From Dalia</p>
<p>Content type: Collection, Video</p>
<p><a class="reference external" href="https://www.youtube.com/neubias">https://www.youtube.com/neubias</a></p>
</section>
<hr class="docutils" />
<section id="nfdi-daten-als-gemeinsames-gut-fur-exzellente-forschung-organisiert-durch-die-wissenschaft-in-deutschland">
<h2>NFDI - Daten als gemeinsames Gut für exzellente Forschung, organisiert durch die Wissenschaft in Deutschland.<a class="headerlink" href="#nfdi-daten-als-gemeinsames-gut-fur-exzellente-forschung-organisiert-durch-die-wissenschaft-in-deutschland" title="Link to this heading">#</a></h2>
<p>Licensed UNKNOWN</p>
<p>Schritt für Schritt verbessern wir die Nutzungsmöglichkeiten von Daten für Wissenschaft und Gesellschaft. Durch unser Zusammenwirken im NFDI-Verein entsteht eine Dachorganisation für das Forschungsdatenmanagement in allen Wissenschaftszweigen.</p>
<p>Tags: Nfdi4Bioimage, Research Data Management, Exclude From Dalia</p>
<p>Content type: Website</p>
<p><a class="reference external" href="https://www.nfdi.de/">https://www.nfdi.de/</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage">
<h2>NFDI4BIOIMAGE<a class="headerlink" href="#nfdi4bioimage" title="Link to this heading">#</a></h2>
<p>Carsten Fortmann-Grote</p>
<p>Published 2024-04-22</p>
<p>Licensed CC-BY-4.0</p>
<p>This presentation was given at the 2nd MPG-NFDI Workshop on April 18th.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/11031747">https://zenodo.org/records/11031747</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11031747">https://doi.org/10.5281/zenodo.11031747</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-an-initiative-for-a-national-research-data-infrastructure-for-microscopy-data">
<h2>NFDI4BIOIMAGE - An Initiative for a National Research Data Infrastructure for Microscopy Data<a class="headerlink" href="#nfdi4bioimage-an-initiative-for-a-national-research-data-infrastructure-for-microscopy-data" title="Link to this heading">#</a></h2>
<p>Christian Schmidt, Elisa Ferrando-May</p>
<p>Published 2021-04-29</p>
<p>Licensed CCY-BY-SA-4.0</p>
<p>Align existing and establish novel services &amp; solutions for data management tasks throughout the bioimage data lifecycle.</p>
<p>Tags: Nfdi4Bioimage, Research Data Management, Exclude From Dalia</p>
<p>Content type: Conference Abstract, Slides</p>
<p><a class="reference external" href="https://doi.org/10.11588/heidok.00029489">https://doi.org/10.11588/heidok.00029489</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis-conference-talk-the-pelagic-imaging-consortium-meets-helmholtz-imaging-5-10-2023-hamburg">
<h2>NFDI4BIOIMAGE - National Research Data Infrastructure for Microscopy and BioImage Analysis [conference talk: The Pelagic Imaging Consortium meets Helmholtz Imaging, 5.10.2023, Hamburg]<a class="headerlink" href="#nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis-conference-talk-the-pelagic-imaging-consortium-meets-helmholtz-imaging-5-10-2023-hamburg" title="Link to this heading">#</a></h2>
<p>Riccardo Massei</p>
<p>Licensed CC-BY-4.0</p>
<p>NFDI4BIOIMAGE is a consortium within the framework of the National Research Data Infrastructure (NFDI) in Germany. In this talk, the consortium and the contribution to the work programme by the Helmholtz Centre for Environmental Research (UFZ) in Leipzig are outlined.</p>
<p>Tags: Research Data Management, Bioimage Analysis, Nfdi4Bioimage, Exclude From Dalia</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.8414318">https://zenodo.org/doi/10.5281/zenodo.8414318</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-a-consortium-of-the-national-research-data-infrastructure">
<h2>NFDI4BIOIMAGE - a consortium of the National Research Data Infrastructure<a class="headerlink" href="#nfdi4bioimage-a-consortium-of-the-national-research-data-infrastructure" title="Link to this heading">#</a></h2>
<p>Nfdi4Bioimage</p>
<p>Licensed UNKNOWN</p>
<p>Tags: Bioimage Analysis, Research Data Management, Nfdi4Bioimage, Exclude From Dalia</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://nfdi4bioimage.de/home/">https://nfdi4bioimage.de/home/</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-calendar-april-2025">
<h2>NFDI4BIOIMAGE Calendar April 2025<a class="headerlink" href="#nfdi4bioimage-calendar-april-2025" title="Link to this heading">#</a></h2>
<p>Martin Zurowietz, Nattkemper, Tim W.</p>
<p>Published 2025-09-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Image from the NFDI4BIOIMAGE Calendar April 2025.
This image shows the BIIGLE image and video annotation tool, which is a web-based software for collaborative research on large imaging datasets [1, 2]. It offers tools for manual and computer-assisted annotation, quality control and the collaboration on custom taxonomies to describe objects. BIIGLE is freely available and can be installed in cloud environments, a local network or on mobile platforms during research expeditions. A public instance can be found at <a class="reference external" href="http://biigle.de">biigle.de</a>.
The annotated image shows the coastline of Fernandina Island, Galapagos, which is the habitat of the Galapagos Marine Iguana (Amblyrhynchus cristatus). The image is a large mosaic that was stitched together from many individual images captured by a drone. The green annotations marking the iguanas were machine-generated as part of a feasibility study for the automatic analysis of the data in the project Iguanas from Above [3, 4].
[1] Langenkämper, D., Zurowietz, M., Schoening, T., &amp; Nattkemper, T. W. (2017). BIIGLE 2.0-browsing and annotating large marine image collections. Frontiers in Marine Science, 4, 83. <a class="reference external" href="https://doi.org/10.3389/fmars.2017.00083">https://doi.org/10.3389/fmars.2017.00083</a>
[2] Zurowietz, M., &amp; Nattkemper, T. W. (2021). Current trends and future directions of large scale image and video annotation: Observations from four years of BIIGLE 2.0. Frontiers in Marine Science, 8, 760036. <a class="reference external" href="https://doi.org/10.3389/fmars.2021.760036">https://doi.org/10.3389/fmars.2021.760036</a>
[3] Varela-Jaramillo, A., Rivas-Torres, G., Guayasamin, J. M., Steinfartz, S., &amp; MacLeod, A. (2023). A pilot study to estimate the population size of endangered Galápagos marine iguanas using drones. Frontiers in Zoology, 20(1), 4. <a class="reference external" href="https://doi.org/10.1186/s12983-022-00478-5">https://doi.org/10.1186/s12983-022-00478-5</a>
[4] <a class="reference external" href="https://iguanasfromabove.com">https://iguanasfromabove.com</a></p>
<p>Project</p>
<p>Iguanas from Above</p>
<p>Location</p>
<p>Fernandina Island, Galapagos</p>
<p>Organism</p>
<p>Amblyrhynchus cristatus</p>
<p>Drone model</p>
<p>DJI Mavic 2 Pro</p>
<p>Camera</p>
<p>Hasselblad L1D-20c</p>
<p>Size</p>
<p>26,545 × 20,894 px</p>
<p>Mosaic algorithm</p>
<p>Agisoft Metashape Professional v.1.6</p>
<p>Submitted via NFDI4Biodiversity</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16980661">https://zenodo.org/records/16980661</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16980661">https://doi.org/10.5281/zenodo.16980661</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-calendar-august-2025">
<h2>NFDI4BIOIMAGE Calendar August 2025<a class="headerlink" href="#nfdi4bioimage-calendar-august-2025" title="Link to this heading">#</a></h2>
<p>Haowen Jiang, Claire Chalopin</p>
<p>Published 2025-09-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Image from the NFDI4BIOIMAGE Calendar August 2025.
This image illustrates tissue oxygen saturation in the hand, calculated using various computer-assisted methods and based on hyperspectral and multispectral imaging. The purpose of this image is to compare the perfusion parameters (3 and 4) obtained with multispectral cameras delivering relatively less spectral information but capable of real-time imaging against the perfusion parameters (2) obtained with a hyperspectral medical system delivering large spectral information but not capable of real-time imaging. The picture shows that deep learning methods (4) perform better than classical methods (3) that are not based on artificial intelligence. It lays the groundwork for future real-time quantitative assessment of perfusion during organ transplantation surgeries.
Image Metadata (using REMBI template):</p>
<p>Study</p>
<p>Study description</p>
<p>Quantification of tissue reperfusion using real-time spectral imaging and deep learning</p>
<p>Study type</p>
<p>Study on volunteers</p>
<p>Study Component</p>
<p>Imaging method</p>
<p>(1) RGB imaging
(2) Hyperspectral imaging
(3) and (4) Multispectral imaging</p>
<p>Image component description</p>
<p>(1) RGB image of the hand under normal perfusion.
(2) Perfusion parameter map computed based on hyperspectral imaging (100 spectral bands between 500 and 1000 nm). High perfusion values are represented in red, low perfusion values in blue.
(3) Perfusion parameter map computed based on multispectral imaging (31 spectral bands between 460 and 850 nm) and using the spectral bands that are available but that are less than in (2). Therefore, the result in (3) looks very different from the result in (2).
(4) Perfusion parameter map computed based on multispectral imaging and using a deep neural network. The result in (4) looks similar to the result in (2).</p>
<p>Biosample</p>
<p>Biological entity</p>
<p>Hand</p>
<p>Organism</p>
<p>Homo sapiens</p>
<p>Image data</p>
<p>Image resolution hyperspectral imaging</p>
<p>Spatial Resolution: 480*640 pixels
Spectral Resolution: 500 nm-1000 nm, 100 bands, 5 nm</p>
<p>Image resolution multispectral imaging</p>
<p>Spatial Resolution: 1088*2048 pixels
Spectral Resolution: 16 bands in 460-600 nm; 15 bands in 600-850 nm</p>
<p>Image mode</p>
<p>Reflectance</p>
<p>Submitted via NFDI4BIOIMAGE</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16993059">https://zenodo.org/records/16993059</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16993059">https://doi.org/10.5281/zenodo.16993059</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-calendar-cover-2025">
<h2>NFDI4BIOIMAGE Calendar Cover 2025<a class="headerlink" href="#nfdi4bioimage-calendar-cover-2025" title="Link to this heading">#</a></h2>
<p>Anne Rademacher, Alik Huseynov, Michele Bortolomeazzi, Wille, Sina Jasmin, Sabrina Schumacher, Pooja Sant, Denise Keitel, Konstantin Okonechnikov, Ghasemi, David R., Pajtler, Kristian W., Jan-Philipp Mallm, Karsten Rippe</p>
<p>Published 2025-09-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Image from the NFDI4BIOIMAGE Calendar Cover 2025.
The image is a visualization showing the integration of multimodal data including a spinning disk confocal image and gene expression data from a spatial transcriptomic experiment on a human medulloblastoma sample. The microscopy image of the tissue with the nuclei in white has been overlayed with the result of the cell segmentation colored according to the assigned cell type (immune cells: red, stromal cells: violet, brain cells: cyan/blue, tumor cells: green). A subset of transcripts for three genes whose expression varies across the different cell types in the tissue have been represented as colored dots (CD4 (immune cells): red, PTCH1 (tumor cells): green, AQP4 (brain cells): blue).
Image Metadata (using REMBI template):</p>
<p>Study</p>
<p>Study description</p>
<p>Comparison of spatial transcriptomics technologies for medulloblastoma cryosection</p>
<p>Study type</p>
<p>Spatial Transcriptomics (Xenium) on medulloblastoma cryosections</p>
<p>Study Component</p>
<p>Imaging method</p>
<p>Xenium and Spinning disk confocal microscopy</p>
<p>Study component description</p>
<p>Datasets with raw and processed data from the study “Comparison of spatial transcriptomics technologies for medulloblastoma cryosections” including Xenium and spinning disk confocal microscopy data</p>
<p>Biosample</p>
<p>Identity</p>
<p>MB266</p>
<p>Biological entity</p>
<p>Human cerebellum from a patient with Medulloblastoma with extensive nodularity</p>
<p>Organism</p>
<p>Homo sapiens</p>
<p>Specimen</p>
<p>Experimental status</p>
<p>Patient sample</p>
<p>Preparation method</p>
<p>10 µm cryosections were acquired using the cryostar NX50 with a cutting temperature of -15 °C. Tissues were section in 10 µm slices and four samples were placed on one Xenium slide. Subsequently, the tissue was fixed with PFA according to the manufacture´s protocol. Tissues were permeabilized with SDS, incubated in 70% ice cold methanol and washed with PBS. Hybridization of the human generic brain panel with 70 add-on genes (Supplementary Dataset 1) was performed at 50°C in a Bio-Rad C1000 touch cycler for 20 hours. Washing, ligation and amplification steps were carried out according to the manufacturer’s instructions. ROIs were selected according to the tissue area excluding non-tissue covered tiles. Each transcript was imaged in a bright state five times across 60 cycle-channels (15 cycles x 4 channels). After the run on the Xenium analyzer slides were removed and buffer exchanged with PBS-T for further storage at 4°C.</p>
<p>Signal/contrast mechanism</p>
<p>Fluorescence</p>
<p>Channel 1 – content</p>
<p>DAPI</p>
<p>Channel 1 – biological entity</p>
<p>Nuclei (DNA)</p>
<p>Image acquisition</p>
<p>Instrument attributes</p>
<p>Imaging of RNAscope samples and reimaging of Xenium slides by SDCM was conducted on an Andor Dragonfly 505 spinning disk confocal system equipped with a Nikon Ti2-E inverted microscope and a CFI P-Fluor 40X/1.30 oil objective or a Plan Apo 60x/1.40 oil objective. Multicolor images were acquired with the following laser lines 405 nm (DAPI), 488 nm (Alexa 488, eosin), 561 nm (Atto 550), 637 nm (Atto 647) 730nm (Alexa 750).</p>
<p>Image acquisition parameters</p>
<p>Images were recorded at 16-bit depth and with 1024x1024 pixels dimensions (pixel size: 0.217 µm) using an iXon Ultra 888 EM-CCD camera. The region of interest was selected based on the DAPI signal and 50 z-slices were acquired with a step size of 0.4 µm (20 µm z-range) per field of view (FOV). Tiles were imaged with a 10% overlap to ensure accurate stitching.</p>
<p>Image data</p>
<p>Type</p>
<p>Figure</p>
<p>Format &amp; compression</p>
<p>PNG</p>
<p>Size description</p>
<p>8800x8788+0+0 pixels (Primary image)</p>
<p>Pixel/voxel size description</p>
<p>0.217 µm (Primary image)</p>
<p>Channel information</p>
<p>RGB</p>
<p>Image processing method</p>
<p>Tiles were imaged with a 10% overlap to ensure accurate stitching. Subsequently, a flatfield-correction was conducted based on the DAPI channel and stitching and registration of the tiles was conducted with Fiji. First, SDCM image stacks were subjected to a maximum intensity projection, followed by flat field and chromatic aberration correction using a custom script. Next, image tiles were stitched using the “Grid/Collection Stitching” plugin. DAPI images from SDCM were registered to MC or Xenium widefield images using “Register Virtual Stack Slices” with Affine feature extraction model and the Elastic bUnwarpJ splines registration model. In case of further staining, images were transformed via Transform Virtual Stack slices employing the transformation file of the DAPI registration.</p>
<p>Image Correlation</p>
<p>Spatial and temporal alignment</p>
<p>The region of interest was selected based on the DAPI signal and 50 z-slices were acquired with a step size of 0.4 µm (20 µm z-range) per field of view (FOV). Tiles were imaged with a 10% overlap to ensure accurate stitching. Subsequently, a flatfield-correction was conducted based on the DAPI channel and stitching and registration of the tiles was conducted with Fiji (<a class="github reference external" href="https://github.com/RippeLab/MBEN/tree/main/stitching">RippeLab/MBEN</a>) (<a class="github reference external" href="https://github.com/RippeLab/MBEN/tree/main/Registration">RippeLab/MBEN</a>).</p>
<p>Related images and relationship</p>
<p>MB266-morphology_mip.ome.tif at <a class="reference external" href="https://www.ebi.ac.uk/biostudies/bioimages/studies/S-BIAD1093">https://www.ebi.ac.uk/biostudies/bioimages/studies/S-BIAD1093</a></p>
<p>Analysed data</p>
<p>Analysis result type</p>
<p>Figure</p>
<p>Data used for analysis</p>
<p>MB266-transcripts.csv.gz, MB266-transcripts.csv.gz at <a class="reference external" href="https://www.ebi.ac.uk/biostudies/bioimages/studies/S-BIAD1093">https://www.ebi.ac.uk/biostudies/bioimages/studies/S-BIAD1093</a></p>
<p>Analysis method and details</p>
<p>Most of the analysis and visualization (including tidyverse, data.table, ggridges R packages) was done in R 4.2.2. Raw data were processed using technology-specific corporate pipelines (custom pipeline was used for MC). For each technology Seurat objects of the sample data and analysis results were created using the Seurat (v. 4.3.0) R package (<a class="github reference external" href="https://github.com/scOpenLab/spatial_analysis/tree/main">scOpenLab/spatial_analysis</a>)</p>
<p>Submitted via NFDI4BIOIMAGE</p>
<p> </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16979744">https://zenodo.org/records/16979744</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16979744">https://doi.org/10.5281/zenodo.16979744</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-calendar-december-2025">
<h2>NFDI4BIOIMAGE Calendar December 2025<a class="headerlink" href="#nfdi4bioimage-calendar-december-2025" title="Link to this heading">#</a></h2>
<p>Kira Müntjes, Kerstin Schipper</p>
<p>Published 2025-09-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Image from the NFDI4BIOIMAGE Calendar December 2025.
The microscopic image shows yeast cells of the fungal model Ustilago maydis that produce single cell oil at nitrogen-starvation conditions. The genetically engineered cells are packed with oil droplets that were visualized by BODIPY staining. The study was conducted in the framework of the BioSC project “NextVegOil”.
Image Metadata (using REMBI template):</p>
<p>Study</p>
<p>Study type</p>
<p>Visualisation of microbial oil in the fungus Ustilago maydis</p>
<p>Study Component</p>
<p>Imaging method</p>
<p>Wide field whole organism microscopy</p>
<p>Biosample</p>
<p>Biological entity</p>
<p>Ustilago maydis</p>
<p>Organism</p>
<p>Yeast cells (sporidia)</p>
<p>Identity</p>
<p>Ustilago maydis MB215 cyp1Δemt1Δ (published in <a class="reference external" href="https://doi.org/10.1128/AEM.71.6.3033-3040.2005">https://doi.org/10.1128/AEM.71.6.3033-3040.2005</a>)</p>
<p>Intrinsic variable</p>
<p>Glycolipid production has been ablated by genetic engineering</p>
<p>Extrinsic variable</p>
<p>BODIPY (4,4-Difluoro-1,3,5,7,8-Pentamethyl-4-Bora-3a,4a-Diaza-s-Indacene 493/503) staining</p>
<p>Experimental variables</p>
<p>Cultivation time</p>
<p>Specimen</p>
<p>Location within biosample</p>
<p>Overview image with yeast cells from liquid culture at nitrogen-starvation condition</p>
<p>Preparation method</p>
<p>Living cells attached to agarose mounts</p>
<p>Signal/contrast mechanism</p>
<p>Differential interference contrast and fluorescence</p>
<p>Channel 1 - content</p>
<p>DIC</p>
<p>Channel 1 - biological entity</p>
<p>Intact yeast cells</p>
<p>Channel 2 - content</p>
<p>BODIPY 493/503</p>
<p>Channel 2 - biological entity</p>
<p>Intracellular lipid droplets</p>
<p>Image acquisition</p>
<p>Instrument attributes</p>
<p>Zeiss Axio Observer.Z1; Prime BSI express; solid-state laser 488 nm</p>
<p>Submitted via NFDI4BIOIMAGE</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16993955">https://zenodo.org/records/16993955</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16993955">https://doi.org/10.5281/zenodo.16993955</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-calendar-february-2025">
<h2>NFDI4BIOIMAGE Calendar February 2025<a class="headerlink" href="#nfdi4bioimage-calendar-february-2025" title="Link to this heading">#</a></h2>
<p>Oleg Kutskiy</p>
<p>Published 2025-09-15</p>
<p>Licensed CC-BY-SA-4.0</p>
<p>Image from the NFDI4BIOIMAGE Calendar February 2025.
“The Way of the Cross: Christ collapses under the weight of the cross” is a recording from the partially destroyed Transfiguration Cathedral in Odessa, Ukraine. The image was taken in September 2023 and impressively shows the urgency of photographic documentation of cultural heritage. It was created as part of the “Documenting Ukrainian Cultural Heritage Project – Photographic Documentation of War-Threatened Buildings in Ukraine”.</p>
<p>Project</p>
<p>Documenting Ukrainian Cultural Heritage – Photographic Documentation of War-Threatened Buildings in Ukraine</p>
<p>Recording date</p>
<p>2023-09-01</p>
<p>Location</p>
<p>The Savior Transfiguration Cathedral, south side choir
Ploshcha Soborna 3, Odessa, Ukraine</p>
<p>Dating</p>
<p>1999/2005</p>
<p>Factual term</p>
<p>Mural</p>
<p>Genus</p>
<p>Wall painting</p>
<p>Status</p>
<p>Partially destroyed 2023-07-23</p>
<p>Image file number</p>
<p>fmd10034507</p>
<p>Topic</p>
<p>Iconography: 73D4113 * the third fall (Christ carrying the cross)</p>
<p>Dataset from</p>
<p>Bildarchiv Foto Marburg</p>
<p>Acquisition parameter</p>
<p>Color, born digital</p>
<p>Submitted via NFDI4Culture</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16980386">https://zenodo.org/records/16980386</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16980386">https://doi.org/10.5281/zenodo.16980386</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-calendar-january-2025">
<h2>NFDI4BIOIMAGE Calendar January 2025<a class="headerlink" href="#nfdi4bioimage-calendar-january-2025" title="Link to this heading">#</a></h2>
<p>Lea Miebach, Sander Bekeschus</p>
<p>Published 2025-09-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Image from the NFDI4BIOIMAGE Calendar January 2025.
A Heart for Redox Biology: The image of primary bone mesenchymal stromal/stem cells (hBM-MSCs) was captured in a study evaluating the cellular effects of therapeutic oxidation in the context of regenerative medicine. The cells were isolated from an arthroplasty patient cohort in a joint research project between the Center for Orthopaedics at University Medical Center and the group ZIK plasmatis at the Leibniz Institute for Plasma Science and Technology (INP) in Greifswald. You can appreciate the characteristic morphology and complex actin cytoskeleton that is crucial for the cellular function of hBM-MSCs. Can you spot the heart that is formed by the prominent actin protrusions of interconnected cells?
Image Metadata (using REMBI template):</p>
<p>Study Component</p>
<p>Imaging method</p>
<p>Spinning-disc confocal mode, epifluorescence</p>
<p>Biosample</p>
<p>Biological entity</p>
<p>Bone marrow-mesenchymal stem cells (BM-MSCs)</p>
<p>Organism</p>
<p>Homo sapiens</p>
<p>Specimen</p>
<p>Preparation method</p>
<p>Fixation (4% PFA)</p>
<p>Signal/contrast mechanism</p>
<p>Fluorescence</p>
<p>Channel 1 – content</p>
<p>4’,6-Diamidin-2-phenylindol (DAPI; Thermo Fisher, USA), blue</p>
<p>Channel 1 – biological entity</p>
<p>Nuclei</p>
<p>Channel 2 – content</p>
<p>MitoSpy Green (Biolegend, USA), green</p>
<p>Channel 2 – biological entity</p>
<p>Mitochondria</p>
<p>Channel 3 – content</p>
<p>Flash Phalloidin Red (Biolegend, USA), orange</p>
<p>Channel 3 – biological entity</p>
<p>Actin</p>
<p>Image acquisition</p>
<p>Microscope model</p>
<p>Operetta CLS (PerkinElmer, USA)</p>
<p>Image data</p>
<p>Type</p>
<p>Raw and processed image in comparison</p>
<p>Magnification</p>
<p>20x air objective (NA = 0.8)</p>
<p>Excitation</p>
<p>Channel 1: 365 nm; Channel 2: 475 nm; Channel 3: 550 nm</p>
<p>Detection</p>
<p>Channel 1: 465 nm; Channel 2: 525 nm; Channel 3: 610 nm</p>
<p>Analysed data</p>
<p>Image processing method</p>
<p>Algorithm-based, unsupervised image segmentation with Harmony 4.9 analysis software (PerkinElmer, USA)</p>
<p>Submitted via NFDI4BIOIMAGE</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16980217">https://zenodo.org/records/16980217</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16980217">https://doi.org/10.5281/zenodo.16980217</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-calendar-july-2025">
<h2>NFDI4BIOIMAGE Calendar July 2025<a class="headerlink" href="#nfdi4bioimage-calendar-july-2025" title="Link to this heading">#</a></h2>
<p>Pilar Lörzing, Denis Iliasov, Michael Schlierf, Thorsten Mascher</p>
<p>Published 2025-09-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Image from the NFDI4BIOIMAGE Calendar July 2025.
The sample was provided through a collaboration with the group of Thorsten Mascher at TU Dresden. Aim of this project is to explore the cellular autofluorescence patterns in Streptomyces using advanced imaging techniques. Streptomyces coelicolor are multicellular, mycelial bacteria that grow as vegetative hyphae. The use of confocal microscopy in this project was crucial for optically sectioning these filamentous cells, enabling the resolution of their cellular autofluorescence patterns with a high signal-to-noise ratio, which allowed us to visualize the 3D arrangement of the hyphae.
Image Metadata (using REMBI template):</p>
<p>Study</p>
<p>Study type</p>
<p>Characterization of the intrinsic autofluorescence in filamentous actinobacteria</p>
<p>Study Component</p>
<p>Imaging method</p>
<p>Spinning Disk Confocal Microscopy</p>
<p>Biosample</p>
<p>Biological entity</p>
<p>Hyphae</p>
<p>Organism</p>
<p>Streptomyces coelicolor M600</p>
<p>Intrinsic variable</p>
<p>Plasmid free derivative of the wild type strain</p>
<p>Experimental variables</p>
<p>Live-Cell imaging</p>
<p>Specimen</p>
<p>Preparation method</p>
<p>S. coelicolor was grown in maltose-yeast extract-malt extract (MYM) medium with tap and deionized water (1:1) and supplemented with 0.2 mL R2 trace element solution per 100 mL. Cultures were inoculated from spore suspension and grown for 18 hours at 28 °C. 2 µl cell suspension was immobilized on 1% agarose pads and covered with a cleaned coverslip (1.5H).</p>
<p>Channel 1 - content</p>
<p>Cellular autofluorescence</p>
<p>Channel 1 - biological entity</p>
<p>S. coelicolor hyphae</p>
<p>Image acquisition</p>
<p>Instrument attributes</p>
<p>Imaging was performed using a Nikon Ti-E Spinning Disk microscope with 100x objective and 1.5x tube lens. Fluorescence was excited with a 488 nm laser and emission light was filtered using a dual band filter 433/530 HC. An Andor Ixon Ultra 888 EMCCD camera was used for detection.</p>
<p>Image acquisition parameter</p>
<p>Z-stacks of confocal images with 0.2 µm step size</p>
<p>Image data</p>
<p>Type</p>
<p>Maximum intensity projection of individual z-stacks</p>
<p>Format &amp; compression</p>
<p>TIFF</p>
<p>Dimension extents</p>
<p>x: 1024 y: 1024 z: 28 px</p>
<p>Size description</p>
<p>x: 63.12 y: 63.12 z: 5.6 µm</p>
<p>Pixel/voxel size description</p>
<p>x: 86 y: 86 z: 200 nm</p>
<p>Submitted via NFDI4BIOIMAGE</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16992904">https://zenodo.org/records/16992904</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16992904">https://doi.org/10.5281/zenodo.16992904</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-calendar-june-2025">
<h2>NFDI4BIOIMAGE Calendar June 2025<a class="headerlink" href="#nfdi4bioimage-calendar-june-2025" title="Link to this heading">#</a></h2>
<p>Kevin Warstat</p>
<p>Published 2025-09-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Image from the NFDI4BIOIMAGE Calendar June 2025.
This illustration compares two orthomosaics generated from UAV imagery. On the left, a true-color RGB orthomosaic is displayed, accompanied by three smaller orthomosaic images above it, each representing the red, green, and blue bands, vividly colored to highlight their significance. On the right, a corresponding NDVI orthomosaic of the same field is shown, with two images above it illustrating the red and near-infrared bands used as input. All images are processed products from structure from motion modelling.</p>
<p>Title</p>
<p>Crop spectra</p>
<p>Research project</p>
<p>PhenoRob (EXC 2070)</p>
<p>Recording date</p>
<p>2023-07-11</p>
<p>Location</p>
<p>Campus Klein-Altendorf, 53359 Rheinbach, Germany</p>
<p>Sensor platform</p>
<p>DJI Matrice 600 Pro</p>
<p>Sensors</p>
<p>Sony alpha 7 mark IV RGB
MicaSense RedEdge-MX Dual multispectral camera</p>
<p>Submitted via FAIRagro</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16992716">https://zenodo.org/records/16992716</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16992716">https://doi.org/10.5281/zenodo.16992716</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-calendar-march-2025">
<h2>NFDI4BIOIMAGE Calendar March 2025<a class="headerlink" href="#nfdi4bioimage-calendar-march-2025" title="Link to this heading">#</a></h2>
<p>Michael Schwarz</p>
<p>Published 2025-09-11</p>
<p>Licensed CC-BY-4.0</p>
<p>Raw microscopy image from the NFDI4Bioimage calendar March 2025.
The image shows 125x magnified microscopic details of a biofilm formed by Pseudomonas fluorescence on the surface of a liquid culture medium. The culture was inoculated with a cellulose-overexpressing and surface-colonizing mScarlet-tagged wild type and a GFP-tagged mutant that is unable to colonize the surface. The biofilm can collapse over time due to its own mass, so that new strategies have to be developed and thus a life cycle emerges.
Image Metadata (using REMBI template):</p>
<p>Study
 </p>
<p>Study description
Biofilm formation</p>
<p>Study Component
 </p>
<p>Imaging method
Stereo microscopy</p>
<p>Biosample
 </p>
<p>Biological entity
Bacteria</p>
<p>Organism
Pseudomonas fluorescence</p>
<p>Specimen
 </p>
<p>Signal/contrast mechanism
Relief, fluorescence</p>
<p>Channel 1 - content
Relief, grey</p>
<p>Channel 1 - biological entity
Details of the biofilm in transmitted light</p>
<p>Channel 2 - content
mScarlet, red</p>
<p>Channel 2 - biological entity
WT over-expressing cellulose and colonizing the surface</p>
<p>Channel 3 - content
GFP, green</p>
<p>Channel 3 - biological entity
∆wss mutant unable to colonize the surface</p>
<p>Image Acquisition
 </p>
<p>Microscope model
Zeiss Axio Zoom V16</p>
<p>Image Data
 </p>
<p>Magnification
125x</p>
<p>Objective
PlanNeoFluar Z 1.0x</p>
<p>Dimension extents
x: 2752, y: 2208</p>
<p>Pixel size description
0.91 µm x 0.91 µm</p>
<p>Image area
2500µm x 2500µm</p>
<p>Submitted via NFDI4BIOIMAGE
 </p>
<p> </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/17098115">https://zenodo.org/records/17098115</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.17098115">https://doi.org/10.5281/zenodo.17098115</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-calendar-may-2025">
<h2>NFDI4BIOIMAGE Calendar May 2025<a class="headerlink" href="#nfdi4bioimage-calendar-may-2025" title="Link to this heading">#</a></h2>
<p>Stefanie Lück</p>
<p>Published 2025-09-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Image from the NFDI4BIOIMAGE Calendar May 2025.
The microscopy image captures the interaction between the barley cv. Golden Promise and the barley powdery mildew fungus Blumeria graminis f.sp. hordei, observed 48 hours post-inoculation. The fungus was stained with Coomassie dye, enhancing its visibility against the barley leaves. The leaves were prepared and fixed onto slides, followed by scanning with a Zeiss Axio Scan Z.1 microscope scanner using a 5x objective lens.
The upper section of the image displays the hyphal colonies, which were automatically segmented, highlighting the fungal structures (black) against the plant tissue (white). The lower section presents a machine learning-based analysis where a Convolutional Neural Network (CNN) was employed to predict the fungal structures. Here, the red bounding boxes show the outer boundaries of detected objects, while the green contours precisely trace the segmented hyphae, illustrating the effectiveness of the segmentation and prediction processes.
Image Metadata (using MIAPPE template):</p>
<p>Investigation information</p>
<p>Investigation Title</p>
<p>Analysis of Hordeum vulgare cv. Golden promise infected with Blumeria graminis f. sp. hordei (causative for barley powdery mildew)</p>
<p>Objective</p>
<p>To study the interaction between Hordeum vulgare and Blumeria graminis f. sp. hordei using advanced imaging techniques and automated image analysis.</p>
<p>Study information</p>
<p>Study Title</p>
<p>Microscopy imaging and analysis of barley powdery mildew infection on Hordeum vulgare cv. Golden promise</p>
<p>Study Type</p>
<p>Microscopy-based phenotyping experiment</p>
<p>Study Description</p>
<p>The study involves imaging barley leaves inoculated with Blumeria graminis f. sp. hordei, followed by automated segmentation and CNN-based prediction of fungal structures.</p>
<p>Plant material</p>
<p>Plant Species</p>
<p>Hordeum vulgare</p>
<p>Cultivar</p>
<p>Golden promise</p>
<p>Experimental design</p>
<p>Experiment Type</p>
<p>Fungal inoculation and microscopy imaging</p>
<p>Inoculation Details</p>
<p>Barley leaves were inoculated with Blumeria graminis f. sp. hordei.</p>
<p>Time post-inoculation</p>
<p>48 hours</p>
<p>Imaging information</p>
<p>Microscopy type</p>
<p>Brightfield microscopy</p>
<p>Staining method</p>
<p>Coomassie stain for fungal structures</p>
<p>Microscope</p>
<p>Zeiss Axio Scan Z.1</p>
<p>Objective Lens</p>
<p>5x</p>
<p>Image Format</p>
<p>Zeiss CZI file</p>
<p>Image analysis information</p>
<p>Segmentation method</p>
<p>Automated segmentation of hyphal colonies</p>
<p>Image analysis software</p>
<p>BluVision Micro software</p>
<p>Prediction method</p>
<p>Convolutional Neural Network (CNN) for fungal structure detection</p>
<p>Upper image</p>
<p>Shows binary image with hyphal colonies (black) and background (white).</p>
<p>Lower image</p>
<p>Displays CNN predictions with red bounding boxes marking detected objects and green contours outlining segmented hyphae.</p>
<p>Submitted via NFDI4Biodiversity</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16991961">https://zenodo.org/records/16991961</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16991961">https://doi.org/10.5281/zenodo.16991961</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-calendar-november-2025">
<h2>NFDI4BIOIMAGE Calendar November 2025<a class="headerlink" href="#nfdi4bioimage-calendar-november-2025" title="Link to this heading">#</a></h2>
<p>Jadranka Macas</p>
<p>Published 2025-09-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Image from the NFDI4BIOIMAGE Calendar November 2025.
The image shows a perivascular accumulation of perivascular B cells, T cells and plasma cells in a human brain tumor. These structures, also known as tertiary lymphoid structures, are sites of lymphocyte clonal expansion and plasma cell formation. The study aims to determine the clinical relevance and immunological function of tertiary lymphoid structures in human primary brain tumors.
Image Metadata (using REMBI template):</p>
<p>Study</p>
<p>Study type</p>
<p>Immunomonitoring study in human oncology</p>
<p>Study Component</p>
<p>Imaging method</p>
<p>COMET™ highplex seq-IF staining and scanning system, HORIZON™ Viewer (Lunaphore Technologies, SA)</p>
<p>Biosample</p>
<p>Biological entity</p>
<p>Tertiary lymphoid structure in glioblastoma</p>
<p>Organism</p>
<p>Homo sapiens</p>
<p>Specimen</p>
<p>Location within biosample</p>
<p>Tumor (glioblastoma)</p>
<p>Preparation method</p>
<p>FFPE sample, automatic sequential-IF using COMET™ (Lunaphore Technologies, SA)</p>
<p>Signal/contrast mechanism</p>
<p>HORIZON™ Viewer (Lunaphore Technologies, SA)</p>
<p>Channel 1 - content</p>
<p>Alexa Fluor Plus 555, red</p>
<p>Channel 1 - biological entity</p>
<p>CD20 - B-cells</p>
<p>Channel 2 - content</p>
<p>Alexa Fluor Plus 647, green</p>
<p>Channel 2 - biological entity</p>
<p>CD3 - T-cells</p>
<p>Channel 3 - content</p>
<p>Alexa Fluor Plus 555, white</p>
<p>Channel 3 - biological entity</p>
<p>CD163 - anti-inflammatory macrophages (M2-like)</p>
<p>Channel 4 - content</p>
<p>Alexa Fluor Plus 647, magenta</p>
<p>Channel 4 - biological entity</p>
<p>MZB-1 - Marginal zone B and B1 cell-specific protein, MEDA-7 - plasma cells, memory B-cells</p>
<p>Channel 5 - content</p>
<p>Alexa Fluor Plus 647, orange</p>
<p>Channel 5 - biological entity</p>
<p>NF- Neurofilament - intermediate filaments around the axons</p>
<p>Channel 6- content</p>
<p>Alexa Fluor Plus 555, cyan</p>
<p>Channel 6 - biological entity</p>
<p>GAP43 - Neuromodulin, neuronal growth-associated protein 43 - neurons</p>
<p>Channel 7 - content</p>
<p>Alexa Fluor Plus 555, blue</p>
<p>Channel 7 - biological entity</p>
<p>vWF - von-Willebrand-Factor - endothelial cells</p>
<p>Image acquisition</p>
<p>Instrument attributes</p>
<p>COMET™ highplex seq-IF staining and scanning system v.1.1.1.0 (Lunaphore Technologies, SA)</p>
<p>Image acquisition parameters</p>
<p>COMET™ acquisition software                                                                                                                                                                                           </p>
<p>Image data</p>
<p>Pixel size</p>
<p>0.23 µm/pixel</p>
<p>Image size</p>
<p>Width 11986 pixels - 2.76 mmHeight 11514 pixels - 2.65 mm</p>
<p>Pixel bit depth</p>
<p>16-bit                                                                                                                                                                                                                                                                             </p>
<p>Channel information</p>
<p>Displayed are 7 markers out of the highplex IF-panel; number of channels 43 (including autofluorescence)</p>
<p>Submitted via NFDI4Immuno</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16993649">https://zenodo.org/records/16993649</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16993649">https://doi.org/10.5281/zenodo.16993649</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-calendar-october-2025">
<h2>NFDI4BIOIMAGE Calendar October 2025<a class="headerlink" href="#nfdi4bioimage-calendar-october-2025" title="Link to this heading">#</a></h2>
<p>Vivien Joisten-Rosenthal</p>
<p>Published 2025-09-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Image from the NFDI4BIOIMAGE Calendar October 2025.
As part of the MibiNet SFB 1535 project (<a class="reference external" href="https://www.sfb1535.hhu.de">https://www.sfb1535.hhu.de</a>), this lichen was collected in the Northern Eifel region, between Blankenheim and Schmidtheim in Germany. Lichens are among the most successful examples of complex mutualistic symbiosis, where a fungus (mycobiont) forms an association with one or more photosynthetic organisms (photobionts), including green algae and/or cyanobacteria. Based on ITS analysis, the lichen shown has been identified as Peltigera neckeri. Lichens of the genus Peltigera are classified as cyanolichens due to their symbiotic association with a cyanobacterial photobiont of the genus Nostoc. The image shows the lichen’s blue-gray thallus when wet, after its collection on a mossy stone.</p>
<p>Research project</p>
<p>MibiNet SFB 1535 Project B02</p>
<p>Recording date; time</p>
<p>2023-10-28; 12:21 CEST</p>
<p>Location</p>
<p>Northern Eifel, between Blankenheim and Schmidtheim, Germany</p>
<p>Environmental conditions</p>
<p>Cloudy, slightly rainy</p>
<p>Temperature</p>
<p>14°C</p>
<p>Organism</p>
<p>Peltigera neckeri</p>
<p>Organism attribute</p>
<p>Cyanolichen, foliose</p>
<p>Mycobiont</p>
<p>Peltigera</p>
<p>Photobiont</p>
<p>Nostoc</p>
<p>Substrate</p>
<p>Moss</p>
<p>Camera</p>
<p>Apple iPhone 12</p>
<p>Objective</p>
<p>iPhone 12 back dual wide camera 4.2mm f/1.6</p>
<p>Size</p>
<p>4,032 x 3,024 px</p>
<p>Submitted via NFDI4BIOIMAGE</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16993297">https://zenodo.org/records/16993297</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16993297">https://doi.org/10.5281/zenodo.16993297</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-calendar-september-2025">
<h2>NFDI4BIOIMAGE Calendar September 2025<a class="headerlink" href="#nfdi4bioimage-calendar-september-2025" title="Link to this heading">#</a></h2>
<p>Heidi Faber-Zuschratter, Torsten Stöter, Werner Zuschratter, Roland Hartig, Markus Wilke</p>
<p>Published 2025-09-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Image from the NFDI4BIOIMAGE Calendar September 2025.
The scanning electron micrograph shows the approach of T-lymphocytes (Jurkat cells; cyan) to an antigen-presenting B cell (Raji cell; yellow) in the center. The image was taken as part of the research work of the CRC 854, which focused on molecular processes that regulate inter- and intracellular communication within the immune system.
Image Metadata (using REMBI template):</p>
<p>Study</p>
<p>Study description</p>
<p>Ultrastructure of the immune synapse</p>
<p>Study type</p>
<p>Research project within DFG CRC 854 (Molecular organisation of cellular communication within the immune system)</p>
<p>Study Component</p>
<p>Imaging method</p>
<p>Scanning Electron Microscopy</p>
<p>Biosample</p>
<p>Biological entity</p>
<p>Jurkat cell line E6.1 and Raji B cell lymphoma cell line</p>
<p>Organism</p>
<p>Homo sapiens</p>
<p>Identity</p>
<p>Z21_A1</p>
<p>Specimen</p>
<p>Preparation method</p>
<p>Cell lines were maintained in RPMI 1640 medium supplemented with 10% fetal calf serum (FCS; PAN Biotech), stable L-glutamine, penicillin (50 U/ml), and streptomycin (50 mg/ml) (Biochrom) in humidified 5% CO2 at 37°C. E6.1 cells were mixed at a 1:1 ratio with Raji B cells that had been pulsed with SEE (bacterial SAG staphylococcal enterotoxin E). After 10 min cells were plated on poly-L-lysine–covered slides at room temperature for 5 min and fixed for 10 min in PBS (pH 7.4) containing 1.5% PFA and 0.025% glutaraldehyde. Cryo-drying by critical point dryer (Leica EM CPD300) followed by sputtering with gold.</p>
<p>Signal/contrast mechanism</p>
<p>Detected secondary electrons</p>
<p>Channel 1 - content</p>
<p>Jurkat cell line E6.1 (artificial color table, cyan)</p>
<p>Channel 1 - biological entity</p>
<p>Surface of Jurkat cells</p>
<p>Channel 2 - content</p>
<p>Raji B cell lymphoma cell line (artificial color table, yellow)</p>
<p>Channel 2 - biological entity</p>
<p>Surface of a Raji B cell</p>
<p>Image acquisition</p>
<p>Instrument attributes</p>
<p>FEI XL30 FEG ESEM</p>
<p>Image acquisition parameters</p>
<p>10 keV, Magnification 6500 x, Scale bar: 2 µm</p>
<p>Submitted via NFDI4BIOIMAGE</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16993178">https://zenodo.org/records/16993178</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16993178">https://doi.org/10.5281/zenodo.16993178</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-perspective-for-a-national-bioimaging-standard">
<h2>NFDI4BIOIMAGE: Perspective for a national bioimaging standard<a class="headerlink" href="#nfdi4bioimage-perspective-for-a-national-bioimaging-standard" title="Link to this heading">#</a></h2>
<p>Josh Moore, Susanne Kunis</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Nfdi4Bioimage, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://ceur-ws.org/Vol-3415/paper-27.pdf">https://ceur-ws.org/Vol-3415/paper-27.pdf</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon">
<h2>NFDI4Bioimage - TA3-Hackathon - UoC-2023 (Cologne Hackathon)<a class="headerlink" href="#nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon" title="Link to this heading">#</a></h2>
<p>Mohamed M. Abdrabbou, Mehrnaz Babaki, Tom Boissonnet, Michele Bortolomeazzi, Eik Dahms, Vanessa A. F. Fuchs, Moritz Hoevels, Niraj Kandpal, Christoph Möhl, Joshua A. Moore, Astrid Schauss, Andrea Schrader, Torsten Stöter, Julia Thönnißen, Monica Valencia-S., H. Lukas Weil, Jens Wendt and Peter Zentis</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Arc, Dataplant, Hackathon, Nfdi4Bioimage, OMERO, Python, Research Data Management, Exclude From Dalia</p>
<p>Content type: Event, Publication, Documentation</p>
<p><a class="github reference external" href="https://github.com/NFDI4BIOIMAGE/Cologne-Hackathon-2023">NFDI4BIOIMAGE/Cologne-Hackathon-2023</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10609770">https://doi.org/10.5281/zenodo.10609770</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon-2023-github-repository">
<h2>NFDI4Bioimage - TA3-Hackathon - UoC-2023 (Cologne-Hackathon-2023, GitHub repository)<a class="headerlink" href="#nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon-2023-github-repository" title="Link to this heading">#</a></h2>
<p>Mohamed Abdrabbou, Mehrnaz Babaki, Tom Boissonnet, Michele Bortolomeazzi, Eik Dahms, Vanessa Fuchs, A. F. Moritz Hoevels, Niraj Kandpal, Christoph Möhl, Joshua A. Moore, Astrid Schauss, Andrea Schrader, Torsten Stöter, Julia Thönnißen, Monica Valencia-S., H. Lukas Weil, Jens Wendt, Peter Zentis</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository documents the first NFDI4Bioimage - TA3-Hackathon - UoC-2023 (Cologne Hackathon), where topics like ‘Interoperability’, ‘REMBI / Mapping’, and ‘Neuroglancer (OMERO / zarr)’ were explored through collaborative discussions and workflow sessions, culminating in reports that bridge NFDI4Bioimage to DataPLANT. Funded by various DFG initiatives, this event emphasized documentation and use cases, contributing preparatory work for future interoperability projects at the 2nd de.NBI BioHackathon in Bielefeld.</p>
<p>Tags: Research Data Management, FAIR-Principles, Bioimage Analysis, Nfdi4Bioimage, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.10609770">https://zenodo.org/doi/10.5281/zenodo.10609770</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-calendar-2024-october-original-image">
<h2>NFDI4Bioimage Calendar 2024 October; original image<a class="headerlink" href="#nfdi4bioimage-calendar-2024-october-original-image" title="Link to this heading">#</a></h2>
<p>Christian Jüngst, Peter Zentis</p>
<p>Published 2024-09-25</p>
<p>Licensed CC-BY-4.0</p>
<p>Raw microscopy image from the NFDI4Bioimage calendar October 2024</p>
<p>Tags: Nfdi4Bioimage, Research Data Management, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/13837146">https://zenodo.org/records/13837146</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13837146">https://doi.org/10.5281/zenodo.13837146</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-calendar-2025-march-original-image">
<h2>NFDI4Bioimage Calendar 2025 March; original image<a class="headerlink" href="#nfdi4bioimage-calendar-2025-march-original-image" title="Link to this heading">#</a></h2>
<p>Sonja Schimmler, Reinhard Altenhöner, Lars Bernard, Juliane Fluck, Axel Klinger, Sören Lorenz, Brigitte Mathiak, Bernhard Miller, Raphael Ritz, Thomas Schörner-Sadenius, Alexander Sczyrba, Regine Stein</p>
<p>Published 2025-02-27</p>
<p>Licensed CC-BY-4.0</p>
<p>Raw microscopy image from the NFDI4Bioimage calendar March 2025.
The image shows 125x magnified microscopic details of a biofilm formed by Pseudomonas fluorescence on the surface of a liquid culture medium. The culture was inoculated with a cellulose-overexpressing and surface-colonizing mScarlet-tagged wild type and a GFP-tagged mutant that is unable to colonize the surface. The biofilm can collapse over time due to its own mass, so that new strategies have to be developed and thus a life cycle emerges.
Image Metadata (using REMBI template):</p>
<p>Study
 </p>
<p>Study description
Biofilm formation</p>
<p>Study Component
 </p>
<p>Imaging method
Stereo microscopy</p>
<p>Biosample
 </p>
<p>Biological entity
Bacteria</p>
<p>Organism
Pseudomonas fluorescence</p>
<p>Specimen
 </p>
<p>Signal/contrast mechanism
Relief, fluorescence</p>
<p>Channel 1 - content
Relief, grey</p>
<p>Channel 1 - biological entity
Details of the biofilm in transmitted light</p>
<p>Channel 2 - content
mScarlet, red</p>
<p>Channel 2 - biological entity
WT over-expressing cellulose and colonizing the surface</p>
<p>Channel 3 - content
GFP, green</p>
<p>Channel 3 - biological entity
∆wss mutant unable to colonize the surface</p>
<p>Image Acquisition
 </p>
<p>Microscope model
Zeiss Axio Zoom V16</p>
<p>Image Data
 </p>
<p>Magnification
125x</p>
<p>Objective
PlanNeoFluar Z 1.0x</p>
<p>Dimension extents
x: 2752, y: 2208</p>
<p>Pixel size description
0.91 µm x 0.91 µm</p>
<p>Image area
2500µm x 2500µm</p>
<p> </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14937632">https://zenodo.org/records/14937632</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14937632">https://doi.org/10.5281/zenodo.14937632</a></p>
</section>
<hr class="docutils" />
<section id="nfditalk-cloud-based-image-data-science">
<h2>NFDITalk Cloud based image data science<a class="headerlink" href="#nfditalk-cloud-based-image-data-science" title="Link to this heading">#</a></h2>
<p>Josh Moore, Yi Sun</p>
<p>Published 2025-06-02</p>
<p>Licensed UNKNOWN</p>
<p>In this talk, we will be discussing OME-ZARR, a cloud-optimized format for scalable bioimage data management, and BARD,  a cloud virtual desktop that provides a seamless way to run resource-intensive applications in the cloud, enabling users to access powerful computing environments from any device with a web browser.</p>
<p>Tags: Bioimage Analysis, OMERO, Exclude From Dalia</p>
<p>Content type: Video</p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=bzfmE29S270">https://www.youtube.com/watch?v=bzfmE29S270</a></p>
</section>
<hr class="docutils" />
<section id="ngff-converter">
<h2>NGFF Converter<a class="headerlink" href="#ngff-converter" title="Link to this heading">#</a></h2>
<p>Licensed GPL-2.0</p>
<p>An easy to use and open source converter for bioimaging data. NGFF-Converter is a GUI application for conversion of bioimage formats into OME-NGFF (Next-Generation File Format) or OME-TIFF.</p>
<p>Tags: Open Source Software, Exclude From Dalia</p>
<p>Content type: Application</p>
<p><a class="reference external" href="https://www.glencoesoftware.com/products/ngff-converter/">https://www.glencoesoftware.com/products/ngff-converter/</a></p>
</section>
<hr class="docutils" />
<section id="nd2-does-not-open-in-fiji-bio-formats-8-1-1">
<h2>Nd2 does not open in Fiji Bio_formats 8.1.1<a class="headerlink" href="#nd2-does-not-open-in-fiji-bio-formats-8-1-1" title="Link to this heading">#</a></h2>
<p>Jaramillo Carlos</p>
<p>Published 2025-06-02</p>
<p>Licensed CC-BY-4.0</p>
<p>this file is a .nd2 image of a pollen grain taken with a Nikon 80i.  It is in RGB and it is a stack of hundreds of Z layers</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15579371">https://zenodo.org/records/15579371</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15579371">https://doi.org/10.5281/zenodo.15579371</a></p>
</section>
<hr class="docutils" />
<section id="nd2-does-not-open-in-fiji-bio-formats-8-1-1-additional-files">
<h2>Nd2 does not open in Fiji Bio_formats 8.1.1 (additional files)<a class="headerlink" href="#nd2-does-not-open-in-fiji-bio-formats-8-1-1-additional-files" title="Link to this heading">#</a></h2>
<p>Jonatan Bustos</p>
<p>Published 2025-05-23</p>
<p>Licensed CC-BY-4.0</p>
<p>This dataset contains 4 .nd2 image files of pollen grains captured using a Nikon 80i microscope. The files include both the original full-frame images and cropped Regions of Interest (ROIs) extracted from them. All images are in RGB format and include multiple Z-stack layers.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15493140">https://zenodo.org/records/15493140</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15493140">https://doi.org/10.5281/zenodo.15493140</a></p>
</section>
<hr class="docutils" />
<section id="nd2-does-not-open-in-fiji-bio-formats-8-1-1-on-windows">
<h2>Nd2 does not open in Fiji Bio_formats 8.1.1 (on Windows)<a class="headerlink" href="#nd2-does-not-open-in-fiji-bio-formats-8-1-1-on-windows" title="Link to this heading">#</a></h2>
<p>Loïc Sauteur</p>
<p>Published 2025-07-31</p>
<p>Licensed CC-BY-4.0</p>
<p>Related to github issue: <a class="github reference external" href="https://github.com/ome/bioformats/issues/3517">ome/bioformats#3517</a>
 </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16628927">https://zenodo.org/records/16628927</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16628927">https://doi.org/10.5281/zenodo.16628927</a></p>
</section>
<hr class="docutils" />
<section id="neurips-2022-cell-segmentation-competition-dataset">
<h2>NeurIPS 2022 Cell Segmentation Competition Dataset<a class="headerlink" href="#neurips-2022-cell-segmentation-competition-dataset" title="Link to this heading">#</a></h2>
<p>Jun Ma, Ronald Xie, Shamini Ayyadhury, Cheng Ge, Anubha Gupta, Ritu Gupta, Song Gu, Yao Zhang, Gihun Lee, Joonkee Kim, Wei Lou, Haofeng Li, Eric Upschulte, Timo Dickscheid, de Almeida, José Guilherme, Yixin Wang, Lin Han, Xin Yang, Marco Labagnara, Vojislav Gligorovski, Maxime Scheder, Rahi, Sahand Jamal, Carly Kempster, Alice Pollitt, Leon Espinosa, Tam Mignot, Middeke, Jan Moritz, Jan-Niklas Eckardt, Wangkai Li, Zhaoyang Li, Xiaochen Cai, Bizhe Bai, Greenwald, Noah F., Van Valen, David, Erin Weisbart, Cimini, Beth A, Trevor Cheung, Oscar Brück, Bader, Gary D., Bo Wang</p>
<p>Published 2024-02-27</p>
<p>Licensed CC-BY-NC-ND-4.0</p>
<p>The official data set for the NeurIPS 2022 competition: cell segmentation in multi-modality microscopy images.
<a class="reference external" href="https://neurips22-cellseg.grand-challenge.org/">https://neurips22-cellseg.grand-challenge.org/</a>
Please cite the following paper if this dataset is used in your research. 
 
&#64;article{NeurIPS-CellSeg,
title = {The Multi-modality Cell Segmentation Challenge: Towards Universal Solutions},
author = {Jun Ma and Ronald Xie and Shamini Ayyadhury and Cheng Ge and Anubha Gupta and Ritu Gupta and Song Gu and Yao Zhang and Gihun Lee and Joonkee Kim and Wei Lou and Haofeng Li and Eric Upschulte and Timo Dickscheid and José Guilherme de Almeida and Yixin Wang and Lin Han and Xin Yang and Marco Labagnara and Vojislav Gligorovski and Maxime Scheder and Sahand Jamal Rahi and Carly Kempster and Alice Pollitt and Leon Espinosa and Tâm Mignot and Jan Moritz Middeke and Jan-Niklas Eckardt and Wangkai Li and Zhaoyang Li and Xiaochen Cai and Bizhe Bai and Noah F. Greenwald and David Van Valen and Erin Weisbart and Beth A. Cimini and Trevor Cheung and Oscar Brück and Gary D. Bader and Bo Wang},
journal = {Nature Methods},      volume={21},      pages={1103–1113},      year = {2024},
doi = {<a class="reference external" href="https://doi.org/10.1038/s41592-024-02233-6">https://doi.org/10.1038/s41592-024-02233-6</a>}
}
 
This is an instance segmentation task where each cell has an individual label under the same category (cells). The training set contains both labeled images and unlabeled images. You can only use the labeled images to develop your model but we encourage participants to try to explore the unlabeled images through weakly supervised learning, semi-supervised learning, and self-supervised learning.
 
The images are provided with original formats, including tiff, tif, png, jpg, bmp… The original formats contain the most amount of information for competitors and you have free choice over different normalization methods. For the ground truth, we standardize them as tiff formats.
 
We aim to maintain this challenge as a sustainable benchmark platform. If you find the top algorithms (<a class="reference external" href="https://neurips22-cellseg.grand-challenge.org/awards/">https://neurips22-cellseg.grand-challenge.org/awards/</a>) don’t perform well on your images, welcome to send us the dataset (<a class="reference external" href="mailto:neurips&#46;cellseg&#37;&#52;&#48;gmail&#46;com">neurips<span>&#46;</span>cellseg<span>&#64;</span>gmail<span>&#46;</span>com</a>)! We will include them in the new testing set and credit your contributions on the challenge website!
 
Dataset License: CC-BY-NC-ND</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/10719375">https://zenodo.org/records/10719375</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10719375">https://doi.org/10.5281/zenodo.10719375</a></p>
</section>
<hr class="docutils" />
<section id="neural-networks-and-deep-learning">
<h2>Neural Networks and Deep Learning<a class="headerlink" href="#neural-networks-and-deep-learning" title="Link to this heading">#</a></h2>
<p>Michael Nielsen</p>
<p>Published 2019-12-01</p>
<p>Licensed CC-BY-NC-3.0 UNPORTED</p>
<p>Neural networks and deep learning currently provide the best solutions to many problems in image recognition, speech recognition, and natural language processing. This book will teach you many of the core concepts behind neural networks and deep learning.</p>
<p>Tags: Deep Learning, Neural Networks, Machine Learning, Exclude From Dalia</p>
<p>Content type: Book</p>
<p><a class="reference external" href="http://neuralnetworksanddeeplearning.com">http://neuralnetworksanddeeplearning.com</a></p>
</section>
<hr class="docutils" />
<section id="new-kid-on-the-nfdi-block-nfdi4bioimage-a-national-initiative-for-fair-data-management-in-bioimaging-and-bioimage-analysis">
<h2>New Kid on the (NFDI) Block: NFDI4BIOIMAGE  - A National Initiative for FAIR Data Management in Bioimaging and Bioimage Analysis<a class="headerlink" href="#new-kid-on-the-nfdi-block-nfdi4bioimage-a-national-initiative-for-fair-data-management-in-bioimaging-and-bioimage-analysis" title="Link to this heading">#</a></h2>
<p>Cornelia Wetzker</p>
<p>Published 2024-10-29</p>
<p>Licensed CC-BY-4.0</p>
<p>The poster introduces the consortium NFDI4BIOIMAGE with its central objectives, provides an overview of challenges in bioimage data handling, sharing and analysis and lists support options by the consortium through its data stewardship team.
It is part of the work of the German consortium NFDI4BIOIMAGE funded by the Deutsche Forschungsgemeinschaft (DFG grant number NFDI 46/1, project number 501864659) and has been presented at the conference FDM&#64;Campus held in Göttingen September 23-25, 2024.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14006558">https://zenodo.org/records/14006558</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14006558">https://doi.org/10.5281/zenodo.14006558</a></p>
</section>
<hr class="docutils" />
<section id="new-report-highlights-the-scientific-impact-of-open-source-software">
<h2>New report highlights the scientific impact of open source software<a class="headerlink" href="#new-report-highlights-the-scientific-impact-of-open-source-software" title="Link to this heading">#</a></h2>
<p>UNKNOWN</p>
<p>Published UNKNOWN</p>
<p>Licensed UNKNOWN</p>
<p>Tags: Open Source, Alphafold, Exclude From Dalia</p>
<p>Content type: Report, Blog Post</p>
<p><a class="reference external" href="https://www.statnews.com/sponsor/2024/11/26/new-report-highlights-the-scientific-impact-of-open-source-software/">https://www.statnews.com/sponsor/2024/11/26/new-report-highlights-the-scientific-impact-of-open-source-software/</a></p>
</section>
<hr class="docutils" />
<section id="nextflow-core">
<h2>NextFlow core<a class="headerlink" href="#nextflow-core" title="Link to this heading">#</a></h2>
<p>nf-core is a community effort to collect a curated set of analysis pipelines built using Nextflow</p>
<p>Tags: Python, Exclude From Dalia</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://nf-co.re/">https://nf-co.re/</a></p>
</section>
<hr class="docutils" />
<section id="nextflow-documentation">
<h2>NextFlow documentation<a class="headerlink" href="#nextflow-documentation" title="Link to this heading">#</a></h2>
<p>Nextflow enables scalable and reproducible scientific workflows using software containers.</p>
<p>Tags: Workflow Engine, Exclude From Dalia</p>
<p>Content type: Documentation</p>
<p><a class="reference external" href="https://www.nextflow.io/">https://www.nextflow.io/</a></p>
</section>
<hr class="docutils" />
<section id="nextflow-scalable-and-reproducible-scientific-workflows">
<h2>Nextflow: Scalable and reproducible scientific workflows<a class="headerlink" href="#nextflow-scalable-and-reproducible-scientific-workflows" title="Link to this heading">#</a></h2>
<p>Floden Evan, Di Tommaso Paolo</p>
<p>Published 2020-12-17</p>
<p>Licensed CC-BY-4.0</p>
<p>Nextflow is an open-source workflow management system that prioritizes portability and reproducibility. It enables users to develop and seamlessly scale genomics workflows locally, on HPC clusters, or in major cloud providers’ infrastructures. Developed since 2014 and backed by a fast-growing community, the Nextflow ecosystem is made up of users and developers across academia, government and industry. It counts over 1M downloads and over 10K users worldwide.</p>
<p>Tags: Workflow Engine, Exclude From Dalia</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/records/4334697">https://zenodo.org/records/4334697</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4334697">https://doi.org/10.5281/zenodo.4334697</a></p>
</section>
<hr class="docutils" />
<section id="nuinsseg">
<h2>NuInsSeg<a class="headerlink" href="#nuinsseg" title="Link to this heading">#</a></h2>
<p>Amirreza Mahbod, Christine Polak, Katharina Feldmann, Rumsha Khan, Katharina Gelles, Georg Dorffner, Ramona Woitek, Sepideh Hatamikia, Isabella Ellinger</p>
<p>Published 2024-05-14</p>
<p>Licensed CC-BY-4.0</p>
<p>A Fully Annotated Dataset for Nuclei Instance Segmentation in H&amp;E-Stained Images</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://www.kaggle.com/datasets/ipateam/nuinsseg">https://www.kaggle.com/datasets/ipateam/nuinsseg</a></p>
</section>
<hr class="docutils" />
<section id="nuclei-of-u2os-cells-in-a-chemical-screen">
<h2>Nuclei of U2OS cells in a chemical screen<a class="headerlink" href="#nuclei-of-u2os-cells-in-a-chemical-screen" title="Link to this heading">#</a></h2>
<p>Vebjorn Ljosa, Katherine L. Sokolnicki, Anne E. Carpenter</p>
<p>Published 2012-06-28</p>
<p>Licensed CC0-1.0</p>
<p>This image set is part of a high-throughput chemical screen on U2OS cells, with examples of 200 bioactive compounds. The effect of the treatments was originally imaged using the Cell Painting assay (fluorescence microscopy). This data set only includes the DNA channel of a single field of view per compound. These images present a variety of nuclear phenotypes, representative of high-throughput chemical perturbations. The main use of this data set is the study of segmentation algorithms that can separate individual nucleus instances in an accurate way, regardless of their shape and cell density. The collection has around 23,000 single nuclei manually annotated to establish a ground truth collection for segmentation evaluation.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://bbbc.broadinstitute.org/BBBC039">https://bbbc.broadinstitute.org/BBBC039</a></p>
</section>
<hr class="docutils" />
<section id="nuclei-of-mouse-embryonic-cells">
<h2>Nuclei of mouse embryonic cells<a class="headerlink" href="#nuclei-of-mouse-embryonic-cells" title="Link to this heading">#</a></h2>
<p>Vebjorn Ljosa, Katherine L. Sokolnicki, Anne E. Carpenter</p>
<p>Published 2012-06-28</p>
<p>Licensed CC0-1.0</p>
<p>Cell dynamics during the early mouse embryogenesis change spatiotemporally. For understanding the mechanism of this developmental process, imaging cell dynamics by live-cell imaging of fluorescently labeled nuclei and performing nuclei segmentation of these images by image processing are essential. This dataset contains the fluorescence images and Ground Truth used when performing nuclei segmentation using deep learning. Fluorescence images are time-series images from fertilization to blastocyst formation. Ground Truth is supervised data of the cell nuclear region.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://bbbc.broadinstitute.org/BBBC050">https://bbbc.broadinstitute.org/BBBC050</a></p>
</section>
<hr class="docutils" />
<section id="ocelot-overlapped-cell-on-tissue-dataset-for-histopathology">
<h2>OCELOT: Overlapped Cell on Tissue Dataset for Histopathology<a class="headerlink" href="#ocelot-overlapped-cell-on-tissue-dataset-for-histopathology" title="Link to this heading">#</a></h2>
<p>Jeongun Ryu, Aaron Valero Puche, JaeWoong Shin, Seonwook Park, Biagio Brattoli, Mohammad Mostafavi, Jinhee Lee, Sérgio Pereira, Wonkyung Jung, Soo Ick Cho, Chan-Young Ock, Kyunghyun Paeng, Donggeun Yoo</p>
<p>Published 2023-03-23</p>
<p>The OCELOT dataset is a histopathology dataset designed to facilitate the development of methods that utilize cell and tissue relationships. The dataset comprises both small and large field-of-view (FoV) patches extracted from digitally scanned whole slide images (WSIs), with overlapping regions. The small and large FoV patches are accompanied by annotations of cells and tissues, respectively. The WSIs are sourced from the publicly available TCGA database and were stained using the H&amp;E method before being scanned with an Aperio scanner.</p>
<p>For more details, please check <a class="reference external" href="https://lunit-io.github.io/research/ocelot_dataset/">https://lunit-io.github.io/research/ocelot_dataset/</a>.</p>
<p> </p>
<p>Before downloading the dataset, please make sure to carefully read and agree to the Terms and Conditions at (<a class="reference external" href="https://lunit-io.github.io/research/ocelot_tc/">https://lunit-io.github.io/research/ocelot_tc/</a>).</p>
<p>Also, please provide 1. name, 2. e-mail address, 3. organization/company name.</p>
<p> </p>
<hr class="docutils" />
<p>Release note.</p>
<p>In version 1.0.1, we exclude four test cases (586, 589, 609, 615) due to under-annotated issue.
In version 1.0.0, we include images and annotations of validation and test splits.
In version 0.1.2, we modified the coordinates of cell labels to range from 0 to 1023 (-1 from the previous coordinates).
In version 0.1.1, we removed non-H&amp;E stained patches from the dataset.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/8417503">https://zenodo.org/records/8417503</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8417503">https://doi.org/10.5281/zenodo.8417503</a></p>
</section>
<hr class="docutils" />
<section id="ome-event-database">
<h2>OME Event Database<a class="headerlink" href="#ome-event-database" title="Link to this heading">#</a></h2>
<p>Tags: OMERO, Research Data Management, Exclude From Dalia</p>
<p>Content type: Collection, Event</p>
<p><a class="reference external" href="https://www.openmicroscopy.org/events/">https://www.openmicroscopy.org/events/</a></p>
</section>
<hr class="docutils" />
<section id="ome-ngff-a-next-generation-file-format-for-expanding-bioimaging-data-access-strategies">
<h2>OME-NGFF: a next-generation file format for expanding bioimaging data-access strategies<a class="headerlink" href="#ome-ngff-a-next-generation-file-format-for-expanding-bioimaging-data-access-strategies" title="Link to this heading">#</a></h2>
<p>Josh Moore, Chris Allan, Sébastien Besson, jean-marie burel, Erin Diel, David Gault, Kevin Kozlowski, Dominik Lindner, Melissa Linkert, Trevor Manz, Will Moore, Constantin Pape, Christian Tischer, Jason R. Swedlow</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Nfdi4Bioimage, Research Data Management, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.nature.com/articles/s41592-021-01326-w">https://www.nature.com/articles/s41592-021-01326-w</a></p>
</section>
<hr class="docutils" />
<section id="ome-zarr-course">
<h2>OME-Zarr course<a class="headerlink" href="#ome-zarr-course" title="Link to this heading">#</a></h2>
<p>Bugra Oezdemir, Christian Tischer</p>
<p>Licensed UNKNOWN</p>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Tutorial</p>
<p><a class="reference external" href="https://git.embl.de/oezdemir/course_scripts#ome-zarr-course">https://git.embl.de/oezdemir/course_scripts#ome-zarr-course</a></p>
</section>
<hr class="docutils" />
<section id="ome2024-ngff-challenge-results">
<h2>OME2024 NGFF Challenge Results<a class="headerlink" href="#ome2024-ngff-challenge-results" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Published 2024-11-01</p>
<p>Licensed CC-BY-4.0</p>
<p>Presented at the 2024 FoundingGIDE event in Okazaki, Japan: <a class="reference external" href="https://founding-gide.eurobioimaging.eu/event/foundinggide-community-event-2024/">https://founding-gide.eurobioimaging.eu/event/foundinggide-community-event-2024/</a>
Note: much of the presentation was a demonstration of the OME2024-NGFF-Challenge – <a class="reference external" href="https://ome.github.io/ome2024-ngff-challenge/">https://ome.github.io/ome2024-ngff-challenge/</a> especially of querying an extraction of the metadata (<a class="github reference external" href="https://github.com/ome/ome2024-ngff-challenge-metadata">ome/ome2024-ngff-challenge-metadata</a>)
 </p>
<p>Tags: Nfdi4Bioimage, Research Data Management, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14234608">https://zenodo.org/records/14234608</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14234608">https://doi.org/10.5281/zenodo.14234608</a></p>
</section>
<hr class="docutils" />
<section id="omero-qupath">
<h2>OMERO - QuPath<a class="headerlink" href="#omero-qupath" title="Link to this heading">#</a></h2>
<p>Rémy Jean Daniel Dornier</p>
<p>Licensed CC-BY-NC-SA-4.0</p>
<p>OMERO-RAW extension for QuPath allows to directly access to the raw pixels of images. All types of images (RGB, fluorescence, …) are supported with this extension.</p>
<p>Tags: Bioimage Analysis, OMERO, Exclude From Dalia</p>
<p>Content type: Online Tutorial</p>
<p><a class="reference external" href="https://wiki-biop.epfl.ch/en/data-management/omero/qupath">https://wiki-biop.epfl.ch/en/data-management/omero/qupath</a></p>
</section>
<hr class="docutils" />
<section id="omero-for-microscopy-research-data-management">
<h2>OMERO for microscopy research data management<a class="headerlink" href="#omero-for-microscopy-research-data-management" title="Link to this heading">#</a></h2>
<p>Thomas Zobel, Sarah Weischner, Jens Wendt</p>
<p>Licensed ALL RIGHTS RESERVED</p>
<p>A use case example from the Münster Imaging Network</p>
<p>Tags: Nfdi4Bioimage, OMERO, Research Data Management, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://analyticalscience.wiley.com/do/10.1002/was.0004000267/">https://analyticalscience.wiley.com/do/10.1002/was.0004000267/</a></p>
</section>
<hr class="docutils" />
<section id="omexcavator-a-tool-for-exporting-and-connecting-domain-specific-metadata-in-a-wider-knowledge-graph">
<h2>OMExcavator: a tool for exporting and connecting domain-specific metadata in a wider knowledge graph<a class="headerlink" href="#omexcavator-a-tool-for-exporting-and-connecting-domain-specific-metadata-in-a-wider-knowledge-graph" title="Link to this heading">#</a></h2>
<p>Stefan Dvoretskii, Michele Bortolomeazzi, Marco Nolden, Christian Schmidt, Klaus Maier-Hein, Josh Moore</p>
<p>Published 2025-02-21</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Nfdi4Bioimage, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15268798">https://zenodo.org/records/15268798</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15268798">https://doi.org/10.5281/zenodo.15268798</a></p>
</section>
<hr class="docutils" />
<section id="omero-tools">
<h2>Omero-tools<a class="headerlink" href="#omero-tools" title="Link to this heading">#</a></h2>
<p>Johannes Soltwedel</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository contains a collection of tools for working with OMERO. Such tools can be working with the OMERO command line interface to transfer datasets between repositories, etc.</p>
<p>Tags: OMERO, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="reference external" href="https://biapol.github.io/omero-tools/">https://biapol.github.io/omero-tools/</a></p>
</section>
<hr class="docutils" />
<section id="open-micoscropy-environment-ome-youtube-channel">
<h2>Open Micoscropy Environment (OME) Youtube Channel<a class="headerlink" href="#open-micoscropy-environment-ome-youtube-channel" title="Link to this heading">#</a></h2>
<p>Published None</p>
<p>Licensed CC-BY-4.0</p>
<p>OME develops open-source software and data format standards for the storage and manipulation of biological microscopy data</p>
<p>Tags: Open Source Software, Exclude From Dalia</p>
<p>Content type: Video, Collection</p>
<p><a class="reference external" href="https://www.youtube.com/&#64;OpenMicroscopyEnvironment">https://www.youtube.com/&#64;OpenMicroscopyEnvironment</a></p>
</section>
<hr class="docutils" />
<section id="open-microscopy-environment-youtube-channel">
<h2>Open Microscopy Environment YouTube channel<a class="headerlink" href="#open-microscopy-environment-youtube-channel" title="Link to this heading">#</a></h2>
<p>YouTube channel collecting videos and webinar recordings about the Open Microscopy Environment (OME), the Next Generation File Format OME-NGFF, the Image Data Resource (IDR), the Omero platform and Omero plugins.</p>
<p>Tags: OMERO, Exclude From Dalia</p>
<p>Content type: Collection, Video</p>
<p><a class="reference external" href="https://www.youtube.com/OpenMicroscopyEnvironment">https://www.youtube.com/OpenMicroscopyEnvironment</a></p>
</section>
<hr class="docutils" />
<section id="open-source-platform-for-scalable-multi-purpose-virtual-desktop-infrastructures">
<h2>Open Source Platform for Scalable Multi-Purpose Virtual Desktop Infrastructures<a class="headerlink" href="#open-source-platform-for-scalable-multi-purpose-virtual-desktop-infrastructures" title="Link to this heading">#</a></h2>
<p>Michael Scherle, Rafael Gieschke, Isabela Mocanu, Björn Grüning, von Suchodoletz, Dirk</p>
<p>Published 2025-09-12</p>
<p>Licensed CC-BY-4.0</p>
<p>Data and access to it are central to each NFDI consortium. However, moving data around is often impractical—it may be too large, sensitive, or restricted by agreements with, e.g., the funding provider, and copying introduces duplication, versioning issues, and loss of provenance. Rather than bringing data to the researcher, a Desktop-as-a-Service (DaaS) approach can offer researchers interactive, high-performance access in a secure and efficient manner. Driven by the need for seamless workflows and efficient data handling in NFDI4BIOIMAGE, we present a DaaS approach that is broadly applicable across NFDI. It supports diverse use cases, such as standardized virtual training environments for distributed participants (like required in DataPLANT), remote visualization of large-scale HPC datasets, and secure access to sensitive data (BERD)—all without the overhead of local machine setup and maintenance.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/17103962">https://zenodo.org/records/17103962</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.17103962">https://doi.org/10.5281/zenodo.17103962</a></p>
</section>
<hr class="docutils" />
<section id="open-microscopy-in-the-life-sciences-quo-vadis">
<h2>Open microscopy in the life sciences: quo vadis?<a class="headerlink" href="#open-microscopy-in-the-life-sciences-quo-vadis" title="Link to this heading">#</a></h2>
<p>Johannes Hohlbein, Benedict Diederich, Barbora Marsikova, Emmanuel G. Reynaud, Séamus Holden, Wiebke Jahr, Robert Haase, Kirti Prakash</p>
<p>Published 2022</p>
<p>Licensed ALL RIGHTS RESERVED</p>
<p>This comment article outlines the current state of the art in open hardware publishing in the context of microscopy.</p>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://doi.org/10.1038/s41592-022-01602-3">https://doi.org/10.1038/s41592-022-01602-3</a></p>
</section>
<hr class="docutils" />
<section id="optimisation-and-validation-of-a-swarm-intelligence-based-segmentation-algorithm-for-low-contrast-positron-emission-tomography">
<h2>Optimisation and Validation of a Swarm Intelligence based Segmentation Algorithm for low Contrast Positron Emission Tomography<a class="headerlink" href="#optimisation-and-validation-of-a-swarm-intelligence-based-segmentation-algorithm-for-low-contrast-positron-emission-tomography" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2014-04-01</p>
<p>Licensed CC-BY-4.0</p>
<p>In the field of radiooncological research, individualised therapy is one of the hot topics at the moment. As a key aspect biologically-adapted therapy is discussed. Therapy adaption based on biological parameters may include tomographic imaging to determine biological properties of the tumour. One often invoked imaging modality is positron emission tomography (PET) using the tracer [18F]-fluoromisonidazole (FMISO) for hypoxia imaging. Hypoxia imaging is of interest, because hypoxic tumours are known to be radiorestistant. Even further, patients with hypoxic tumours have worse prognosis compared to patients with normoxic tumours. Thus, hypoxia imaging appears promising for radiotherapy treatment adaption. For example, volumetric analysis of FMISO PET could deliver additional hypoxia target volumes, which may be irradiated with higher radiation doses to improve the therapeutic effect. However, limited contrast between target volume and background in FMISO PET images interferes image analysis.Established methods for target volume delineation in PET do not allow determination of reliable contours in FMISO PET. To tackle this aspect, this thesis focusses on an earlier developed swarm intelligence based segmentation algorithm for FMISO PET and rather, its optimisation and validation in a clinically relevant setting. In this setting, clinical FMISO PET images were used which were acquired as part of a clinical trial performed at the Clinic and Policlinic for Radiation Therapy and Radiooncology of the University Hospital Carl Gustav Carus Dresden. The segmentation algorithm was applied to these imaging data sets and optimised using a cross-validation approach incorporating reference contours from experienced observers who outlined FMISO PET positive volumes manually. Afterwards, the performance of the algorithm and the properties of the resulting contours were studied in more detail. The algorithm was shown to deliver contours which were similar to manually-created contours to a degree like manually-created contours were similar to each other. Thus, the application of the algorithm in clinical research is recommended to eliminate inter-observer-variabilities. Finally, it was shown that repeated FMISO PET imaging before and shortly after the beginning of combined radiochemotherapy lead to manually-created contours with significantly higher variations than the variations of automatically-created contours using the proposed algorithm. Increased contour similarity in subsequently acquired imaging data highlights the observer-independence of the algorithm. While several observers outline different volumes, in identical data sets as well as in subsequent imaging data sets, the algorithm outlines more stable volumes in both cases. Thus, increased contour reproducibility is reached by automation of the delineation process by the proposed algorithm. </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/7209862">https://zenodo.org/records/7209862</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7209862">https://doi.org/10.5281/zenodo.7209862</a></p>
</section>
<hr class="docutils" />
<section id="optimized-cranial-window-implantation-for-subcellular-and-functional-imaging-in-vivo">
<h2>Optimized cranial window implantation for subcellular and functional imaging in vivo<a class="headerlink" href="#optimized-cranial-window-implantation-for-subcellular-and-functional-imaging-in-vivo" title="Link to this heading">#</a></h2>
<p>Ben Vermaercke</p>
<p>Published 2025-01-13</p>
<p>Licensed CC-BY-4.0</p>
<p>Intravital workshop 15/11/2024</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14641777">https://zenodo.org/records/14641777</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14641777">https://doi.org/10.5281/zenodo.14641777</a></p>
</section>
<hr class="docutils" />
<section id="parallel-fiji-visualizer">
<h2>Parallel_Fiji_Visualizer<a class="headerlink" href="#parallel-fiji-visualizer" title="Link to this heading">#</a></h2>
<p>Matthew Mueller, Aaron, Advanced Bioimaging Center</p>
<p>Published 2024-05-15T06:14:24+00:00</p>
<p>Licensed BSD-3-CLAUSE</p>
<p>Tags: Fiji, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/abcucberkeley/Parallel_Fiji_Visualizer">abcucberkeley/Parallel_Fiji_Visualizer</a></p>
</section>
<hr class="docutils" />
<section id="parhyale-3d-segmentation-dataset">
<h2>Parhyale 3D segmentation dataset<a class="headerlink" href="#parhyale-3d-segmentation-dataset" title="Link to this heading">#</a></h2>
<p>Frederike Alwes, Ko Sugawara, Michalis Averof</p>
<p>Published 2023-08-11</p>
<p>Licensed CC-BY-4.0</p>
<p>The Parhyale 3D Segmentation dataset consists of 50 timepoints (TP01-TP50) of 3D images (512x512x34), where the manual annotations can be found at discrete 6 timepoints (at TP01, TP11, TP21, TP31, TP41 and TP50).</p>
<p>For further details, see README file.</p>
<p>This version fixes the duplicated label IDs found in the previous version of label files. This version ensures that each instance has a unique ID. Thanks to Jackson Borchardt for reporting that error.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/8252039">https://zenodo.org/records/8252039</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8252039">https://doi.org/10.5281/zenodo.8252039</a></p>
</section>
<hr class="docutils" />
<section id="platynereis-em-training-data">
<h2>Platynereis EM training data<a class="headerlink" href="#platynereis-em-training-data" title="Link to this heading">#</a></h2>
<p>Constantin Pape</p>
<p>Published 2020-02-19</p>
<p>Licensed CC-BY-4.0</p>
<p>Training data for Convolutional Neural Networks used in the publication Whole-body integration of gene expression and single-cell morphology. We provide training data for segmenting structures in the SerialBlockface Electron Microscopy data-set containing a complete 6 day old Platynereis dumerilii larva, in particular for:</p>
<ul class="simple">
<li><p>cell membranes: 9 training blocks &#64; resolution 20x20x25 nm. Based on initial training data provided by <a class="reference external" href="https://ariadne.ai/">https://ariadne.ai/</a>.</p></li>
<li><p>cilia: 3 training and 2 validation blocks &#64; resolution 20x20x25 nm.</p></li>
<li><p>cuticle: 5 training blocks &#64; resolution 40x40x50 nm.</p></li>
<li><p>nuclei: 12 training blocks &#64; resolution 80x80x100 nm. Based on initial training data provided by <a class="reference external" href="https://ariadne.ai/">https://ariadne.ai/</a>.</p></li>
</ul>
<p>For details on how to use this data for training, see <a class="github reference external" href="https://github.com/platybrowser/platybrowser-backend/tree/master/segmentation">platybrowser/platybrowser-backend</a>.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/3675220">https://zenodo.org/records/3675220</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.3675220">https://doi.org/10.5281/zenodo.3675220</a></p>
</section>
<hr class="docutils" />
<section id="platynereis-dumerilii-full-length-transcriptome-of-developmental-stages">
<h2>Platynereis dumerilii full-length transcriptome of developmental stages<a class="headerlink" href="#platynereis-dumerilii-full-length-transcriptome-of-developmental-stages" title="Link to this heading">#</a></h2>
<p>Vellutini, Bruno C., Mette Handberg-Thorsager, Pavel Tomancak</p>
<p>Published 2024-11-29</p>
<p>Licensed CC-BY-4.0</p>
<p>To generate a high-quality full-length transcriptome for the annelid Platynereis dumerilii, we collected samples from representative developmental stages, from unfertilized eggs to 5 days post-fertilization. Each sample consisted of a bulk mix from 1 to 5 batches of embryos fertilized by different parents. We incubated all batches at 18 degrees Celsius until the desired time point, then collected the embryos into a clean tube and snap-froze them in liquid nitrogen with as little seawater as possible. The samples were stored at -80 degrees Celsius until RNA extraction. We extracted total RNA from the samples using a Trizol protocol. After measuring the RNA concentration with NanoDrop, we created a bulk RNA mix by combining 1 µL from each sample into a new tube. We gave the sample to the Sequencing and Genotyping facility of the Max Planck Institute of Molecular Cell Biology and Genetics, who ran aliquots of this bulk mix through a Bioanalyzer and gel electrophoresis. They found no evidence of RNA degradation. From this sample, they prepared PacBio Iso-Seq libraries using the Express Template Prep Kit 2.0 and sequenced full-length transcripts on a SMRT 8M Cell for 30 hours using a PacBio Sequel II System. They processed the raw movie subreads with SMRT Analysis software, following the Iso-Seq v3 workflow to generate representative circular consensus sequences, demultiplex and remove primers, trim poly(A) tails, and remove concatemers. After transcript clustering and merging, the resulting dataset contained 176,122 polished high-quality isoforms. Using Cogent, we removed redundant isoforms and obtained a dataset with 117,524 transcripts. From this, we generated a dataset containing only the longest isoform for each gene, with 70,003 sequences in total. We calculated descriptive metrics using Transrate. To estimate their completeness, we used BUSCO for metazoa and obtained a score of 85%. Finally, we annotated the longest-isoform dataset using EnTAP. About 85% of the transcripts have a coding sequence. We obtained annotations for 67% of the sequences, while 33% have remained unannotated.
Datasets</p>
<p>file name
file size (zipped)
sequences
description</p>
</section>
<section id="pdum-workflow-zip-folder-3-40-gb">
<h2>0-Pdum_workflow.zip (folder)
3.40 GB<a class="headerlink" href="#pdum-workflow-zip-folder-3-40-gb" title="Link to this heading">#</a></h2>
<p>entire pipeline with notebook entries and analyses</p>
<p>1-Pdum_hq_isoforms.zip (fasta)
180.30 MB
176,122
polished high-quality isoforms from CCS</p>
<p>2-Pdum_co_isoforms.zip (fasta)
70.68 MB
117,524
non-redundant polished high-quality isoforms</p>
<p>3-Pdum_co_longest.zip (fasta)
54.85 MB
70,003
longest of non-redundant polished high-quality isoforms</p>
<p>4-Pdum_co_longest_annotations.zip (tsv)
34.37 MB
70,003 (46,635 annotated)
annotations for longest-isoform dataset</p>
<p> </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14250773">https://zenodo.org/records/14250773</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14250773">https://doi.org/10.5281/zenodo.14250773</a></p>
</section>
<hr class="docutils" />
<section id="plugin-omero-batch-plugin">
<h2>Plugin “omero-batch-plugin”<a class="headerlink" href="#plugin-omero-batch-plugin" title="Link to this heading">#</a></h2>
<p>Licensed GPL-2.0</p>
<p>An ImageJ plugin to run a script or macro on a batch of images from/to OMERO.</p>
<p>Tags: OMERO, Imagej, Imagej Macro, Github, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/GReD-Clermont/omero_batch-plugin">GReD-Clermont/omero_batch-plugin</a></p>
</section>
<hr class="docutils" />
<section id="plugin-omero-cli-transfer">
<h2>Plugin “omero-cli-transfer”<a class="headerlink" href="#plugin-omero-cli-transfer" title="Link to this heading">#</a></h2>
<p>Erick Martins Ratamero, jean-marie burel, Will Moore, Guillaume Gay, Christoph Moehl, et al.</p>
<p>Published 2024-09-14</p>
<p>Licensed GPL-2.0</p>
<p>An OMERO CLI plugin for creating and using transfer packets between OMERO servers.</p>
<p>Tags: OMERO, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/ome/omero-cli-transfer">ome/omero-cli-transfer</a></p>
</section>
<hr class="docutils" />
<section id="plugin-simple-omero-client">
<h2>Plugin “simple-omero-client”<a class="headerlink" href="#plugin-simple-omero-client" title="Link to this heading">#</a></h2>
<p>Pierre Pouchin, Rdornier, kekunn, jean-marie burel</p>
<p>Licensed GPL-2.0</p>
<p>A wrapper library which can be called from scripts in Fiji, but can mostly be used in Maven projects to wrap calls to the underlying OMERO Java Gateway.</p>
<p>Tags: OMERO, Github, Fiji, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/GReD-Clermont/simple-omero-client">GReD-Clermont/simple-omero-client</a></p>
</section>
<hr class="docutils" />
<section id="predicting-axillary-lymph-node-metastasis-in-early-breast-cancer-using-deep-learning-on-primary-tumor-biopsy-slides">
<h2>Predicting Axillary Lymph Node Metastasis in Early Breast Cancer Using Deep Learning on Primary Tumor Biopsy Slides<a class="headerlink" href="#predicting-axillary-lymph-node-metastasis-in-early-breast-cancer-using-deep-learning-on-primary-tumor-biopsy-slides" title="Link to this heading">#</a></h2>
<p>Wenqi Tang, MIC Group</p>
<p>Published 2021-12-12</p>
<p>Licensed UNLICENSED</p>
<p>This repo is the official implementation of our paper “Predicting Axillary Lymph Node Metastasis in Early Breast Cancer Using Deep Learning on Primary Tumor Biopsy Slides”.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="github reference external" href="https://github.com/bupt-ai-cz/BALNMP">bupt-ai-cz/BALNMP</a></p>
</section>
<hr class="docutils" />
<section id="preprint-be-sustainable-recommendations-for-fair-resources-in-life-sciences-research-eosc-life-s-lessons">
<h2>Preprint: “Be Sustainable”, Recommendations for FAIR Resources in Life Sciences research: EOSC-Life’s Lessons<a class="headerlink" href="#preprint-be-sustainable-recommendations-for-fair-resources-in-life-sciences-research-eosc-life-s-lessons" title="Link to this heading">#</a></h2>
<p>Romain David, Arina Rybina, jean-marie burel, Jean-Karim Heriche, Pauline Audergon, Jan-Willem Boiten, Frederik Coppens, Sara Crockett, Exter Katrina, Sven Fahrener, Maddalena Fratelli, Carole Goble, Philipp Gormanns, Tobias Grantner, Bjorn Gruning, Kim Tamara Gurwitz, John Hancock, Henriette Harmse, Petr Holub, Nick Juty, Geoffrey Karnbach, Emma Karoune, Antje Keppler, Jessica Klemeier, Carla Lancelotti, Jean-Luc Legras, L. Allyson Lister, Dario Livio Longo, Rebecca Ludwig, Benedicte Madon, Marzia Massimi, Vera Matser, Rafaele Matteoni, Mayrhofer Michaela Th., Christian Ohmann, Maria Panagiotopoulou, Helen Parkinson, Isabelle Perseil, Claudia Pfander, Roland Pieruschka, Michael Raess, Andreas Rauber, Audrey S. Richard, Paolo Romano, Antonio Rosato, Alex Sanchez-Pla, Susanna-Assunta Sansone, Ugis Sarkans, Beatriz Serrano-Solano, Jing Tang, Ziaurrehman Tanoli, Jonathan Tedds, Harald Wagener, Martin Weise, Hans V. Westerhoff, Rudolf Wittner, Jonathan Ewbank, Niklas Blomberg, Philip Gribbon</p>
<p>Published 2023-09-12</p>
<p>Licensed CC-BY-4.0</p>
<p>“Be SURE - Be SUstainable REcommendations”The main goals and challenges for the Life Science (LS) communities in the Open Science framework are to increase reuse and sustainability of data resources, software tools, and workflows, especially in large-scale data-driven research and computational analyses. Here, we present key findings, procedures, effective measures and recommendations for generating and establishing sustainable LS resources based on the collaborative, cross-disciplinary work done within the EOSC-Life (European Open Science Cloud for Life Sciences) consortium. Bringing together 13 European LS Research Infrastructures (RIs), it has laid the foundation for an open, digital space to support biological and medical research. Using lessons learned from 27 selected projects, we describe the organisational, technical, financial and legal/ethical challenges that represent the main barriers to sustainability in the life sciences. We show how EOSC-Life provides a model for sustainable FAIR data management, including solutions for sensitive- and industry-related resources, by means of cross-disciplinary training and best practices sharing. Finally, we illustrate how data harmonisation and collaborative work facilitate interoperability of tools, data, solutions and lead to a better understanding of concepts, semantics and functionalities in the life <a class="reference external" href="http://sciences.IN">sciences.IN</a> PRESS EMBO Journal: <a class="reference external" href="https://www.embopress.org/journal/14602075&amp;amp;nbsp;AVAILABLE">https://www.embopress.org/journal/14602075&amp;nbsp;AVAILABLE</a> SOON at : <a class="reference external" href="https://doi.org/10.15252/embj.2023115008">https://doi.org/10.15252/embj.2023115008</a> </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/8338931">https://zenodo.org/records/8338931</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8338931">https://doi.org/10.5281/zenodo.8338931</a></p>
</section>
<hr class="docutils" />
<section id="prodgerlab-stardist-hiv-target-cell-training-set">
<h2>ProdgerLab-StarDist-HIV Target Cell Training Set<a class="headerlink" href="#prodgerlab-stardist-hiv-target-cell-training-set" title="Link to this heading">#</a></h2>
<p>Zhongtian Shao</p>
<p>Published 2023-06-28</p>
<p>Licensed CC-BY-4.0</p>
<p>40 annotated immunofluorescence microscopy images (600 microns x 600 microns) of foreskin tissue stained for CD3/CD4/CCR5/Nuclei. These images were used to train StarDist models used for the identification of HIV Target Cells in foreskin tissue section scans. </p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/8091914">https://zenodo.org/records/8091914</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8091914">https://doi.org/10.5281/zenodo.8091914</a></p>
</section>
<hr class="docutils" />
<section id="rdf-as-a-bridge-to-domain-platforms-like-omero-or-there-and-back-again">
<h2>RDF as a bridge to domain-platforms like OMERO, or There and back again.<a class="headerlink" href="#rdf-as-a-bridge-to-domain-platforms-like-omero-or-there-and-back-again" title="Link to this heading">#</a></h2>
<p>Josh Moore, Andra Waagmeester, Kristina Hettne, Katherine Wolstencroft, Susanne Kunis</p>
<p>Licensed CC-BY-4.0</p>
<p>In 2005, the first version of OMERO stored RDF natively. However, just a year after the 1.0 release of RDF, performance considerations led to the development of a more traditional SQL approach for OMERO. A binary protocol makes it possible to query and retrieve metadata but the resulting information cannot immediately be combined with other sources. This is the adventure of rediscovering the benefit of RDF triples as a – if not the – common exchange mechanism.</p>
<p>Tags: Research Data Management, FAIR-Principles, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.10687658">https://zenodo.org/doi/10.5281/zenodo.10687658</a></p>
</section>
<hr class="docutils" />
<section id="rdm4mic-presentations">
<h2>RDM4Mic Presentations<a class="headerlink" href="#rdm4mic-presentations" title="Link to this heading">#</a></h2>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Research Data Management, Exclude From Dalia</p>
<p>Content type: Collection</p>
<p><a class="github reference external" href="https://github.com/German-BioImaging/RDM4mic/tree/master/presentations">German-BioImaging/RDM4mic</a></p>
</section>
<hr class="docutils" />
<section id="rdm4mic">
<h2>RDM4mic<a class="headerlink" href="#rdm4mic" title="Link to this heading">#</a></h2>
<p>Licensed UNKNOWN</p>
<p>Tags: Research Data Management, OMERO, Exclude From Dalia</p>
<p>Content type: Collection, Video</p>
<p><a class="reference external" href="https://www.youtube.com/&#64;RDM4mic">https://www.youtube.com/&#64;RDM4mic</a></p>
</section>
<hr class="docutils" />
<section id="rdmbites-bioimage-metadata">
<h2>RDMBites BioImage metadata<a class="headerlink" href="#rdmbites-bioimage-metadata" title="Link to this heading">#</a></h2>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Collection, Video</p>
<p><a class="reference external" href="https://www.youtube.com/watch?v=aRHNHk07t3Q&amp;amp;list=PLyCNTVs-UBvuJF7WausQ5q7v7pI1vEpI1">https://www.youtube.com/watch?v=aRHNHk07t3Q&amp;list=PLyCNTVs-UBvuJF7WausQ5q7v7pI1vEpI1</a></p>
</section>
<hr class="docutils" />
<section id="rdmo-research-data-management-organiser">
<h2>RDMO - Research Data Management Organiser<a class="headerlink" href="#rdmo-research-data-management-organiser" title="Link to this heading">#</a></h2>
<p>Licensed UNKNOWN</p>
<p>Der Research Data Management Organiser (RDMO) unterstützt Forschungsprojekte bei der Planung, Umsetzung und Verwaltung aller Aufgaben des Forschungsdatenmanagements.</p>
<p>Tags: Research Data Management, Open Source Software, Exclude From Dalia</p>
<p>Content type: Website, Online Tutorial</p>
<p><a class="reference external" href="https://rdmorganiser.github.io/">https://rdmorganiser.github.io/</a></p>
</section>
<hr class="docutils" />
<section id="rdm-system-connector">
<h2>RDM_system_connector<a class="headerlink" href="#rdm-system-connector" title="Link to this heading">#</a></h2>
<p>SaibotMagd</p>
<p>Licensed UNKNOWN</p>
<p>This tool is intended to link different research data management platforms with each other.</p>
<p>Tags: Research Data Management, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/SaibotMagd/RDM_system_connector">SaibotMagd/RDM_system_connector</a></p>
</section>
<hr class="docutils" />
<section id="rembi-recommended-metadata-for-biological-imagesenabling-reuse-of-microscopy-data-in-biology">
<h2>REMBI - Recommended Metadata for Biological Images—enabling reuse of microscopy data in biology<a class="headerlink" href="#rembi-recommended-metadata-for-biological-imagesenabling-reuse-of-microscopy-data-in-biology" title="Link to this heading">#</a></h2>
<p>Ugis Sarkans, Wah Chiu, Lucy Collinson, Michele C. Darrow, Jan Ellenberg, David Grunwald, et al.</p>
<p>Published 2021-05-21</p>
<p>Licensed UNKNOWN</p>
<p>Bioimaging data have significant potential for reuse, but unlocking this potential requires systematic archiving of data and metadata in public databases. The authors propose draft metadata guidelines to begin addressing the needs of diverse communities within light and electron microscopy.</p>
<p>Tags: Metadata, Research Data Management, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8606015/</a></p>
<p><a class="reference external" href="https://www.nature.com/articles/s41592-021-01166-8">https://www.nature.com/articles/s41592-021-01166-8</a></p>
<p><a class="reference external" href="https://doi.org/10.1038/s41592-021-01166-8">https://doi.org/10.1038/s41592-021-01166-8</a></p>
</section>
<hr class="docutils" />
<section id="research-data-management-on-campus-and-in-nfdi4bioimage">
<h2>RESEARCH DATA MANAGEMENT on Campus and in NFDI4BIOIMAGE<a class="headerlink" href="#research-data-management-on-campus-and-in-nfdi4bioimage" title="Link to this heading">#</a></h2>
<p>Cornelia Wetzker, Michael Schlierf</p>
<p>Published 2024-08-29</p>
<p>Licensed CC-BY-4.0</p>
<p>The poster is part of the work of the German consortium NFDI4BIOIMAGE funded by the Deutsche Forschungsgemeinschaft (DFG grant number NFDI 46/1, project number 501864659).</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/13684187">https://zenodo.org/records/13684187</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13684187">https://doi.org/10.5281/zenodo.13684187</a></p>
</section>
<hr class="docutils" />
<section id="reconstructed-images-of-a-2dsim-multiposition-acquisition">
<h2>Reconstructed images of a 2DSIM multiposition acquisition.<a class="headerlink" href="#reconstructed-images-of-a-2dsim-multiposition-acquisition" title="Link to this heading">#</a></h2>
<p>Louis Romette</p>
<p>Published 2025-02-19</p>
<p>Licensed CC-BY-4.0</p>
<p>Acquired with an Nikon SIM, in 2D-SIM mode at 488nm of excitation with 30% laser power and 200ms of exposition.  Fluorescence is a knocked-in mStayGold-β2Spectrin. Cells are rat hippocampal neurons à DIV 3. The file is a reconstructed multiposition acquisition (10 positions). Uploaded to show a probable issue with Bio-Formats in Fiji, where SIM reconstrcuted multipositions files open like static noise. </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14893791">https://zenodo.org/records/14893791</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14893791">https://doi.org/10.5281/zenodo.14893791</a></p>
</section>
<hr class="docutils" />
<section id="reference-collection-to-push-back-against-common-statistical-myths">
<h2>Reference Collection to push back against “Common Statistical Myths”<a class="headerlink" href="#reference-collection-to-push-back-against-common-statistical-myths" title="Link to this heading">#</a></h2>
<p>Andrew Althouse</p>
<p>Published 2023-06-29</p>
<p>Licensed UNKNOWN</p>
<p>Reference Collection to understand how to deal with common statistical myths.</p>
<p>Tags: Statistics, Exclude From Dalia</p>
<p>Content type: Wiki</p>
<p><a class="reference external" href="https://discourse.datamethods.org/t/reference-collection-to-push-back-against-common-statistical-myths/1787">https://discourse.datamethods.org/t/reference-collection-to-push-back-against-common-statistical-myths/1787</a></p>
</section>
<hr class="docutils" />
<section id="reporting-and-reproducibility-in-microscopy">
<h2>Reporting and reproducibility in microscopy<a class="headerlink" href="#reporting-and-reproducibility-in-microscopy" title="Link to this heading">#</a></h2>
<p>Published 2021-12-03</p>
<p>Licensed UNKNOWN</p>
<p>This Focus issue features a series of papers offering guidelines and tools for improving the tracking and reporting of microscopy metadata with an emphasis on reproducibility and data re-use.</p>
<p>Tags: Reproducibility, Metadata, Exclude From Dalia</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://www.nature.com/collections/djiciihhjh">https://www.nature.com/collections/djiciihhjh</a></p>
</section>
<hr class="docutils" />
<section id="repository-for-combinatorial-wnt-signaling-landscape-during-brachiopod-anteroposterior-patterning">
<h2>Repository for: Combinatorial Wnt signaling landscape during brachiopod anteroposterior patterning<a class="headerlink" href="#repository-for-combinatorial-wnt-signaling-landscape-during-brachiopod-anteroposterior-patterning" title="Link to this heading">#</a></h2>
<p>Vellutini, Bruno C., Martín-Durán, José M., Aina Børve, Andreas Hejnol</p>
<p>Published 2024-08-16</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository contains the data and analyses for the manuscript:
Vellutini, B. C., Martín-Durán, J. M., Børve, A. &amp; Hejnol, A. Combinatorial Wnt signaling landscape during brachiopod anteroposterior patterning. BMC Biol. 22, 1–23 (2024). <a class="reference external" href="https://doi.org/10.1186/s12915-024-01988-w">https://doi.org/10.1186/s12915-024-01988-w</a>
The source is maintained at <a class="github reference external" href="https://github.com/bruvellu/terebratalia-wnts">bruvellu/terebratalia-wnts</a>.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/13338425">https://zenodo.org/records/13338425</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13338425">https://doi.org/10.5281/zenodo.13338425</a></p>
</section>
<hr class="docutils" />
<section id="research-data-reusability-conceptual-foundations-barriers-and-enabling-technologies">
<h2>Research Data Reusability - Conceptual Foundations, Barriers and Enabling Technologies<a class="headerlink" href="#research-data-reusability-conceptual-foundations-barriers-and-enabling-technologies" title="Link to this heading">#</a></h2>
<p>Costantino Thanos</p>
<p>Published 2017-01-09</p>
<p>Licensed CC-BY-4.0</p>
<p>This article discusses various aspects of data reusability in the context of scientific research, including technological, legal, and policy frameworks.</p>
<p>Tags: Research Data Management, Open Science, Data Protection, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.mdpi.com/2304-6775/5/1/2">https://www.mdpi.com/2304-6775/5/1/2</a></p>
</section>
<hr class="docutils" />
<section id="research-data-what-are-the-key-issues-to-consider-when-publishing-this-kind-of-material">
<h2>Research data - what are the key issues to consider when publishing this kind of material?<a class="headerlink" href="#research-data-what-are-the-key-issues-to-consider-when-publishing-this-kind-of-material" title="Link to this heading">#</a></h2>
<p>Licensed UNKNOWN</p>
<p>The website offers detailed advice on publishing research data, focusing on key issues like data management, FAIR data principles, legal considerations, and repository selection.</p>
<p>Tags: Research Data Management, FAIR-Principles, Licensing, Exclude From Dalia</p>
<p>Content type: Tutorial</p>
<p><a class="reference external" href="https://www.publisso.de/en/advice/publishing-advice-faqs/research-data">https://www.publisso.de/en/advice/publishing-advice-faqs/research-data</a></p>
</section>
<hr class="docutils" />
<section id="research-data-management-for-bioimaging-the-2021-nfdi4bioimage-community-survey">
<h2>Research data management for bioimaging - the 2021 NFDI4BIOIMAGE community survey<a class="headerlink" href="#research-data-management-for-bioimaging-the-2021-nfdi4bioimage-community-survey" title="Link to this heading">#</a></h2>
<p>Christian Schmidt, Janina Hanne, Josh Moore, Christian Meesters, Elisa Ferrando-May, et al.</p>
<p>Published 2022-09-20</p>
<p>Licensed CC-BY-4.0</p>
<p>As an initiative within Germany’s National Research Data Infrastructure, the authors conducted this community survey in summer 2021 to assess the state of the art of bioimaging RDM and the community needs.</p>
<p>Tags: Research Data Management, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://f1000research.com/articles/11-638/v2">https://f1000research.com/articles/11-638/v2</a></p>
</section>
<hr class="docutils" />
<section id="id2">
<h2>Research data management for bioimaging: the 2021 NFDI4BIOIMAGE community survey<a class="headerlink" href="#id2" title="Link to this heading">#</a></h2>
<p>Christian Schmidt, Janina Hanne, Josh Moore, Christian Meesters, Elisa Ferrando-May, Stefanie Weidtkamp-Peters, members of the NFDI4BIOIMAGE initiative</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Nfdi4Bioimage, Research Data Management, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://f1000research.com/articles/11-638">https://f1000research.com/articles/11-638</a></p>
</section>
<hr class="docutils" />
<section id="root-tissue-segmentation-dataset">
<h2>Root tissue segmentation dataset<a class="headerlink" href="#root-tissue-segmentation-dataset" title="Link to this heading">#</a></h2>
<p>Julian Wanner, Kuhn Cuellar, Luis, Friederike Wanke</p>
<p>Published 2022-01-12</p>
<p>Licensed CC-BY-4.0</p>
<p>The PHDFM dataset is composed of fluorescence microscopy images of root tissue samples from A. thaliana, using the ratiometric fluorescent indicator 8‐hydroxypyrene‐1,3,6‐trisulfonic acid trisodium salt (HPTS). This semantic segmentation training dataset consists of 2D microscopy images (the brightfield channel for excitation at 405 nm), each containing a segmentation mask as an additional image channel (manually annotated by plant biologists). The segmentation masks classify pixels into the following 5 labels with the corresponding IDs: background (0), root tissue (1), early elongation zone (2), late elongation zone (3), and meristematic zone (4).</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/5841376">https://zenodo.org/records/5841376</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5841376">https://doi.org/10.5281/zenodo.5841376</a></p>
</section>
<hr class="docutils" />
<section id="round-table-workshop-1-sample-stabilization-in-intravital-imaging">
<h2>Round Table Workshop 1 - Sample Stabilization in intravital Imaging<a class="headerlink" href="#round-table-workshop-1-sample-stabilization-in-intravital-imaging" title="Link to this heading">#</a></h2>
<p>Michael Gerlach, Hans-Ulrich Fried, Christiane Peuckert</p>
<p>Published 2024-11-14</p>
<p>Licensed CC-BY-4.0</p>
<p>Notes from a round table workshop on the 4th Day of Intravital Microscopy in Leuven, Belgium.
Contains hands-on tips, tricks and schemes to improve sample stability during various models of Intravital Miroscopy.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14161289">https://zenodo.org/records/14161289</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14161289">https://doi.org/10.5281/zenodo.14161289</a></p>
</section>
<hr class="docutils" />
<section id="round-table-workshop-2-correction-of-drift-and-movement">
<h2>Round Table Workshop 2 - Correction of Drift and Movement<a class="headerlink" href="#round-table-workshop-2-correction-of-drift-and-movement" title="Link to this heading">#</a></h2>
<p>Dr. Hellen Ishikawa-Ankerhold, Max Nobis</p>
<p>Published 2024-11-14</p>
<p>Licensed CC-BY-4.0</p>
<p>Session 2 of a round table workshop. Features description of image processing methods useful in intravital imaging to compensate for the motion of living tissue.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14161633">https://zenodo.org/records/14161633</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14161633">https://doi.org/10.5281/zenodo.14161633</a></p>
</section>
<hr class="docutils" />
<section id="stedycon-obf-dataset-with-simulated-intensity-and-complex-stacks-for-bioformats-mr-4362">
<h2>STEDYCON OBF dataset with simulated intensity and complex stacks for bioformats MR #4362<a class="headerlink" href="#stedycon-obf-dataset-with-simulated-intensity-and-complex-stacks-for-bioformats-mr-4362" title="Link to this heading">#</a></h2>
<p>Nils Gladitz</p>
<p>Published 2025-09-02</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/17039369">https://zenodo.org/records/17039369</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.17039369">https://doi.org/10.5281/zenodo.17039369</a></p>
</section>
<hr class="docutils" />
<section id="sample-data-for-pr-4284-https-github-com-ome-bioformats-pull-4284">
<h2>Sample data for PR#4284 (<a class="github reference external" href="https://github.com/ome/bioformats/pull/4284">ome/bioformats#4284</a>)<a class="headerlink" href="#sample-data-for-pr-4284-https-github-com-ome-bioformats-pull-4284" title="Link to this heading">#</a></h2>
<p>Jürgen Bohl</p>
<p>Published 2025-03-04</p>
<p>Licensed CC-BY-4.0</p>
<p>With this file the problem addressed in PR#4284 can be reproduced: when runningbfconvert -series 4 -channel 0 2025_01_27__0007_offline_Zen_3_9_5.czi output.png
the result is garbled.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14968770">https://zenodo.org/records/14968770</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14968770">https://doi.org/10.5281/zenodo.14968770</a></p>
</section>
<hr class="docutils" />
<section id="sciaugment">
<h2>SciAugment<a class="headerlink" href="#sciaugment" title="Link to this heading">#</a></h2>
<p>Martin Schätz</p>
<p>Published 2022-07-29</p>
<p>Licensed OTHER-OPEN</p>
<p>SciAugment v0.2.0 has pip installable version, channel-wise augmentation was added, and an option for all augmentations or no augmentation. Examples of how to use the tool are in README and in Google Colab notebooks. Practical examples of how to use results with YOLOv5 on scientific data can be found in the SciCount project.</p>
<p>SciAugment aims to provide an option to create an augmented image set with similar changes in data as the imaging sensor and technique would do.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/6991106">https://zenodo.org/records/6991106</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6991106">https://doi.org/10.5281/zenodo.6991106</a></p>
</section>
<hr class="docutils" />
<section id="scientific-colour-maps">
<h2>Scientific colour maps<a class="headerlink" href="#scientific-colour-maps" title="Link to this heading">#</a></h2>
<p>Fabio Crameri</p>
<p>Published 2023-10-05</p>
<p>Licensed ALL RIGHTS RESERVED</p>
<p>Scientific, colour-vision deficiency friendly and perceptually-uniform colour maps that include all readers and significantly reduce visual errors.</p>
<p>Tags: FAIR-Principles, Research Data Management, Exclude From Dalia</p>
<p>Content type: Website</p>
<p><a class="reference external" href="https://www.fabiocrameri.ch/colourmaps/">https://www.fabiocrameri.ch/colourmaps/</a></p>
</section>
<hr class="docutils" />
<section id="scripts-filopodyanr-a-case-study-for-the-neubias-ts7-in-szeged">
<h2>Scripts_FilopodyanR - a case study for the NEUBIAS TS7 in Szeged<a class="headerlink" href="#scripts-filopodyanr-a-case-study-for-the-neubias-ts7-in-szeged" title="Link to this heading">#</a></h2>
<p>Marion Louveaux</p>
<p>Licensed UNKNOWN</p>
<p>Tags: Neubias, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Code</p>
<p><a class="github reference external" href="https://github.com/marionlouveaux/NEUBIAS2018_TS7/">marionlouveaux/NEUBIAS2018_TS7</a></p>
</section>
<hr class="docutils" />
<section id="segmentation-of-nuclei-in-histopathology-images-by-deep-regression-of-the-distance-map">
<h2>Segmentation of Nuclei in Histopathology Images by deep regression of the distance map<a class="headerlink" href="#segmentation-of-nuclei-in-histopathology-images-by-deep-regression-of-the-distance-map" title="Link to this heading">#</a></h2>
<p>Naylor Peter Jack, Walter Thomas, Laé Marick, Reyal Fabien</p>
<p>Published 2018-02-16</p>
<p>Licensed CC-BY-4.0</p>
<p>This dataset has been annonced in our accepted paper “Segmentation of Nuclei in Histopathology Images by deep regression of the distance map” in Transcation on Medical Imaging on the 13th of August. This dataset consists of 50 annotated images, divided into 11 patients.</p>
<p>Tags: Nuclei Images, Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/1175282#.WyP61xy-l5E">https://zenodo.org/records/1175282#.WyP61xy-l5E</a></p>
</section>
<hr class="docutils" />
<section id="segmenting-cells-in-a-spheroid-in-3d-using-2d-stardist-within-trackmate">
<h2>Segmenting cells in a spheroid in 3D using 2D StarDist within TrackMate<a class="headerlink" href="#segmenting-cells-in-a-spheroid-in-3d-using-2d-stardist-within-trackmate" title="Link to this heading">#</a></h2>
<p>Jean-Yves Tinevez, Joanna W. Pylvänäinen, Guillaume Jacquemet</p>
<p>Published 2021-08-19</p>
<p>Licensed CC-BY-4.0</p>
<p>3D image of cells in a spheroid, imaged on a confocal microscope, used in a tutorial to demonstrate how to hack TrackMate to segment cells in 3D using the 2D segmentation algorithms it ships.</p>
<p>Image by Guillaume Jacquemet.</p>
<p>For more details see <a class="reference external" href="https://imagej.net/plugins/trackmate/trackmate-stardist#generation-of-3d-labels-by-tracking-2d-labels-using-trackmate">https://imagej.net/plugins/trackmate/trackmate-stardist#generation-of-3d-labels-by-tracking-2d-labels-using-trackmate</a></p>
<p> </p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/5220610">https://zenodo.org/records/5220610</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5220610">https://doi.org/10.5281/zenodo.5220610</a></p>
</section>
<hr class="docutils" />
<section id="setting-up-an-institutional-omero-environment-for-bioimage-data-perspectives-from-both-facility-staff-and-users">
<h2>Setting up an institutional OMERO environment for bioimage data: Perspectives from both facility staff and users<a class="headerlink" href="#setting-up-an-institutional-omero-environment-for-bioimage-data-perspectives-from-both-facility-staff-and-users" title="Link to this heading">#</a></h2>
<p>Anett Jannasch, Silke Tulok, Chukwuebuka William Okafornta, Thomas Kugel, Michele Bortolomeazzi, Tom Boissonnet, Christian Schmidt, Andy Vogelsang</p>
<p>Published 2024-09-14</p>
<p>Licensed CC-BY-4.0</p>
<p>Modern bioimaging core facilities at research institutions are essential for managing and maintaining high-end instruments, providing training and support for researchers in experimental design, image acquisition and data analysis.</p>
<p>Tags: Nfdi4Bioimage, OMERO, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://onlinelibrary.wiley.com/doi/10.1111/jmi.13360">https://onlinelibrary.wiley.com/doi/10.1111/jmi.13360</a></p>
</section>
<hr class="docutils" />
<section id="simulated-hl60-cells-from-the-cell-tracking-challenge">
<h2>Simulated HL60 cells (from the Cell Tracking Challenge)<a class="headerlink" href="#simulated-hl60-cells-from-the-cell-tracking-challenge" title="Link to this heading">#</a></h2>
<p>Vebjorn Ljosa, Katherine L. Sokolnicki, Anne E. Carpenter</p>
<p>Published 2012-06-28</p>
<p>Licensed CC0-1.0</p>
<p>These are synthetic images from the Cell Tracking Challenge. The images depict simulated nuclei of HL60 cells stained with Hoescht (training datasets). These synthetic images of HL60 cells provide an opportunity to test image analysis software by comparing segmentation results to the available ground truth for each time point. The number of clustered nuclei increases with time adding more complexity to the problem. This time-laps dataset can be used for simple segmentation or for nuclei tracking.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://bbbc.broadinstitute.org/BBBC035">https://bbbc.broadinstitute.org/BBBC035</a></p>
</section>
<hr class="docutils" />
<section id="single-cell-approach-dissecting-agr-quorum-sensing-dynamics-in-staphylococcus-aureus">
<h2>Single-cell approach dissecting agr quorum sensing dynamics in Staphylococcus aureus<a class="headerlink" href="#single-cell-approach-dissecting-agr-quorum-sensing-dynamics-in-staphylococcus-aureus" title="Link to this heading">#</a></h2>
<p>Julian Bär</p>
<p>Published 2024-02-28</p>
<p>Licensed CC-BY-4.0</p>
<p>Training data for the two StarDist2D models and the DeLTA 2.0 2D tracking model used in the publication on bioarxiv. The trained stardist models are included in the respective zip files of the training data. mm: mother-machine; cc: connected chamber. Each of them contains two folders, img and seg_label. They contain matching pairs of phasecontrast images (img) and label images (seg_label). 
 
tracking_set_subset.zip contains the training data for the DeLTA tracking model following the default folder structure. We used custom weight functions to create the training weight maps in the folder wei. The folder wei_bck contains weights generated with the original function.
The unet_pads_tracking.hdf5 is the retrained tracking model used in the associated publication.
See associated GitHub repository for example code on how to use the models for segmentation and tracking.
The four numbered zip files contain the data used to create all figures displaying image analysis output.
Abstract:
Staphylococcus aureus both colonizes humans and causes severe virulent infections. Virulence is regulated by the agr quorum sensing system and its autoinducing peptide (AIP), with dynamics at the single-cell level across four agr-types – each defined by distinct AIP sequences and capable of cross-inhibition – remaining elusive. Employing microfluidics, time-lapse microscopy, and deep-learning image analysis, we uncovered significant differences in AIP sensitivity among agr-types. We observed bimodal agr activation, attributed to intergenerational phenotypic stability and influenced by AIP concentration. Upon AIP stimulation, agr‑III showed AIP insensitivity, while agr‑II exhibited increased sensitivity and prolonged generation time. Beyond expected cross-inhibition of agr‑I by heterologous AIP‑II and ‑III, the presumably cross-activating AIP‑IV also inhibited agr‑I. Community interactions across different agr-type pairings revealed four main patterns: stable or switched dominance, and delayed or stable dual activation, influenced by community characteristics. These insights underscore the potential of personalized treatment strategies considering virulence and genetic diversity.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/10720439">https://zenodo.org/records/10720439</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10720439">https://doi.org/10.5281/zenodo.10720439</a></p>
</section>
<hr class="docutils" />
<section id="snakemake-documentation">
<h2>Snakemake Documentation<a class="headerlink" href="#snakemake-documentation" title="Link to this heading">#</a></h2>
<p>The Snakemake workflow management system is a tool to create reproducible and scalable data analyses.</p>
<p>Tags: Workflow Engine, Python, Exclude From Dalia</p>
<p>Content type: Documentation</p>
<p><a class="reference external" href="https://snakemake.readthedocs.io/en/stable/">https://snakemake.readthedocs.io/en/stable/</a></p>
<p><a class="reference external" href="https://academic.oup.com/bioinformatics/article/28/19/2520/290322">https://academic.oup.com/bioinformatics/article/28/19/2520/290322</a></p>
</section>
<hr class="docutils" />
<section id="spatialdata-an-open-and-universal-data-framework-for-spatial-omics">
<h2>SpatialData: an open and universal data framework for spatial omics<a class="headerlink" href="#spatialdata-an-open-and-universal-data-framework-for-spatial-omics" title="Link to this heading">#</a></h2>
<p>Luca Marconato, Giovanni Palla, Kevin A Yamauchi, Isaac Virshup, Elyas Heidari, Tim Treis, Marcella Toth, Rahul Shrestha, Harald Vöhringer, Wolfgang Huber, Moritz Gerstung, Josh Moore, Fabian J Theis, Oliver Stegle</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Python, Exclude From Dalia</p>
<p>Content type: Publication, Preprint</p>
<p><a class="reference external" href="https://www.biorxiv.org/content/10.1101/2023.05.05.539647v1.abstract">https://www.biorxiv.org/content/10.1101/2023.05.05.539647v1.abstract</a></p>
</section>
<hr class="docutils" />
<section id="stackview-sliceplot-example-data">
<h2>Stackview sliceplot example data<a class="headerlink" href="#stackview-sliceplot-example-data" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-11-03</p>
<p>Licensed CC-BY-4.0</p>
<p>This is a dataset of PNG images of <a class="reference external" href="https://zenodo.org/records/12623730">Bio-Image Data Science teaching slides</a>. The png_umap.yml file contains a list of all images and a dimensionality reduced embedding (Uniform Manifold Approximation Projection, UMAP) made using OpenAI’s text-embedding-ada-002 model.
A notebook for visualizing this data is published here: <a class="github reference external" href="https://github.com/haesleinhuepf/stackview/blob/main/docs/sliceplot.ipynb">haesleinhuepf/stackview</a></p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14030307">https://zenodo.org/records/14030307</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14030307">https://doi.org/10.5281/zenodo.14030307</a></p>
</section>
<hr class="docutils" />
<section id="standard-and-super-resolution-bioimaging-data-analysis-a-primer">
<h2>Standard and Super-Resolution Bioimaging Data Analysis: A Primer<a class="headerlink" href="#standard-and-super-resolution-bioimaging-data-analysis-a-primer" title="Link to this heading">#</a></h2>
<p>Ann Wheeler (Editor), Ricardo Henriques (Editor)</p>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Book</p>
<p><a class="reference external" href="https://www.wiley.com/en-us/Standard+and+Super+Resolution+Bioimaging+Data+Analysis%3A+A+Primer-p-9781119096900">https://www.wiley.com/en-us/Standard+and+Super+Resolution+Bioimaging+Data+Analysis%3A+A+Primer-p-9781119096900</a></p>
</section>
<hr class="docutils" />
<section id="stardist-adipocyte-segmentation-training-data-training-notebook-and-model">
<h2>StarDist Adipocyte Segmentation Training data, Training Notebook and Model<a class="headerlink" href="#stardist-adipocyte-segmentation-training-data-training-notebook-and-model" title="Link to this heading">#</a></h2>
<p>Sarkis Rita, Naveiras Olaia, Burri Olivier, Weigert Martin, De Leval Laurence</p>
<p>Published 2022-08-17</p>
<p>Licensed CC-BY-4.0</p>
<p>Data from H&amp;E human bone marrow whole slide scanner images used in the paper: “MarrowQuant 2.0: a digital pathology workflow assisting bone marrow evaluation in clinical and experimental hematology” (<a class="reference external" href="https://doi.org/10.21203/rs.3.rs-1860140/v1">https://doi.org/10.21203/rs.3.rs-1860140/v1</a>)</p>
<p> </p>
<p>292 image patches</p>
<p>Ground truth were manually annotated using QuPath and split into 263 images for training and 29 for validation.</p>
<p>Training in StarDist was done on a Windows 10 PC with an RTX 2080 GPU. The requirements file for installing a Python 3.7 environment to run the attached notebooks is provided (stardist-val.txt).</p>
<p>The StarDist model configuration can be found in the Jupyter Notebook :</p>
<p>Adipocyte Training.ipynb</p>
<p>Model validation and metrics can be performed by running the notebook after finishing the Adipocyte Training notebook.</p>
<p>Quality Control.ipynb</p>
<p> </p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/7003909">https://zenodo.org/records/7003909</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7003909">https://doi.org/10.5281/zenodo.7003909</a></p>
</section>
<hr class="docutils" />
<section id="stardist-model-and-data-for-the-segmentation-of-yersinia-enterocolitica-cells-in-widefield-images">
<h2>StarDist model and data for the segmentation of Yersinia enterocolitica cells in widefield images<a class="headerlink" href="#stardist-model-and-data-for-the-segmentation-of-yersinia-enterocolitica-cells-in-widefield-images" title="Link to this heading">#</a></h2>
<p>Christoph Spahn, Andreas Diepold, Francesca Ermoli</p>
<p>Published 2024-05-02</p>
<p>Licensed CC-BY-4.0</p>
<p>Dataset and StarDist model for the segmentation of Yersinia enterocolitica cells
This dataset and StarDist model are part of the publication “Active downregulation of the type III secretion system at higher local cell densities promotes Yersinia replication and dissemination”.
It contains the dataset that was used for training the provided StarDist model using ZeroCostDL4Mic.
Data:
Yersinia enterocolitica cells were spotted on an agarose pad (1.5% low melting agarose (Sigma-Aldrich) in minimal medium, 1% Casamino acids, 5 mM EGTA,  glass depression slides (Marienfeld)). For imaging, a Deltavision Elite Optical Sectioning Microscope equipped with a UPlanSApo 100×/1.40 oil objective (Olympus) and an EDGE sCMOS_5.5 camera (Photometrics) was used. Z-stacks with 9 slices (∆z = 0.15 µm) per fluorescence channel were acquired and  5 slices were selected for network training. Images were annotated in Fiji using the Freehand selection tool, and brightlight and mask images were quartered to obtain the final dataset of 300 paired images. 260 images were used for training, while 40 images were used to test model performance.
Model:
The StarDist 2D model was trained from scratch for 100 epochs on 300 paired image patches (image dimensions: (480 x 480 px²), patch size: (480 x 480 px²)) with a batch size of 4 and a mae loss function, using the StarDist 2D ZeroCostDL4Mic notebook (v 1) (von Chamier &amp; Laine et al., 2020). Grid parameter was set to 2 and the number of rays to 120. The model was trained with an initial learning rate of 0.0003 using a 80/20 train/test split. The dataset was augmented 4-fold by flipping and rotation.
Key python packages used include tensorflow (v 0.1.12), Keras (v2.3.1), csbdeep (v 0.7.2), numpy (v 1.21.6), cuda (v 11.1.105Build cuda_11.1.TC455_06.29190527_0). The training was accelerated using a Tesla T4 GPU.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/11105050">https://zenodo.org/records/11105050</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11105050">https://doi.org/10.5281/zenodo.11105050</a></p>
</section>
<hr class="docutils" />
<section id="stardist-aspc1-lifeact">
<h2>StarDist_AsPC1_Lifeact<a class="headerlink" href="#stardist-aspc1-lifeact" title="Link to this heading">#</a></h2>
<p>Gautier Follain, Sujan Ghimire, Joanna Pylvänäinen, Johanna Ivaska, Guillaume Jacquemet</p>
<p>Published 2024-08-29</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository includes a StarDist deep learning model designed for segmenting AsPC1 cells labeled with Lifeact from fluorescence microscopy images. The model distinguishes individual AsPC1 cells within clusters and separates them from the background. The model was trained on a small dataset and achieved an Intersection over Union (IoU) score of 0.884 and an F1 Score of 0.967, indicating high accuracy in cell segmentation.
Specifications</p>
<p>Model: StarDist for segmenting AsPC1 cells in fluorescence microscopy images</p>
<p>Training Dataset:</p>
<p>Number of Images: 10 paired fluorescence microscopy images and label masks</p>
<p>Microscope: Spinning disk confocal microscope (3i CSU-W1) with a 20x objective, NA 0.8</p>
<p>Data Type: Fluorescence microscopy images of the AsPC1 Lifeact channel with manually segmented masks</p>
<p>File Format: TIFF (.tif)</p>
<p>Fluorescence Images: 16-bit</p>
<p>Masks: 8-bit</p>
<p>Image Size: 1024 x 1024 pixels (Pixel size: 0.6337 x 0.6337 µm²)</p>
<p>Model Capabilities:</p>
<p>Segment AsPC1 Cells: Detects individual AsPC1 cells from a cluster and separates them from the background</p>
<p>Measure Intensity: Enables measurement of CD44, ICAM1, ICAM2, or Fibronectin intensity under individual cells in respective channels</p>
<p>Performance:</p>
<p>Average IoU: 0.884</p>
<p>Average F1 Score: 0.967</p>
<p>Model Training: Conducted using ZeroCostDL4Mic (<a class="github reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki">HenriquesLab/ZeroCostDL4Mic</a>)</p>
<p>Reference
Fast label-free live imaging reveals key roles of flow dynamics and CD44-HA interaction in cancer cell arrest on endothelial monolayers</p>
<p>Gautier Follain, Sujan Ghimire, Joanna W. Pylvänäinen, Monika Vaitkevičiūtė, Diana Wurzinger, Camilo Guzmán, James RW Conway, Michal Dibus, Sanna Oikari, Kirsi Rilla, Marko Salmi, Johanna Ivaska, Guillaume Jacquemet
bioRxiv 2024.09.30.615654; doi: <a class="reference external" href="https://doi.org/10.1101/2024.09.30.615654">https://doi.org/10.1101/2024.09.30.615654</a>
 </p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/13442128">https://zenodo.org/records/13442128</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13442128">https://doi.org/10.5281/zenodo.13442128</a></p>
</section>
<hr class="docutils" />
<section id="stardist-bf-monocytes-dataset">
<h2>StarDist_BF_Monocytes_dataset<a class="headerlink" href="#stardist-bf-monocytes-dataset" title="Link to this heading">#</a></h2>
<p>Gautier Follain, Sujan Ghimire, Joanna Pylvänäinen, Johanna Ivaska, Guillaume Jacquemet</p>
<p>Published 2024-01-26</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository includes a StarDist deep learning model and its training and validation datasets for detecting mononucleated cells perfused over an endothelial cell monolayer. The model was trained on 27 manually annotated images and achieved an average F1 Score of 0.941. The dataset and model are helpful for biomedical research, especially in studying interactions between mononucleated and endothelial cells.
Specifications</p>
<p>Model: StarDist for mononucleated cell detection on endothelial cells</p>
<p>Training Dataset:</p>
<p>Number of Images: 27 paired brightfield microscopy images and label masks</p>
<p>Microscope: Nikon Eclipse Ti2-E, 20x objective</p>
<p>Data Type: Brightfield microscopy images with manually segmented masks</p>
<p>File Format: TIFF (.tif)</p>
<p>Brightfield Images: 16-bit</p>
<p>Masks: 8-bit</p>
<p>Image Size: 1024 x 1022 pixels (Pixel size: 650 nm)</p>
<p>Training Parameters:</p>
<p>Epochs: 400</p>
<p>Patch Size: 992 x 992 pixels</p>
<p>Batch Size: 2</p>
<p>Performance:</p>
<p>Average F1 Score: 0.941</p>
<p>Average IoU: 0.831</p>
<p>Model Training: Conducted using ZeroCostDL4Mic (<a class="github reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki">HenriquesLab/ZeroCostDL4Mic</a>)</p>
<p>Reference
Fast label-free live imaging reveals key roles of flow dynamics and CD44-HA interaction in cancer cell arrest on endothelial monolayers
Gautier Follain, Sujan Ghimire, Joanna W. Pylvänäinen, Monika Vaitkevičiūtė, Diana Wurzinger, Camilo Guzmán, James RW Conway, Michal Dibus, Sanna Oikari, Kirsi Rilla, Marko Salmi, Johanna Ivaska, Guillaume Jacquemet
bioRxiv 2024.09.30.615654; doi: <a class="reference external" href="https://doi.org/10.1101/2024.09.30.615654">https://doi.org/10.1101/2024.09.30.615654</a></p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/10572200">https://zenodo.org/records/10572200</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10572200">https://doi.org/10.5281/zenodo.10572200</a></p>
</section>
<hr class="docutils" />
<section id="stardist-bf-neutrophil-dataset">
<h2>StarDist_BF_Neutrophil_dataset<a class="headerlink" href="#stardist-bf-neutrophil-dataset" title="Link to this heading">#</a></h2>
<p>Gautier Follain, Sujan Ghimire, Joanna Pylvänäinen, Johanna Ivaska, Guillaume Jacquemet</p>
<p>Published 2024-01-26</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository includes a StarDist deep learning model and its training and validation datasets for detecting neutrophils perfused over an endothelial cell monolayer. The model was trained on 36 manually annotated images, achieving an average F1 Score of 0.969. The dataset and model are intended for use in biomedical research, particularly for analyzing interactions between neutrophils and endothelial cells.
Specifications</p>
<p>Model: StarDist for neutrophil detection on endothelial cells</p>
<p>Training Dataset:</p>
<p>Number of Images: 36 paired brightfield microscopy images and label masks</p>
<p>Microscope: Nikon Eclipse Ti2-E, 20x objective</p>
<p>Data Type: Brightfield microscopy images with manually segmented masks</p>
<p>File Format: TIFF (.tif)</p>
<p>Brightfield Images: 16-bit</p>
<p>Masks: 8-bit</p>
<p>Image Size: 1024 x 1022 pixels (Pixel size: 650 nm)</p>
<p>Training Parameters:</p>
<p>Epochs: 400</p>
<p>Patch Size: 992 x 992 pixels</p>
<p>Batch Size: 2</p>
<p>Performance:</p>
<p>Average F1 Score: 0.969</p>
<p>Average IoU: 0.914</p>
<p>Model Training: Conducted using ZeroCostDL4Mic (<a class="github reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki">HenriquesLab/ZeroCostDL4Mic</a>)</p>
<p>Reference
Fast label-free live imaging reveals key roles of flow dynamics and CD44-HA interaction in cancer cell arrest on endothelial monolayers</p>
<p>Gautier Follain, Sujan Ghimire, Joanna W. Pylvänäinen, Monika Vaitkevičiūtė, Diana Wurzinger, Camilo Guzmán, James RW Conway, Michal Dibus, Sanna Oikari, Kirsi Rilla, Marko Salmi, Johanna Ivaska, Guillaume Jacquemet
bioRxiv 2024.09.30.615654; doi: <a class="reference external" href="https://doi.org/10.1101/2024.09.30.615654">https://doi.org/10.1101/2024.09.30.615654</a></p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/10572231">https://zenodo.org/records/10572231</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10572231">https://doi.org/10.5281/zenodo.10572231</a></p>
</section>
<hr class="docutils" />
<section id="stardist-bf-cancer-cell-dataset-10x">
<h2>StarDist_BF_cancer_cell_dataset_10x<a class="headerlink" href="#stardist-bf-cancer-cell-dataset-10x" title="Link to this heading">#</a></h2>
<p>Gautier Follain, Sujan Ghimire, Joanna Pylvänäinen, Johanna Ivaska, Guillaume Jacquemet</p>
<p>Published 2024-08-12</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository includes a StarDist deep learning model and its training dataset designed for segmenting cancer cells perfused over an endothelial cell monolayer captured at 10x magnification. The model was trained on 77 manually annotated images, with the dataset being computationally augmented during training by a factor of 8. The model was trained for 500 epochs and achieved an average F1 Score of 0.968, indicating high accuracy in segmenting cancer cells on endothelial cells.
Specifications</p>
<p>Model: StarDist for cancer cell segmentation on endothelial cells (10x magnification)</p>
<p>Training Dataset:</p>
<p>Number of Images: 77 paired brightfield microscopy images and label masks</p>
<p>Augmented Dataset: Computational augmentation by a factor of 8 during training</p>
<p>Microscope: Nikon Eclipse Ti2-E, 10x objective</p>
<p>Data Type: Brightfield microscopy images with manually segmented masks</p>
<p>File Format: TIFF (.tif)</p>
<p>Brightfield Images: 16-bit</p>
<p>Masks: 8-bit or 16-bit</p>
<p>Image Size: 1024 x 1022 pixels (pixel size: 1.3148 μm)</p>
<p>Training Parameters:</p>
<p>Epochs: 500</p>
<p>Patch Size: 992 x 992 pixels</p>
<p>Batch Size: 2</p>
<p>Performance:</p>
<p>Average F1 Score: 0.968</p>
<p>Average IoU: 0.882</p>
<p>Model Training: Conducted using ZeroCostDL4Mic (<a class="github reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki">HenriquesLab/ZeroCostDL4Mic</a>)</p>
<p>Reference
Fast label-free live imaging reveals key roles of flow dynamics and CD44-HA interaction in cancer cell arrest on endothelial monolayers</p>
<p>Gautier Follain, Sujan Ghimire, Joanna W. Pylvänäinen, Monika Vaitkevičiūtė, Diana Wurzinger, Camilo Guzmán, James RW Conway, Michal Dibus, Sanna Oikari, Kirsi Rilla, Marko Salmi, Johanna Ivaska, Guillaume Jacquemet
bioRxiv 2024.09.30.615654; doi: <a class="reference external" href="https://doi.org/10.1101/2024.09.30.615654">https://doi.org/10.1101/2024.09.30.615654</a></p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/13304399">https://zenodo.org/records/13304399</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13304399">https://doi.org/10.5281/zenodo.13304399</a></p>
</section>
<hr class="docutils" />
<section id="stardist-bf-cancer-cell-dataset-20x">
<h2>StarDist_BF_cancer_cell_dataset_20x<a class="headerlink" href="#stardist-bf-cancer-cell-dataset-20x" title="Link to this heading">#</a></h2>
<p>Gautier Follain, Sujan Ghimire, Joanna Pylvänäinen, Johanna Ivaska, Guillaume Jacquemet</p>
<p>Published 2024-01-26</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository contains a StarDist deep learning model and its training and validation datasets designed for segmenting cancer cells perfused over an endothelial cell monolayer captured at 20x magnification. Using computational methods, the initial dataset of 20 manually annotated images was augmented to 160 paired images. The model was trained over 400 epochs and achieved an average F1 Score of 0.921, demonstrating high accuracy in cell segmentation tasks.
Specifications</p>
<p>Model: StarDist for cancer cell segmentation on endothelial cells (20x magnification)</p>
<p>Training Dataset:</p>
<p>Number of Original Images: 20 paired brightfield microscopy images and label masks</p>
<p>Microscope: Nikon Eclipse Ti2-E, 20x objective</p>
<p>Data Type: Brightfield microscopy images with manually segmented masks</p>
<p>File Format: TIFF (.tif)</p>
<p>Brightfield Images: 16-bit</p>
<p>Masks: 8-bit</p>
<p>Image Size: 1024 x 1022 pixels (Pixel size: 650 nm)</p>
<p>Training Parameters:</p>
<p>Epochs: 400</p>
<p>Patch Size: 992 x 992 pixels</p>
<p>Batch Size: 2</p>
<p>Performance:</p>
<p>Average F1 Score: 0.921</p>
<p>Average IoU: 0.793</p>
<p>Model Training: Conducted using ZeroCostDL4Mic (<a class="github reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki">HenriquesLab/ZeroCostDL4Mic</a>)</p>
<p> </p>
<p>Reference
Fast label-free live imaging reveals key roles of flow dynamics and CD44-HA interaction in cancer cell arrest on endothelial monolayers</p>
<p>Gautier Follain, Sujan Ghimire, Joanna W. Pylvänäinen, Monika Vaitkevičiūtė, Diana Wurzinger, Camilo Guzmán, James RW Conway, Michal Dibus, Sanna Oikari, Kirsi Rilla, Marko Salmi, Johanna Ivaska, Guillaume Jacquemet
bioRxiv 2024.09.30.615654; doi: <a class="reference external" href="https://doi.org/10.1101/2024.09.30.615654">https://doi.org/10.1101/2024.09.30.615654</a></p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/10572122">https://zenodo.org/records/10572122</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10572122">https://doi.org/10.5281/zenodo.10572122</a></p>
</section>
<hr class="docutils" />
<section id="stardist-fluorescent-cells">
<h2>StarDist_Fluorescent_cells<a class="headerlink" href="#stardist-fluorescent-cells" title="Link to this heading">#</a></h2>
<p>Gautier Follain, Sujan Ghimire, Joanna Pylvänäinen, Johanna Ivaska, Guillaume Jacquemet</p>
<p>Published 2024-01-26</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository includes a StarDist deep learning model and its training and validation datasets for detecting fluorescently labeled cancer cells perfused over an endothelial cell monolayer. The model was trained on 66 images labeled with CellTrace and demonstrated high accuracy, achieving an average F1 Score of 0.877. The dataset and the trained model can be used for biomedical image analysis, particularly in cancer research.
Specifications</p>
<p>Model: StarDist for cancer cell detection</p>
<p>Training Dataset:</p>
<p>Number of Images: 66 paired fluorescent microscopy images and label masks</p>
<p>Microscope: Nikon Eclipse Ti2-E, 10x objective</p>
<p>Data Type: Fluorescent microscopy images with manually segmented masks</p>
<p>File Format: TIFF (.tif)</p>
<p>Brightfield Images: 16-bit</p>
<p>Masks: 8-bit</p>
<p>Image Size: 1024 x 1024 pixels (Pixel size: 1.3205 μm)</p>
<p>Training Parameters:</p>
<p>Epochs: 200</p>
<p>Patch Size: 1024 x 1024 pixels</p>
<p>Batch Size: 2</p>
<p>Performance:</p>
<p>Average F1 Score: 0.877</p>
<p>Average IoU: 0.646</p>
<p>Model Training: Conducted using ZeroCostDL4Mic (<a class="github reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki">HenriquesLab/ZeroCostDL4Mic</a>)</p>
<p>Reference
Fast label-free live imaging reveals key roles of flow dynamics and CD44-HA interaction in cancer cell arrest on endothelial monolayers</p>
<p>Gautier Follain, Sujan Ghimire, Joanna W. Pylvänäinen, Monika Vaitkevičiūtė, Diana Wurzinger, Camilo Guzmán, James RW Conway, Michal Dibus, Sanna Oikari, Kirsi Rilla, Marko Salmi, Johanna Ivaska, Guillaume Jacquemet
bioRxiv 2024.09.30.615654; doi: <a class="reference external" href="https://doi.org/10.1101/2024.09.30.615654">https://doi.org/10.1101/2024.09.30.615654</a></p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/10572310">https://zenodo.org/records/10572310</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10572310">https://doi.org/10.5281/zenodo.10572310</a></p>
</section>
<hr class="docutils" />
<section id="stardist-huvec-nuclei-dataset">
<h2>StarDist_HUVEC_nuclei_dataset<a class="headerlink" href="#stardist-huvec-nuclei-dataset" title="Link to this heading">#</a></h2>
<p>Gautier Follain, Sujan Ghimire, Joanna Pylvänäinen, Johanna Ivaska, Guillaume Jacquemet</p>
<p>Published 2024-02-05</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository contains a StarDist deep learning model and its training and validation datasets for segmenting endothelial nuclei while ignoring cancer cells. The cancer cells were perfused over an endothelial cell monolayer. The initial dataset consisted of 17 images, where cancer cell nuclei were manually removed after segmentation with the StarDist Versatile Nuclei model. This dataset was augmented to 68 paired images using computational techniques like rotation and flipping. The model was trained for 200 epochs, achieving an average F1 Score of 0.976, demonstrating high accuracy in segmenting endothelial nuclei while excluding cancer cells.
Specifications</p>
<p>Model: StarDist for segmenting endothelial nuclei while ignoring cancer cells</p>
<p>Training Dataset:</p>
<p>Number of Original Images: 17 paired predictions of nuclei and label images</p>
<p>Augmented Dataset: Expanded to 68 paired images using rotation and flipping</p>
<p>Source Image Generation: Generated using a pix2pix model trained to predict nuclei from brightfield images of cancer cells on top of an endothelium (DOI: 10.5281/zenodo.10617532)</p>
<p>Target Image Generation: Masks obtained via manual segmentation</p>
<p>File Format: TIFF (.tif)</p>
<p>Brightfield Images: 8-bit</p>
<p>Masks: 8-bit</p>
<p>Image Size: 1024 x 1022 pixels (uncalibrated)</p>
<p>Training Parameters:</p>
<p>Epochs: 200</p>
<p>Patch Size: 1024 x 1024 pixels</p>
<p>Batch Size: 2</p>
<p>Performance:</p>
<p>Average F1 Score: 0.976</p>
<p>Average IoU: 0.927</p>
<p>Model Training: Conducted using ZeroCostDL4Mic (<a class="github reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki">HenriquesLab/ZeroCostDL4Mic</a>)</p>
<p>Reference
Fast label-free live imaging reveals key roles of flow dynamics and CD44-HA interaction in cancer cell arrest on endothelial monolayers</p>
<p>Gautier Follain, Sujan Ghimire, Joanna W. Pylvänäinen, Monika Vaitkevičiūtė, Diana Wurzinger, Camilo Guzmán, James RW Conway, Michal Dibus, Sanna Oikari, Kirsi Rilla, Marko Salmi, Johanna Ivaska, Guillaume Jacquemet
bioRxiv 2024.09.30.615654; doi: <a class="reference external" href="https://doi.org/10.1101/2024.09.30.615654">https://doi.org/10.1101/2024.09.30.615654</a></p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/10617532">https://zenodo.org/records/10617532</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10617532">https://doi.org/10.5281/zenodo.10617532</a></p>
</section>
<hr class="docutils" />
<section id="stardist-tumorcell-nuclei">
<h2>StarDist_TumorCell_nuclei<a class="headerlink" href="#stardist-tumorcell-nuclei" title="Link to this heading">#</a></h2>
<p>Gautier Follain, Sujan Ghimire, Joanna Pylvänäinen, Johanna Ivaska, Guillaume Jacquemet</p>
<p>Published 2024-08-29</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository contains a StarDist deep learning model designed for segmenting tumor cell nuclei from the DAPI channel in fluorescence microscopy images while excluding HUVEC nuclei. The model was trained to accurately detect individual tumor cell nuclei for subsequent measurement of CD44, ICAM1, ICAM2, or Fibronectin intensity around or under the nuclei. The model achieved an Intersection over Union (IoU) score of 0.558 and an F1 Score of 0.793, reflecting its capability to distinguish tumor cell nuclei from HUVEC nuclei.
Specifications</p>
<p>Model: StarDist for segmenting tumor cell nuclei from the DAPI fluorescence channel</p>
<p>Training Dataset:</p>
<p>Number of Images: 48 paired fluorescence microscopy images and label masks</p>
<p>Microscope: Spinning disk confocal microscope (3i CSU-W1) with a 20x objective, NA 0.8</p>
<p>Data Type: Fluorescence microscopy images of the DAPI channel with manually segmented masks</p>
<p>File Format: TIFF (.tif)</p>
<p>Fluorescence Images: 16-bit</p>
<p>Masks: 8-bit</p>
<p>Image Size: 920 x 920 pixels (Pixel size: 0.6337 x 0.6337 µm²)</p>
<p>Model Capabilities:</p>
<p>Segment Tumor Cell Nuclei: Detects individual tumor cell nuclei in the DAPI channel while distinguishing them from HUVEC nuclei</p>
<p>Measure Intensity: Enables measurement of CD44, ICAM1, ICAM2, or Fibronectin intensity around or under tumor cell nuclei in respective channels</p>
<p>Performance:</p>
<p>Average IoU: 0.558</p>
<p>Average F1 Score: 0.793</p>
<p>Model Training: Conducted using ZeroCostDL4Mic (<a class="github reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki">HenriquesLab/ZeroCostDL4Mic</a>)</p>
<p>Reference
Fast label-free live imaging reveals key roles of flow dynamics and CD44-HA interaction in cancer cell arrest on endothelial monolayers</p>
<p>Gautier Follain, Sujan Ghimire, Joanna W. Pylvänäinen, Monika Vaitkevičiūtė, Diana Wurzinger, Camilo Guzmán, James RW Conway, Michal Dibus, Sanna Oikari, Kirsi Rilla, Marko Salmi, Johanna Ivaska, Guillaume Jacquemet
bioRxiv 2024.09.30.615654; doi: <a class="reference external" href="https://doi.org/10.1101/2024.09.30.615654">https://doi.org/10.1101/2024.09.30.615654</a>
 </p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/13443221">https://zenodo.org/records/13443221</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13443221">https://doi.org/10.5281/zenodo.13443221</a></p>
</section>
<hr class="docutils" />
<section id="stardist-model-and-training-dataset-for-automated-tracking-of-mda-mb-231-and-bt20-cells">
<h2>Stardist model and training dataset for automated tracking of MDA-MB-231 and BT20 cells<a class="headerlink" href="#stardist-model-and-training-dataset-for-automated-tracking-of-mda-mb-231-and-bt20-cells" title="Link to this heading">#</a></h2>
<p>Hussein Al-Akhrass, Johanna Ivaska, Guillaume Jacquemet</p>
<p>Published 2021-05-26</p>
<p>Licensed CC-BY-4.0</p>
<p>StarDist Model:
The StarDist model was generated using the ZeroCostDL4Mic platform (Chamier et al., 2021). This custom StarDist model was trained for 300 epochs using 46 manually annotated paired images (image dimensions: (1024, 1024)) with a batch size of 2, an augmentation factor of 4 and a mae loss function. The StarDist “Versatile fluorescent nuclei” model was used as a training starting point. Key python packages used include TensorFlow (v 0.1.12), Keras (v 2.3.1), CSBdeep (v 0.6.1), NumPy (v 1.19.5), Cuda (v 11.0.221). The training was accelerated using a Tesla P100GPU.
The model weights can be used in the ZeroCostDL4Mic StarDist 2D notebook or in the StarDist Fiji plugin.</p>
<p>StarDist Training dataset:
Paired microscopy images (fluorescence) and corresponding masks</p>
<p>Microscopy data type: Fluorescence microscopy (SiR-DNA) and masks obtained via manual segmentation (see <a class="github reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki/Stardist">HenriquesLab/ZeroCostDL4Mic</a> for details about the segmentation)</p>
<p>Cells were imaged using a 20x Nikon CFI Plan Apo Lambda objective (NA 0.75) one frame every 10 minutes for 16h.</p>
<p>Cell type: MDA-MB-231 cells and BT20 cells</p>
<p>File format: .tif (16-bit for fluorescence and 8 and 16-bit for the masks)</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/4811213">https://zenodo.org/records/4811213</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.4811213">https://doi.org/10.5281/zenodo.4811213</a></p>
</section>
<hr class="docutils" />
<section id="stardist-miapaca2-from-cd44">
<h2>Stardist_MiaPaCa2_from_CD44<a class="headerlink" href="#stardist-miapaca2-from-cd44" title="Link to this heading">#</a></h2>
<p>Gautier Follain, Sujan Ghimire, Joanna Pylvänäinen, Johanna Ivaska, Guillaume Jacquemet</p>
<p>Published 2024-08-29</p>
<p>Licensed CC-BY-4.0</p>
<p>This repository contains a StarDist deep learning model designed for segmenting MiaPaCa2 cells from the CD44 channel in fluorescence microscopy images. The model is capable of accurately segmenting individual MiaPaCa2 cells while excluding HUVECs. Trained on a small dataset, the model achieved an Intersection over Union (IoU) score of 0.884 and an F1 Score of 0.950, indicating high precision in cell segmentation.
Specifications</p>
<p>Model: StarDist for segmenting MiaPaCa2 cells from the CD44 fluorescence channel</p>
<p>Training Dataset:</p>
<p>Number of Images: 8 paired fluorescence microscopy images and label masks</p>
<p>Microscope: Spinning disk confocal microscope (3i CSU-W1) with a 20x objective, NA 0.8</p>
<p>Data Type: Fluorescence microscopy images of the CD44 channel, obtained after immunofluorescence staining with primary and secondary antibodies and manually segmented masks</p>
<p>File Format: TIFF (.tif)</p>
<p>Fluorescence Images: 16-bit</p>
<p>Masks: 8-bit</p>
<p>Image Size: 920 x 920 pixels (Pixel size: 0.6337 x 0.6337 µm²)</p>
<p>Model Capabilities:</p>
<p>Segment MiaPaCa2 Cells: Accurately detects individual MiaPaCa2 cells while ignoring HUVECs</p>
<p>Measure CD44 Intensity: Allows for the measurement of CD44 intensity around MiaPaCa2 cells, specifically from the CD44 channel</p>
<p>Performance:</p>
<p>Average IoU: 0.884</p>
<p>Average F1 Score: 0.950</p>
<p>Model Training: Conducted using ZeroCostDL4Mic (<a class="github reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki">HenriquesLab/ZeroCostDL4Mic</a>)</p>
<p>Reference
Fast label-free live imaging reveals key roles of flow dynamics and CD44-HA interaction in cancer cell arrest on endothelial monolayers</p>
<p>Gautier Follain, Sujan Ghimire, Joanna W. Pylvänäinen, Monika Vaitkevičiūtė, Diana Wurzinger, Camilo Guzmán, James RW Conway, Michal Dibus, Sanna Oikari, Kirsi Rilla, Marko Salmi, Johanna Ivaska, Guillaume Jacquemet
bioRxiv 2024.09.30.615654; doi: <a class="reference external" href="https://doi.org/10.1101/2024.09.30.615654">https://doi.org/10.1101/2024.09.30.615654</a></p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/13442877">https://zenodo.org/records/13442877</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13442877">https://doi.org/10.5281/zenodo.13442877</a></p>
</section>
<hr class="docutils" />
<section id="statistical-rethinking">
<h2>Statistical Rethinking<a class="headerlink" href="#statistical-rethinking" title="Link to this heading">#</a></h2>
<p>Richard McElreath</p>
<p>Published 2024-03-01</p>
<p>Licensed CC0-1.0</p>
<p>This course teaches data analysis, but it focuses on scientific models. The unfortunate truth about data is that nothing much can be done with it, until we say what caused it. We will prioritize conceptual, causal models and precise questions about those models. We will use Bayesian data analysis to connect scientific models to evidence. And we will learn powerful computational tools for coping with high-dimension, imperfect data of the kind that biologists and social scientists face.</p>
<p>Tags: Statistics, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/rmcelreath/stat_rethinking_2024">rmcelreath/stat_rethinking_2024</a></p>
</section>
<hr class="docutils" />
<section id="studentsourcing-aggregating-and-re-using-data-from-a-practical-cell-biology-course">
<h2>Studentsourcing - aggregating and re-using data from a practical cell biology course<a class="headerlink" href="#studentsourcing-aggregating-and-re-using-data-from-a-practical-cell-biology-course" title="Link to this heading">#</a></h2>
<p>Joachim Goedhart</p>
<p>Tags: Sharing, Exclude From Dalia</p>
<p>Content type: Preprint</p>
<p><a class="reference external" href="https://www.biorxiv.org/content/10.1101/2023.10.09.561479v1">https://www.biorxiv.org/content/10.1101/2023.10.09.561479v1</a></p>
</section>
<hr class="docutils" />
<section id="submitting-data-to-the-bioimage-archive">
<h2>Submitting data to the BioImage Archive<a class="headerlink" href="#submitting-data-to-the-bioimage-archive" title="Link to this heading">#</a></h2>
<p>Licensed CC0-1.0</p>
<p>To submit, you’ll need to register an account, organise and upload your data, prepare a file list, and then submit using our web submission form. These steps are explained here.</p>
<p>Tags: Research Data Management, Exclude From Dalia</p>
<p>Content type: Tutorial, Video</p>
<p><a class="reference external" href="https://www.ebi.ac.uk/bioimage-archive/submit/">https://www.ebi.ac.uk/bioimage-archive/submit/</a></p>
</section>
<hr class="docutils" />
<section id="synapsenet-training-data">
<h2>SynapseNet Training Data<a class="headerlink" href="#synapsenet-training-data" title="Link to this heading">#</a></h2>
<p>Constantin Pape</p>
<p>Published 2024-12-01</p>
<p>Licensed CC-BY-4.0</p>
<p>This dataset contains room-temperature single-axis TEM tomograms from Schaffer collateral and mossy fiber synapses in organotypic hippocampal slices. The tomograms were published in the two studies [1, 2]. The data was re-used for training deep neural networks to segment different synaptic structures in electron micrographs in [3]. For the tomograms, organotypic slices were prepared from the hippocampi of neonatal mice according to the interface protocol55 and vitrified after 28 days in vitro in culture medium supplemented with 20% (w/v) bovine serum albumin using an HPM100 (Leica) high-pressure freezing device. The dataset also contains 23 tomograms resulting from chemically-fixed material, which were also published in (Maus et al., 2020). For these tomograms, wild-type animals at postnatal day 28 were transcardially perfused under deep anesthesia, first with 0.9% sodium chloride solution, and then one of two fixatives (Fixative 1: Ice-cold 4% paraformaldehyde, 2.5% glutaraldehyde in 0.1 M phosphate buffer16; Fixative 2: 37° C 2% paraformaldehyde, 2.5% glutaraldehyde, 2 mM CaCl2, in 0.1 M cacodylate buffer56). Brains were rinsed and sectioned coronally through the dorsal hippocampus in an ice-cold 0.1 M phosphate buffer using a VT 1200S vibratome (Leica) (step size 100 µm; amplitude 1.5 mm, speed 0.1 mm/sec). Hippocampal CA3 subregions were excised using a 1.5 mm diameter biopsy punch and high-pressure frozen on the same day in 20% (w/v) bovine serum albumin using an HPM100 (Leica) high-pressure freezing device. For both sample preparations, automated freeze-substitution was performed. Tomograms were collected using a 200 kV JEM-2100 (JEOL) transmission electron microscope equipped with an 11 MP Orius SC1000 CCD camera (Gatan). Tilt-series (tilt range +/- 60°; 1° angular increments) were acquired at 30 000x magnification using SerialEM58. Tomographic reconstructions were generated using weighted back-projection with etomo.The data is organized into two different subfolders for data with annotations for “vesicles” and “active_zones”. Each of these subfolders is further subdivided into “train” and “test” folders, which containtomograms for the two different sample preparations in “chemical_fixation” and “single_axis_tem”.Each tomogram and the corresponding annotation is stored as a hdf5 file, containing the following internal datasets:- raw: The tomogram data.- labels/vesicles: Annotations for the synaptic vesicles, annotated with IMOD, further postprocessed and then exported to instance masks. (for tomograms in “vesicles”)- labels/AZ: Annotations for the active zone, annotated with IMOD and exported to binary masks.
[1] Imig et al., The Morphological and Molecular Nature of Synaptic Vesicle Priming at Presynaptic Active Zones, Neuron, 2014, DOI:10.1016/j.neuron.2014.10.009[2] Maus et al., Ultrastructural Correlates of Presynaptic Functional Heterogeneity in Hippocampal Synapses, Cell Reports, 2020, DOI: 10.1016/j.celrep.2020.02.083[3] Muth, Moschref et al., 2024, Preprint to be published</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/14330011">https://zenodo.org/records/14330011</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14330011">https://doi.org/10.5281/zenodo.14330011</a></p>
</section>
<hr class="docutils" />
<section id="synthetic-cells">
<h2>Synthetic cells<a class="headerlink" href="#synthetic-cells" title="Link to this heading">#</a></h2>
<p>Vebjorn Ljosa, Katherine L. Sokolnicki, Anne E. Carpenter</p>
<p>Published 2012-06-28</p>
<p>Licensed CC-BY-NC-SA-3.0</p>
<p>One of the principal challenges in counting or segmenting nuclei is dealing with clustered nuclei. To help assess algorithms performance in this regard, this synthetic image set consists of five subsets with increasing degree of clustering.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://bbbc.broadinstitute.org/BBBC004">https://bbbc.broadinstitute.org/BBBC004</a></p>
</section>
<hr class="docutils" />
<section id="synthetic-images-and-segmentation-masks-simulating-hl-60-cell-nucleus-in-3d">
<h2>Synthetic images and segmentation masks simulating HL-60 cell nucleus in 3D<a class="headerlink" href="#synthetic-images-and-segmentation-masks-simulating-hl-60-cell-nucleus-in-3d" title="Link to this heading">#</a></h2>
<p>David Svoboda, Michal Kozubek, Stanislav Stejskal, Teresa Zulueta-Coarasa</p>
<p>Published 2024-11-26</p>
<p>Licensed CC-BY-3.0</p>
<p>One of the principal challenges in counting or segmenting nuclei is dealing with clustered nuclei. To help assess algorithms performance in this regard, this synthetic image set consists of four subsets with increasing degree of clustering. Each subset is also provided in two different levels of quality: high SNR and low SNR.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://www.ebi.ac.uk/bioimage-archive/galleries/ai/analysed-dataset/S-BIAD1492/">https://www.ebi.ac.uk/bioimage-archive/galleries/ai/analysed-dataset/S-BIAD1492/</a></p>
</section>
<hr class="docutils" />
<section id="tess-event-database">
<h2>TESS Event database<a class="headerlink" href="#tess-event-database" title="Link to this heading">#</a></h2>
<p>Tags: Bioinformatics, Exclude From Dalia</p>
<p>Content type: Collection, Event</p>
<p><a class="reference external" href="https://tess.elixir-europe.org/events">https://tess.elixir-europe.org/events</a></p>
</section>
<hr class="docutils" />
<section id="tess-training-materials">
<h2>TESS training materials<a class="headerlink" href="#tess-training-materials" title="Link to this heading">#</a></h2>
<p>Licensed UNKNOWN</p>
<p>Tags: Bioinformatics, Exclude From Dalia</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://tess.elixir-europe.org/materials">https://tess.elixir-europe.org/materials</a></p>
</section>
<hr class="docutils" />
<section id="tnbc">
<h2>TNBC<a class="headerlink" href="#tnbc" title="Link to this heading">#</a></h2>
<p>Naylor Peter Jack, Walter Thomas, Laé Marick, Reyal Fabien</p>
<p>Published 2018-02-16</p>
<p>Licensed CC-BY-4.0</p>
<p>Involves an annotated large number of cells, including normal epithelial and myoepithelial breast cells (localized in ducts and lobules), invasive carcinomatous cells, fibroblasts, endothelial cells, adipocytes, macrophages and inflammatory cells (lymphocytes and plasmocytes). In total, our data set consists of 50 images with a total of 4022 annotated cells, the maximum number of cells in one sample is 293 and the minimum number of cells in one sample is 5, with an average of 80 cells per sample and a high standard deviation of 58. The annotation was performed by three experts: an expert pathologist and two trained research fellows. Each sample was annotated by one of the annotators, checked by another one and in case of disagreement, a consensus was established by discussion among the 3 experts.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://paperswithcode.com/dataset/tnbc">https://paperswithcode.com/dataset/tnbc</a></p>
</section>
<hr class="docutils" />
<section id="terminology-service-for-research-data-management-and-knowledge-discovery-in-low-temperature-plasma-physics">
<h2>Terminology service for research data management and knowledge discovery in low-temperature plasma physics<a class="headerlink" href="#terminology-service-for-research-data-management-and-knowledge-discovery-in-low-temperature-plasma-physics" title="Link to this heading">#</a></h2>
<p>Markus M. Becker, Ihda Chaerony Siffa, Roman Baum</p>
<p>Published 2024-12-11</p>
<p>Licensed CC-BY-4.0</p>
<p>Abstract:
Terminology services (TS) [1,2] play a pivotal role in achieving structured metadata by providing controlled vocabularies and ontologies that standardize the description of data. This is a crucial aspect of research data management (RDM) in all scientific disciplines. In addition, TS facilitate the use of a common vocabulary within a scientific community also in a more general context, e.g. to annotate scientific papers, patents or other content for better discoverability, as envisaged by the Open Research Knowledge Graph (ORKG) [3] or the Patents4Science project [4]. 
To make use of these opportunities, terminologies, ontologies and knowledge graphs must be developed and made available as TS where they do not yet exist. This step is currently being taken by the research community in low-temperature plasma (LTP) physics. LTP physics explores partially ionized gases and its technological applications. This vibrant field offers innovative solutions for societal challenges, ranging from developing efficient lighting and solar cells to revolutionizing healthcare through plasma medicine. Various activities and projects have been started in the past years to support the RDM in LTP research and development and to facilitate the application of data-driven research methods. These activities are supported in parts by the NFDI4BIOIMAGE consortium, active work in the NFDI section “(Meta)data, Terminologies, Provenance”, and the basic service Terminology Services 4 NFDI (TS4NFDI) funded by Base4NFDI. 
Recently, the ontology Plasma-O [5–7] for LTP physics has been developed at INP in collaboration with FIZ Karlsruhe – Leibniz Institute for Information Infrastructure, providing a framework for structuring metadata and building a knowledge graph for scientific information within the field. The present contribution will show how a TS utilizing this resource can support different aspects of RDM and knowledge discovery using concrete examples. The application cases include (i) standardizing data annotation: By providing researchers with a controlled vocabulary of LTP-specific terms and their relationships, ensuring consistent and unambiguous data descriptions; (ii) enabling semantic search: Moving beyond keyword-based searches, TS allow for complex queries based on the relationships between concepts, significantly improving data discoverability; (iii) facilitating data integration: By mapping data from different sources to a common ontology, TS enable seamless integration and analysis of heterogeneous datasets, which is crucial for data-driven research and development. The TS Suite of TS4NFDI with the provided widgets [8] fits perfectly to the requirements of these three application cases and will support the harmonization of metadata in LTP physics. The implementation of a public TS is required to provide the domain-specific metadata in a standardized format and will be instrumental in unlocking the full potential of the TS widgets for RDM and knowledge discovery by LTP researchers. Furthermore, the results can provide insights to other domains on how to apply TS to their specific needs.
 The work was supported in parts by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under the National Research Data Infrastructure – [NFDI46/1] – 501864659 and project number 496963457 as well as by the Federal Ministry of Education and Research (BMBF), project number 16KOA013A.
References:</p>
<p>[1]</p>
<p>S. Jupp, T. Burdett, C. Leroy, H. Parkinson, “A new Ontology Lookup Service at EMBL-EBI”, Workshop on Semantic Web Applications and Tools for Life Sciences (2015), <a class="reference external" href="https://ceur-ws.org/Vol-1546/paper_29.pdf">https://ceur-ws.org/Vol-1546/paper_29.pdf</a> (accessed: 2024-09-20).</p>
<p>[2]</p>
<p>P. L. Whetzel, N. F. Noy, N. H. Shah, P. R. Alexander, C. Nyulas, T. Tudorache, M. A. Musen, “BioPortal: enhanced functionality via new Web services from the National Center for Biomedical Ontology to access and use ontologies in software applications”, Nucleic Acids Res. 39 (2011) W541–W545, <a class="reference external" href="https://doi.org/10.1093/nar/gkr469">https://doi.org/10.1093/nar/gkr469</a>.</p>
<p>[3]</p>
<p>Open Research Knowledge Graph, <a class="reference external" href="https://orkg.org/">https://orkg.org/</a> (accessed: 2024-09-20).</p>
<p>[4]</p>
<p>Patents4Science – Establishing an Information Infrastructure for the Use of Patent Knowledge in Science, <a class="reference external" href="https://www.patents4science.org/">https://www.patents4science.org/</a> (accessed: 2024-09-20).</p>
<p>[5]</p>
<p>H. Sack, F. Hoppe, “Verbundprojekt: Qualitätssicherung und Vernetzung von Forschungsdaten in der Plasmatechnologie - QPTDat; Teilvorhaben: Wissensgraph und Ontologieentwicklung zur Vernetzung von Metadaten : Schlussbericht des Teilvorhabens”, 2023, <a class="reference external" href="https://doi.org/10.2314/KXP:1883436974">https://doi.org/10.2314/KXP:1883436974</a>.</p>
<p>[6]</p>
<p>I. Chaerony Siffa, R. Wagner, L. Vilardell Scholten, M. M. Becker, “Semantic Information Management in Low-Temperature Plasma Science and Technology with VIVO”, 2024, preprint, <a class="reference external" href="https://doi.org/10.48550/arXiv.2409.11065">https://doi.org/10.48550/arXiv.2409.11065</a>.</p>
<p>[7]</p>
<p>I. Chaerony Siffa, R. Wagner, L. Vilardell Scholten, M. M. Becker, “Plasma Ontology and Knowledge Graph Initial Release v0.5.0”, 2024, Zenodo, <a class="reference external" href="https://doi.org/10.5281/zenodo.13325226">https://doi.org/10.5281/zenodo.13325226</a>.</p>
<p>[8]</p>
<p>J. Sasse, V. Kneip, R. Baum, P. Zimmermann, J. Darms, J. Schneider, V. Clemens, P. Oladazimi, L. Kühnel, “ts4nfdi/terminology-service-suite: v2.6.0”, 2024, Zenodo, <a class="reference external" href="https://doi.org/10.5281/zenodo.13692297">https://doi.org/10.5281/zenodo.13692297</a>.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14381522">https://zenodo.org/records/14381522</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14381522">https://doi.org/10.5281/zenodo.14381522</a></p>
</section>
<hr class="docutils" />
<section id="tess-search-for-data-life-cycle">
<h2>Tess Search for Data Life Cycle<a class="headerlink" href="#tess-search-for-data-life-cycle" title="Link to this heading">#</a></h2>
<p>Licensed UNKNOWN</p>
<p>Tags: Data Life Cycle, Research Data Management, Exclude From Dalia</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://tess.elixir-europe.org/search?q=data+life+cycle#materials">https://tess.elixir-europe.org/search?q=data+life+cycle#materials</a></p>
</section>
<hr class="docutils" />
<section id="test-dataset-for-whole-slide-image-registration">
<h2>Test Dataset for Whole Slide Image Registration<a class="headerlink" href="#test-dataset-for-whole-slide-image-registration" title="Link to this heading">#</a></h2>
<p>Romain Guiet, Nicolas Chiaruttini</p>
<p>Published 2021-04-12</p>
<p>Licensed CC-BY-4.0</p>
<p>Mouse duodenum fixed in 4% PFA overnight at 4°C, processed for paraffin infiltration using a standard histology procedure and cut at 4 microns were dewaxed, rehydrated, permeabilized with 0.5% Triton X-100 in PBS 1x and stained with Azide - Alexa Fluor 555 (Thermo Fisher) to detect EdU and DAPI for nuclei. The images were taken using a Leica DM5500 microscope with a 40X N.A.1 objective (black&amp;white camera: DFC350FXR2, pixel dimension: 0.161 microns). Next, the slide was unmounted and stained using the fully automated Ventana Discovery xT autostainer (Roche Diagnostics, Rotkreuz, Switzerland). All steps were performed on automate with Ventana solutions. Sections were pretreated with heat using the CC1 solution under mild conditions. The primary rat anti BrDU (clone: BU1/75 (ICR1), Serotec, diluted 1:300) was incubated 1 hour at 37°C. After incubation with a donkey anti rat biotin diluted 1:200 (Jackson ImmunoResearch Laboratories), chromogenic revelation was performed with DabMap kit. The section was counterstained with Harris hematoxylin (J.T. Baker) before a second round of imaging on DM5500 PL Fluotar 40X N.A.1.0 oil (color camera: DFC 320 R2, pixel dimension: 0.1725 microns). Before acquisition, a white-balance as well as a shading correction is performed according to Leica LAS software wizard. The fluorescence and DAB images were converted in ome.tiff multiresolution file with the kheops Fiji Plugin.</p>
<p>Sampled prepared in the EPFL histology core facility by Nathalie Müller and Gian-Filippo Mancini.</p>
<p>Associated documents:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>https://c4science.ch/w/bioimaging_and_optics_platform_biop/teaching/dab-intensity/
https://imagej.net/plugins/bdv/warpy/warpy
</pre></div>
</div>
<p>This document contains a full QuPath project with an example of registered image.</p>
<p> </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/5675686">https://zenodo.org/records/5675686</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5675686">https://doi.org/10.5281/zenodo.5675686</a></p>
</section>
<hr class="docutils" />
<section id="the-bioimage-archive-building-a-home-for-life-sciences-microscopy-data">
<h2>The BioImage Archive – Building a Home for Life-Sciences Microscopy Data<a class="headerlink" href="#the-bioimage-archive-building-a-home-for-life-sciences-microscopy-data" title="Link to this heading">#</a></h2>
<p>Matthew Hartley, Gerard J. Kleywegt, Ardan Patwardhan, Ugis Sarkans, Jason R. Swedlow, Alvis Brazma</p>
<p>Published 2022-06-22</p>
<p>Licensed UNKNOWN</p>
<p>The BioImage Archive is a new archival data resource at the European Bioinformatics Institute (EMBL-EBI).</p>
<p>Tags: Research Data Management, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0022283622000791?via%3Dihub">https://www.sciencedirect.com/science/article/pii/S0022283622000791?via%3Dihub</a></p>
<p><a class="reference external" href="https://doi.org/10.1016/j.jmb.2022.167505">https://doi.org/10.1016/j.jmb.2022.167505</a></p>
</section>
<hr class="docutils" />
<section id="the-fair-guiding-principles-for-scientific-data-management-and-stewardship">
<h2>The FAIR Guiding Principles for scientific data management and stewardship<a class="headerlink" href="#the-fair-guiding-principles-for-scientific-data-management-and-stewardship" title="Link to this heading">#</a></h2>
<p>Mark D. Wilkinson, Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, et. al</p>
<p>Published 2016-03-15</p>
<p>Licensed CC-BY-4.0</p>
<p>This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.</p>
<p>Tags: FAIR-Principles, Research Data Management, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.nature.com/articles/sdata201618">https://www.nature.com/articles/sdata201618</a></p>
<p><a class="reference external" href="https://doi.org/10.1038/sdata.2016.18">https://doi.org/10.1038/sdata.2016.18</a></p>
</section>
<hr class="docutils" />
<section id="the-fair-guiding-principles-for-data-stewardship-fair-enough">
<h2>The FAIR guiding principles for data stewardship - fair enough?<a class="headerlink" href="#the-fair-guiding-principles-for-data-stewardship-fair-enough" title="Link to this heading">#</a></h2>
<p>Martin Boeckhout, Gerhard A. Zielhuis, Annelien L. Bredenoord</p>
<p>Published 2018-05-17</p>
<p>Licensed CC-BY-4.0</p>
<p>The FAIR guiding principles for research data stewardship (findability, accessibility, interoperability, and reusability) look set to become a cornerstone of research in the life sciences. A critical appraisal of these principles in light of ongoing discussions and developments about data sharing is in order.</p>
<p>Tags: FAIR-Principles, Data Stewardship, Sharing, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.nature.com/articles/s41431-018-0160-0">https://www.nature.com/articles/s41431-018-0160-0</a></p>
</section>
<hr class="docutils" />
<section id="the-fiji-updater">
<h2>The Fiji Updater<a class="headerlink" href="#the-fiji-updater" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Licensed ALL RIGHTS RESERVED</p>
<p>Article about the Fiji Updater explaining how it works in the background.</p>
<p>Tags: Imagej, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://analyticalscience.wiley.com/do/10.1002/was.0004000112/">https://analyticalscience.wiley.com/do/10.1002/was.0004000112/</a></p>
</section>
<hr class="docutils" />
<section id="the-information-infrastructure-for-bioimage-data-i3d-bio-project-to-advance-fair-microscopy-data-management-for-the-community">
<h2>The Information Infrastructure for BioImage Data (I3D:bio) project to advance FAIR microscopy data management for the community<a class="headerlink" href="#the-information-infrastructure-for-bioimage-data-i3d-bio-project-to-advance-fair-microscopy-data-management-for-the-community" title="Link to this heading">#</a></h2>
<p>Christian Schmidt, Michele Bortolomeazzi, Tom Boissonnet, Julia Dohle, Tobias Wernet, Janina Hanne, Roland Nitschke, Susanne Kunis, Karen Bernhardt, Stefanie Weidtkamp-Peters, Elisa Ferrando-May</p>
<p>Published 2024-03-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Research data management (RDM) in microscopy and image analysis is a challenging task. Large files in proprietary formats, complex N-dimensional array structures, and various metadata models and formats can make image data handling inconvenient and difficult. For data organization, annotation, and sharing, researchers need solutions that fit everyday practice and comply with the FAIR (Findable, Accessible, Interoperable, Reusable) principles. International community-based efforts have begun creating open data models (OME), an open file format and translation library (OME-TIFF, Bio-Formats), data management software platforms, and microscopy metadata recommendations and annotation tools. Bringing these developments into practice requires support and training. Iterative feedback and tool improvement is needed to foster practical adoption by the scientific community. The Information Infrastructure for BioImage Data (I3D:bio) project works on guidelines, training resources, and practical assistance for FAIR microscopy RDM adoption with a focus on the management platform OMERO and metadata annotations.</p>
<p>Tags: Nfdi4Bioimage, Research Data Management, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/10805204">https://zenodo.org/records/10805204</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10805204">https://doi.org/10.5281/zenodo.10805204</a></p>
</section>
<hr class="docutils" />
<section id="the-open-microscopy-environment-ome-data-model-and-xml-file-open-tools-for-informatics-and-quantitative-analysis-in-biological-imaging">
<h2>The Open Microscopy Environment (OME) Data Model and XML file - open tools for informatics and quantitative analysis in biological imaging<a class="headerlink" href="#the-open-microscopy-environment-ome-data-model-and-xml-file-open-tools-for-informatics-and-quantitative-analysis-in-biological-imaging" title="Link to this heading">#</a></h2>
<p>Ilya G. Goldberg, Chris Allan, jean-marie burel, Doug Creager, Andrea Falconi, et. al</p>
<p>Published 2005-05-03</p>
<p>Licensed CC-BY-4.0</p>
<p>The Open Microscopy Environment (OME) defines a data model and a software implementation to serve as an informatics framework for imaging in biological microscopy experiments, including representation of acquisition parameters, annotations and image analysis results.</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://genomebiology.biomedcentral.com/articles/10.1186/gb-2005-6-5-r47">https://genomebiology.biomedcentral.com/articles/10.1186/gb-2005-6-5-r47</a></p>
<p><a class="reference external" href="https://doi.org/10.1186/gb-2005-6-5-r47">https://doi.org/10.1186/gb-2005-6-5-r47</a></p>
</section>
<hr class="docutils" />
<section id="the-role-of-helmholtz-centers-in-nfdi4bioimage-a-national-consortium-enhancing-fair-data-management-for-microscopy-and-bioimage-analysis">
<h2>The role of Helmholtz Centers in NFDI4BIOIMAGE - A national consortium enhancing FAIR data management for microscopy and bioimage analysis<a class="headerlink" href="#the-role-of-helmholtz-centers-in-nfdi4bioimage-a-national-consortium-enhancing-fair-data-management-for-microscopy-and-bioimage-analysis" title="Link to this heading">#</a></h2>
<p>Riccardo Massei, Christian Schmidt, Michele Bortolomeazzi, Julia Thoennissen, Jan Bumberger, Timo Dickscheid, Jan-Philipp Mallm, Elisa Ferrando-May</p>
<p>Published 2024-06-06</p>
<p>Licensed CC-BY-4.0</p>
<p>Germany’s National Research Data Infrastructure (NFDI) aims to establish a sustained, cross-disciplinary research data management (RDM) infrastructure that enables researchers to handle FAIR (findable, accessible, interoperable, reusable) data. While FAIR principles have been adopted by funders, policymakers, and publishers, their practical implementation remains an ongoing effort. In the field of bio-imaging, harmonization of data formats, metadata ontologies, and open data repositories is necessary to achieve FAIR data. The NFDI4BIOIMAGE was established to address these issues and develop tools and best practices to facilitate FAIR microscopy and image analysis data in alignment with international community activities. The consortium operates through its Data Stewards team to provide expertise and direct support to help overcome RDM challenges. The three Helmholtz Centers in NFDI4BIOIMAGE aim to collaborate closely with other centers and initiatives, such as HMC, Helmholtz AI, and HIP. Here we present NFDI4BIOIMAGE’s work and its significance for research in Helmholtz and beyond</p>
<p>Tags: Nfdi4Bioimage, Research Data Management, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/11501662">https://zenodo.org/records/11501662</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.11501662">https://doi.org/10.5281/zenodo.11501662</a></p>
</section>
<hr class="docutils" />
<section id="towards-fair-data-workflows-for-multidisciplinary-science-ongoing-endeavors-and-future-perspectives-in-plasma-technology">
<h2>Towards FAIR Data Workflows for Multidisciplinary Science: Ongoing Endeavors and Future Perspectives in Plasma Technology<a class="headerlink" href="#towards-fair-data-workflows-for-multidisciplinary-science-ongoing-endeavors-and-future-perspectives-in-plasma-technology" title="Link to this heading">#</a></h2>
<p>Robert Wagner, Dagmar Waltemath, Kristina Yordanova, Markus Becker</p>
<p>Licensed CC-BY-NC-ND-4.0</p>
<p>This paper focuses on the ongoing process of establishing a FAIR (Findable, Accessible, Interoperable and Reusable) data workflow for multidisciplinary research and development in applied plasma science. The presented workflow aims to support researchers in handling their project data while also fulfilling the requirements of modern digital research data management.</p>
<p>Tags: Research Data Management, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.scitepress.org/Link.aspx?doi=10.5220/0012808000003756">https://www.scitepress.org/Link.aspx?doi=10.5220/0012808000003756</a></p>
</section>
<hr class="docutils" />
<section id="towards-preservation-of-life-science-data-with-nfdi4bioimage">
<h2>Towards Preservation of Life Science Data with NFDI4BIOIMAGE<a class="headerlink" href="#towards-preservation-of-life-science-data-with-nfdi4bioimage" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-09-03</p>
<p>Licensed CC-BY-4.0</p>
<p>This talk will present the initiatives of the NFDI4BioImage consortium aimed at the long-term preservation of life science data. We will discuss our efforts to establish metadata standards, which are crucial for ensuring data reusability and integrity. The development of sustainable infrastructure is another key focus, enabling seamless data integration and analysis in the cloud. We will take a look at how we manage training materials and communicate with our community. Through these actions, NFDI4BioImage seeks to enable FAIR bioimage data management for German researchers, across disciplines and embedded in the international framework.</p>
<p>Tags: Nfdi4Bioimage, Research Data Management, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/13640979">https://zenodo.org/records/13640979</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13640979">https://doi.org/10.5281/zenodo.13640979</a></p>
</section>
<hr class="docutils" />
<section id="towards-transparency-and-knowledge-exchange-in-ai-assisted-data-analysis-code-generation">
<h2>Towards Transparency and Knowledge Exchange in AI-assisted Data Analysis Code Generation<a class="headerlink" href="#towards-transparency-and-knowledge-exchange-in-ai-assisted-data-analysis-code-generation" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2024-10-14</p>
<p>Licensed CC-BY-4.0</p>
<p>The integration of Large Language Models (LLMs) in scientific research presents both opportunities and challenges for life scientists. Key challenges include ensuring transparency in AI-generated content and facilitating efficient knowledge exchange among researchers. These issues arise from the in-transparent nature of AI-driven code generation and the informal sharing of AI insights, which may hinder reproducibility and collaboration. This paper introduces git-bob, an innovative AI-assistant designed to address these challenges by fostering an interactive and transparent collaboration platform within GitHub. By enabling seamless dialogue between humans and AI, git-bob ensures that AI contributions are transparent and reproducible. Moreover, it supports collaborative knowledge exchange, enhancing the interdisciplinary dialogue necessary for cutting-edge life sciences research. The open-source nature of git-bob further promotes accessibility and customization, positioning it as a vital tool in employing LLMs responsibly and effectively within scientific communities.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/13928832">https://zenodo.org/records/13928832</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13928832">https://doi.org/10.5281/zenodo.13928832</a></p>
</section>
<hr class="docutils" />
<section id="towards-community-driven-metadata-standards-for-light-microscopy-tiered-specifications-extending-the-ome-model">
<h2>Towards community-driven metadata standards for light microscopy - tiered specifications extending the OME model<a class="headerlink" href="#towards-community-driven-metadata-standards-for-light-microscopy-tiered-specifications-extending-the-ome-model" title="Link to this heading">#</a></h2>
<p>Mathias Hammer, Maximiliaan Huisman, Alessandro Rigano, Ulrike Boehm, James J. Chambers, et al.</p>
<p>Published 2022-07-10</p>
<p>Licensed UNKNOWN</p>
<p>Rigorous record-keeping and quality control are required to ensure the quality, reproducibility and value of imaging data. The 4DN Initiative and BINA here propose light Microscopy Metadata specifications that extend the OME data model, scale with experimental intent and complexity, and make it possible for scientists to create comprehensive records of imaging experiments.</p>
<p>Tags: Reproducibility, Bioimage Analysis, Metadata, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9271325/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9271325/</a></p>
</section>
<hr class="docutils" />
<section id="training-set-of-microscopy-images-for-dietler-et-al-nature-communications-2020">
<h2>Training set of microscopy images for Dietler et al. Nature Communications 2020<a class="headerlink" href="#training-set-of-microscopy-images-for-dietler-et-al-nature-communications-2020" title="Link to this heading">#</a></h2>
<p>Nicola Dietler, Matthias Minder, Vojislav Gligorovski, Economou, Augoustina Maria, Joly, Denis Alain Henri Lucien, Ahmad Sadeghi, Chan, Chun Hei Michael, Mateusz Kozinski, Martin Weigert, Anne-Florence Bitbol, Rahi, Sahand Jamal</p>
<p>Published 2021-12-07</p>
<p>Licensed CC-BY-4.0</p>
<p>Training set of microscopy images for Dietler et al. Nature Communications 2020</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/5765648">https://zenodo.org/records/5765648</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.5765648">https://doi.org/10.5281/zenodo.5765648</a></p>
</section>
<hr class="docutils" />
<section id="trendsinmicroscopy2025">
<h2>TrendsInMicroscopy2025<a class="headerlink" href="#trendsinmicroscopy2025" title="Link to this heading">#</a></h2>
<p>Marcelo Zoccoler, Johannes Soltwedel</p>
<p>Published 2025-03-10T13:42:57+00:00</p>
<p>Licensed CC-BY-4.0</p>
<p>Course contents for biapol course at Trends in Microscopy conference 2025</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="reference external" href="https://biapol.github.io/TrendsInMicroscopy_2025/">https://biapol.github.io/TrendsInMicroscopy_2025/</a></p>
<p><a class="github reference external" href="https://github.com/BiAPoL/TrendsInMicroscopy_2025">BiAPoL/TrendsInMicroscopy_2025</a></p>
</section>
<hr class="docutils" />
<section id="understanding-metric-related-pitfalls-in-image-analysis-validation">
<h2>Understanding metric-related pitfalls in image analysis validation<a class="headerlink" href="#understanding-metric-related-pitfalls-in-image-analysis-validation" title="Link to this heading">#</a></h2>
<p>Annika Reinke, et al.</p>
<p>Published 2023</p>
<p>This article gives a detailed overview about pitfalls when using metric for image analysis algorithm validation.</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Publication, Preprint</p>
<p><a class="reference external" href="https://arxiv.org/abs/2302.01790v3">https://arxiv.org/abs/2302.01790v3</a></p>
</section>
<hr class="docutils" />
<section id="upcoming-image-analysis-events">
<h2>Upcoming Image Analysis Events<a class="headerlink" href="#upcoming-image-analysis-events" title="Link to this heading">#</a></h2>
<p>Curtis Rueden, Albane de la Villegeorges, Simon F. Nørrelykke, Romain Guiet, Olivier Burri, et al.</p>
<p>Licensed UNKNOWN</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Collection, Event, Forum Post, Workshop</p>
<p><a class="reference external" href="https://forum.image.sc/t/upcoming-image-analysis-events/60018/67">https://forum.image.sc/t/upcoming-image-analysis-events/60018/67</a></p>
</section>
<hr class="docutils" />
<section id="using-glittr-org-to-find-compare-and-re-use-online-training-materials">
<h2>Using <a class="reference external" href="http://Glittr.org">Glittr.org</a> to find, compare and re-use online training materials<a class="headerlink" href="#using-glittr-org-to-find-compare-and-re-use-online-training-materials" title="Link to this heading">#</a></h2>
<p>Geert van Geest, Yann Haefliger, Monique Zahn-Zabal, Patricia M. Palagi</p>
<p>Licensed CC-BY-4.0</p>
<p><a class="reference external" href="http://Glittr.org">Glittr.org</a> is a platform that aggregates and indexes training materials on computational life sciences from public git repositories, making it easier for users to find, compare, and analyze these resources based on various metrics. By providing insights into the availability of materials, collaboration patterns, and licensing practices, <a class="reference external" href="http://Glittr.org">Glittr.org</a> supports adherence to the FAIR principles, benefiting the broader life sciences community.</p>
<p>Tags: Bioimage Analysis, Research Data Management, Exclude From Dalia</p>
<p>Content type: Publication, Preprint</p>
<p><a class="reference external" href="https://www.biorxiv.org/content/10.1101/2024.08.20.608021v1">https://www.biorxiv.org/content/10.1101/2024.08.20.608021v1</a></p>
</section>
<hr class="docutils" />
<section id="v4sdb-winter-school-2025">
<h2>V4SDB_Winter_School_2025<a class="headerlink" href="#v4sdb-winter-school-2025" title="Link to this heading">#</a></h2>
<p>Joanna Pylvänäinen</p>
<p>Published 2025-01-13T08:29:22+00:00</p>
<p>Training materials for V4SDB Student Winter School, 28th-31st January 2025 at ELTE Eötvös Loránd University in Budapest, Hungary</p>
<p>Tags: Cell Tracking, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Github Repository, Collection</p>
<p><a class="github reference external" href="https://github.com/CellMigrationLab/V4SDB_Winter_School_2025">CellMigrationLab/V4SDB_Winter_School_2025</a></p>
</section>
<hr class="docutils" />
<section id="volumetric-segmentation-of-biological-cells-and-subcellular-structures-for-optical-diffraction-tomography-images-dataset">
<h2>Volumetric segmentation of biological cells and subcellular structures for optical diffraction tomography images - dataset<a class="headerlink" href="#volumetric-segmentation-of-biological-cells-and-subcellular-structures-for-optical-diffraction-tomography-images-dataset" title="Link to this heading">#</a></h2>
<p>Martyna Mazur, Wojciech Krauze</p>
<p>Published 2023-06-16</p>
<p>Licensed CC-BY-4.0</p>
<p>This dataset includes 4 files with segmentation results for 4 different ODT reconstructions of SH-SY5Y neuroblastoma cell. The segmentation results contain:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>3D binary masks of biological cells obtained through Cellpose [1] and ODT-SAS;
3D binary masks of organelles: nucleoli and lipid structures (LS) obtained through slice-by-slice manual segmentation&amp;nbsp;and ODT-SAS.
</pre></div>
</div>
<p>All files are .*mat files.</p>
<p>The files REC_SH-SY5Y_1.mat, REC_SH-SY5Y_2.mat and REC_SH-SY5Y_3.mat consist of 7 variables:</p>
<p>RECON – tomographic reconstruction of SH-SY5Y neuroblastoma cell;
n_imm – refractive index of object immersion medium;
dx – object space sample size in XY [(\mu m)];
rayXY – xy-coordinates of illumination vectors;</p>
<p>maskManual – table with manually determined 3D binary masks of organelles;
maskCellpose – 3D binary mask of biological cell obtained through Cellpose;
maskODTSAS – table with 3D binary masks of biological cell and their organelles obtained through ODT-SAS.</p>
<p>File REC_SH-SY5Y_4.mat includes masks for the ODT-SAS and Cellpose segmentation of three closely packed cells and consists of 5 variables: RECON, n_imm, dx, maskCellpose and maskODTSAS.</p>
<p>Access a particular 3D binary mask from ‘maskManual’ and ‘maskODTSAS’ tables, using the following names: ‘Cell’, ‘Nucleoli’, ‘LS’.
For example:</p>
<p>cellMask = maskODTSAS.Cell{1};</p>
<p>[1] Stringer, C., Wang, T., Michaelos, M., &amp; Pachitariu, M. (2021). Cellpose: a generalist algorithm for cellular segmentation. Nature methods, 18(1), 100-106.</p>
<p> </p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/8188948">https://zenodo.org/records/8188948</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.8188948">https://doi.org/10.5281/zenodo.8188948</a></p>
</section>
<hr class="docutils" />
<section id="webatlas-pipeline-for-integrated-single-cell-and-spatial-transcriptomic-data">
<h2>WebAtlas pipeline for integrated single cell and spatial transcriptomic data<a class="headerlink" href="#webatlas-pipeline-for-integrated-single-cell-and-spatial-transcriptomic-data" title="Link to this heading">#</a></h2>
<p>Tong Li, David Horsfall, Daniela Basurto-Lozada</p>
<p>Published 2023-04-28</p>
<p>Licensed None</p>
<p>Single cell and spatial transcriptomics illuminate complementary features of tissues. However, the online dissemination and exploration of multi-modal datasets is challenging. We introduce the WebAtlas pipeline for user-friendly sharing and interactive navigation of integrated datasets. WebAtlas unifies commonly used atlassing technologies into the cloud-optimised Zarr format and builds on Vitessce to enable remote data navigation. We showcase WebAtlas on the developing human lower limb to cross-query cell types and genes across single cell, sequencing- and imaging-based spatial transcriptomic data.</p>
<p>Tags: Spatial Transcriptomics, Single Cell, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Collection, Atlas</p>
<p><a class="reference external" href="https://developmental.cellatlas.io/webatlas">https://developmental.cellatlas.io/webatlas</a></p>
<p><a class="reference external" href="https://www.biorxiv.org/content/10.1101/2023.05.19.541329v1">https://www.biorxiv.org/content/10.1101/2023.05.19.541329v1</a></p>
</section>
<hr class="docutils" />
<section id="welcome-to-bioimage-town">
<h2>Welcome to BioImage Town<a class="headerlink" href="#welcome-to-bioimage-town" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Licensed CC-BY-4.0</p>
<p>Welcome at NFDI4BIOIMAGE All-Hands Meeting in Düsseldorf, Germany, October 16, 2023</p>
<p>Tags: OMERO, Bioimage Analysis, Nfdi4Bioimage, Exclude From Dalia</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.10008464">https://zenodo.org/doi/10.5281/zenodo.10008464</a></p>
</section>
<hr class="docutils" />
<section id="what-is-bioimage-analysis-an-introduction">
<h2>What is Bioimage Analysis? An Introduction<a class="headerlink" href="#what-is-bioimage-analysis-an-introduction" title="Link to this heading">#</a></h2>
<p>Kota Miura</p>
<p>Licensed UNKNOWN</p>
<p>Tags: Neubias, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://www.dropbox.com/s/5abw3cvxrhpobg4/20220923_DefragmentationTS.pdf?dl=0">https://www.dropbox.com/s/5abw3cvxrhpobg4/20220923_DefragmentationTS.pdf?dl=0</a></p>
</section>
<hr class="docutils" />
<section id="who-you-gonna-call-data-stewards-to-the-rescue">
<h2>Who you gonna call? - Data Stewards to the rescue<a class="headerlink" href="#who-you-gonna-call-data-stewards-to-the-rescue" title="Link to this heading">#</a></h2>
<p>Vanessa Aphaia Fiona Fuchs, Jens Wendt, Maximilian Müller, Mohsen Ahmadi, Riccardo Massei, Cornelia Wetzker</p>
<p>Published 2024-03-01</p>
<p>Licensed CC-BY-4.0</p>
<p>The Data Steward Team of the NFDI4BIOIMAGE consortium presents themselves and the services (including the Helpdesk) that we offer.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/10730424">https://zenodo.org/records/10730424</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10730424">https://doi.org/10.5281/zenodo.10730424</a></p>
</section>
<hr class="docutils" />
<section id="workflowhub">
<h2>WorkflowHub<a class="headerlink" href="#workflowhub" title="Link to this heading">#</a></h2>
<p>Stian Soiland-Reyes, Finn Bacall, Bert Droesbeke, Alan R Williams, Johan Gustafsson, et al.</p>
<p>Licensed BSD-3-CLAUSE</p>
<p>A registry for describing, sharing and publishing scientific computational workflows.</p>
<p>Tags: Bioinformatics, Workflow, Workflow Engine, Python, R, Exclude From Dalia</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://workflowhub.eu/">https://workflowhub.eu/</a></p>
</section>
<hr class="docutils" />
<section id="working-group-charter-rdm-helpdesk-network">
<h2>Working Group Charter. RDM Helpdesk Network<a class="headerlink" href="#working-group-charter-rdm-helpdesk-network" title="Link to this heading">#</a></h2>
<p>Judith Engel, Patrick Helling, Robert Herrenbrück, MarinaLemaire, Hela Mehrtens, Marcus Schmidt, Martha Stellmacher, Lukas Weimer, Cord Wiljes, Wolf Zinke</p>
<p>Published 2024-11-04</p>
<p>Licensed CC-BY-4.0</p>
<p>Support is an essential component of an efficient infrastructure for research data management (RDM). Helpdesks guide researchers through this complex landscape and provide reliable support about all questions regarding research data management, including support for technical services, best practices, requirements of funding organizations and legal topics. In NFDI, most consortia have already established or are planning to establish helpdesks to support their specific communities. On a local level, many institutions have set up RDM helpdesks that provide support for the researchers of their own institution. Additional RDM support services are offered by RDM federal state initiatives, by research data centers, by specialist libraries, by the EOSC, and by providers of RDM-relevant tools. Helpdesks cover a wide range of institutions, disciplines, topics, methodologies and target audiences. However, the individual helpdesks are not yet interconnected and therefore cannot complement one another in an efficient way: Given the wide and constantly increasing complexity of RDM, no single helpdesk can provide the expertise for all potential support requests. Therefore, we see great potential in combining the efforts and resources of the existing RDM helpdesks into an efficient and comprehensive national RDM support network in order to provide optimal and tailored RDM support to all researchers and research-related institutions in Germany and in an international context.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14035822">https://zenodo.org/records/14035822</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14035822">https://doi.org/10.5281/zenodo.14035822</a></p>
</section>
<hr class="docutils" />
<section id="workshop-june2024-madrid">
<h2>Workshop-June2024-Madrid<a class="headerlink" href="#workshop-june2024-madrid" title="Link to this heading">#</a></h2>
<p>Licensed MIT</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Workshop, Collection</p>
<p><a class="github reference external" href="https://github.com/bioimage-io/Workshop-June2024-Madrid">bioimage-io/Workshop-June2024-Madrid</a></p>
</section>
<hr class="docutils" />
<section id="zarr-a-cloud-optimized-storage-for-interactive-access-of-large-arrays">
<h2>Zarr - A Cloud-Optimized Storage for Interactive Access of Large Arrays<a class="headerlink" href="#zarr-a-cloud-optimized-storage-for-interactive-access-of-large-arrays" title="Link to this heading">#</a></h2>
<p>Josh Moore, Susanne Kunis</p>
<p>Published 2023-09-07</p>
<p>Licensed CC-BY-4.0</p>
<p>For decades, the sharing of large N-dimensional datasets has posed issues across multiple domains. Interactively accessing terabyte-scale data has previously required significant server resources to properly prepare cropped or down-sampled representations on the fly. Now, a cloud-native chunked format easing this burden has been adopted in the bioimaging domain for standardization. The format — Zarr — is potentially of interest for other consortia and sections of NFDI.</p>
<p>Tags: Nfdi4Bioimage, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Publication</p>
<p><a class="reference external" href="https://www.tib-op.org/ojs/index.php/CoRDI/article/view/285">https://www.tib-op.org/ojs/index.php/CoRDI/article/view/285</a></p>
</section>
<hr class="docutils" />
<section id="zeiss-axiozoom-stage-adapter">
<h2>Zeiss AxioZoom Stage Adapter<a class="headerlink" href="#zeiss-axiozoom-stage-adapter" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-06-20</p>
<p>Licensed CC-BY-4.0</p>
<p>A 3D- printable microscope stage adapter for the reproducible accomodation of samples at a Zeiss AxioZoom stereomicroscope.
4 cylindrical anchors are fixed to the glass plate of the stage. The stage adapter is reversibly placed on these anchors.
 </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/7963020">https://zenodo.org/records/7963020</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7963020">https://doi.org/10.5281/zenodo.7963020</a></p>
</section>
<hr class="docutils" />
<section id="zeiss-axiozoom-stage-adapter-12-6well-plate">
<h2>Zeiss AxioZoom Stage Adapter - 12/6Well Plate<a class="headerlink" href="#zeiss-axiozoom-stage-adapter-12-6well-plate" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-06-20</p>
<p>Licensed CC-BY-4.0</p>
<p>A 3D- printable microscope stage adapter for the reproducible accomodation of 6 or 12-well plates at a Zeiss AxioZoom microscope.
4 cylindrical anchors are fixed to the glass plate of the stage. The stage adapter is reversibly placed on these anchors and acommodates a standard Greiner 6- or 12-well plate.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/7944877">https://zenodo.org/records/7944877</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7944877">https://doi.org/10.5281/zenodo.7944877</a></p>
</section>
<hr class="docutils" />
<section id="zeiss-axiozoom-stage-adapter-em-block-holder">
<h2>Zeiss AxioZoom Stage Adapter - EM block holder<a class="headerlink" href="#zeiss-axiozoom-stage-adapter-em-block-holder" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-06-20</p>
<p>Licensed CC-BY-4.0</p>
<p>A 3D- printable microscope stage adapter for the reproducible accomodation of EM Blocks at a Zeiss AxioZoom microscope.</p>
<p>4 cylindrical anchors are fixed to the glass plate of the stage. The stage adapter is reversibly placed on these anchors and acommodates 70 standard resin EM blocks.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/7963006">https://zenodo.org/records/7963006</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7963006">https://doi.org/10.5281/zenodo.7963006</a></p>
</section>
<hr class="docutils" />
<section id="zeiss-axiozoom-stage-adapter-microscope-slides">
<h2>Zeiss AxioZoom Stage Adapter - Microscope slides<a class="headerlink" href="#zeiss-axiozoom-stage-adapter-microscope-slides" title="Link to this heading">#</a></h2>
<p>Michael Gerlach</p>
<p>Published 2024-06-21</p>
<p>Licensed CC-BY-4.0</p>
<p>A 3D- printable microscope stage adapter for the reproducible accomodation of microscopic slides at a Zeiss AxioZoom microscope.
4 cylindrical anchors are fixed to the glass plate of the stage. The stage adapter is reversibly placed on these anchors and acommodates 4 standard glass slides.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/7945018">https://zenodo.org/records/7945018</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7945018">https://doi.org/10.5281/zenodo.7945018</a></p>
</section>
<hr class="docutils" />
<section id="zerocostdl4mic-stardist-2d-example-training-and-test-dataset-light">
<h2>ZeroCostDL4Mic - Stardist 2D example training and test dataset (light)<a class="headerlink" href="#zerocostdl4mic-stardist-2d-example-training-and-test-dataset-light" title="Link to this heading">#</a></h2>
<p>Johanna Jukkala, Guillaume Jacquemet</p>
<p>Published 2023-05-19</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: ZeroCostDL4Mic - Stardist 2D example training and test dataset (light)</p>
<p>(see our Wiki for details)</p>
<p>Data type: Paired microscopy images (fluorescence) and corresponding masks</p>
<p>Microscopy data type: Fluorescence microscopy (SiR-DNA) and masks obtained via manual segmentation (see <a class="reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki/Stardist&amp;amp;nbsp;for">https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki/Stardist&amp;nbsp;for</a> details about the segmentation)</p>
<p>Microscope: Spinning disk confocal microscope with a 20x 0.8 NA objective</p>
<p>Cell type: <a class="reference external" href="http://DCIS.COM">DCIS.COM</a> LifeAct-RFP cells</p>
<p>File format: .tif (16-bit for fluorescence and 8 and 16-bit for the masks)</p>
<p>Image size: 1024x1024 (Pixel size: 634 nm)</p>
<p> </p>
<p>Author(s): Johanna Jukkala1,2 and Guillaume Jacquemet1,2</p>
<p>Contact email: <a class="reference external" href="mailto:guillaume&#46;jacquemet&#37;&#52;&#48;abo&#46;fi">guillaume<span>&#46;</span>jacquemet<span>&#64;</span>abo<span>&#46;</span>fi</a></p>
<p>Affiliation : </p>
<ol class="arabic simple">
<li><p>Faculty of Science and Engineering, Cell Biology, Åbo Akademi University, 20520 Turku, Finland</p></li>
<li><p>Turku Bioscience Centre, University of Turku and Åbo Akademi University, FI-20520 Turku, Finland</p></li>
</ol>
<p>Funding bodies: G.J. was supported by grants awarded by the Academy of Finland, the Sigrid Juselius Foundation and Åbo Akademi University Research Foundation (CoE CellMech) and by Drug Discovery and Diagnostics strategic funding to Åbo Akademi University.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/7949940">https://zenodo.org/records/7949940</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.7949940">https://doi.org/10.5281/zenodo.7949940</a></p>
</section>
<hr class="docutils" />
<section id="zerocostdl4mic-stardist-example-training-and-test-dataset">
<h2>ZeroCostDL4Mic - Stardist example training and test dataset<a class="headerlink" href="#zerocostdl4mic-stardist-example-training-and-test-dataset" title="Link to this heading">#</a></h2>
<p>Johanna Jukkala, Guillaume Jacquemet</p>
<p>Published 2020-03-17</p>
<p>Licensed CC-BY-4.0</p>
<p>Name: ZeroCostDL4Mic - Stardist example training and test dataset</p>
<p>(see our Wiki for details)</p>
<p> </p>
<p>Data type: Paired microscopy images (fluorescence) and corresponding masks</p>
<p>Microscopy data type: Fluorescence microscopy (SiR-DNA) and masks obtained via manual segmentation (see <a class="github reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki/Stardist">HenriquesLab/ZeroCostDL4Mic</a> for details about the segmentation)</p>
<p>Microscope: Spinning disk confocal microscope with a 20x 0.8 NA objective</p>
<p>Cell type: <a class="reference external" href="http://DCIS.COM">DCIS.COM</a> LifeAct-RFP cells</p>
<p>File format: .tif (16-bit for fluorescence and 8 and 16-bit for the masks)</p>
<p>Image size: 1024x1024 (Pixel size: 634 nm)</p>
<p> </p>
<p>Author(s): Johanna Jukkala1,2 and Guillaume Jacquemet1,2</p>
<p>Contact email: <a class="reference external" href="mailto:guillaume&#46;jacquemet&#37;&#52;&#48;abo&#46;fi">guillaume<span>&#46;</span>jacquemet<span>&#64;</span>abo<span>&#46;</span>fi</a></p>
<p>Affiliation : </p>
<ol class="arabic simple">
<li><p>Faculty of Science and Engineering, Cell Biology, Åbo Akademi University, 20520 Turku, Finland</p></li>
<li><p>Turku Bioscience Centre, University of Turku and Åbo Akademi University, FI-20520 Turku, Finland</p></li>
</ol>
<p> </p>
<p>Associated publications: Unpublished</p>
<p>Funding bodies: G.J. was supported by grants awarded by the Academy of Finland, the Sigrid Juselius Foundation and Åbo Akademi University Research Foundation (CoE CellMech) and by Drug Discovery and Diagnostics strategic funding to Åbo Akademi University.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://zenodo.org/records/3715492">https://zenodo.org/records/3715492</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.3715492">https://doi.org/10.5281/zenodo.3715492</a></p>
</section>
<hr class="docutils" />
<section id="zerocostdl4mic-exploiting-google-colab-to-develop-a-free-and-open-source-toolbox-for-deep-learning-in-microscopy">
<h2>ZeroCostDL4Mic: exploiting Google Colab to develop a free and open-source toolbox for Deep-Learning in microscopy<a class="headerlink" href="#zerocostdl4mic-exploiting-google-colab-to-develop-a-free-and-open-source-toolbox-for-deep-learning-in-microscopy" title="Link to this heading">#</a></h2>
<p>Lucas von Chamier, Romain F. Laine, Johanna Jukkala, Christoph Spahn, Daniel Krentzel, Elias Nehme, Martina Lerche, Sara Hernández-pérez, Pieta Mattila, Eleni Karinou, Séamus Holden, Ahmet Can Solak, Alexander Krull, Tim-Oliver Buchholz, Martin L Jones, Loic Alain Royer, Christophe Leterrier, Yoav Shechtman, Florian Jug, Mike Heilemann, Guillaume Jacquemet, Ricardo Henriques</p>
<p>Licensed MIT</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Notebook, Collection</p>
<p><a class="github reference external" href="https://github.com/HenriquesLab/ZeroCostDL4Mic">HenriquesLab/ZeroCostDL4Mic</a></p>
<p><a class="reference external" href="https://www.nature.com/articles/s41467-021-22518-0">https://www.nature.com/articles/s41467-021-22518-0</a></p>
<p><a class="reference external" href="https://doi.org/10.1038/s41467-021-22518-0">https://doi.org/10.1038/s41467-021-22518-0</a></p>
</section>
<hr class="docutils" />
<section id="bina-cc-scalable-strategies-for-a-next-generation-of-fair-bioimaging">
<h2>[BINA CC] Scalable strategies for a next-generation of FAIR bioimaging<a class="headerlink" href="#bina-cc-scalable-strategies-for-a-next-generation-of-fair-bioimaging" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Published 2024-09-24</p>
<p>Licensed CC-BY-4.0</p>
<p>Presented at <a class="reference external" href="https://www.bioimagingnorthamerica.org/events/bina-2024-community-congress/">https://www.bioimagingnorthamerica.org/events/bina-2024-community-congress/</a></p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/13831274">https://zenodo.org/records/13831274</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.13831274">https://doi.org/10.5281/zenodo.13831274</a></p>
</section>
<hr class="docutils" />
<section id="cordi-2023-zarr-a-cloud-optimized-storage-for-interactive-access-of-large-arrays">
<h2>[CORDI 2023] Zarr: A Cloud-Optimized Storage for Interactive Access of Large Arrays<a class="headerlink" href="#cordi-2023-zarr-a-cloud-optimized-storage-for-interactive-access-of-large-arrays" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Licensed CC-BY-4.0</p>
<p>For decades, the sharing of large N-dimensional datasets has posed issues across multiple domains. Interactively accessing terabyte-scale data has previously required significant server resources to properly prepare cropped or down-sampled representations on the fly. Now, a cloud-native chunked format easing this burden has been adopted in the bioimaging domain for standardization. The format — Zarr — is potentially of interest for other consortia and sections of NFDI.</p>
<p>Tags: Research Data Management, Bioimage Analysis, Data Science, Exclude From Dalia</p>
<p>Content type: Poster</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.8340247">https://zenodo.org/doi/10.5281/zenodo.8340247</a></p>
</section>
<hr class="docutils" />
<section id="community-meeting-2024-overview-team-image-data-analysis-and-management">
<h2>[Community Meeting 2024] Overview Team Image Data Analysis and Management<a class="headerlink" href="#community-meeting-2024-overview-team-image-data-analysis-and-management" title="Link to this heading">#</a></h2>
<p>Susanne Kunis, Thomas Zobel</p>
<p>Published 2024-03-08</p>
<p>Licensed CC-BY-4.0</p>
<p>Overview of Activities of the Team Image Data Analysis and Management of German BioImaging e.V.
 </p>
<p>Tags: Nfdi4Bioimage, Research Data Management, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/10796364">https://zenodo.org/records/10796364</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10796364">https://doi.org/10.5281/zenodo.10796364</a></p>
</section>
<hr class="docutils" />
<section id="community-meeting-2024-supporting-and-financing-rdm-projects-within-gerbi">
<h2>[Community Meeting 2024] Supporting and financing RDM projects within GerBI<a class="headerlink" href="#community-meeting-2024-supporting-and-financing-rdm-projects-within-gerbi" title="Link to this heading">#</a></h2>
<p>Stefanie Weidtkamp-Peters, Josh Moore, Christian Schmidt, Roland Nitschke, Susanne Kunis, Thomas Zobel</p>
<p>Published 2024-03-28</p>
<p>Licensed CC-BY-4.0</p>
<p>Overview of GerBI RDM projects: why and how?</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/10889694">https://zenodo.org/records/10889694</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10889694">https://doi.org/10.5281/zenodo.10889694</a></p>
</section>
<hr class="docutils" />
<section id="gbi-eoe-ix-nfdi4bioimage">
<h2>[GBI EoE IX] NFDI4BIOIMAGE<a class="headerlink" href="#gbi-eoe-ix-nfdi4bioimage" title="Link to this heading">#</a></h2>
<p>National Research Data Infrastructure
for Microscopy and BioImage Analysis</p>
<p>Josh Moore</p>
<p>Published 2024-10-29</p>
<p>Licensed CC-BY-4.0</p>
<p>Presented at <a class="reference external" href="https://globalbioimaging.org/exchange-of-experience/exchange-of-experience-ix">https://globalbioimaging.org/exchange-of-experience/exchange-of-experience-ix</a> in Okazaki, Japan.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14001388">https://zenodo.org/records/14001388</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14001388">https://doi.org/10.5281/zenodo.14001388</a></p>
</section>
<hr class="docutils" />
<section id="n4bi-ahm-welcome-to-bioimage-town">
<h2>[N4BI AHM] Welcome to BioImage Town<a class="headerlink" href="#n4bi-ahm-welcome-to-bioimage-town" title="Link to this heading">#</a></h2>
<p>Josh Moore</p>
<p>Published 2023-10-16</p>
<p>Licensed CC-BY-4.0</p>
<p>Keynote at the NFDI4BIOIMAGE All-Hands Meeting in Düsseldorf, Germany, October 16, 2023.</p>
<p>Tags: Nfdi4Bioimage, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15031842">https://zenodo.org/records/15031842</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15031842">https://doi.org/10.5281/zenodo.15031842</a></p>
</section>
<hr class="docutils" />
<section id="short-talk-nfdi4bioimage-a-consortium-in-the-national-research-data-infrastructure">
<h2>[Short Talk] NFDI4BIOIMAGE - A consortium in the National Research Data Infrastructure<a class="headerlink" href="#short-talk-nfdi4bioimage-a-consortium-in-the-national-research-data-infrastructure" title="Link to this heading">#</a></h2>
<p>Christian Schmidt</p>
<p>Published 2024-04-10</p>
<p>Licensed CC-BY-4.0</p>
<p>Short Talk about the NFDI4BIOIMAGE consortium presented at the RDM in (Bio-)Medicine Information Event on April 10th, 2024, organized C³RDM &amp; ZB MED.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/10939520">https://zenodo.org/records/10939520</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.10939520">https://doi.org/10.5281/zenodo.10939520</a></p>
</section>
<hr class="docutils" />
<section id="solved-sample-fluorescence-qptiff-file-not-rendered-correctly-by-qupath-v-0-6-0-correctly-by-qupath-v-0-5-1">
<h2>[Solved] Sample fluorescence .qptiff file not rendered correctly by QuPath v.0.6.0, correctly by Qupath v.0.5.1<a class="headerlink" href="#solved-sample-fluorescence-qptiff-file-not-rendered-correctly-by-qupath-v-0-6-0-correctly-by-qupath-v-0-5-1" title="Link to this heading">#</a></h2>
<p>VP</p>
<p>Published 2025-07-29</p>
<p>Licensed CDLA-SHARING-1.0</p>
<p>Solution: <a class="reference external" href="https://forum.image.sc/t/weird-representation-of-qptiff-of-fluorescent-sample-in-qupath-v-0-6-0/115165/6?u=zuksmp3">https://forum.image.sc/t/weird-representation-of-qptiff-of-fluorescent-sample-in-qupath-v-0-6-0/115165/6?u=zuksmp3</a>
Image in qptiff file format of an immunofluorescence sample acquired on a KF-400-FL slide scanner. Image with three channels: blue, red, green. Weirdly rendered by QuPath v.0.6.0, but correctly displayed in v.0.5.1 and Fiji.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16569043">https://zenodo.org/records/16569043</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16569043">https://doi.org/10.5281/zenodo.16569043</a></p>
</section>
<hr class="docutils" />
<section id="workshop-material-fit-for-omero-how-imaging-facilities-and-it-departments-work-together-to-enable-rdm-for-bioimaging-october-16-17-2024-heidelberg">
<h2>[Workshop Material] Fit for OMERO - How imaging facilities and IT departments work together to enable RDM for bioimaging, October 16-17, 2024, Heidelberg<a class="headerlink" href="#workshop-material-fit-for-omero-how-imaging-facilities-and-it-departments-work-together-to-enable-rdm-for-bioimaging-october-16-17-2024-heidelberg" title="Link to this heading">#</a></h2>
<p>Tom Boissonnet, Bettina Hagen, Susanne Kunis, Christian Schmidt, Stefanie Weidtkamp-Peters</p>
<p>Published 2024-11-18</p>
<p>Licensed CC-BY-4.0</p>
<p>Fit for OMERO: How imaging facilities and IT departments work together to enable RDM for bioimaging
Description:
Research data management (RDM) in bioimaging is challenging because of large file sizes, heterogeneous file formats and the variability of imaging methods. The image data management system OMERO (OME Remote Objects) allows for centralized and secure storage, organization, annotation, and interrogation of microscopy data by researchers. It is an internationally well-supported open-source software tool that has become one of the best-known image data management tools among bioimaging scientists. Nevertheless, the de novo setup of OMERO at an institute is a multi-stakeholder process that demands time, funds, organization and iterative implementation. In this workshop, participants learn how to begin setting up OMERO-based image data management at their institution. The topics include:</p>
<p>Stakeholder identification at the university / research institute
Process management, time line expectations, and resources planning
Learning about each other‘s perspectives on chances and challenges for RDM
Funding opportunities and strategies for IT and imaging core facilities
Hands-on: Setting up an OMERO server in a virtual machine environment</p>
<p>Target audience:
This workshop was directed at universities and research institutions who consider or plan to implement OMERO, or are in an early phase of implementation. This workshop was intended for teams from IT departments and imaging facilities to participate together with one person from the IT department, and one person from the imaging core facility at the same institution.
The trainers:</p>
<p>Prof. Dr. Stefanie Weidtkamp-Peters (Imaging Core Facility Head, Center for Advanced Imaging, Heinrich Heine University of Düsseldorf)
Dr. Susanne Kunis (Software architect, OMERO administrator, metadata specialist, University of Osnabrück)
Dr. Tom Boissonnet (OMERO admin and image metadata specialist, Center for Advanced Imaging, Heinrich Heine University of Düsseldorf)
Dr. Bettina Hagen (IT Administration and service specialist, Max Planck Institute for the Biology of Ageing, Cologne) 
Dr. Christian Schmidt (Science Manager for Research Data Management in Bioimaging, German Cancer Research Center (DKFZ), Heidelberg)</p>
<p>Time and place
The format was a two-day, in-person workshop (October 16-17, 2024). Location: Heidelberg, Germany
Workshop learning goals</p>
<p>Learn the steps to establish a local RDM environment fit for bioimaging data
Create a network of IT experts and bioimaging specialists for bioimage RDM across institutions
Establish a stakeholder process management for installing OMERO-based RDM
Learn from each other, leverage different expertise
Learn how to train users, establish sustainability strategies, and foster FAIR RDM for bioimaging at your institution</p>
<p>Tags: Nfdi4Bioimage, Research Data Management, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/14178789">https://zenodo.org/records/14178789</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.14178789">https://doi.org/10.5281/zenodo.14178789</a></p>
</section>
<hr class="docutils" />
<section id="arivis-vision4d-tutorials">
<h2>arivis Vision4D Tutorials<a class="headerlink" href="#arivis-vision4d-tutorials" title="Link to this heading">#</a></h2>
<p>Licensed ALL RIGHTS RESERVED</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Collection, Video</p>
<p><a class="reference external" href="https://www.youtube.com/playlist?list=PLRc9dt9lEZh_SVRC4G5moOvgHuvjPwmv0">https://www.youtube.com/playlist?list=PLRc9dt9lEZh_SVRC4G5moOvgHuvjPwmv0</a></p>
</section>
<hr class="docutils" />
<section id="bioformats2raw-converter">
<h2>bioformats2raw Converter<a class="headerlink" href="#bioformats2raw-converter" title="Link to this heading">#</a></h2>
<p>Melissa Linkert, Chris Allan, Josh Moore, Sébastien Besson, David Gault, et al.</p>
<p>Licensed GPL-2.0</p>
<p>Java application to convert image file formats, including .mrxs, to an intermediate Zarr structure compatible with the OME-NGFF specification.</p>
<p>Tags: Open Source Software, Exclude From Dalia</p>
<p>Content type: Application, Github Repository</p>
<p><a class="github reference external" href="https://github.com/glencoesoftware/bioformats2raw">glencoesoftware/bioformats2raw</a></p>
</section>
<hr class="docutils" />
<section id="bioimageio-chatbot">
<h2>bioimageio-chatbot<a class="headerlink" href="#bioimageio-chatbot" title="Link to this heading">#</a></h2>
<p>Wei Ouyang, Wanlu Lei, Caterina Fuster-Barceló, Gabe Reder, arratemunoz, Weize, Curtis Rueden, Matt McCormick</p>
<p>Published 2023-10-10T16:05:49+00:00</p>
<p>Licensed MIT</p>
<p>Your Personal Assistant in Computational Bioimaging.</p>
<p>Tags: Artificial Intelligence, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/bioimage-io/bioimageio-chatbot">bioimage-io/bioimageio-chatbot</a></p>
</section>
<hr class="docutils" />
<section id="cba-support-template">
<h2>cba-support-template<a class="headerlink" href="#cba-support-template" title="Link to this heading">#</a></h2>
<p>Arif Khan, Christian Tischer, Sebastian Gonzalez, Dominik Kutra, Felix Schneider, et al.</p>
<p>Published 2021-12-01</p>
<p>Licensed MIT</p>
<p>Tags: Workflow, Research Data Management, Exclude From Dalia</p>
<p>Content type: Tutorial</p>
<p><a class="reference external" href="https://git.embl.de/grp-cba/cba-support-template">https://git.embl.de/grp-cba/cba-support-template</a></p>
</section>
<hr class="docutils" />
<section id="cellpose-training-data">
<h2>cellpose training data<a class="headerlink" href="#cellpose-training-data" title="Link to this heading">#</a></h2>
<p>Carsen Stringer, Tim Wang, Michalis Michaelos, Marius Pachitariu</p>
<p>Published 2020-12-14</p>
<p>Licensed CUSTOM LICENSE</p>
<p>This is a cellpose training dataset. Cellpose is a generalist deep learning model for cell segmentation.</p>
<p>Tags: Ai-Ready, Exclude From Dalia</p>
<p>Content type: Data</p>
<p><a class="reference external" href="https://www.cellpose.org/dataset">https://www.cellpose.org/dataset</a></p>
</section>
<hr class="docutils" />
<section id="datenbiene">
<h2>datenbiene<a class="headerlink" href="#datenbiene" title="Link to this heading">#</a></h2>
<p>Torsten Stöter</p>
<p>Published 2025-02-02T18:50:20+00:00</p>
<p>Licensed GNU GENERAL PUBLIC LICENSE V3.0</p>
<p>Tags: Research Data Management, Exclude From Dalia</p>
<p>Content type: Github Repository, Software</p>
<p><a class="github reference external" href="https://github.com/tstoeter/datenbiene">tstoeter/datenbiene</a></p>
</section>
<hr class="docutils" />
<section id="de-nbi-youtube-channel">
<h2>de.NBI YouTube Channel<a class="headerlink" href="#de-nbi-youtube-channel" title="Link to this heading">#</a></h2>
<p>de.NBI</p>
<p>Published 2015-08-28</p>
<p>Licensed UNKNOWN</p>
<p>The de.NBI (German Network for Bioformatics Infrastructure) Youtube channel (<a class="reference external" href="http://www.denbi.de/">http://www.denbi.de/</a>)</p>
<p>Tags: Bioinformatics, Exclude From Dalia</p>
<p>Content type: Youtube Channel</p>
<p><a class="reference external" href="https://www.youtube.com/&#64;denbi5170">https://www.youtube.com/&#64;denbi5170</a></p>
</section>
<hr class="docutils" />
<section id="de-nbi-cloud-access-registration-guide">
<h2>de.NBI cloud access registration guide<a class="headerlink" href="#de-nbi-cloud-access-registration-guide" title="Link to this heading">#</a></h2>
<p>de.NBI</p>
<p>Published 2024-11-04</p>
<p>Licensed UNKNOWN</p>
<p>Tutorial for registering for de.NBI cloud access</p>
<p>Tags: Bioinformatics, Cloud Computing, Exclude From Dalia</p>
<p>Content type: Tutorial</p>
<p><a class="reference external" href="https://cloud.denbi.de/wiki/registration/">https://cloud.denbi.de/wiki/registration/</a></p>
</section>
<hr class="docutils" />
<section id="denbi-online-training-media-library">
<h2>deNBI Online Training Media Library<a class="headerlink" href="#denbi-online-training-media-library" title="Link to this heading">#</a></h2>
<p>de.NBI</p>
<p>Licensed UNKNOWN</p>
<p>The de.NBI (German Network for Bioformatics Infrastructure) Online Training &amp; Media Library provides a collection of training materials for bioinformatics and computational biology.</p>
<p>Tags: Bioinformatics, Galaxy, Exclude From Dalia</p>
<p>Content type: Website</p>
<p><a class="reference external" href="https://www.denbi.de/online-training-media-library">https://www.denbi.de/online-training-media-library</a></p>
</section>
<hr class="docutils" />
<section id="dmtxsamplecreator">
<h2>dmtxSampleCreator<a class="headerlink" href="#dmtxsamplecreator" title="Link to this heading">#</a></h2>
<p>SaibotMagd</p>
<p>Published 2023-06-06T11:52:14+00:00</p>
<p>Licensed APACHE-2.0</p>
<p>firefox extension: reads datamatrix code from camera and create a sample in an inventory to link it into an ELN.</p>
<p>Tags: Nfdi4Bioimage, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/SaibotMagd/dmtxSampleCreator">SaibotMagd/dmtxSampleCreator</a></p>
</section>
<hr class="docutils" />
<section id="embo-bia-2025">
<h2>embo-bia-2025<a class="headerlink" href="#embo-bia-2025" title="Link to this heading">#</a></h2>
<p>Kevin Yamauchi</p>
<p>Published 2025-08-18T09:32:20+00:00</p>
<p>Licensed BSD-3-CLAUSE</p>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/kevinyamauchi/embo-bia-2025">kevinyamauchi/embo-bia-2025</a></p>
</section>
<hr class="docutils" />
<section id="i2k-2020-s3-zarr-workshop">
<h2>i2k-2020-s3-zarr-workshop<a class="headerlink" href="#i2k-2020-s3-zarr-workshop" title="Link to this heading">#</a></h2>
<p>Constantin Pape, Christian Tischer</p>
<p>Licensed UNKNOWN</p>
<p>Tags: Python, Big Data, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/tischi/i2k-2020-s3-zarr-workshop">tischi/i2k-2020-s3-zarr-workshop</a></p>
</section>
<hr class="docutils" />
<section id="ilastik-interactive-machine-learning-for-bio-image-analysis">
<h2>ilastik: interactive machine learning for (bio)image analysis<a class="headerlink" href="#ilastik-interactive-machine-learning-for-bio-image-analysis" title="Link to this heading">#</a></h2>
<p>Anna Kreshuk, Dominik Kutra</p>
<p>Licensed CC-BY-4.0</p>
<p>Tags: Artificial Intelligence, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Slides</p>
<p><a class="reference external" href="https://zenodo.org/doi/10.5281/zenodo.4330625">https://zenodo.org/doi/10.5281/zenodo.4330625</a></p>
</section>
<hr class="docutils" />
<section id="imaris-file-not-read-by-bfgetreader">
<h2>imaris file not read by bfGetReader()<a class="headerlink" href="#imaris-file-not-read-by-bfgetreader" title="Link to this heading">#</a></h2>
<p>Julien Dubrulle</p>
<p>Published 2025-03-10</p>
<p>Licensed CC-BY-4.0</p>
<p>This file cannot be read by bfGetReader() v8.1.1 on a Windows operating workstation.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/15001649">https://zenodo.org/records/15001649</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.15001649">https://doi.org/10.5281/zenodo.15001649</a></p>
</section>
<hr class="docutils" />
<section id="martinschatz-cz-scicount-v1-0-0-with-reusable-example-notebooks">
<h2>martinschatz-cz/SciCount: v1.0.0 with reusable example notebooks<a class="headerlink" href="#martinschatz-cz-scicount-v1-0-0-with-reusable-example-notebooks" title="Link to this heading">#</a></h2>
<p>Martin Schätz, Lukáš Mrazík, Karolina Máhlerova</p>
<p>Published 2022-08-02</p>
<p>Licensed OTHER-OPEN</p>
<p>The first version contains an example of augmentation of scientific data and object detection with YOLO_v5 on colony counting (2 classes), object counting in blood smears (can be used as semisupervised learning for faster annotation), and wildlife detection from night records with a camera trap.</p>
<p>The project is available on GitHub.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/6953610">https://zenodo.org/records/6953610</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.6953610">https://doi.org/10.5281/zenodo.6953610</a></p>
</section>
<hr class="docutils" />
<section id="microlist">
<h2>microlist<a class="headerlink" href="#microlist" title="Link to this heading">#</a></h2>
<p>Licensed ALL RIGHTS RESERVED</p>
<p>A searchable database of resources for light and electron microscopists</p>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Collection</p>
<p><a class="reference external" href="https://www.microlist.org/">https://www.microlist.org/</a></p>
</section>
<hr class="docutils" />
<section id="ome-ngff-validator">
<h2>ome-ngff-validator<a class="headerlink" href="#ome-ngff-validator" title="Link to this heading">#</a></h2>
<p>Will Moore, Josh Moore, Yaroslav Halchenko, Sébastien Besson</p>
<p>Published 2022-09-29</p>
<p>Licensed BSD-2-CLAUSE</p>
<p>Web page for validating OME-NGFF files.</p>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Github Repository, Application</p>
<p><a class="reference external" href="https://ome.github.io/ome-ngff-validator/">https://ome.github.io/ome-ngff-validator/</a></p>
<p><a class="github reference external" href="https://github.com/ome/ome-ngff-validator">ome/ome-ngff-validator</a></p>
</section>
<hr class="docutils" />
<section id="ome2024-ngff-challenge">
<h2>ome2024-ngff-challenge<a class="headerlink" href="#ome2024-ngff-challenge" title="Link to this heading">#</a></h2>
<p>Will Moore, Josh Moore, sherwoodf, jean-marie burel, Norman Rzepka, dependabot[bot], JensWendt, Joost de Folter, Torsten St\xF6ter, AybukeKY, Eric Perlman, Tom Boissonnet</p>
<p>Published 2024-08-30T12:00:53+00:00</p>
<p>Licensed BSD-3-CLAUSE</p>
<p>Project planning and material repository for the 2024 challenge to generate 1 PB of OME-Zarr data</p>
<p>Tags: Sharing, Nfdi4Bioimage, Research Data Management, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/ome/ome2024-ngff-challenge">ome/ome2024-ngff-challenge</a></p>
</section>
<hr class="docutils" />
<section id="omero-arc">
<h2>omero-arc<a class="headerlink" href="#omero-arc" title="Link to this heading">#</a></h2>
<p>Christoph Moehl, Peter Zentis, Niraj Kandpal</p>
<p>Published 2023-12-18T16:11:04+00:00</p>
<p>Licensed GNU GENERAL PUBLIC LICENSE V3.0</p>
<p>Library to export OMERO projects to ARC repositories</p>
<p>Tags: OMERO, Research Data Management, Exclude From Dalia</p>
<p>Content type: Github Repository, Software</p>
<p><a class="github reference external" href="https://github.com/cmohl2013/omero-arc">cmohl2013/omero-arc</a></p>
</section>
<hr class="docutils" />
<section id="omero-ontop-mappings">
<h2>omero-ontop-mappings<a class="headerlink" href="#omero-ontop-mappings" title="Link to this heading">#</a></h2>
<p>Carsten Fortmann-Grote, andrawaag, Jerven Bolleman</p>
<p>Published 2024-09-13T08:01:09+00:00</p>
<p>ONTOP module for querying OMERO with SPARQL</p>
<p>Tags: OMERO, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/German-BioImaging/omero-ontop-mappings">German-BioImaging/omero-ontop-mappings</a></p>
</section>
<hr class="docutils" />
<section id="omero-quay">
<h2>omero-quay<a class="headerlink" href="#omero-quay" title="Link to this heading">#</a></h2>
<p>Alexis Lebon, Anatole Chessel, Raphael Braud-Mussi, Marine Breuilly, Denis Ressnikoff, Dorian Kauffmann, Elvire Guiot, Emmanuel Faure, Perrine Gilloteaux, Guillaume Gay, Guillaume Jean-François, Jerome Mutterer, Paulette Lieby, Julio Mateos-Langerak, Guillaume Maucort, Marc Mongy, Mylene Pezet, Sotirios Papadiamantis, Théo Barnouin, Mathieu Vigneau</p>
<p>Published 2023-06-16</p>
<p>Licensed MPL-2.0</p>
<p>omero-quay is a microscopy data transport layer between data management tools. Currently, it supports the iRODS — OMERO architecture built at France BioImaging fbi-omero.</p>
<p>Tags: Data Management, OMERO, Exclude From Dalia</p>
<p>Content type: Gitlab Repository</p>
<p><a class="reference external" href="https://gitlab.in2p3.fr/fbi-data/omero-quay">https://gitlab.in2p3.fr/fbi-data/omero-quay</a></p>
</section>
<hr class="docutils" />
<section id="omero-vitessce">
<h2>omero-vitessce<a class="headerlink" href="#omero-vitessce" title="Link to this heading">#</a></h2>
<p>Michele Bortolomeazzi</p>
<p>Published 2024-11-25T10:51:01+00:00</p>
<p>Licensed AGPL-3.0</p>
<p><a class="reference external" href="http://OMERO.web">OMERO.web</a> plugin for the Vitessce multimodal data viewer.</p>
<p>Tags: OMERO, Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/NFDI4BIOIMAGE/omero-vitessce">NFDI4BIOIMAGE/omero-vitessce</a></p>
</section>
<hr class="docutils" />
<section id="patho-prompt-injection">
<h2>patho_prompt_injection<a class="headerlink" href="#patho-prompt-injection" title="Link to this heading">#</a></h2>
<p>JanClusmann, Tim Lenz</p>
<p>Published 2024-11-08T08:32:03+00:00</p>
<p>Licensed GPL-3.0</p>
<p>Tags: Histopathology, Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Github Repository, Notebook</p>
<p><a class="github reference external" href="https://github.com/KatherLab/patho_prompt_injection">KatherLab/patho_prompt_injection</a></p>
</section>
<hr class="docutils" />
<section id="quantixed-thedigitalcell-first-complete-code-set">
<h2>quantixed/TheDigitalCell: First complete code set<a class="headerlink" href="#quantixed-thedigitalcell-first-complete-code-set" title="Link to this heading">#</a></h2>
<p>Stephen Royle</p>
<p>Published 2019-04-17</p>
<p>Licensed GPL-3.0</p>
<p>First complete code set for The Digital Cell book.</p>
<p>Tags: Bioimage Analysis, Exclude From Dalia</p>
<p>Content type: Code</p>
<p><a class="github reference external" href="https://github.com/quantixed/TheDigitalCell">quantixed/TheDigitalCell</a></p>
<p><a class="reference external" href="https://zenodo.org/records/2643411">https://zenodo.org/records/2643411</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.2643411">https://doi.org/10.5281/zenodo.2643411</a></p>
</section>
<hr class="docutils" />
<section id="raw2ometiff-converter">
<h2>raw2ometiff Converter<a class="headerlink" href="#raw2ometiff-converter" title="Link to this heading">#</a></h2>
<p>Melissa Linkert, Chris Allan, Sébastien Besson, Josh Moore</p>
<p>Licensed GPL-2.0</p>
<p>Java application to convert a directory of tiles to an OME-TIFF pyramid. This is the second half of iSyntax/.mrxs =&gt; OME-TIFF conversion.</p>
<p>Tags: Open Source Software, Exclude From Dalia</p>
<p>Content type: Application, Github Repository</p>
<p><a class="github reference external" href="https://github.com/glencoesoftware/raw2ometiff">glencoesoftware/raw2ometiff</a></p>
</section>
<hr class="docutils" />
<section id="re3data-org-registry-of-research-data-repositories">
<h2><a class="reference external" href="http://re3data.org">re3data.org</a> - registry of Research Data Repositories<a class="headerlink" href="#re3data-org-registry-of-research-data-repositories" title="Link to this heading">#</a></h2>
<p>Licensed CC-BY-4.0</p>
<p>Re3data is a global registry of research data repositories that covers research data repositories from different academic disciplines. It includes repositories that enable permanent storage of and access to data sets to researchers, funding bodies, publishers, and scholarly institutions.</p>
<p>Tags: Research Data Management, Exclude From Dalia</p>
<p>Content type: Website</p>
<p><a class="reference external" href="https://www.re3data.org/">https://www.re3data.org/</a></p>
</section>
<hr class="docutils" />
<section id="training">
<h2>training<a class="headerlink" href="#training" title="Link to this heading">#</a></h2>
<p>Erick Martins Ratamero, dependabot[bot]</p>
<p>Published 2020-03-09T13:25:54+00:00</p>
<p>Licensed MIT</p>
<p>repo for training materials</p>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/erickmartins/training">erickmartins/training</a></p>
<hr class="docutils" />
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./tags"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="data_stewardship.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Data stewardship (6)</p>
      </div>
    </a>
    <a class="right-next"
       href="fair-principles.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Fair-principles (29)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lif-files-misbehaving-in-fiji-but-fine-in-lasx">.lif files misbehaving in fiji but fine in LASX</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#frames-of-fluorescent-particles">10 frames of fluorescent particles</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-science-bowl">2018 Data Science Bowl</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimage-analysis-survey-community-experiences-and-needs-for-the-future">2020 BioImage Analysis Survey: Community experiences and needs for the future</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#d-ground-truth-annotations-of-nuclei-in-3d-microscopy-volumes">3D Ground Truth Annotations of Nuclei in 3D Microscopy Volumes</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#d-hl60-cell-line-synthetic-data">3D HL60 Cell line (synthetic data)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#d-nuclei-annotations-and-stardist-3d-model-s-rat-brain">3D Nuclei annotations and StarDist 3D model(s) (rat brain)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#d-cell-shape-of-drosophila-wing-disc">3D cell shape of Drosophila Wing Disc</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#d-light-sheet-microscopy-data-for-selma3d-2024-challenge-training-subset-with-annotations">3D light-sheet microscopy data for SELMA3D 2024 challenge - Training subset with annotations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#d-nuclei-instance-segmentation-dataset-of-fluorescence-microscopy-volumes-of-c-elegans">3D nuclei instance segmentation dataset of fluorescence microscopy volumes of C. elegans</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-cloud-optimized-storage-for-interactive-access-of-large-arrays">A Cloud-Optimized Storage for Interactive Access of Large Arrays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-glimpse-of-the-open-source-flim-analysis-software-tools-flimfit-flute-and-napari-flim-phasor-plotter">A Glimpse of the Open-Source FLIM Analysis Software Tools FLIMfit, FLUTE and napari-flim-phasor-plotter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-call-for-public-archives-for-biological-image-data">A call for public archives for biological image data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-checklist-for-designing-and-improving-the-visualization-of-scientific-data">A checklist for designing and improving the visualization of scientific data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-deep-learning-approach-to-quantify-auditory-hair-cells">A deep learning approach to quantify auditory hair cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-mihc-mrxs-example">A mihc mrxs example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-study-on-long-term-reproducibility-of-image-analysis-results-on-imagej-and-fiji">A study on long-term reproducibility of image analysis results on ImageJ and Fiji</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abic-intermediate-fiji-image-analysis-course-2024">ABIC - Intermediate Fiji Image Analysis Course 2024</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ai4life-teams-up-with-galaxy-training-network-gtn-to-enhance-training-resources">AI4Life teams up with Galaxy Training Network (GTN) to enhance training resources</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abdominal-imaging-window-aiw-for-intravital-imaging">Abdominal Imaging Window (AIW) for Intravital Imaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#aberrated-bead-stack">Aberrated Bead Stack</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abstract-nfdi-basic-service-for-data-management-plans">Abstract - NFDI Basic Service for Data Management Plans</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#adding-a-workflow-to-biaflows">Adding a Workflow to BIAFLOWS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#an-annotated-fluorescence-image-dataset-for-training-nuclear-segmentation-methods">An annotated fluorescence image dataset for training nuclear segmentation methods</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#an-annotated-high-content-fluorescence-microscopy-dataset-with-hoechst-33342-stained-nuclei-and-manually-labelled-outlines">An annotated high-content fluorescence microscopy dataset with Hoechst 33342-stained nuclei and manually labelled outlines</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#an-image-based-data-driven-analysis-of-cellular-architecture-in-a-developing-tissue">An image-based data-driven analysis of cellular architecture in a developing tissue</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#andor-dragonfly-confocal-image-of-bpae-cells-stained-for-actin-ims-file-format">Andor Dragonfly confocal image of BPAE cells stained for actin, IMS file format</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#angebote-der-nfdi-fur-die-forschung-im-bereich-zoologie">Angebote der NFDI für die Forschung im Bereich Zoologie</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#annotated-research-context-arc">Annotated Research Context (ARC</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#annotated-high-throughput-microscopy-image-sets-for-validation">Annotated high-throughput microscopy image sets for validation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#artificial-blobs-and-labels-image">Artificial Blobs and Labels image</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assessment-of-residual-breast-cancer-cellularity-after-neoadjuvant-chemotherapy-using-digital-pathology">Assessment of Residual Breast Cancer Cellularity after Neoadjuvant Chemotherapy using Digital Pathology</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#astigmatic-4pi-bead-stack">Astigmatic 4Pi bead stack</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#automatic-labelling-of-hela-kyoto-cells-using-deep-learning-tools">Automatic labelling of HeLa “Kyoto” cells using Deep Learning tools</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#axioscan-7-fluorescent-channels-not-displaying-in-qupath">Axioscan 7 fluorescent channels not displaying in QuPath</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bccd-dataset">BCCD Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bhg2023-omero-arc">BHG2023-OMERO-ARC</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bia-seminar-series">BIA Seminar Series</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bids-lecture-2024">BIDS-lecture-2024</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#biomero-a-scalable-and-extensible-image-analysis-framework">BIOMERO - A scalable and extensible image analysis framework</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#beads-imaged-over-time">Beads imaged over time</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#biapy-bioimage-analysis-pipelines-in-python">BiaPy: Bioimage analysis pipelines in Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bigdataprocessor2-a-free-and-open-source-fiji-plugin-for-inspection-and-processing-of-tb-sized-image-data">BigDataProcessor2: A free and open-source Fiji plugin for inspection and processing of TB sized image data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis">Bio Image Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis-lecture-2020">Bio Image Analysis Lecture 2020</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-analysis-icob-2023">Bio-image Analysis ICOB 2023</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-data-science-lectures-2025-uni-leipzig-scads-ai">Bio-image Data Science Lectures 2025 @ Uni Leipzig / ScaDS.AI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-image-data-science-lectures-uni-leipzig-scads-ai">Bio-image Data Science Lectures @ Uni Leipzig / ScaDS.AI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bio-tools-database">Bio.tools database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioengine">BioEngine</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioengine-documentation">BioEngine Documentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioformats-command-line-cli-tools">BioFormats Command line (CLI) tools</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimage-archive-ai-gallery">BioImage Archive AI Gallery</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimage-archive-visual-gallery">BioImage Archive Visual Gallery</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimage-archive-volume-em-gallery">BioImage Archive Volume EM Gallery</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimage-informatics-index-training-materials">BioImage Informatics Index Training Materials</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimage-archive">Bioimage Archive</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimage-model-zoo">Bioimage Model Zoo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimaging-workflow-based-on-omero-elabftw-and-adamant-for-integrating-images-with-multimodal-metadata">Bioimaging workflow based on OMERO, eLabFTW, and Adamant for integrating images with multimodal metadata</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#biologists-stop-putting-umap-plots-in-your-papers">Biologists, stop putting UMAP plots in your papers</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#biomero">Biomero</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#breast-cancer-nuclei-images-for-dl-training-zerocostdl4mic-stardist-model">Breast Cancer Nuclei images for DL Training + ZeroCostDL4Mic StarDist Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#breast-cancer-semantic-segmentation-bcss-dataset">Breast Cancer Semantic Segmentation (BCSS) dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bridging-imaging-users-to-imaging-analysis-a-community-survey">Bridging Imaging Users to Imaging Analysis - A community survey</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bring-your-own-data-workshops">Bring your own data workshops</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-fair-image-analysis-pipelines-for-high-content-screening-hcs-data-using-galaxy">Building FAIR image analysis pipelines for high-content-screening (HCS) data using Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-a-fair-image-data-ecosystem-for-microscopy-communities">Building a FAIR image data ecosystem for microscopy communities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clij-gpu-accelerated-image-processing-for-everyone">CLIJ: GPU-accelerated image processing for everyone</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coba-nih-2024-bridging-imaging-users-to-imaging-analysis-survey-survey-data-with-preliminary-exploration">COBA-NIH/2024_Bridging_Imaging_Users_to_Imaging_Analysis_Survey: Survey data with preliminary exploration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coba-center-for-open-bioimage-analysis-youtube-channel">COBA: Center for Open Bioimage Analysis YouTube Channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ct-physics">CT Physics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#czi-carl-zeiss-image-dataset-with-artificial-test-camera-images-with-various-dimension-for-testing-libraries-reading">CZI (Carl Zeiss Image) dataset with artificial test camera images with various dimension for testing libraries reading</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#czi-file-examples">CZI file examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#czi-open-science-program-collection">CZI: Open Science Program Collection</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-tracking-challenge-2d-datasets">Cell Tracking Challenge - 2D Datasets</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-tracking-challenge-3d-datasets">Cell Tracking Challenge - 3D Datasets</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellbindb-a-large-scale-multimodal-annotated-dataset">CellBinDB: A Large-Scale Multimodal Annotated Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#celltrackcolab">CellTrackColab</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellpose-model-for-digital-phase-contrast-images">Cellpose model for Digital Phase Contrast images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellpose-models-for-label-prediction-from-brightfield-and-digital-phase-contrast-images">Cellpose models for Label Prediction from Brightfield and Digital Phase Contrast images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellpose-training-data-and-scripts-from-inhibition-of-cers1-in-aging-skeletal-muscle-exacerbates-age-related-muscle-impairments">Cellpose training data and scripts from “Inhibition of CERS1 in aging skeletal muscle exacerbates age-related muscle impairments”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellpose-training-data-and-scripts-from-machine-learning-for-histological-annotation-and-quantification-of-cortical-layers">Cellpose training data and scripts from “Machine learning for histological annotation and quantification of cortical layers”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#checklists-for-publishing-images-and-image-analysis">Checklists for publishing images and image analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chinese-hamster-ovary-cells">Chinese Hamster Ovary Cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#choose-an-open-source-license">Choose an open source license</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#chris-halvin-youtube-channel">Chris Halvin YouTube channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cloud-based-virtual-desktops-for-reproducible-research">Cloud-Based Virtual Desktops for Reproducible Research</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#collaborative-working-and-version-control-with-git-hub">Collaborative working and  Version Control with Git[Hub]</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#combining-stardist-and-trackmate-example-1-breast-cancer-cell-dataset">Combining StarDist and TrackMate example 1 -  Breast cancer cell dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#combining-stardist-and-trackmate-example-2-t-cell-dataset">Combining StarDist and TrackMate example 2 -  T cell dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#combining-stardist-and-trackmate-example-3-flow-chamber-dataset">Combining StarDist and TrackMate example 3 -  Flow chamber dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#combining-the-bids-and-arc-directory-structures-for-multimodal-research-data-organization">Combining the BIDS and ARC Directory Structures for Multimodal Research Data Organization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conference-slides-4th-day-of-intravital-microscopy">Conference Slides - 4th Day of Intravital Microscopy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cryonuseg">CryoNuSeg</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dcimg-dense-beads-taken-in-chunks-over-time">DCIMG dense beads taken in chunks over time</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-napari-napari-as-a-tool-for-deep-learning-project-management">DEEP NAPARI : Napari as a tool for deep learning project management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dl4miceverywhere">DL4MicEverywhere</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dl4proteins-notebooks">DL4Proteins-notebooks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dl-mbl-2021-exercises">DL@MBL 2021 Exercises</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dng-in-bioformat-opens-in-wrong-resolution">DNG in BioFormat opens in wrong resolution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dask-course">Dask Course</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-stewardship-wizard">Data Stewardship Wizard</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-life-cycle">Data life cycle</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-from-incell-2200-microscope-misread-as-a-plate">Dataset from InCell 2200 microscope misread as a plate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deconvolution-test-dataset">Deconvolution Test Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-learning-segmentation-projects-of-fib-sem-dataset-of-u2-os-cell">Deep learning segmentation projects of FIB-SEM dataset of U2-OS cell</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deep-learning-training-data-jove">Deep learning training data (JOVE)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deepbacs-bacillus-subtilis-fluorescence-segmentation-dataset">DeepBacs – Bacillus subtilis fluorescence segmentation dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deepbacs-escherichia-coli-bright-field-segmentation-dataset">DeepBacs – Escherichia coli bright field segmentation dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deepbacs-mixed-segmentation-dataset-and-stardist-model">DeepBacs – Mixed segmentation dataset and StarDist model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deepbacs-staphylococcus-aureus-widefield-segmentation-dataset">DeepBacs – Staphylococcus aureus widefield segmentation dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#democratizing-knowledge-representation-with-biocypher">Democratizing knowledge representation with BioCypher</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#detection-and-segmentation-of-cell-nuclei-in-virtual-microscopy-images-a-minimum-model-approach">Detection and Segmentation of Cell Nuclei in Virtual Microscopy Images A Minimum-Model Approach</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#developing-semi-automatic-analysis-pipelines-and-technological-solutions-for-metadata-annotation-and-management-in-high-content-screening-hcs-bioimaging">Developing (semi)automatic analysis pipelines and technological solutions for metadata annotation and management in high-content screening (HCS) bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#development-fair-image-analysis-workflows-and-rdm-pipelines-in-galaxy">Development FAIR image analysis workflows and RDM pipelines in Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diffusion-models-for-image-restoration-an-introduction">Diffusion Models for Image Restoration - An Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#digital-phase-contrast-on-primary-dermal-human-fibroblasts-cells">Digital Phase Contrast on Primary Dermal Human Fibroblasts cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#digitalsreeni-youtube-channel">DigitalSreeni YouTube Channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dokumentation-und-anleitung-zum-elektronischen-laborbuch-elabftw">Dokumentation und Anleitung zum elektronischen Laborbuch (eLabFTW)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#drosophila-kc167-cells">Drosophila Kc167 cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#edam-bioimaging-the-ontology-of-bioimage-informatics-operations-topics-data-and-formats">EDAM-bioimaging - The ontology of bioimage informatics operations, topics, data, and formats</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embl-ebi-material-collection">EMBL-EBI material collection</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embo-practical-course-advanced-methods-in-bioimage-analysis">EMBO Practical Course Advanced methods in bioimage analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#epflx-image-processing-and-analysis-for-life-scientists">EPFLx: Image Processing and Analysis for Life Scientists</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#effect-of-local-topography-on-cell-division-of-staphylococci-sp">Effect of local topography on cell division of Staphylococci sp.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embedseg-repository">EmbedSeg Repository</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embryonic-mice-ultrasound-volumes-with-body-and-brain-volume-segmentation-masks">Embryonic mice ultrasound volumes with body and brain volume segmentation masks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#enabling-global-image-data-sharing-in-the-life-sciences">Enabling Global Image Data Sharing in the Life Sciences</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#erick-martins-ratamero-expanding-the-ome-ecosystem-for-imaging-data-management-scipy-2024">Erick Martins Ratamero - Expanding the OME ecosystem for imaging data management | SciPy 2024</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-scientific-ambassadors-program">Euro-BioImaging  Scientific Ambassadors Program</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-annual-report-2020">Euro-BioImaging Annual Report 2020</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-annual-report-2021">Euro-BioImaging Annual Report 2021</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-annual-report-2023">Euro-BioImaging Annual Report 2023</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-annual-report-2024">Euro-BioImaging Annual Report 2024</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-communication-youtube-channel">Euro-BioImaging Communication YouTube Channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-eric-annual-report-2022">Euro-BioImaging ERIC Annual Report 2022</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-s-template-for-research-data-management-plans">Euro-BioImaging’s Template for Research Data Management Plans</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#euro-bioimaging-batchconvert-v0-0-4">Euro-BioImaging/BatchConvert: v0.0.4</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evident-oir-sample-files-tiles-stitched-image-fv-4000">Evident OIR sample files tiles + stitched image - FV 4000</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evident-oir-sample-files-with-lambda-scan-fv-4000">Evident OIR sample files with lambda scan - FV 4000</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-imaris-ims-datasets">Example Imaris ims datasets.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-microscopy-metadata-json-files-produced-using-micro-meta-app-to-document-example-microscopy-experiments-performed-at-individual-core-facilities">Example Microscopy Metadata JSON files produced using Micro-Meta App to document example microscopy experiments performed at individual core facilities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-operetta-dataset">Example Operetta Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-pipeline-tutorial">Example Pipeline Tutorial</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#excel-template-for-adding-key-value-pairs-to-images">Excel template for adding Key-Value Pairs to images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fair-bioimage-data">FAIR BioImage Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fair-high-content-screening-in-bioimaging">FAIR High Content Screening in Bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fiber-and-vessel-dataset-for-segmentation-and-characterization">Fiber and vessel dataset for segmentation and characterization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fiji">Fiji</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fiji-is-just-imagej-tutorials">Fiji Is Just ImageJ Tutorials</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fit-for-omero-how-imaging-facilities-and-it-departments-work-together-to-enable-rdm-for-bioimaging">Fit for OMERO: How imaging facilities and IT departments work together to enable RDM for bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forschungsdatenmanagement-zukunftsfest-gestalten-impulse-fur-die-strukturevaluation-der-nationalen-forschungsdateninfrastruktur-nfdi">Forschungsdatenmanagement zukunftsfest gestalten – Impulse für die   Strukturevaluation der Nationalen Forschungsdateninfrastruktur (NFDI)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fractal-documentation">Fractal Documentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#galaxy-documentation">Galaxy Documentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#galaxy-imaging">Galaxy Imaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#galaxy-training">Galaxy Training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#galaxy-training-material">Galaxy Training Material</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#galaxyproject-youtube-channel">GalaxyProject YouTube Channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gerbi-teaching-resources-link-list">GerBI Teaching Resources Link List</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gerbi-chat-teil-1-vom-bedarf-bis-zum-groszgerateantrag-schreiben">GerBI-Chat: Teil 1 - Vom Bedarf bis zum Großgeräteantrag-Schreiben</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gerbi-chat-teil-2-wie-schreibe-ich-am-besten-einen-groszegrateantrag">GerBI-Chat: Teil 2 - Wie schreibe ich am besten einen Großegräteantrag</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#get-started-accessing-the-de-nbi-cloud">Get started accessing the de.NBI cloud.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ghent-university-research-data-management-rdm-policy-and-support">Ghent University Research Data Management (RDM) - policy and support</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#glencoe-software-webinars">Glencoe Software Webinars</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#globias">GloBIAS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#globias-in-person-workshop-2024">GloBIAS in-person workshop 2024</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#global-bioimaging-training-database">Global BioImaging Training Database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#global-bioimaging-youtube-channel">Global BioImaging YouTube channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#go-nuclear-a-deep-learning-based-toolkit-for-3d-nuclei-segmentation-and-quantitative-analysis-in-cellular-and-tissue-context">Go-Nuclear. A deep learning-based toolkit for 3D nuclei segmentation and quantitative analysis in cellular and tissue context</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ground-truth-cell-body-segmentation-used-for-starfinity-training">Ground-truth cell body segmentation used for Starfinity training</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gut-analysis-toolbox">Gut Analysis Toolbox</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gut-analysis-toolbox-training-data-and-2d-models-for-segmenting-enteric-neurons-neuronal-subtypes-and-ganglia">Gut Analysis Toolbox: Training data and 2D models for segmenting enteric neurons, neuronal subtypes and ganglia</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hpa-nucleus-segmentation-dpnunet">HPA Nucleus Segmentation (DPNUnet)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ht1080wt-cells-embedded-in-3d-collagen-type-i-matrices-manual-annotations-for-cell-instance-segmentation-and-tracking">HT1080WT cells embedded in 3D collagen type I matrices - manual annotations for cell instance segmentation and tracking</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hackaton-results-conversion-of-knime-image-analysis-workflows-to-galaxy">Hackaton Results - Conversion of KNIME image analysis workflows to Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#harmonizing-the-generation-and-pre-publication-stewardship-of-fair-image-data">Harmonizing the Generation and Pre-publication Stewardship of FAIR Image Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hela-kyoto-cells-under-the-scope">HeLa “Kyoto” cells under the scope</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hitchhiking-through-a-diverse-bio-image-analysis-software-universe">Hitchhiking through a diverse Bio-image Analysis Software Universe</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-open-source-software-could-finally-get-the-worlds-microscopes-speaking-the-same-language">How open-source software could finally get the world’s microscopes speaking the same language</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-get-started-with-jupyter-and-colab">How to get started with Jupyter and Colab</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-make-cartographic-projections-using-imsane">How to make cartographic projections using ImSAnE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#human-dab-staining-axioscan-bf-20x">Human DAB staining Axioscan BF 20x</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#human-ht29-colon-cancer-cells">Human HT29 colon-cancer cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#human-hepatocyte-and-murine-fibroblast-cells-co-culture-experiment">Human Hepatocyte and Murine Fibroblast cells Co-culture experiment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#human-lung-tissue-microscopy-dic-fluorescence-cell-and-nuclei-semantic-instance-annotations">Human Lung Tissue Microscopy (DIC, Fluorescence, Cell and Nuclei Semantic Instance Annotations)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#human-u2os-cells-out-of-focus">Human U2OS cells (out of focus)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#i3d-bio-information-infrastructure-for-bioimage-data-bioimage-metadata">I3D bio – Information Infrastructure for BioImage Data - Bioimage Metadata</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#i3d-bio-list-of-online-training-material">I3D:bio list of online training material</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ics-ids-stitched-file">ICS/IDS stitched file</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#itkelastix-examples">ITKElastix Examples</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ibiology-bioimage-analysis-course-the-life-cycle-of-an-image-data-set">Ibiology. Bioimage Analysis Course. The Life Cycle of an Image Data Set</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-data-resources">Image Data Resources</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-data-services-at-euro-bioimaging-community-efforts-towards-fair-image-data-and-analysis-services">Image Data Services at Euro-BioImaging: Community efforts towards FAIR Image Data and Analysis Services</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-analysis-in-galaxy">Image analysis in Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imagej-bioformats-8-3-0-importer-incorrectly-reading-nd2-metadata">ImageJ Bioformats 8.3.0 Importer Incorrectly Reading ND2 Metadata</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imagej-tool-for-percentage-estimation-of-pneumonia-in-lungs">ImageJ tool for percentage estimation of pneumonia in lungs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#images-acquired-with-zeiss-sigma-300-images-with-low-magnification-are-corrently-not-handeled-correctly">Images acquired with Zeiss Sigma 300 - Images with low magnification are corrently not handeled correctly</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imaris-tutorials">Imaris Tutorials</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-kidney">Implantation of abdominal imaging windows on the mouse kidney</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-kidney-short-version">Implantation of abdominal imaging windows on the mouse kidney - short version</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-liver">Implantation of abdominal imaging windows on the mouse liver</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implantation-of-abdominal-imaging-windows-on-the-mouse-liver-short-version">Implantation of abdominal imaging windows on the mouse liver - short version</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#incell-datasets-with-mix-of-2d-and-3d-failed-to-be-read">InCell datasets with mix of 2D and 3D failed to be read</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ink-in-a-dish">Ink in a dish</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#insights-and-impact-from-five-cycles-of-essential-open-source-software-for-science">Insights and Impact From Five Cycles of Essential Open Source Software for Science</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#insights-from-acquiring-open-medical-imaging-datasets-for-foundation-model-development">Insights from Acquiring Open Medical Imaging  Datasets for Foundation Model Development</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Insights from Acquiring Open Medical Imaging Datasets for Foundation Model Development</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#institutionalization-and-collaboration-as-a-way-of-addressing-the-challenges-open-science-presents-to-libraries-the-university-of-konstanz-as-a-national-pioneer">Institutionalization and Collaboration as a Way of Addressing the Challenges Open Science Presents to Libraries: The University of Konstanz as a National Pioneer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#integration-of-bioimage-and-omics-data-resources">Integration of Bioimage and *Omics data resources</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#intravital-microscopy-contrasting-agents-for-application-database">Intravital microscopy contrasting agents for application - Database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introducing-omero-vitessce-an-omero-web-plugin-for-multi-modal-data">Introducing OMERO-vitessce: an OMERO.web plugin for multi-modal data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-light-microscopy-widefield-microscopy">Introduction to light-microscopy / Widefield microscopy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#jipipe-visual-batch-processing-for-imagej">JIPipe: visual batch processing for ImageJ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#jupyter-for-interactive-cloud-computing">Jupyter for interactive cloud computing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#knime-image-processing">KNIME Image Processing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pair-template-for-annotation-in-omero-for-light-microscopy-data-acquired-with-axioscan7-core-facility-cellular-imaging-cfci">Key-Value pair template for annotation in OMERO for light microscopy data acquired with AxioScan7 - Core Facility Cellular Imaging (CFCI)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pair-template-for-annotation-of-datasets-in-omero-perikles-study">Key-Value pair template for annotation of datasets in OMERO (PERIKLES study)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pair-template-for-annotation-of-datasets-in-omero-for-light-and-electron-microscopy-data-within-the-research-group-of-prof-muller-reichert">Key-Value pair template for annotation of datasets in OMERO for light- and electron microscopy data within the research group of Prof. Müller-Reichert</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-value-pairs-scripts">Key-Value pairs scripts</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#leo">LEO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#leo-linking-eln-with-omero">LEO: Linking ELN with OMERO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lmrg-image-analysis-study-fish-datasets">LMRG Image Analysis Study - FISH datasets</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lmrg-image-analysis-study-nuclei-datasets">LMRG Image Analysis Study - nuclei datasets</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lsm-example-j-dubrulle">LSM example J. Dubrulle</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lz4-compressed-imaris-ims-example-datasets">LZ4-compressed Imaris ims example datasets.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#large-tiling-confocal-acquisition-rat-brain">Large tiling confocal acquisition (rat brain)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laser-perturbation-imaging-data-for-patterned-invagination-prevents-mechanical-instability-during-gastrulation">Laser perturbation imaging data for: Patterned invagination prevents mechanical instability during gastrulation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laulauthom-maskfromrois-fiji-masks-from-rois-plugins-for-fiji-initial-release">LauLauThom/MaskFromRois-Fiji: Masks from ROIs plugins for Fiji - initial release</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#laulauthom-maskfromrois-fiji-v1-0-1-better-handle-cancel">LauLauThom/MaskFromRois-Fiji: v1.0.1 - better handle “cancel”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-materials-of-the-deeplife-course">Lecture-materials of the DeepLife course</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#leica-lif-file-with-errors-in-channel-order-when-imported-with-bio-formats">Leica (.lif) file with errors in channel order when imported with Bio-formats</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#leitlinie-grundsatze-policy-richtlinie-forschungsdaten-policies-an-deutschen-universitaten">Leitlinie? Grundsätze? Policy? Richtlinie? – Forschungsdaten-Policies an deutschen Universitäten</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#life-science-competence-centres-open-by-design">Life Science Competence Centres: Open by Design</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lightsheet-and-in-situ-imaging-data-for-patterned-invagination-prevents-mechanical-instability-during-gastrulation">Lightsheet and in situ imaging data for: Patterned invagination prevents mechanical instability during gastrulation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#limeseg-test-datasets">LimeSeg Test Datasets</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linked-open-data-for-microbial-population-biology">Linked (Open) Data for Microbial Population Biology</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linking-of-research-meta-data-in-omero-to-foster-fair-data-in-plasma-science">Linking of Research (Meta-)data in OMERO to Foster FAIR Data in Plasma Science</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lund-declaration-on-maximising-the-benefits-of-research-data">Lund Declaration on Maximising the Benefits of Research Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lynsec-lymphoma-nuclear-segmentation-and-classification">LyNSeC: Lymphoma Nuclear Segmentation and Classification</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mdemic-a-metadata-annotation-tool-to-facilitate-management-of-fair-image-data-in-the-bioimaging-community">MDEmic: a metadata annotation tool to facilitate management of FAIR image data in the bioimaging community</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#midog-2021">MIDOG 2021</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mri-physics">MRI Physics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-and-deep-learning-on-the-cloud-segmentation">Machine and Deep Learning on the cloud: Segmentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#masterclasses-from-the-euro-bioimaging-evolve-mentoring-programme-2025">Masterclasses from the Euro-Bioimaging EVOLVE Mentoring programme 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#materials-for-embl-coding-club-mini-tutorials">Materials for EMBL Coding Club Mini-Tutorials</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#measuring-reporter-activity-domain-in-epi-aggregates-and-gastruloids-ijm">Measuring reporter activity domain in EPI aggregates and Gastruloids.ijm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#melanoma-histopathology-dataset-with-tissue-and-nuclei-annotations">Melanoma Histopathology Dataset with Tissue and Nuclei Annotations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#melbourne-advanced-microscopy-facility">Melbourne Advanced Microscopy Facility</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#membrain-seg-training-data">MemBrain-seg training data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#memorandum-of-understanding-of-nfdi-consortia-from-earth-chemical-and-life-sciences-to-support-a-network-called-the-geo-chem-life-science-helpdesk-cluster">Memorandum of Understanding of NFDI consortia from Earth-, Chemical and Life Sciences to support a network called the Geo-Chem-Life Science Helpdesk Cluster</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metadata-annotation-workflow-for-omero-with-tabbles">Metadata Annotation Workflow for OMERO with Tabbles</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metadata-in-bioimaging">Metadata in Bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#methodsj2-a-software-tool-to-capture-metadata-and-generate-comprehensive-microscopy-methods-text">MethodsJ2: a software tool to capture metadata and generate comprehensive microscopy methods text</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#metrics-reloaded-a-framework-for-trustworthy-image-analysis-validation">Metrics Reloaded - A framework for trustworthy image analysis validation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mitobo-a-toolbox-for-image-processing-and-analysis">MiToBo - A Toolbox for Image Processing and Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#micro-meta-app-an-interactive-tool-for-collecting-microscopy-metadata-based-on-community-specifications">Micro-Meta App: an interactive tool for collecting microscopy metadata based on community specifications</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microsam-talks">MicroSam-Talks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microscopy-bids-an-extension-to-the-brain-imaging-data-structure-for-microscopy-data">Microscopy-BIDS - An Extension to the Brain Imaging Data Structure for Microscopy Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microscopydb">MicroscopyDB</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monuseg-dataset">MoNuSeg Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-and-simulations-for-patterned-invagination-prevents-mechanical-instability-during-gastrulation">Model and simulations for: Patterned invagination prevents mechanical instability during gastrulation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling-community-standards-for-metadata-as-templates-makes-data-fair">Modeling community standards for metadata as templates makes data FAIR</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#models-and-applications-for-bioimage-io">Models and Applications for BioImage.IO</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modular-training-resources-for-bioimage-analysis">Modular training resources for bioimage analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#modularimageanalysis-mia-assembly-of-modularisedimage-and-object-analysis-workflows-in-imagej">ModularImageAnalysis (MIA): Assembly of modularisedimage and object analysis workflows in ImageJ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monusac-2020">MonuSAC 2020</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#morpholibj-documentation">MorphoLibJ documentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mouse-embryo-blastocyst-cells">Mouse embryo blastocyst cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multimodal-large-language-models-for-bioimage-analysis">Multimodal large language models for bioimage analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multiplexed-histology-of-covid-19-post-mortem-lung-samples-control-case-1-fov1">Multiplexed histology of COVID-19 post-mortem lung samples - CONTROL CASE 1 FOV1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neubias-youtube-channel">NEUBIAS YouTube Channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi-daten-als-gemeinsames-gut-fur-exzellente-forschung-organisiert-durch-die-wissenschaft-in-deutschland">NFDI - Daten als gemeinsames Gut für exzellente Forschung, organisiert durch die Wissenschaft in Deutschland.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage">NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-an-initiative-for-a-national-research-data-infrastructure-for-microscopy-data">NFDI4BIOIMAGE - An Initiative for a National Research Data Infrastructure for Microscopy Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-national-research-data-infrastructure-for-microscopy-and-bioimage-analysis-conference-talk-the-pelagic-imaging-consortium-meets-helmholtz-imaging-5-10-2023-hamburg">NFDI4BIOIMAGE - National Research Data Infrastructure for Microscopy and BioImage Analysis [conference talk: The Pelagic Imaging Consortium meets Helmholtz Imaging, 5.10.2023, Hamburg]</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-a-consortium-of-the-national-research-data-infrastructure">NFDI4BIOIMAGE - a consortium of the National Research Data Infrastructure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-april-2025">NFDI4BIOIMAGE Calendar April 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-august-2025">NFDI4BIOIMAGE Calendar August 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-cover-2025">NFDI4BIOIMAGE Calendar Cover 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-december-2025">NFDI4BIOIMAGE Calendar December 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-february-2025">NFDI4BIOIMAGE Calendar February 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-january-2025">NFDI4BIOIMAGE Calendar January 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-july-2025">NFDI4BIOIMAGE Calendar July 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-june-2025">NFDI4BIOIMAGE Calendar June 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-march-2025">NFDI4BIOIMAGE Calendar March 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-may-2025">NFDI4BIOIMAGE Calendar May 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-november-2025">NFDI4BIOIMAGE Calendar November 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-october-2025">NFDI4BIOIMAGE Calendar October 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-september-2025">NFDI4BIOIMAGE Calendar September 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-perspective-for-a-national-bioimaging-standard">NFDI4BIOIMAGE: Perspective for a national bioimaging standard</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon">NFDI4Bioimage - TA3-Hackathon - UoC-2023 (Cologne Hackathon)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-ta3-hackathon-uoc-2023-cologne-hackathon-2023-github-repository">NFDI4Bioimage - TA3-Hackathon - UoC-2023 (Cologne-Hackathon-2023, GitHub repository)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-2024-october-original-image">NFDI4Bioimage Calendar 2024 October; original image</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-2025-march-original-image">NFDI4Bioimage Calendar 2025 March; original image</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfditalk-cloud-based-image-data-science">NFDITalk Cloud based image data science</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ngff-converter">NGFF Converter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nd2-does-not-open-in-fiji-bio-formats-8-1-1">Nd2 does not open in Fiji Bio_formats 8.1.1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nd2-does-not-open-in-fiji-bio-formats-8-1-1-additional-files">Nd2 does not open in Fiji Bio_formats 8.1.1 (additional files)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nd2-does-not-open-in-fiji-bio-formats-8-1-1-on-windows">Nd2 does not open in Fiji Bio_formats 8.1.1 (on Windows)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neurips-2022-cell-segmentation-competition-dataset">NeurIPS 2022 Cell Segmentation Competition Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-networks-and-deep-learning">Neural Networks and Deep Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#new-kid-on-the-nfdi-block-nfdi4bioimage-a-national-initiative-for-fair-data-management-in-bioimaging-and-bioimage-analysis">New Kid on the (NFDI) Block: NFDI4BIOIMAGE  - A National Initiative for FAIR Data Management in Bioimaging and Bioimage Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#new-report-highlights-the-scientific-impact-of-open-source-software">New report highlights the scientific impact of open source software</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nextflow-core">NextFlow core</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nextflow-documentation">NextFlow documentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nextflow-scalable-and-reproducible-scientific-workflows">Nextflow: Scalable and reproducible scientific workflows</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nuinsseg">NuInsSeg</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nuclei-of-u2os-cells-in-a-chemical-screen">Nuclei of U2OS cells in a chemical screen</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nuclei-of-mouse-embryonic-cells">Nuclei of mouse embryonic cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ocelot-overlapped-cell-on-tissue-dataset-for-histopathology">OCELOT: Overlapped Cell on Tissue Dataset for Histopathology</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome-event-database">OME Event Database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome-ngff-a-next-generation-file-format-for-expanding-bioimaging-data-access-strategies">OME-NGFF: a next-generation file format for expanding bioimaging data-access strategies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome-zarr-course">OME-Zarr course</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome2024-ngff-challenge-results">OME2024 NGFF Challenge Results</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omero-qupath">OMERO - QuPath</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omero-for-microscopy-research-data-management">OMERO for microscopy research data management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omexcavator-a-tool-for-exporting-and-connecting-domain-specific-metadata-in-a-wider-knowledge-graph">OMExcavator: a tool for exporting and connecting domain-specific metadata in a wider knowledge graph</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omero-tools">Omero-tools</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-micoscropy-environment-ome-youtube-channel">Open Micoscropy Environment (OME) Youtube Channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-microscopy-environment-youtube-channel">Open Microscopy Environment YouTube channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-source-platform-for-scalable-multi-purpose-virtual-desktop-infrastructures">Open Source Platform for Scalable Multi-Purpose Virtual Desktop Infrastructures</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#open-microscopy-in-the-life-sciences-quo-vadis">Open microscopy in the life sciences: quo vadis?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimisation-and-validation-of-a-swarm-intelligence-based-segmentation-algorithm-for-low-contrast-positron-emission-tomography">Optimisation and Validation of a Swarm Intelligence based Segmentation Algorithm for low Contrast Positron Emission Tomography</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimized-cranial-window-implantation-for-subcellular-and-functional-imaging-in-vivo">Optimized cranial window implantation for subcellular and functional imaging in vivo</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parallel-fiji-visualizer">Parallel_Fiji_Visualizer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parhyale-3d-segmentation-dataset">Parhyale 3D segmentation dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#platynereis-em-training-data">Platynereis EM training data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#platynereis-dumerilii-full-length-transcriptome-of-developmental-stages">Platynereis dumerilii full-length transcriptome of developmental stages</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pdum-workflow-zip-folder-3-40-gb">0-Pdum_workflow.zip (folder)
3.40 GB</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plugin-omero-batch-plugin">Plugin “omero-batch-plugin”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plugin-omero-cli-transfer">Plugin “omero-cli-transfer”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plugin-simple-omero-client">Plugin “simple-omero-client”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#predicting-axillary-lymph-node-metastasis-in-early-breast-cancer-using-deep-learning-on-primary-tumor-biopsy-slides">Predicting Axillary Lymph Node Metastasis in Early Breast Cancer Using Deep Learning on Primary Tumor Biopsy Slides</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprint-be-sustainable-recommendations-for-fair-resources-in-life-sciences-research-eosc-life-s-lessons">Preprint: “Be Sustainable”, Recommendations for FAIR Resources in Life Sciences research: EOSC-Life’s Lessons</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prodgerlab-stardist-hiv-target-cell-training-set">ProdgerLab-StarDist-HIV Target Cell Training Set</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdf-as-a-bridge-to-domain-platforms-like-omero-or-there-and-back-again">RDF as a bridge to domain-platforms like OMERO, or There and back again.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdm4mic-presentations">RDM4Mic Presentations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdm4mic">RDM4mic</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdmbites-bioimage-metadata">RDMBites BioImage metadata</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdmo-research-data-management-organiser">RDMO - Research Data Management Organiser</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rdm-system-connector">RDM_system_connector</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#rembi-recommended-metadata-for-biological-imagesenabling-reuse-of-microscopy-data-in-biology">REMBI - Recommended Metadata for Biological Images—enabling reuse of microscopy data in biology</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-management-on-campus-and-in-nfdi4bioimage">RESEARCH DATA MANAGEMENT on Campus and in NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reconstructed-images-of-a-2dsim-multiposition-acquisition">Reconstructed images of a 2DSIM multiposition acquisition.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reference-collection-to-push-back-against-common-statistical-myths">Reference Collection to push back against “Common Statistical Myths”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reporting-and-reproducibility-in-microscopy">Reporting and reproducibility in microscopy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#repository-for-combinatorial-wnt-signaling-landscape-during-brachiopod-anteroposterior-patterning">Repository for: Combinatorial Wnt signaling landscape during brachiopod anteroposterior patterning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-reusability-conceptual-foundations-barriers-and-enabling-technologies">Research Data Reusability - Conceptual Foundations, Barriers and Enabling Technologies</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-what-are-the-key-issues-to-consider-when-publishing-this-kind-of-material">Research data - what are the key issues to consider when publishing this kind of material?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#research-data-management-for-bioimaging-the-2021-nfdi4bioimage-community-survey">Research data management for bioimaging - the 2021 NFDI4BIOIMAGE community survey</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Research data management for bioimaging: the 2021 NFDI4BIOIMAGE community survey</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#root-tissue-segmentation-dataset">Root tissue segmentation dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#round-table-workshop-1-sample-stabilization-in-intravital-imaging">Round Table Workshop 1 - Sample Stabilization in intravital Imaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#round-table-workshop-2-correction-of-drift-and-movement">Round Table Workshop 2 - Correction of Drift and Movement</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stedycon-obf-dataset-with-simulated-intensity-and-complex-stacks-for-bioformats-mr-4362">STEDYCON OBF dataset with simulated intensity and complex stacks for bioformats MR #4362</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sample-data-for-pr-4284-https-github-com-ome-bioformats-pull-4284">Sample data for PR#4284 (https://github.com/ome/bioformats/pull/4284)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sciaugment">SciAugment</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scientific-colour-maps">Scientific colour maps</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#scripts-filopodyanr-a-case-study-for-the-neubias-ts7-in-szeged">Scripts_FilopodyanR - a case study for the NEUBIAS TS7 in Szeged</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#segmentation-of-nuclei-in-histopathology-images-by-deep-regression-of-the-distance-map">Segmentation of Nuclei in Histopathology Images by deep regression of the distance map</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#segmenting-cells-in-a-spheroid-in-3d-using-2d-stardist-within-trackmate">Segmenting cells in a spheroid in 3D using 2D StarDist within TrackMate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-up-an-institutional-omero-environment-for-bioimage-data-perspectives-from-both-facility-staff-and-users">Setting up an institutional OMERO environment for bioimage data: Perspectives from both facility staff and users</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#simulated-hl60-cells-from-the-cell-tracking-challenge">Simulated HL60 cells (from the Cell Tracking Challenge)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#single-cell-approach-dissecting-agr-quorum-sensing-dynamics-in-staphylococcus-aureus">Single-cell approach dissecting agr quorum sensing dynamics in Staphylococcus aureus</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#snakemake-documentation">Snakemake Documentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spatialdata-an-open-and-universal-data-framework-for-spatial-omics">SpatialData: an open and universal data framework for spatial omics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stackview-sliceplot-example-data">Stackview sliceplot example data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#standard-and-super-resolution-bioimaging-data-analysis-a-primer">Standard and Super-Resolution Bioimaging Data Analysis: A Primer</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-adipocyte-segmentation-training-data-training-notebook-and-model">StarDist Adipocyte Segmentation Training data, Training Notebook and Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-model-and-data-for-the-segmentation-of-yersinia-enterocolitica-cells-in-widefield-images">StarDist model and data for the segmentation of Yersinia enterocolitica cells in widefield images</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-aspc1-lifeact">StarDist_AsPC1_Lifeact</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-bf-monocytes-dataset">StarDist_BF_Monocytes_dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-bf-neutrophil-dataset">StarDist_BF_Neutrophil_dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-bf-cancer-cell-dataset-10x">StarDist_BF_cancer_cell_dataset_10x</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-bf-cancer-cell-dataset-20x">StarDist_BF_cancer_cell_dataset_20x</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-fluorescent-cells">StarDist_Fluorescent_cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-huvec-nuclei-dataset">StarDist_HUVEC_nuclei_dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-tumorcell-nuclei">StarDist_TumorCell_nuclei</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-model-and-training-dataset-for-automated-tracking-of-mda-mb-231-and-bt20-cells">Stardist model and training dataset for automated tracking of MDA-MB-231 and BT20 cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stardist-miapaca2-from-cd44">Stardist_MiaPaCa2_from_CD44</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistical-rethinking">Statistical Rethinking</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#studentsourcing-aggregating-and-re-using-data-from-a-practical-cell-biology-course">Studentsourcing - aggregating and re-using data from a practical cell biology course</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#submitting-data-to-the-bioimage-archive">Submitting data to the BioImage Archive</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#synapsenet-training-data">SynapseNet Training Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#synthetic-cells">Synthetic cells</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#synthetic-images-and-segmentation-masks-simulating-hl-60-cell-nucleus-in-3d">Synthetic images and segmentation masks simulating HL-60 cell nucleus in 3D</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tess-event-database">TESS Event database</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tess-training-materials">TESS training materials</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tnbc">TNBC</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#terminology-service-for-research-data-management-and-knowledge-discovery-in-low-temperature-plasma-physics">Terminology service for research data management and knowledge discovery in low-temperature plasma physics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tess-search-for-data-life-cycle">Tess Search for Data Life Cycle</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#test-dataset-for-whole-slide-image-registration">Test Dataset for Whole Slide Image Registration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-bioimage-archive-building-a-home-for-life-sciences-microscopy-data">The BioImage Archive – Building a Home for Life-Sciences Microscopy Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-fair-guiding-principles-for-scientific-data-management-and-stewardship">The FAIR Guiding Principles for scientific data management and stewardship</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-fair-guiding-principles-for-data-stewardship-fair-enough">The FAIR guiding principles for data stewardship - fair enough?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-fiji-updater">The Fiji Updater</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-information-infrastructure-for-bioimage-data-i3d-bio-project-to-advance-fair-microscopy-data-management-for-the-community">The Information Infrastructure for BioImage Data (I3D:bio) project to advance FAIR microscopy data management for the community</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-open-microscopy-environment-ome-data-model-and-xml-file-open-tools-for-informatics-and-quantitative-analysis-in-biological-imaging">The Open Microscopy Environment (OME) Data Model and XML file - open tools for informatics and quantitative analysis in biological imaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-role-of-helmholtz-centers-in-nfdi4bioimage-a-national-consortium-enhancing-fair-data-management-for-microscopy-and-bioimage-analysis">The role of Helmholtz Centers in NFDI4BIOIMAGE - A national consortium enhancing FAIR data management for microscopy and bioimage analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#towards-fair-data-workflows-for-multidisciplinary-science-ongoing-endeavors-and-future-perspectives-in-plasma-technology">Towards FAIR Data Workflows for Multidisciplinary Science: Ongoing Endeavors and Future Perspectives in Plasma Technology</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#towards-preservation-of-life-science-data-with-nfdi4bioimage">Towards Preservation of Life Science Data with NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#towards-transparency-and-knowledge-exchange-in-ai-assisted-data-analysis-code-generation">Towards Transparency and Knowledge Exchange in AI-assisted Data Analysis Code Generation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#towards-community-driven-metadata-standards-for-light-microscopy-tiered-specifications-extending-the-ome-model">Towards community-driven metadata standards for light microscopy - tiered specifications extending the OME model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-set-of-microscopy-images-for-dietler-et-al-nature-communications-2020">Training set of microscopy images for Dietler et al. Nature Communications 2020</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#trendsinmicroscopy2025">TrendsInMicroscopy2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-metric-related-pitfalls-in-image-analysis-validation">Understanding metric-related pitfalls in image analysis validation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#upcoming-image-analysis-events">Upcoming Image Analysis Events</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-glittr-org-to-find-compare-and-re-use-online-training-materials">Using Glittr.org to find, compare and re-use online training materials</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#v4sdb-winter-school-2025">V4SDB_Winter_School_2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#volumetric-segmentation-of-biological-cells-and-subcellular-structures-for-optical-diffraction-tomography-images-dataset">Volumetric segmentation of biological cells and subcellular structures for optical diffraction tomography images - dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#webatlas-pipeline-for-integrated-single-cell-and-spatial-transcriptomic-data">WebAtlas pipeline for integrated single cell and spatial transcriptomic data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#welcome-to-bioimage-town">Welcome to BioImage Town</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-bioimage-analysis-an-introduction">What is Bioimage Analysis? An Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#who-you-gonna-call-data-stewards-to-the-rescue">Who you gonna call? - Data Stewards to the rescue</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workflowhub">WorkflowHub</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#working-group-charter-rdm-helpdesk-network">Working Group Charter. RDM Helpdesk Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workshop-june2024-madrid">Workshop-June2024-Madrid</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zarr-a-cloud-optimized-storage-for-interactive-access-of-large-arrays">Zarr - A Cloud-Optimized Storage for Interactive Access of Large Arrays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter">Zeiss AxioZoom Stage Adapter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter-12-6well-plate">Zeiss AxioZoom Stage Adapter - 12/6Well Plate</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter-em-block-holder">Zeiss AxioZoom Stage Adapter - EM block holder</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zeiss-axiozoom-stage-adapter-microscope-slides">Zeiss AxioZoom Stage Adapter - Microscope slides</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zerocostdl4mic-stardist-2d-example-training-and-test-dataset-light">ZeroCostDL4Mic - Stardist 2D example training and test dataset (light)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zerocostdl4mic-stardist-example-training-and-test-dataset">ZeroCostDL4Mic - Stardist example training and test dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zerocostdl4mic-exploiting-google-colab-to-develop-a-free-and-open-source-toolbox-for-deep-learning-in-microscopy">ZeroCostDL4Mic: exploiting Google Colab to develop a free and open-source toolbox for Deep-Learning in microscopy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bina-cc-scalable-strategies-for-a-next-generation-of-fair-bioimaging">[BINA CC] Scalable strategies for a next-generation of FAIR bioimaging</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cordi-2023-zarr-a-cloud-optimized-storage-for-interactive-access-of-large-arrays">[CORDI 2023] Zarr: A Cloud-Optimized Storage for Interactive Access of Large Arrays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#community-meeting-2024-overview-team-image-data-analysis-and-management">[Community Meeting 2024] Overview Team Image Data Analysis and Management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#community-meeting-2024-supporting-and-financing-rdm-projects-within-gerbi">[Community Meeting 2024] Supporting and financing RDM projects within GerBI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gbi-eoe-ix-nfdi4bioimage">[GBI EoE IX] NFDI4BIOIMAGE</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#n4bi-ahm-welcome-to-bioimage-town">[N4BI AHM] Welcome to BioImage Town</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#short-talk-nfdi4bioimage-a-consortium-in-the-national-research-data-infrastructure">[Short Talk] NFDI4BIOIMAGE - A consortium in the National Research Data Infrastructure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solved-sample-fluorescence-qptiff-file-not-rendered-correctly-by-qupath-v-0-6-0-correctly-by-qupath-v-0-5-1">[Solved] Sample fluorescence .qptiff file not rendered correctly by QuPath v.0.6.0, correctly by Qupath v.0.5.1</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#workshop-material-fit-for-omero-how-imaging-facilities-and-it-departments-work-together-to-enable-rdm-for-bioimaging-october-16-17-2024-heidelberg">[Workshop Material] Fit for OMERO - How imaging facilities and IT departments work together to enable RDM for bioimaging, October 16-17, 2024, Heidelberg</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#arivis-vision4d-tutorials">arivis Vision4D Tutorials</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioformats2raw-converter">bioformats2raw Converter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bioimageio-chatbot">bioimageio-chatbot</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cba-support-template">cba-support-template</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cellpose-training-data">cellpose training data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datenbiene">datenbiene</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#de-nbi-youtube-channel">de.NBI YouTube Channel</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#de-nbi-cloud-access-registration-guide">de.NBI cloud access registration guide</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#denbi-online-training-media-library">deNBI Online Training Media Library</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dmtxsamplecreator">dmtxSampleCreator</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embo-bia-2025">embo-bia-2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#i2k-2020-s3-zarr-workshop">i2k-2020-s3-zarr-workshop</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ilastik-interactive-machine-learning-for-bio-image-analysis">ilastik: interactive machine learning for (bio)image analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imaris-file-not-read-by-bfgetreader">imaris file not read by bfGetReader()</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#martinschatz-cz-scicount-v1-0-0-with-reusable-example-notebooks">martinschatz-cz/SciCount: v1.0.0 with reusable example notebooks</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#microlist">microlist</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome-ngff-validator">ome-ngff-validator</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ome2024-ngff-challenge">ome2024-ngff-challenge</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omero-arc">omero-arc</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omero-ontop-mappings">omero-ontop-mappings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omero-quay">omero-quay</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#omero-vitessce">omero-vitessce</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#patho-prompt-injection">patho_prompt_injection</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quantixed-thedigitalcell-first-complete-code-set">quantixed/TheDigitalCell: First complete code set</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#raw2ometiff-converter">raw2ometiff Converter</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#re3data-org-registry-of-research-data-repositories">re3data.org - registry of Research Data Repositories</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training">training</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Robert Haase, Clément Caporal,... and the NFDI4BioImage Initiative
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on 2025-10-21.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <p>
Copyright: Licensed <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">CC-BY 4.0</a> unless mentioned otherwise. 
Contributions and feedback are welcome.
</p>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>