
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Recently added (10) &#8212; NFDI4BioImage Training Materials</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/css/searchbox.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/0.6.0/lunr.min.js"></script>
    <script src="_static/js/searchbox.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'whats_new';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="How to contribute" href="contributing/index.html" />
    <link rel="prev" title="NFDI4BioImage Training Materials" href="readme.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="2025-09-17"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="readme.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="NFDI4BioImage Training Materials - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="NFDI4BioImage Training Materials - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="readme.html">
                    NFDI4BioImage Training Materials
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">What's new</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Recently added (10)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Contributing</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="contributing/index.html">How to contribute</a></li>

<li class="toctree-l1"><a class="reference internal" href="contributing/submit_app.html">Using the Training Materials Submission App</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing/format.html">YML format</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">By tag</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="tags/ai-ready.html">Ai-ready (84)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/artificial_intelligence.html">Artificial intelligence (51)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/bioimage_analysis.html">Bioimage analysis (210)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/bioinformatics.html">Bioinformatics (19)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/data_stewardship.html">Data stewardship (6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/exclude_from_dalia.html">Exclude from dalia (455)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/fair-principles.html">Fair-principles (27)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/fiji.html">Fiji (6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/galaxy.html">Galaxy (6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/imagej.html">Imagej (20)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/include_in_dalia.html">Include in dalia (332)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/licensing.html">Licensing (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/metadata.html">Metadata (15)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/napari.html">Napari (14)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/neubias.html">Neubias (27)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/nfdi4bioimage.html">Nfdi4bioimage (80)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/omero.html">Omero (39)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/open_science.html">Open science (9)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/open_source_software.html">Open source software (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/python.html">Python (71)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/reproducibility.html">Reproducibility (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/research_data_management.html">Research data management (145)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/sharing.html">Sharing (12)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/workflow.html">Workflow (9)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tags/workflow_engine.html">Workflow engine (13)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">By content type</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="content_types/blog%20post.html">Blog post (28)</a></li>
<li class="toctree-l1"><a class="reference internal" href="content_types/book.html">Book (21)</a></li>
<li class="toctree-l1"><a class="reference internal" href="content_types/code.html">Code (10)</a></li>
<li class="toctree-l1"><a class="reference internal" href="content_types/collection.html">Collection (86)</a></li>
<li class="toctree-l1"><a class="reference internal" href="content_types/data.html">Data (92)</a></li>
<li class="toctree-l1"><a class="reference internal" href="content_types/document.html">Document (8)</a></li>
<li class="toctree-l1"><a class="reference internal" href="content_types/documentation.html">Documentation (19)</a></li>
<li class="toctree-l1"><a class="reference internal" href="content_types/event.html">Event (8)</a></li>
<li class="toctree-l1"><a class="reference internal" href="content_types/github%20repository.html">Github repository (69)</a></li>
<li class="toctree-l1"><a class="reference internal" href="content_types/notebook.html">Notebook (57)</a></li>
<li class="toctree-l1"><a class="reference internal" href="content_types/online%20tutorial.html">Online tutorial (10)</a></li>
<li class="toctree-l1"><a class="reference internal" href="content_types/poster.html">Poster (10)</a></li>
<li class="toctree-l1"><a class="reference internal" href="content_types/preprint.html">Preprint (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="content_types/publication.html">Publication (71)</a></li>
<li class="toctree-l1"><a class="reference internal" href="content_types/slides.html">Slides (84)</a></li>
<li class="toctree-l1"><a class="reference internal" href="content_types/tutorial.html">Tutorial (48)</a></li>
<li class="toctree-l1"><a class="reference internal" href="content_types/video.html">Video (38)</a></li>
<li class="toctree-l1"><a class="reference internal" href="content_types/website.html">Website (11)</a></li>
<li class="toctree-l1"><a class="reference internal" href="content_types/workshop.html">Workshop (14)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">By license</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="licenses/all_rights_reserved.html">All rights reserved (13)</a></li>
<li class="toctree-l1"><a class="reference internal" href="licenses/apache-2.0.html">Apache-2.0 (6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="licenses/bsd-2-clause.html">Bsd-2-clause (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="licenses/bsd-3-clause.html">Bsd-3-clause (37)</a></li>
<li class="toctree-l1"><a class="reference internal" href="licenses/cc-by-3.0.html">Cc-by-3.0 (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="licenses/cc-by-4.0.html">Cc-by-4.0 (407)</a></li>
<li class="toctree-l1"><a class="reference internal" href="licenses/cc-by-nc-sa-4.0.html">Cc-by-nc-sa-4.0 (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="licenses/cc-by-sa-4.0.html">Cc-by-sa-4.0 (6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="licenses/cc0-1.0.html">Cc0-1.0 (25)</a></li>
<li class="toctree-l1"><a class="reference internal" href="licenses/gpl-2.0.html">Gpl-2.0 (8)</a></li>
<li class="toctree-l1"><a class="reference internal" href="licenses/gpl-3.0.html">Gpl-3.0 (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="licenses/mit.html">Mit (32)</a></li>
<li class="toctree-l1"><a class="reference internal" href="licenses/unknown.html">Unknown (109)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">By domain</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="domain/bbbc.broadinstitute.org.html">Bbbc.broadinstitute.org (12)</a></li>
<li class="toctree-l1"><a class="reference internal" href="domain/biapol.github.io.html">Biapol.github.io (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="domain/docs.google.com.html">Docs.google.com (6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="domain/doi.org.html">Doi.org (347)</a></li>
<li class="toctree-l1"><a class="reference internal" href="domain/f1000research.com.html">F1000research.com (11)</a></li>
<li class="toctree-l1"><a class="reference internal" href="domain/focalplane.biologists.com.html">Focalplane.biologists.com (14)</a></li>
<li class="toctree-l1"><a class="reference internal" href="domain/git.mpi-cbg.de.html">Git.mpi-cbg.de (7)</a></li>
<li class="toctree-l1"><a class="reference internal" href="domain/github.com.html">Github.com (150)</a></li>
<li class="toctree-l1"><a class="reference internal" href="domain/training.galaxyproject.org.html">Training.galaxyproject.org (5)</a></li>
<li class="toctree-l1"><a class="reference internal" href="domain/www.biorxiv.org.html">Www.biorxiv.org (6)</a></li>
<li class="toctree-l1"><a class="reference internal" href="domain/www.ebi.ac.uk.html">Www.ebi.ac.uk (18)</a></li>
<li class="toctree-l1"><a class="reference internal" href="domain/www.nature.com.html">Www.nature.com (18)</a></li>
<li class="toctree-l1"><a class="reference internal" href="domain/www.youtube.com.html">Www.youtube.com (28)</a></li>
<li class="toctree-l1"><a class="reference internal" href="domain/zenodo.org.html">Zenodo.org (327)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="statistics/readme.html">Statistics</a></li>
<li class="toctree-l1"><a class="reference internal" href="export/readme.html">Open data</a></li>
<li class="toctree-l1"><a class="reference internal" href="gdpr_compliance.html">GDPR Compliance Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="imprint.html">Imprint</a></li>

</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/NFDI4BIOIMAGE/training" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/NFDI4BIOIMAGE/training/issues/new?title=Issue%20on%20page%20%2Fwhats_new.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/whats_new.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Recently added (10)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-perspective-on-fair-and-scalable-access-to-large-image-data">A Perspective on FAIR and Scalable Access to Large Image Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coba-nih-2024-bridging-imaging-users-to-imaging-analysis-survey-survey-data-with-preliminary-exploration">COBA-NIH/2024_Bridging_Imaging_Users_to_Imaging_Analysis_Survey: Survey data with preliminary exploration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cloud-based-virtual-desktops-for-reproducible-research">Cloud-Based Virtual Desktops for Reproducible Research</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#development-fair-image-analysis-workflows-and-rdm-pipelines-in-galaxy">Development FAIR image analysis workflows and RDM pipelines in Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-analysis-in-healthcare-the-current-landscape-trends-and-collaborative-opportunities">Image Analysis in Healthcare - The Current Landscape, Trends, and Collaborative Opportunities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linking-of-research-meta-data-in-omero-to-foster-fair-data-in-plasma-science">Linking of Research (Meta-)data in OMERO to Foster FAIR Data in Plasma Science</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-cover-2025">NFDI4BIOIMAGE Calendar Cover 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-january-2025">NFDI4BIOIMAGE Calendar January 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reproducible-bio-image-analysis-using-python-napari-jupyter-and-ai">Reproducible Bio-Image Analysis using Python, Napari, Jupyter and AI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embo-bia-2025">embo-bia-2025</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="recently-added-10">
<h1>Recently added (10)<a class="headerlink" href="#recently-added-10" title="Link to this heading">#</a></h1>
<section id="a-perspective-on-fair-and-scalable-access-to-large-image-data">
<h2>A Perspective on FAIR and Scalable Access to Large Image Data<a class="headerlink" href="#a-perspective-on-fair-and-scalable-access-to-large-image-data" title="Link to this heading">#</a></h2>
<p>Julia Thönnißen, Sarah Oliveira, Alexander Oberstrass, Jan-Oliver Kropp, Xiao Gui, Christian Schiffer, Timo Dickscheid</p>
<p>Published 2025-08-04</p>
<p>Licensed CC-BY-4.0</p>
<p>The rapid development of new imaging technologies across scientific domains–especially high-throughput technologies–results in a growing volume of image datasets in the Tera- to Petabyte scale. Efficient visualization and analysis of such massive image resources is critical but remains challenging due to the sheer size of the data, its continuous growth, and the limitations of conventional software tools to address these problems. Tools for visualization, annotation and analysis of large image data are confronted with the fundamental dilemma of balancing computational efficiency and memory requirements. Many tools are unable to process large datasets due to memory constraints, requiring workarounds like downsampling. On the other hand, solutions that can handle large data efficiently often rely on specialized or even proprietary file formats, limiting interoperability with other software. This reflects diverging requirements: storage favours compression for efficiency, analysis demands fast data access, and visualization requires tiled, multi-resolution representations. Lacking a unified approach for these conflicting needs, the operation of large and dynamically evolving image repositories in practice often requires undesirable data conversions and costly data duplication. In addressing these challenges, the bioimaging community increasingly adheres to the FAIR principles [1] through national and international initiatives [2], [3], [4]. For example, the Open Microscopy Environment (OME) fosters standards such as OME-TIFF [5] and its cloud-native successor OME-NGFF [6]; BioFormats [7] and OMERO [8] facilitate metadata-rich data handling across diverse platforms; and BrAinPI [9] provides web-based visualization of images via Neuroglancer [10]. These tools represent important developments towards more efficient and standardized use of bioimaging data. However, for very large and dynamically growing repositories, it is still not feasible to settle on a single standard for a subset of these tools, in particular in the light of very diverging needs for massively parallel processing on HPC systems. Therefore, converting data to a single target format is often not a practical solution. We propose a concept for a modular image delivery service which acts as a middleware between large image data resources and applications, serving image data from a cloud resource in multiple requested representations on demand. The service allows reading data stored in different input file formats, applying coordinate transformations and filtering operations on-the-fly, and serving the results in a range of different output formats and layouts. Building upon a common framework for reading and transforming data, an extensible set of access points connects the service to client applications: Lightweight REST APIs allow web-based mutli-resolution access (e.g., in common formats such as used in Neuroglancer and OpenSeadragon base viewers); mountable filesystem interfaces enable linking the repository to file-oriented solutions (e.g., OMERO, ImageJ); and programmatic access from customizable software tools (e.g., Napari). To provide compatibility with upcoming image data standards like BIDS [11] and minimize conversion efforts, the service is able to dynamically expose standard-conform views into arbitrarily organized datasets. The proposed approach for reading and transforming data on-the-fly eliminates the need for redundant storage and application-specific conversions of datasets, improving workflow efficiency and sustainability. In summary, we advocate for the development of a flexible and extensible image data service that supports large-scale analysis, dynamic transformations, multi-tool interoperability, and compatibility with community standards for large image datasets. This way it supports the FAIR principles, reduces integration barriers, meets the performance demands of modern imaging research, and still fosters the use of existing community developments.</p>
<p>Tags: Include In Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16736220">https://zenodo.org/records/16736220</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16736220">https://doi.org/10.5281/zenodo.16736220</a></p>
</section>
<hr class="docutils" />
<section id="coba-nih-2024-bridging-imaging-users-to-imaging-analysis-survey-survey-data-with-preliminary-exploration">
<h2>COBA-NIH/2024_Bridging_Imaging_Users_to_Imaging_Analysis_Survey: Survey data with preliminary exploration<a class="headerlink" href="#coba-nih-2024-bridging-imaging-users-to-imaging-analysis-survey-survey-data-with-preliminary-exploration" title="Link to this heading">#</a></h2>
<p>Erin Weisbart</p>
<p>Published 2025-09-15</p>
<p>Licensed BSD-3-CLAUSE</p>
<p>Contains the survey data collected through the 2024 Bridging Imaging Users to Imaging Analysis Survey and figures/code from preliminary data exploration of the survey results.</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/17127544">https://zenodo.org/records/17127544</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.17127544">https://doi.org/10.5281/zenodo.17127544</a></p>
</section>
<hr class="docutils" />
<section id="cloud-based-virtual-desktops-for-reproducible-research">
<h2>Cloud-Based Virtual Desktops for Reproducible Research<a class="headerlink" href="#cloud-based-virtual-desktops-for-reproducible-research" title="Link to this heading">#</a></h2>
<p>Yi Sun, Christian Tischer, Kelleher, Harry Alexander, Jean-Karim Heriche</p>
<p>Published 2025-09-10</p>
<p>Licensed CC-BY-4.0</p>
<p>Reproducing computing environments become increasingly challenging in research, especially when compute-intensive scientific workflows require specialised software stacks, specialized hardware (e.g. GPUs), and interactive analysis tools. While traditional high-performance computing (HPC) systems offer scalable resources for batch processing, they don’t easily support interactive workflows. On the other hand, workstations have fixed resources  and face workflow deployment challenges because conflicts can occur when multiple tools and dependencies are deployed into the same environment. To address these limitations, we present cloud-based virtual desktop platforms, built on the desktop-as-a-service (DaaS) model, using a containerised, cloud-native approach.  Our platforms offer on-demand, customized desktop environments accessible from any web browser, with dynamic allocation of CPU, memory, and GPU resources for efficient utilization of resources. We introduce two types of virtual desktops: BAND, built on top of a Slurm scheduler and BARD, using Kubernetes. In both cases, containerization ensures consistent and reproducible environments across sessions and pre-installed software improves accessibility for researchers. Deployment and system administration are also simplified through the use of orchestration and automation tools.  Our virtual desktop platforms are particularly valuable for bioimage analysis, which requires complex workflows involving high interactivity, multiple software and GPU acceleration. By combining containerization and cloud-native services, BAND and BARD offer a scalable and sustainable model for delivering interactive, reproducible research environments.</p>
<p>Tags: Nfdi4Bioimage, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/17092303">https://zenodo.org/records/17092303</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.17092303">https://doi.org/10.5281/zenodo.17092303</a></p>
</section>
<hr class="docutils" />
<section id="development-fair-image-analysis-workflows-and-rdm-pipelines-in-galaxy">
<h2>Development FAIR image analysis workflows and RDM pipelines in Galaxy<a class="headerlink" href="#development-fair-image-analysis-workflows-and-rdm-pipelines-in-galaxy" title="Link to this heading">#</a></h2>
<p>Riccardo Massei, Beatriz Serrano-Solano, Anne Fouilloux, Björg Gruening, Yi Sun, Diana Chiang, Matthias Bernt, Leonid Kostrykin</p>
<p>Published 2025-09-10</p>
<p>Licensed CC-BY-4.0</p>
<p>Imaging is crucial across various scientific disciplines, particularly in life sciences, where it plays a key role in studies ranging from single molecules to whole organisms. However, the complexity and sheer volume of image data present significant challenges. Managing and analyzing this data efficiently requires well-defined image processing tools and analysis pipelines that align with the FAIR principles—ensuring they are findable, accessible, interoperable, and reusable across different domains. In the frame of NFDI4BIOIMAGE1 (the National Research Data Infrastructure focusing on bioimaging in Germany), we want to find viable solutions for storing, processing, analyzing, and sharing bioimaging data. In particular, we want to develop solutions to make findable and machine-readable metadata developing analysis pipelines. In scientific research, such pipelines are crucial for maintaining data integrity, supporting reproducibility, and enabling interdisciplinary collaboration. These tools can be used by different users to retrieve images based on specific attributes as well as support quality control by identifying appropriate metadata. Galaxy, an open-source, web-based platform for data-intensive research, offers a solution by enabling the construction of reproducible pipelines for image analysis2. By integrating popular analysis software like CellProfiler and connecting with cloud services such as OMERO and IDR, Galaxy facilitates the seamless access and management of image data. This capability is particularly valuable in bioimaging, where automated pipelines can streamline the handling of complex metadata, ensuring data integrity and fostering interdisciplinary collaboration. This approach not only increases the efficiency of RDM processes in bioimaging but also contributes to the broader scientific community’s efforts to embrace FAIR principles, ultimately advancing scientific discovery and innovation. In the present poster, we showed how to integrate RDM processes and tools in Galaxy. We will showcase how Images can be enriched with metadata (i.e. key-value pairs, tags, raw data, regions of interest) and uploaded to a target OME Remote Objects (OMERO) server using a novel set of OMERO tools developed with Galaxy3. Workflows give the possibility to the user to intuitively fetch images from the local server and perform image analysis (i.e. annotation). Furthermore, we will show the potential integration of eletronic lab books such as eLabFTW4, cloud storage systems (i.e. OneData)5 and interactive norebooks (Jupyter Notebooks) 6 in the Galaxy pipeline.</p>
<p>Tags: Nfdi4Bioimage, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/17093454">https://zenodo.org/records/17093454</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.17093454">https://doi.org/10.5281/zenodo.17093454</a></p>
</section>
<hr class="docutils" />
<section id="image-analysis-in-healthcare-the-current-landscape-trends-and-collaborative-opportunities">
<h2>Image Analysis in Healthcare - The Current Landscape, Trends, and Collaborative Opportunities<a class="headerlink" href="#image-analysis-in-healthcare-the-current-landscape-trends-and-collaborative-opportunities" title="Link to this heading">#</a></h2>
<p>Martin Schätz, Pérez Koldenkova, Vadim</p>
<p>Published 2025-09-09</p>
<p>Licensed CC-BY-4.0</p>
<p>Workshop presentation from XXXIV Foro de Investigación en Salud 2025.</p>
<p>Tags: Include In Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/17080219">https://zenodo.org/records/17080219</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.17080219">https://doi.org/10.5281/zenodo.17080219</a></p>
</section>
<hr class="docutils" />
<section id="linking-of-research-meta-data-in-omero-to-foster-fair-data-in-plasma-science">
<h2>Linking of Research (Meta-)data in OMERO to Foster FAIR Data in Plasma Science<a class="headerlink" href="#linking-of-research-meta-data-in-omero-to-foster-fair-data-in-plasma-science" title="Link to this heading">#</a></h2>
<p>Robert Wagner, Mohsen Ahmadi, Dagmar Waltemath, Kristina Yordanova, Becker, Markus M.</p>
<p>Published 2025-09-10</p>
<p>Licensed CC-BY-4.0</p>
<p>Applied plasma research involves several disciplines such as physics, medicine and biology to solve application-oriented problems, often generating large and heterogeneous experimental data sets. The descriptions and metadata describing these interdisciplinary scientific investiga-tions is stored in distributed systems (e.g., physical laboratory notebooks or electronic labora-tory notebooks (ELN) like eLabFTW [1]), and the experimental data are either stored locally within the laboratories or on centralized institutional storage systems. As a result, the collected information often has to be tediously assembled for processing into publications. The workflow represented in Figure 1 addresses this suboptimal situation and promotes the combination of the image database OMERO [2], the ELN system eLabFTW, the research data management tool Adamant [3] and Python scripts for handling microscopy images in plasma life science and plasma medicine [4]. This workflow highlights how the developments from the NFDI4BIOIMAGE consortium can be brought into practical applications by addressing the specific demands of plasma science, where domain-specific metadata is essential for effective data interpretation and reuse. It showcases the benefits of FAIR [5] metadata combining do-main-specific requirements with method-specific solutions. Similar to most imaging workflows, image analysis in plasma research requires metadata from several sections of the experiment. Moreover, the plasma-related metadata are essential for the experimental context and must be included in the analysis, e.g. to describe the influence of plasma on the treated sample. Therefore, the metadata schema Plasma-MDS [6] is adapted to collect plasma-related metadata, such as information on the plasma species having a major impact on the treated samples. Alongside Plasma-MDS, the Recommended Metadata for Bio-logical Images (REMBI) standard [7] is used for the biological metadata such as the sample preparation and treatment procedures. The collection of these metadata is realized using Adamant, which enables the beginner-friendly collection of structured metadata. The tool presents JSON schemas in easy-to-read and easy-to-fill HTML forms, enabling metadata validation. Once completed and validated, the metadata are uploaded directly to eLabFTW using Adamant’s workflow functionalities. The images from the treated samples are uploaded to OMERO by OMERO.insight and afterwards automatically annotated via Python scripts. These scripts take previously collected metadata from the related eLabFTW experiments and the microscope description metadata collected by the Micro Meta App [8], which are also stored in eLabFTW. The metadata is categorized and annotated according to the various data organizational levels within OMERO, specifically fo-cusing on project and dataset hierarchies, as well as screens that are composed of plates, which in turn contain wells. Screens resemble microwell plates, commonly used in a variety of biological experiments. The hieraic organization of metadata significantly enhances the ease of reusing images and associated metadata for subsequent processing and analysis. By efficiently distributing and reducing large metadata sets to an acceptable level, while simultaneously eliminating redun-dancies, this approach facilitates straightforward analyses with tools like ImageJ [9] and FIJI [10], thanks to the close association of metadata with the images themselves. In summary, one of the application-specific developments within the NFDI4BIOIMAGE consor-tium is presented, which contributes to the adoption of the FAIR principles in laboratory envi-ronments. Further work will address the integration of ontologies for the semantic description of data and metadata.</p>
<p>Tags: Nfdi4Bioimage, Bioimage Analysis, Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/17092348">https://zenodo.org/records/17092348</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.17092348">https://doi.org/10.5281/zenodo.17092348</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-calendar-cover-2025">
<h2>NFDI4BIOIMAGE Calendar Cover 2025<a class="headerlink" href="#nfdi4bioimage-calendar-cover-2025" title="Link to this heading">#</a></h2>
<p>Anne Rademacher, Alik Huseynov, Michele Bortolomeazzi, Wille, Sina Jasmin, Sabrina Schumacher, Pooja Sant, Denise Keitel, Konstantin Okonechnikov, Ghasemi, David R., Pajtler, Kristian W., Jan-Philipp Mallm, Karsten Rippe</p>
<p>Published 2025-09-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Image from the NFDI4BIOIMAGE Calendar Cover 2025.
The image is a visualization showing the integration of multimodal data including a spinning disk confocal image and gene expression data from a spatial transcriptomic experiment on a human medulloblastoma sample. The microscopy image of the tissue with the nuclei in white has been overlayed with the result of the cell segmentation colored according to the assigned cell type (immune cells: red, stromal cells: violet, brain cells: cyan/blue, tumor cells: green). A subset of transcripts for three genes whose expression varies across the different cell types in the tissue have been represented as colored dots (CD4 (immune cells): red, PTCH1 (tumor cells): green, AQP4 (brain cells): blue).
Image Metadata (using REMBI template):</p>
<p>Study</p>
<p>Study description</p>
<p>Comparison of spatial transcriptomics technologies for medulloblastoma cryosection</p>
<p>Study type</p>
<p>Spatial Transcriptomics (Xenium) on medulloblastoma cryosections</p>
<p>Study Component</p>
<p>Imaging method</p>
<p>Xenium and Spinning disk confocal microscopy</p>
<p>Study component description</p>
<p>Datasets with raw and processed data from the study “Comparison of spatial transcriptomics technologies for medulloblastoma cryosections” including Xenium and spinning disk confocal microscopy data</p>
<p>Biosample</p>
<p>Identity</p>
<p>MB266</p>
<p>Biological entity</p>
<p>Human cerebellum from a patient with Medulloblastoma with extensive nodularity</p>
<p>Organism</p>
<p>Homo sapiens</p>
<p>Specimen</p>
<p>Experimental status</p>
<p>Patient sample</p>
<p>Preparation method</p>
<p>10 µm cryosections were acquired using the cryostar NX50 with a cutting temperature of -15 °C. Tissues were section in 10 µm slices and four samples were placed on one Xenium slide. Subsequently, the tissue was fixed with PFA according to the manufacture´s protocol. Tissues were permeabilized with SDS, incubated in 70% ice cold methanol and washed with PBS. Hybridization of the human generic brain panel with 70 add-on genes (Supplementary Dataset 1) was performed at 50°C in a Bio-Rad C1000 touch cycler for 20 hours. Washing, ligation and amplification steps were carried out according to the manufacturer’s instructions. ROIs were selected according to the tissue area excluding non-tissue covered tiles. Each transcript was imaged in a bright state five times across 60 cycle-channels (15 cycles x 4 channels). After the run on the Xenium analyzer slides were removed and buffer exchanged with PBS-T for further storage at 4°C.</p>
<p>Signal/contrast mechanism</p>
<p>Fluorescence</p>
<p>Channel 1 – content</p>
<p>DAPI</p>
<p>Channel 1 – biological entity</p>
<p>Nuclei (DNA)</p>
<p>Image acquisition</p>
<p>Instrument attributes</p>
<p>Imaging of RNAscope samples and reimaging of Xenium slides by SDCM was conducted on an Andor Dragonfly 505 spinning disk confocal system equipped with a Nikon Ti2-E inverted microscope and a CFI P-Fluor 40X/1.30 oil objective or a Plan Apo 60x/1.40 oil objective. Multicolor images were acquired with the following laser lines 405 nm (DAPI), 488 nm (Alexa 488, eosin), 561 nm (Atto 550), 637 nm (Atto 647) 730nm (Alexa 750).</p>
<p>Image acquisition parameters</p>
<p>Images were recorded at 16-bit depth and with 1024x1024 pixels dimensions (pixel size: 0.217 µm) using an iXon Ultra 888 EM-CCD camera. The region of interest was selected based on the DAPI signal and 50 z-slices were acquired with a step size of 0.4 µm (20 µm z-range) per field of view (FOV). Tiles were imaged with a 10% overlap to ensure accurate stitching.</p>
<p>Image data</p>
<p>Type</p>
<p>Figure</p>
<p>Format &amp; compression</p>
<p>PNG</p>
<p>Size description</p>
<p>8800x8788+0+0 pixels (Primary image)</p>
<p>Pixel/voxel size description</p>
<p>0.217 µm (Primary image)</p>
<p>Channel information</p>
<p>RGB</p>
<p>Image processing method</p>
<p>Tiles were imaged with a 10% overlap to ensure accurate stitching. Subsequently, a flatfield-correction was conducted based on the DAPI channel and stitching and registration of the tiles was conducted with Fiji. First, SDCM image stacks were subjected to a maximum intensity projection, followed by flat field and chromatic aberration correction using a custom script. Next, image tiles were stitched using the “Grid/Collection Stitching” plugin. DAPI images from SDCM were registered to MC or Xenium widefield images using “Register Virtual Stack Slices” with Affine feature extraction model and the Elastic bUnwarpJ splines registration model. In case of further staining, images were transformed via Transform Virtual Stack slices employing the transformation file of the DAPI registration.</p>
<p>Image Correlation</p>
<p>Spatial and temporal alignment</p>
<p>The region of interest was selected based on the DAPI signal and 50 z-slices were acquired with a step size of 0.4 µm (20 µm z-range) per field of view (FOV). Tiles were imaged with a 10% overlap to ensure accurate stitching. Subsequently, a flatfield-correction was conducted based on the DAPI channel and stitching and registration of the tiles was conducted with Fiji (<a class="github reference external" href="https://github.com/RippeLab/MBEN/tree/main/stitching">RippeLab/MBEN</a>) (<a class="github reference external" href="https://github.com/RippeLab/MBEN/tree/main/Registration">RippeLab/MBEN</a>).</p>
<p>Related images and relationship</p>
<p>MB266-morphology_mip.ome.tif at <a class="reference external" href="https://www.ebi.ac.uk/biostudies/bioimages/studies/S-BIAD1093">https://www.ebi.ac.uk/biostudies/bioimages/studies/S-BIAD1093</a></p>
<p>Analysed data</p>
<p>Analysis result type</p>
<p>Figure</p>
<p>Data used for analysis</p>
<p>MB266-transcripts.csv.gz, MB266-transcripts.csv.gz at <a class="reference external" href="https://www.ebi.ac.uk/biostudies/bioimages/studies/S-BIAD1093">https://www.ebi.ac.uk/biostudies/bioimages/studies/S-BIAD1093</a></p>
<p>Analysis method and details</p>
<p>Most of the analysis and visualization (including tidyverse, data.table, ggridges R packages) was done in R 4.2.2. Raw data were processed using technology-specific corporate pipelines (custom pipeline was used for MC). For each technology Seurat objects of the sample data and analysis results were created using the Seurat (v. 4.3.0) R package (<a class="github reference external" href="https://github.com/scOpenLab/spatial_analysis/tree/main">scOpenLab/spatial_analysis</a>)</p>
<p>Submitted via NFDI4BIOIMAGE</p>
<p> </p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16979744">https://zenodo.org/records/16979744</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16979744">https://doi.org/10.5281/zenodo.16979744</a></p>
</section>
<hr class="docutils" />
<section id="nfdi4bioimage-calendar-january-2025">
<h2>NFDI4BIOIMAGE Calendar January 2025<a class="headerlink" href="#nfdi4bioimage-calendar-january-2025" title="Link to this heading">#</a></h2>
<p>Lea Miebach, Sander Bekeschus</p>
<p>Published 2025-09-15</p>
<p>Licensed CC-BY-4.0</p>
<p>Image from the NFDI4BIOIMAGE Calendar January 2025.
A Heart for Redox Biology: The image of primary bone mesenchymal stromal/stem cells (hBM-MSCs) was captured in a study evaluating the cellular effects of therapeutic oxidation in the context of regenerative medicine. The cells were isolated from an arthroplasty patient cohort in a joint research project between the Center for Orthopaedics at University Medical Center and the group ZIK plasmatis at the Leibniz Institute for Plasma Science and Technology (INP) in Greifswald. You can appreciate the characteristic morphology and complex actin cytoskeleton that is crucial for the cellular function of hBM-MSCs. Can you spot the heart that is formed by the prominent actin protrusions of interconnected cells?
Image Metadata (using REMBI template):</p>
<p>Study Component</p>
<p>Imaging method</p>
<p>Spinning-disc confocal mode, epifluorescence</p>
<p>Biosample</p>
<p>Biological entity</p>
<p>Bone marrow-mesenchymal stem cells (BM-MSCs)</p>
<p>Organism</p>
<p>Homo sapiens</p>
<p>Specimen</p>
<p>Preparation method</p>
<p>Fixation (4% PFA)</p>
<p>Signal/contrast mechanism</p>
<p>Fluorescence</p>
<p>Channel 1 – content</p>
<p>4’,6-Diamidin-2-phenylindol (DAPI; Thermo Fisher, USA), blue</p>
<p>Channel 1 – biological entity</p>
<p>Nuclei</p>
<p>Channel 2 – content</p>
<p>MitoSpy Green (Biolegend, USA), green</p>
<p>Channel 2 – biological entity</p>
<p>Mitochondria</p>
<p>Channel 3 – content</p>
<p>Flash Phalloidin Red (Biolegend, USA), orange</p>
<p>Channel 3 – biological entity</p>
<p>Actin</p>
<p>Image acquisition</p>
<p>Microscope model</p>
<p>Operetta CLS (PerkinElmer, USA)</p>
<p>Image data</p>
<p>Type</p>
<p>Raw and processed image in comparison</p>
<p>Magnification</p>
<p>20x air objective (NA = 0.8)</p>
<p>Excitation</p>
<p>Channel 1: 365 nm; Channel 2: 475 nm; Channel 3: 550 nm</p>
<p>Detection</p>
<p>Channel 1: 465 nm; Channel 2: 525 nm; Channel 3: 610 nm</p>
<p>Analysed data</p>
<p>Image processing method</p>
<p>Algorithm-based, unsupervised image segmentation with Harmony 4.9 analysis software (PerkinElmer, USA)</p>
<p>Submitted via NFDI4BIOIMAGE</p>
<p>Tags: Exclude From Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/16980217">https://zenodo.org/records/16980217</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.16980217">https://doi.org/10.5281/zenodo.16980217</a></p>
</section>
<hr class="docutils" />
<section id="reproducible-bio-image-analysis-using-python-napari-jupyter-and-ai">
<h2>Reproducible Bio-Image Analysis using Python, Napari, Jupyter and AI<a class="headerlink" href="#reproducible-bio-image-analysis-using-python-napari-jupyter-and-ai" title="Link to this heading">#</a></h2>
<p>Robert Haase</p>
<p>Published 2025-09-09</p>
<p>Licensed CC-BY-4.0</p>
<p>In this slide deck we learn how to write reproducible bio-image analysis code in Jupyter notebooks. Goal is not just to have code running elsewhere reproducibly, but also enabling others to understand workflows to enable them reproducing the analysis also in their mind and potentially other tools. Additionally we cover how to generate Jupyter notebooks from Napari and using artificial intelligence, namely bia-bob.</p>
<p>Tags: Nfdi4Bioimage, Bioimage Analysis, Include In Dalia</p>
<p><a class="reference external" href="https://zenodo.org/records/17085991">https://zenodo.org/records/17085991</a></p>
<p><a class="reference external" href="https://doi.org/10.5281/zenodo.17085991">https://doi.org/10.5281/zenodo.17085991</a></p>
</section>
<hr class="docutils" />
<section id="embo-bia-2025">
<h2>embo-bia-2025<a class="headerlink" href="#embo-bia-2025" title="Link to this heading">#</a></h2>
<p>Kevin Yamauchi</p>
<p>Published 2025-08-18T09:32:20+00:00</p>
<p>Licensed BSD-3-CLAUSE</p>
<p>Tags: Exclude From Dalia</p>
<p>Content type: Github Repository</p>
<p><a class="github reference external" href="https://github.com/kevinyamauchi/embo-bia-2025">kevinyamauchi/embo-bia-2025</a></p>
<hr class="docutils" />
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="readme.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">NFDI4BioImage Training Materials</p>
      </div>
    </a>
    <a class="right-next"
       href="contributing/index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">How to contribute</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-perspective-on-fair-and-scalable-access-to-large-image-data">A Perspective on FAIR and Scalable Access to Large Image Data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coba-nih-2024-bridging-imaging-users-to-imaging-analysis-survey-survey-data-with-preliminary-exploration">COBA-NIH/2024_Bridging_Imaging_Users_to_Imaging_Analysis_Survey: Survey data with preliminary exploration</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cloud-based-virtual-desktops-for-reproducible-research">Cloud-Based Virtual Desktops for Reproducible Research</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#development-fair-image-analysis-workflows-and-rdm-pipelines-in-galaxy">Development FAIR image analysis workflows and RDM pipelines in Galaxy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-analysis-in-healthcare-the-current-landscape-trends-and-collaborative-opportunities">Image Analysis in Healthcare - The Current Landscape, Trends, and Collaborative Opportunities</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linking-of-research-meta-data-in-omero-to-foster-fair-data-in-plasma-science">Linking of Research (Meta-)data in OMERO to Foster FAIR Data in Plasma Science</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-cover-2025">NFDI4BIOIMAGE Calendar Cover 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nfdi4bioimage-calendar-january-2025">NFDI4BIOIMAGE Calendar January 2025</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reproducible-bio-image-analysis-using-python-napari-jupyter-and-ai">Reproducible Bio-Image Analysis using Python, Napari, Jupyter and AI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#embo-bia-2025">embo-bia-2025</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Robert Haase, Clément Caporal,... and the NFDI4BioImage Initiative
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on 2025-09-17.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <p>
Copyright: Licensed <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">CC-BY 4.0</a> unless mentioned otherwise. 
Contributions and feedback are welcome.
</p>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>